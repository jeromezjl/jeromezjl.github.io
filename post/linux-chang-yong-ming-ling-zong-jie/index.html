<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="Jerome">
<meta name="description" content="Jerome&#39;s blog">
<meta name="theme-color" content="#343a40">
<title>【Linux】常用命令总结 | Jerome</title>
<link rel="shortcut icon" href="/favicon.ico?v=1711722264691">
<link rel="stylesheet" href="/media/css/gemini.css">
<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.loli.net/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/default.css"
  rel="stylesheet">

<link rel="stylesheet" href="/styles/main.css">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/media/js/jquery.js"></script>
<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>




<script>
  var _hmt = _hmt || [];
  (function () {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?912d7399b0bd888a157481e9409a2639";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>



  <meta name="description" content="【Linux】常用命令总结" />
  <meta name="keywords" content="Linux" />
</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="gemini">
  <header class="header  ">
    <div class="blog-header box-shadow-wrapper bg-color " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="brand">
              <span>Jerome</span>
            </a>  
          
        </div>
        
          <p class="subtitle">精于心，简于形</p>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-globe"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/archives" target="_self">
                  <i class="fa fa-globe"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/tags" target="_self">
                  <i class="fa fa-globe"></i> 标签
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/post/about" target="_self">
                  <i class="fa fa-globe"></i> 关于
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/post/tree" target="_self">
                  <i class="fa fa-globe"></i> 索引
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友链
                  
                </a>
              </li>
            
          
          
            <li id="fa_search" class="nav-item">
              <a href="javascript:void(0);">
                <i class="fa fa-search"></i> <span class="language" data-lan="search">搜索</span>
              </a>
            </li>
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout gemini ">
      <div class="section-layout-wrapper">
        

<div class="sidebar">
  
    <div class="sidebar-box box-shadow-wrapper bg-color right-motion" id="sidebar">
      
        <div class="post-list-sidebar">
          <div class="sidebar-title">
            <span id="tocSideBar" class="sidebar-title-item sidebar-title-active language" data-lan="index">文章目录</span>
            <span id="metaSideBar" class="sidebar-title-item language" data-lan="preview">站点概览</span>
          </div>
        </div>
      
      <div class="sidebar-body gemini" id="sidebar_body">
        
          
            <div class="post-side-meta" id="post_side_meta">
              
<div class="sidebar-wrapper box-shadow-wrapper bg-color">
  <div class="sidebar-item">
    <img class="site-author-image right-motion" src="/images/avatar.png"/>
    <p class="site-author-name">Jerome</p>
    
  </div>
  <div class="sidebar-item side-item-stat right-motion">
    <div class="sidebar-item-box">
      <a href="/archives/">
        
        <span class="site-item-stat-count">114</span>
        <span class="site-item-stat-name language" data-lan="article">文章</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">25</span>
        <span class="site-item-stat-name language" data-lan="tag">标签</span>
      </a>
    </div>
  </div>
  
    
  
  
    <div class="sidebar-item sidebar-item-social">
      <div class="social-item">
        
          
            <a href="https://github.com/jeromezjl">
              <i class="fa fa-github" title="Github"></i>
            </a>
          
            <a href="https://space.bilibili.com/430199065">
              <i class="fa fa-bold" title="b站"></i>
            </a>
          
            <a href="https://jeromezjl.github.io/post/wechat/">
              <i class="fa fa-wechat" title="Wechat"></i>
            </a>
          
            <a href="https://www.instagram.com/jeromezjl/">
              <i class="fa fa-instagram" title="Instagram"></i>
            </a>
          
            <a href="">
              <i class="fa fa-envelope-o" title="zhangjilong@bupt.edu.cn"></i>
            </a>
          
        
        
      </div>
    </div>
  



</div>
            </div>
            <div class="post-toc sidebar-body-active" id="post_toc" style="opacity: 1;">
              <div class="toc-box right-motion">
  <div class="toc-wrapper  auto"
    id="toc_wrapper">
    <ul class="markdownIt-TOC">
<li><a href="#%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C">文件操作</a></li>
<li><a href="#%E7%B3%BB%E7%BB%9F">系统</a></li>
<li><a href="#%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91">内核模块开发</a></li>
</ul>

  </div>
</div>

<script>

  let lastTop = 0, lList = [], hList = [], postBody, lastIndex = -1;
  let active = 'active-show', activeClass = 'active-current';
  let tocWrapper = document.querySelector('#toc_wrapper');
  let tocContent = tocWrapper.children[0];
  let autoNumber = tocWrapper && tocWrapper.classList.contains('auto-number');

  function addTocNumber(elem, deep) {
    if (!elem) {
      return;
    }
    let prop = elem.__proto__;

    if (prop === HTMLUListElement.prototype) {
      for (let i = 0; i < elem.children.length; i++) {
        addTocNumber(elem.children[i], deep + (i + 1) + '.');
      }
    } else if (prop === HTMLLIElement.prototype) {
      // 保存li元素
      if (elem.children[0] && elem.children[0].__proto__ === HTMLAnchorElement.prototype) {
        lList.push(elem);
      }
      for (let i = 0; i < elem.children.length; i++) {
        let cur = elem.children[i];
        if (cur.__proto__ === HTMLAnchorElement.prototype) {
          if (autoNumber) {
            cur.text = deep + ' ' + cur.text;
          }
        } else if (cur.__proto__ === HTMLUListElement.prototype) {
          addTocNumber(cur, deep);
        }
      }
    }
  }

  function removeParentActiveClass() {
    let parents = tocContent.querySelectorAll('.' + active)
    parents.forEach(function (elem) {
      elem.classList.remove(active);
    });
  }

  function addActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.add(activeClass);
    }
  }

  function removeActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.remove(activeClass);
    }
  }

  function addActiveLiElemment(elem, parent) {
    if (!elem || elem === parent) {
      return;
    } else {
      if (elem.__proto__ === HTMLLIElement.prototype) {
        elem.classList.add(active);
      }
      addActiveLiElemment(elem.parentElement, parent);
    }
  }

  function showToc() {
    if (tocWrapper) {
      postBody = document.querySelector('#post_body');
      for (let i = 0; i < postBody.children.length; i++) {
        if (postBody.children[i].__proto__ === HTMLHeadingElement.prototype) {
          hList.push(postBody.children[i]);
        }
      }
      if (tocWrapper.classList.contains('compress')) {
        tocContent.classList.add('closed');
      } else if (tocWrapper.classList.contains('no_compress')) {
        tocContent.classList.add('expanded');
      } else {
        if (hList.length > 10) {
          active = 'active-hidden'
          tocContent.classList.add('closed');
        } else {
          tocContent.classList.add('expanded');
        }
      }
    }
  }

  (function () {
    // 处理不是从#一级标题开始目录
    if (tocContent.children.length === 1 && tocContent.children[0].__proto__ === HTMLLIElement.prototype) {
      let con = tocContent.children[0].children[0];
      tocContent.innerHTML = con.innerHTML;
    }
    let markdownItTOC = document.querySelector('.markdownIt-TOC');
    let innerHeight = window.innerHeight;
    markdownItTOC.style = `max-height: ${innerHeight - 80 > 0 ? innerHeight - 80 : innerHeight}px`
    addTocNumber(tocContent, '');
  })();

  document.addEventListener('scroll', function (e) {
    if (lList.length <= 0) {
      return;
    }
    let scrollTop = document.scrollingElement.scrollTop + 10;
    let dir;

    if (lastTop - scrollTop > 0) {
      dir = 'up';
    } else {
      dir = 'down';
    }

    lastTop = scrollTop;
    if (scrollTop <= 0) {
      if (lastIndex >= 0 && lastIndex < hList.length) {
        lList[lastIndex].classList.remove(activeClass);
      }
      return;
    }

    let current = 0, hasFind = false;
    for (let i = 0; i < hList.length; i++) {
      if (hList[i].offsetTop > scrollTop) {
        current = i;
        hasFind = true;
        break;
      }
    }
    if (!hasFind && scrollTop > lList[lList.length - 1].offsetTop) {
      current = hList.length - 1;
    } else {
      current--;
    }
    if (dir === 'down') {
      if (current > lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex)
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    } else {
      if (current < lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex);
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    }
  });


  window.addEventListener('load', function () {
    showToc();
    document.querySelector('#sidebar').style = 'display: block;';
    tocWrapper.classList.add('toc-active');
    setTimeout(function () {
      if ("createEvent" in document) {
        let evt = document.createEvent("HTMLEvents");
        evt.initEvent("scroll", false, true);
        document.dispatchEvent(evt);
      }
      else {
        document.fireEvent("scroll");
      }
    }, 500)
  })

</script>
            </div>
          
        
      </div>
    </div>
  
</div>
<script>
  const SIDEBAR_TITLE_ACTIVE = 'sidebar-title-active';
  const SIDEBAR_BODY_ACTIVE = 'sidebar-body-active';
  const SLIDE_UP_IN = 'slide-up-in';

  let sidebar = document.querySelector('#sidebar'),
  tocSideBar = document.querySelector('#tocSideBar'),
  metaSideBar = document.querySelector('#metaSideBar'),
  postToc = document.querySelector('#post_toc'),
  postSiteMeta = document.querySelector('#post_side_meta'),
  sidebarTitle = document.querySelector('.sidebar-title'),
  sidebarBody = document.querySelector('#sidebar_body');

  tocSideBar && tocSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  metaSideBar && metaSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  function toggleSidebar(e) {
    let currentTitle = document.querySelector("."+SIDEBAR_TITLE_ACTIVE);
    if (currentTitle == e.srcElement) {
      return ;
    }
    let current, showElement, hideElement;
    if (e.srcElement == metaSideBar) {
      showElement = postSiteMeta;
      hideElement = postToc;
    } else if (e.srcElement == tocSideBar){
      showElement = postToc;
      hideElement = postSiteMeta;
    }
    currentTitle.classList.remove(SIDEBAR_TITLE_ACTIVE);
    e.srcElement.classList.add(SIDEBAR_TITLE_ACTIVE);

    jQuery.Velocity(hideElement, 'stop');
    jQuery.Velocity(hideElement, 'transition.slideUpOut', {
      display: 'none',
      duration: 200,
      complete: function () {
        jQuery.Velocity(showElement, 'transition.slideDownIn', {
          duration: 200
        });
      }
    })
    hideElement.classList.remove(SIDEBAR_BODY_ACTIVE);
    showElement.classList.add(SIDEBAR_BODY_ACTIVE);
  }

  postToc && postToc.addEventListener('transitionend', function() {
    this.classList.remove(SLIDE_UP_IN);
  });

  if (sidebarBody) {
    if (sidebarBody.classList.contains('pisces') || sidebarBody.classList.contains('gemini')) {
      let hasFix = false;
      let scrollEl = document.querySelector('.main-continer');
      let limitTop = document.querySelector('#nav_ul').children.length * 42 + 162;
      window.addEventListener('scroll', function(e) {
        if (document.scrollingElement.scrollTop >= limitTop) {
          if (!hasFix) {
            sidebar.classList.add('sidebar-fixed');
            hasFix = true;
          }
        } else {
          if (hasFix) {
            sidebar.classList.remove('sidebar-fixed');
            hasFix = false;
          }
        }
      });
    }
  }
  
</script>
        <div class="section-box box-shadow-wrapper">
          <div class="section bg-color post post-page">
            <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://jeromezjl.github.io/post/linux-chang-yong-ming-ling-zong-jie/"> 【Linux】常用命令总结 </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2023-03-08 20:06:46">2023-03-08</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">标签:</span>
       
      <a href="https://jeromezjl.github.io/tag/3w7kKXNiz/">
        <span>Linux</span>
      </a>
       
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span
        >2<span class="language" data-lan="minute"
          >分钟</span
        ></span
      >
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span
        >328<span class="pc-show language" data-lan="words"
          >字数</span
        ></span
      >
    </span>
    
  </div>
</section>

            <div class="post-body next-md-body" id="post_body">
              <h1 id="文件操作">文件操作</h1>
<p>打开文件：vi 文件名<br>
复制粘贴：Ctrl+shift+C；Ctrl+shift+V（在shell中使用）<br>
创建文件：$ &gt; test.txt<br>
通过文件名获取文件绝对路径：find ~ -name test.txt （其中，<sub>后必须有空格，且</sub>表示全局查找；若 find . -name test.txt 则是在当前文件夹下查找。）<br>
进入文件路径：cd ~/filename<br>
<a href="https://www.runoob.com/linux/linux-comm-mkdir.html">创建文件夹：mkdir -p dirname</a><br>
查看当前目录所有文件：ls<br>
pwd：获取当前目录的绝对路径<br>
按文件名删除文件：rm -f 文件名</p>
<h1 id="系统">系统</h1>
<p>切换到root用户：sudo -s<br>
输出内核版本、主机名、操作系统版本、CPU类型等信息：uname -a<br>
查看已安装的linux-image各版本：dpkg --get-selections | grep linux-image<br>
卸载内核：sudo apt-get remove linux-image-5.4.0-xx-generic<br>
运行该代码将版本后面带有deinstall的彻底卸载干净：sudo dpkg -P linux-image-5.4.0-84-generic<br>
输入 Ctrl+c 终止当前运行</p>
<h1 id="内核模块开发">内核模块开发</h1>
<p>查看已经存在的mod：lsmod<br>
删除mod：rmmod modname<br>
将编译好的mod加载进去：sudo insmod hello.ko<br>
查看内核日志，最后为新模块产生的日志：dmesg<br>
看最近的内核日志：dmesg | tail<br>
实时监视内核日志的变化，并输出最新的日志信息：tail -f /var/log/kern.log</p>

            </div>
            
              <div class="reward-btn">
                <div class="reward-btn-text">赞赏</div>
              </div>
            
            
              <div class="post-footer">
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong class="language" data-lan="author">本文作者：</strong>
      Jerome
    </li>
    <li class="post-copyright-link">
      <strong class="language" data-lan="link">本文链接：</strong>
      <a href="https://jeromezjl.github.io/post/linux-chang-yong-ming-ling-zong-jie/" title="【Linux】常用命令总结">https://jeromezjl.github.io/post/linux-chang-yong-ming-ling-zong-jie/</a>
    </li>
    <li class="post-copyright-license">
      <strong class="language" data-lan="copyright">版权声明： </strong>
      本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！
    </li>
  </ul>
  <div class="tags">
    
      <a href="https://jeromezjl.github.io/tag/3w7kKXNiz/"># Linux</a>
    
  </div>
  <div class="nav">
    <div class="nav-prev">
      
        <i class="fa fa-chevron-left"></i>
        <a class="nav-pc-next" title="【Linux】内核模块开发" href="https://jeromezjl.github.io/post/linux-nei-he-mo-kuai-kai-fa/">【Linux】内核模块开发</a class="nav-pc-next">
        <a class="nav-mobile-prev" title="【Linux】内核模块开发" href="https://jeromezjl.github.io/post/linux-nei-he-mo-kuai-kai-fa/">上一篇</a>
      
    </div>
    <div class="nav-next">
      
        <a class="nav-pc-next" title="C++查缺补漏" href="https://jeromezjl.github.io/post/ccha-que-bu-lou/">C++查缺补漏</a>
        <a class="nav-mobile-next" title="C++查缺补漏" href="https://jeromezjl.github.io/post/ccha-que-bu-lou/">下一篇</a>
        <i class="fa fa-chevron-right"></i>
      
    </div>
  </div>
</div>
            
            
  <script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<div id="vcomments" style="padding: 10px 0px 0px 0px"></div>

<style>
  .v .veditor {
    min-height: 10rem;
    background-image: url('');
    background-size: contain;
    background-repeat: no-repeat;
    background-position: right;
    background-color: rgba(255, 255, 255, 0);
    resize: none;
  }

  .v .vwrap {
    border: 1px solid #000 !important;
  }

  .v .vbtn {
    padding: .4rem 1.2rem !important;
    border-color: #fff !important;
    background-color: #49b1f5 !important;
    color: #fff !important;
    font-size: .7rem !important;
  }

  .v .vcards .vcard .vh .vmeta .vat {
    padding: 0 .8rem !important;
    border: 1px solid #00c4b6 !important;
    border-radius: 5px !important;
    color: #00c4b6 !important;
  }
</style>
<script>
  new Valine({
    el: '#vcomments',
    appId: '',
    appKey: '',
    avatar: '',
    placeholder: '',
    pageSize: '',
    lang: 'zh-cn',
    enableQQ: 'true' === 'false',
    visitor: 'true' === 'false',
    highlight: 'true' === 'true',
    avatarForce: 'true' === 'false',
    serverURLs: '',
		recordIP: 'true' === 'true',
  });
</script>

          </div>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <center id="runTimeBox">
      已运行:<span id="run_time"></span>
    </center>
    <span id="busuanzi_container_site_pv">浏览数:<span id="busuanzi_value_site_pv"></span> 次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">访客数:<span id="busuanzi_value_site_uv"></span> 人</span>

    <script>
      BirthDay = new Date('');
      if (BirthDay.getTime()) {
        function runTime() {
          str = "";
          today = new Date();
          timeold = today.getTime() - BirthDay.getTime();
          msPerDay = 24 * 60 * 60 * 1000;
          e_daysold = timeold / msPerDay;
          daysold = Math.floor(e_daysold);
          str += daysold + "天";
          return str;
        }
        setInterval(function () {
          $("#run_time").html(runTime());
        }, 1000);
      } else {
        document.querySelector('.footer').removeChild(document.querySelector('#runTimeBox'));
      }
    </script>
    <div class="poweredby">
      <a href="https://jeromezjl.github.io/post/shuo-du-ke-yi-shuo/" target="_blank">Jerome</a>
    </div>
  </footer>
  
    
        <div class="gemini back-to-top" id="back_to_top">
          <i class="fa fa-arrow-up"></i>
          
            <span class="scrollpercent"> <span id="back_to_top_text">0</span>% </span>
            
        </div>
        
          
            
              <div class="bg-img">
                <img src="https://tse1-mm.cn.bing.net/th/id/R-C.0b7b7f15b83e7326de9078d0998d5eac?rik=KDIsnoDnAZ%2b5mw&amp;riu=http%3a%2f%2fwww.obzhi.com%2fwp-content%2fuploads%2f2020%2f09%2fkejigan.jpg&amp;ehk=6nuckhqgEl%2fAyE7ZDxsZnTs1%2bLpurRBJEk6V%2fhbe1cw%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0" />
              </div>
              
                
                  
                        
</div>
<script>
  let sideBarOpen = "sidebar-open";
  let body = document.body;
  let back2Top = document.querySelector("#back_to_top"),
    back2TopText = document.querySelector("#back_to_top_text"),
    drawerBox = document.querySelector("#drawer_box"),
    rightSideBar = document.querySelector(".sidebar"),
    viewport = document.querySelector("body");

  function scrollAnimation(currentY, targetY) {
    let needScrollTop = targetY - currentY;
    let _currentY = currentY;
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10);
      _currentY += dist;
      window.scrollTo(_currentY, currentY);
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY);
      } else {
        window.scrollTo(_currentY, targetY);
      }
    }, 1);
  }

  back2Top.addEventListener("click", function (e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });

  window.addEventListener("scroll", function (e) {
    let percent =
      (document.scrollingElement.scrollTop /
        (document.scrollingElement.scrollHeight -
          document.scrollingElement.clientHeight)) *
      100;
    if (percent > 1 && !back2Top.classList.contains("back-top-active")) {
      back2Top.classList.add("back-top-active");
    }
    if (percent == 0) {
      back2Top.classList.remove("back-top-active");
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });

  let hasCacu = false;
  window.addEventListener("resize", function (e) {
    calcuHeight();
  });

  function calcuHeight() {
    // 动态调整站点概览高度
    if (
      (!hasCacu && back2Top.classList.contains("pisces")) ||
      back2Top.classList.contains("gemini")
    ) {
      let sideBar = document.querySelector(".sidebar");
      let navUl = document.querySelector("#site_nav");
      sideBar.style =
        "margin-top:" + (navUl.offsetHeight + navUl.offsetTop + 15) + "px;";
      hasCacu = true;
    }
  }
  calcuHeight();

  let open = false,
    MOTION_TIME = 300,
    RIGHT_MOVE_DIS = "320px";

  if (drawerBox) {
    let rightMotions = document.querySelectorAll(".right-motion");
    let right = drawerBox.classList.contains("right");

    let transitionDir = right
      ? "transition.slideRightIn"
      : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS,
      };
      closeProp = {
        paddingRight: "0px",
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS,
      };
      closeProp = {
        paddingLeft: "0px",
      };
    }

    drawerBox.onclick = function () {
      open = !open;
      jQuery.Velocity(rightSideBar, "stop");
      jQuery.Velocity(viewport, "stop");
      jQuery.Velocity(rightMotions, "stop");
      if (open) {
        jQuery.Velocity(
          rightSideBar,
          {
            width: RIGHT_MOVE_DIS,
          },
          {
            duration: MOTION_TIME,
            begin: function () {
              jQuery.Velocity(rightMotions, transitionDir, {});
            },
          }
        );
        jQuery.Velocity(viewport, openProp, {
          duration: MOTION_TIME,
        });
      } else {
        jQuery.Velocity(
          rightSideBar,
          {
            width: "0px",
          },
          {
            duration: MOTION_TIME,
            begin: function () {
              jQuery.Velocity(rightMotions, {
                opacity: 0,
              });
            },
          }
        );
        jQuery.Velocity(viewport, closeProp, {
          duration: MOTION_TIME,
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle("muse-line");
      }
      drawerBox.classList.toggle(sideBarOpen);
    };
  }

  // 链接跳转
  let newWindow = "true";
  if (newWindow === "true") {
    let links = document.querySelectorAll(".post-body a");
    links.forEach((item) => {
      if (!item.classList.contains("btn")) {
        item.setAttribute("target", "_blank");
      }
    });
  }

  let faSearch = document.querySelector("#fa_search");
  faSearch &&
    faSearch.addEventListener("click", function () {
      document.querySelector("#search_mask").style = "";
    });

  // 代码高亮
  hljs.initHighlightingOnLoad();

  // 离开当前页title变化
  var leaveTitle = "";
  var normal_title = document.title;
  if (leaveTitle) {
    document.addEventListener("visibilitychange", function () {
      if (document.visibilityState == "hidden") {
        normal_title = document.title;
        document.title = leaveTitle;
      } else {
        document.title = normal_title;
      }
    });
  }
</script>

<link rel="stylesheet" href="/media/css/jquery.fancybox.css" />
<script src="/media/js/jquery.fancybox.js"></script>

<script>
  let images = document.querySelectorAll(".section img");
  images.forEach((image) => {
    var parent = image.parentElement;
    var next = image.nextElementSibling;
    parent.removeChild(image);
    var aelem = document.createElement("a");
    aelem.href = image.src;
    aelem.dataset["fancybox"] = "images";
    aelem.dataset["rel"] = "fancybox-button";
    aelem.classList.add("fancybox");
    aelem.appendChild(image);
    parent.insertBefore(aelem, next);
  });
</script>
    <div class="reward-mask" style="display: none;">
  <div class="reward-relative">
    <span class="close" aria-hidden="true">x</span>
    <div class="reward-body">
      <h2>感谢您的支持，我会继续努力的!</h2>
      <div class="reward-img-box">
        <div style="position: relative; width: 140px; height: 140px;">
          
          
          
            <img id="wx" class="reward-img" src="\media\images\custom-wxImg.jpg" alt="赞赏码">
          
        </div>
      </div>
      <p class="reward-word">扫码打赏，你说多少就多少</p>
      <p class="reward-tip"> </p>
    </div>
    <div class="bottom">
      
      
      <div id="wxBtn" class="pay-text">
        微信支付
      </div>
      
    </div>
  </div>
</div>
<style>
  .reward-mask {
    position: fixed;
    z-index: 99999;
    top: 0;
    bottom: 0;
    left: 0;
    right: 0;
    background-color: #00000054;
  }

  .reward-relative {
    position: relative;
    width: 480px;
    text-align: center;
    margin: 0 auto;
    border-radius: 5px;
    background-color: #fff;
    top: 50%;
    margin-top: -205px;
  }

  .reward-relative .close {
    position: absolute;
    right: 10px;
    font-weight: normal;
    font-size: 16px;
    color: #929292;
  }

  .reward-body {
    padding: 40px 20px 20px;
  }

  .bottom {
    display: flex;
  }

  .reward-btn {
    text-align: center;
  }

  .reward-btn-text {
    display: inline-block;
    cursor: pointer;
    width: 60px;
    height: 60px;
    line-height: 60px;
    border-radius: 50%;
    background-color: #ff9734;
    color: #FFF;
    margin-top: 20px;
  }

  .pay-text {
    margin-top: 10px;
    padding: 10px;
    flex: 1;
    transition: all .2s linear;
  }

  .pay-text:hover {
    background-color: #a5a5a536;
  }

  .reward-body h2 {
    padding-top: 10px;
    text-align: center;
    color: #a3a3a3;
    font-size: 16px;
    font-weight: normal;
    margin: 0 0 20px;
  }

  .reward-body h2:after,
  .reward-body h2:before {
    font-family: Arial, Helvetica, sans-serif;
    background: 0 0;
    width: 0;
    height: 0;
    font-style: normal;
    color: #eee;
    font-size: 80px;
    position: absolute;
    top: 20px;
  }

  .reward-body h2:before {
    content: '\201c';
    left: 50px;
  }

  .reward-body h2:after {
    content: '\201d';
    right: 80px;
  }

  .reward-img-box {
    display: inline-block;
    padding: 10px;
    border: 6px solid #ea5f00;
    margin: 0 auto;
    border-radius: 3px;
    position: relative;
  }

  .reward-img {
    position: absolute;
    left: 0px;
    top: 0px;
    width: 100%;
    height: 100%;
  }

  @media (max-width: 767px) {
    .reward-relative {
      height: 100%;
      top: 0px;
      margin-top: 0;
      width: auto;
    }

    .reward-relative .bottom {
      flex-direction: column;
    }

    .reward-relative .pay-text {
      width: 80%;
      margin: 5px auto;
      border: 1px solid silver;
      padding: 6px;
      border-radius: 4px;
    }

    .reward-body h2:after {
      right: 40px;
    }

    .reward-body h2:after,
    .reward-body h2:before {
      font-size: 60px;
    }

    .reward-body h2:before {
      left: 20px;
    }
  }
</style>
<script>
  !function () {
    var mask = document.querySelector('.reward-mask');
    let close = document.querySelector('.reward-relative .close');
    let rewardBtn = document.querySelector('.reward-btn');

    let zfb = document.querySelector('#zfb'),
      wx = document.querySelector('#wx'),
      zfbBtn = document.querySelector('#zfbBtn'),
      wxBtn = document.querySelector('#wxBtn');

    if (zfbBtn && wxBtn) {
      zfbBtn.addEventListener('click', () => {
        jQuery.Velocity(zfb, 'transition.slideLeftIn', {
          duration: 400
        });
        jQuery.Velocity(wx, 'transition.slideRightOut', {
          display: 'none',
          duration: 400
        });
      });

      wxBtn.addEventListener('click', () => {
        jQuery.Velocity(wx, 'transition.slideRightIn', {
          duration: 400
        });
        jQuery.Velocity(zfb, 'transition.slideLeftOut', {
          display: 'none',
          duration: 400
        });
      });
    }

    rewardBtn.addEventListener('click', (e) => {
      jQuery.Velocity(mask, 'transition.slideDownIn', {
        duration: 400
      })
    });

    close.addEventListener('click', (e) => {
      e.preventDefault();
      jQuery.Velocity(mask, 'transition.slideUpOut', {
        duration: 400
      })
    })
  }()
</script>

  </div>
</body>

  <div class="search-mask" id="search_mask" style="display: none;">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input id="search" type="text" class="language" data-lan="search" placeholder="搜索">
      </div>
      <i id="close" class="fa fa-times-circle"></i>
    </div>
    <div class="stat-box">
      <span id="stat_count">0</span><span class="language" data-lan="stat">条相关条目，使用了</span><span id="stat_times">0</span><span class="language" data-lan="stat-time">毫秒</span>
      <hr>
    </div>
    <div class="result" id="result">
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/408-fu-shi/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/366839763&#34;&gt;计算机网络八股文背诵版&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/373966882&#34;&gt;操作系统八股文背诵版&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_43468008/article/details/129418769&#34;&gt;考研408 王道计算机考研 (初试/复试) 网课笔记总结&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/yinghui_yht/article/details/105443770&#34;&gt;计算机考研复试问题汇总（408+计算机前言知识）&lt;/a&gt;&lt;/p&gt;
">408复试</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/aienglish/"" data-c="
          &lt;ol&gt;
&lt;li&gt;Artificial General（通用） Intelligence (AGI) represents the hypothetical（假想） ability of an AI system to understand, learn, and apply knowledge across a wide range of tasks at a level of complexity comparable to human intelligence. Unlike narrow AI designed for specific tasks, AGI would possess the versatility and adaptability to perform any intellectual task that a human being can. This includes reasoning, problem-solving, abstract thinking, understanding natural language, and learning from experience. Achieving AGI is considered a monumental milestone in AI research, marking the advent of machines with human-like cognitive abilities.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;人工通用智能（AGI）代表了一个AI系统的假想能力，即理解、学习并应用知识去完成广泛的任务，这些任务的复杂度与人类智能相当。与为特定任务设计的狭义人工智能不同，AGI将拥有执行人类可以执行的任何智力任务的多功能性和适应性。这包括推理、解决问题、抽象思考、理解自然语言以及从经验中学习。实现AGI被认为是AI研究的一个重要里程碑，标志着具有类似人类认知能力的机器的到来。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Supervised learning is a machine learning approach where models are trained on labeled data, meaning each input example is paired with the correct output. The model learns by comparing its predictions to the actual outputs during training, adjusting until it can accurately predict outcomes for unseen data. Unsupervised learning, conversely, involves training models on data without explicit instructions on what to predict. The model identifies patterns and structures within the data autonomously. Supervised learning is typically used for classification and regression tasks, while unsupervised learning is used for clustering, dimensionality reduction, and association rule learning.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;监督学习是一种机器学习方法，其中模型是在标注数据上训练的，这意味着每个输入实例都与正确的输出配对。模型通过在训练期间将其预测与实际输出进行比较来学习，并调整直到它能够准确预测未见数据的结果。相反，无监督学习涉及在没有关于应预测什么的明确指导的数据上训练模型。模型自主地识别数据中的模式和结构。监督学习通常用于分类和回归任务，而无监督学习用于聚类、降维和关联规则学习。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;A Multilayer Perception (MLP) is a class of feedforward artificial neural network (ANN) that consists of at least three layers of nodes: an input layer, one or more hidden layers, and an output layer. Each node, except for input nodes, uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its architecture of multiple layers and nonlinear processing enables complex pattern recognition and decision-making, making it foundational to deep learning. Deep learning involves networks with many layers (deep architectures) that can learn hierarchical representations of data, significantly advancing capabilities in AI research and applications.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;多层感知机（MLP）是一种前馈人工神经网络（ANN），至少包括三层节点：一个输入层、一个或多个隐藏层以及一个输出层。除输入节点外，每个节点都使用非线性激活函数。MLP利用一种称为反向传播的监督学习技术进行训练。它的多层结构和非线性处理使得复杂的模式识别和决策成为可能，是深度学习的基础。深度学习涉及有许多层（深度架构）的网络，这些网络可以学习数据的层次化表示，显著推进了AI研究和应用能力。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Backpropagation is a cornerstone algorithm for training neural networks, particularly in deep learning. It operates by propagating the error backward from the output layer to the input layer, allowing the algorithm to adjust the weights of connections in order to minimize the error in predictions. This process involves two key phases: forward pass, where input data is fed through the network to generate output predictions, and backward pass, where the gradient of the loss function is computed with respect to each weight by the chain rule, enabling the network to learn from errors systematically. This iterative adjustment refines the model&#39;s accuracy over time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;反向传播是训练神经网络，尤其是在深度学习中的基石算法。它通过将错误从输出层反向传播到输入层来运作，允许算法调整连接权重以最小化预测中的错误。这个过程涉及两个关键阶段：前向传播，输入数据通过网络生成输出预测；反向传播，利用链式规则计算损失函数的梯度相对于每个权重，使网络能够系统地从错误中学习。这种迭代调整随着时间提高了模型的准确性。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Overfitting is a common problem in machine learning, where a model learns the training data too well, including its noise and outliers, rather than generalizing from the pattern it should learn. This results in high accuracy on training data but poor performance on new, unseen data. Essentially, the model becomes overly complex, capturing spurious correlations that do not exist in real-world data. To combat overfitting, techniques such as cross-validation, regularization, and pruning can be used, along with ensuring a sufficient amount of diverse training data. Overfitting highlights the delicate balance between model complexity and its generalization ability.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;过拟合是机器学习中的一个常见问题，其中模型过于完美地学习了训练数据，包括其噪音和异常值，而不是从它应该学习的模式中泛化。这导致在训练数据上的高准确度但在新的、未见过的数据上的性能差。本质上，模型变得过于复杂，捕捉到了在现实世界数据中不存在的假相关性。为了对抗过拟合，可以使用交叉验证、正则化和剪枝等技术，同时确保有足够数量的多样化训练数据。过拟合突出了模型复杂度和其泛化能力之间微妙的平衡。&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;A Convolutional Neural Network (CNN) is a class of deep learning algorithm that can take in an input image, assign importance (learnable weights and biases) to various aspects or objects in the image, and differentiate from one another. The preprocessing required in a CNN is much lower compared to other classification algorithms. The architecture of a CNN is analogous to that of the connectivity pattern of neurons in the human brain and was inspired by the organization of the visual cortex. CNNs are primarily used in image recognition, image classification, object detection, and similar tasks, leveraging their ability to learn spatial hierarchies of features.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;卷积神经网络（CNN）是一种深度学习算法，可以接受输入图像，为图像中的不同方面或对象分配重要性（可学习的权重和偏差），并且彼此区分开来。与其他分类算法相比，CNN所需的预处理要少得多。CNN的架构类似于人脑神经元的连接模式，并且受到视觉皮层组织的启发。CNN主要用于图像识别、图像分类、对象检测以及类似任务，利用它们学习特征的空间层次结构的能力。&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;Deep Reinforcement Learning (DRL) combines deep learning and reinforcement learning principles to create systems that can learn to make decisions. Deep learning processes vast amounts of data through neural networks, enabling feature detection and recognition. Reinforcement learning, on the other hand, is about agents learning to make actions in an environment to achieve a goal, guided by rewards or penalties. DRL utilizes deep neural networks to interpret complex, high-dimensional inputs, allowing the agent to learn optimal actions from its experiences, without explicit programming. This approach has led to significant breakthroughs, such as mastering complex games and improving decision-making in robotics and autonomous vehicles.**&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;深度强化学习（DRL）结合了深度学习和强化学习原理，创造了能够学习做出决策的系统。深度学习通过神经网络处理大量数据，使特征检测和识别成为可能。另一方面，强化学习是关于代理在环境中学习采取行动以实现目标，由奖励或惩罚指导。DRL利用深度神经网络来解释复杂的、高维输入，允许代理从经验中学习最优行动，无需显式编程。这种方法已经在如掌握复杂游戏和改善机器人与自动驾驶车辆的决策制定方面取得了重大突破。&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;In deep learning, activation functions are crucial for neural networks to learn complex patterns. They introduce non-linearity into the network, allowing it to model complicated relationships between inputs and outputs that linear equations cannot. Without activation functions, a neural network, regardless of its depth, would behave like a single-layer perceptron, only capable of solving linear problems. Activation functions, such as Sigmoid, ReLU, and Tanh, help decide whether a neuron should be activated or not, determining the output of neural networks based on input features. This enables deep learning models to tackle non-linear problems, like image recognition and natural language processing, effectively.**&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在深度学习中，激活函数对于神经网络学习复杂模式至关重要。它们为网络引入非线性，使其能够模拟输入与输出之间的复杂关系，而这是线性方程无法做到的。没有激活函数，无论神经网络的深度如何，都会表现得像一个只能解决线性问题的单层感知机。激活函数，如Sigmoid、ReLU和Tanh，帮助决定一个神经元是否应该被激活，决定了神经网络基于输入特征的输出。这使得深度学习模型能够有效地处理非线性问题，如图像识别和自然语言处理。&lt;/p&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;A generative model in artificial intelligence is an approach used to automatically generate new data instances that resemble a given set of data. Unlike discriminative models, which focus on determining the boundary between different classes, generative models learn the underlying distribution of input data, enabling them to produce new examples that could plausibly come from the original dataset. This ability makes generative models especially valuable in tasks such as image and text generation, data augmentation, and unsupervised learning. Popular examples of generative models include Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), which have been applied in creating realistic images, text-to-image synthesis, and more.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在人工智能中，生成模型是一种用于自动生成类似于给定数据集的新数据实例的方法。与专注于确定不同类别之间边界的判别模型不同，生成模型学习输入数据的底层分布，使它们能够生成可能来自原始数据集的新例子。这种能力使得生成模型在图像和文本生成、数据增强和无监督学习等任务中特别有价值。流行的生成模型例子包括生成对抗网络（GANs）和变分自编码器（VAEs），这些已被应用于创造逼真的图像、文本到图像的合成等。&lt;/p&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;Transformer is a groundbreaking architecture in deep learning, introduced for dealing with sequential data, notably in natural language processing (NLP). Unlike its predecessors that relied on recurrence or convolutions, the transformer utilizes attention mechanisms to weigh the significance of different words within the input data. This allows it to capture complex dependencies and relationships within the data more effectively. The architecture comprises an encoder to process the input and a decoder for output generation. Transformers have led to significant advancements in tasks such as machine translation, text summarization, and language understanding, serving as the foundation for models like BERT and GPT.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Transformer 是深度学习中的一种开创性架构，专门用于处理顺序数据，特别是在自然语言处理（NLP）中。与依赖于递归或卷积的前身不同，Transformer 利用注意力机制来权衡输入数据中不同单词的重要性。这使它能够更有效地捕捉数据内的复杂依赖关系。该架构包括一个编码器来处理输入和一个解码器来生成输出。Transformer 在机器翻译、文本摘要和语言理解等任务上取得了重大进展，为像BERT和GPT这样的模型提供了基础。&lt;/p&gt;
">AIEnglish</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/1/"" data-c="
          &lt;p&gt;我从来不拘泥一种音乐风格，因为我觉得音乐是和情绪密切挂钩的。兴奋的时候喜欢听快乐的歌，平静的时候喜欢听舒缓的爵士乐，比如阳光温暖的午后，浮躁的时候听古典，心情便会平静下来，很治愈。好久没听古典了，说实话，好久也心情欣赏音乐了。今天听了古典，才发现救赎之道自在其中。&lt;/p&gt;
">1</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/fu-shi-xiang-mu/"" data-c="
          &lt;h1 id=&#34;gan&#34;&gt;GAN&lt;/h1&gt;
&lt;p&gt;使用 CIFAR-10 数据集，包含动物和交通工具的图片&lt;br&gt;
生成器和判别器都使用 CNN&lt;br&gt;
生成器：四层卷积，中间用 ReLU，最后用 Tanh&lt;br&gt;
判别器：四层卷积，中间用 ReLU，最后用 Sigmoid&lt;br&gt;
使用交叉熵损失函数&lt;br&gt;
先训练判别器，给判别器真实图片和假图片，分别带有标签，来更新判别器参数&lt;br&gt;
再训练生成器，让生成器生成图片，让判别器判断，更新生成器的参数，使判别器认为生成的是真实图片&lt;/p&gt;
&lt;h1 id=&#34;cnn-人脸识别&#34;&gt;CNN 人脸识别&lt;/h1&gt;
&lt;p&gt;首先进行三分类，小组同学三人，每人录制一个全方位的不同角度的面部视频，&lt;br&gt;
使用openCV对视频进行分割，获得3000张左右不同角度、不同光照的人脸图片&lt;br&gt;
CNN：使用alexnet架构，5层卷积，3层最大池化，使用 ReLU 激活，最后 softmax&lt;/p&gt;
&lt;h1 id=&#34;手写数字&#34;&gt;手写数字&lt;/h1&gt;
&lt;p&gt;LeNet-5&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710506415759.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
使用MNIST：28x28，第一层 padding=2，输入网络是 32x32&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输入层（Input Layer）&lt;/strong&gt;：接受的输入图像大小通常是32x32像素。这是因为网络设计时考虑到数字的实际大小和希望网络能够捕捉到重要的特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第一卷积层（C1）&lt;/strong&gt;：这一层使用6个卷积核（或滤波器），每个大小为5x5，步长为1，无填充（padding），输出的特征图（feature map）大小为28x28x6。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第一下采样层（S2）&lt;/strong&gt;：也称为池化层，使用2x2的窗口进行平均池化，步长为2，将特征图的维度降低到14x14x6。这一步骤有助于减少数据的空间尺寸，从而减少计算量和控制过拟合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二卷积层（C3）&lt;/strong&gt;：这一层有16个卷积核，每个大小为5x5，处理上一层的输出，产生10x10x16的特征图。这一层的设计允许网络学习更高级的特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二下采样层（S4）&lt;/strong&gt;：同样采用2x2平均池化，步长为2，输出的维度为5x5x16。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;全连接层（F5）&lt;/strong&gt;：这一层有120个节点，它将前一层的输出展平（flatten）并全连接到这120个节点上。这一层开始将学到的特征组合成更高级别的模式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二全连接层（F6）&lt;/strong&gt;：这一层有84个节点，进一步处理特征，为最终的分类决策做准备。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输出层（Output Layer）&lt;/strong&gt;：最后是一个具有10个节点的输出层，对应于10个数字类（0到9）。这一层通常使用softmax激活函数，将网络的输出转换为概率分布。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两层卷积两层池化，卷积池化之间使用 Sigmoid 激活，最后使用全连接层映射到 10 个分类&lt;/p&gt;
&lt;h1 id=&#34;光度立体法&#34;&gt;光度立体法&lt;/h1&gt;
&lt;p&gt;对要检测物体在不同方向的光照条件下进行多次拍照。每次改变的只有光源的位置，确保光源的强度和颜色保持一致。&lt;br&gt;
结合不同光照下的像素亮度值，使用最小二乘法计算每个像素点处的表面法向量。用法向量重构三维物体&lt;/p&gt;
&lt;h1 id=&#34;sift和词袋模型图片分类&#34;&gt;SIFT和词袋模型图片分类&lt;/h1&gt;
&lt;p&gt;使用 15-Scene 数据集，包含 15 种不同类型的场景，例如办公室、厨房、卧室、客厅、乡村、海滩等。&lt;br&gt;
共4400张左右，7比3的比例来划分训练集和测试集&lt;/p&gt;
&lt;p&gt;原理&lt;br&gt;
SIFT对每张图片生成不同个数的特征描述向量，将这些向量输入kmeans中，聚为300类，即构建了大小为300的视觉词汇表&lt;br&gt;
使用bow对图像编码：&lt;br&gt;
对于每张图像，将其SIFT特征向量与视觉词汇表中的词汇进行比较，找出每个特征向量最接近的视觉词。然后，为每张图像创建一个长度为k的向量（即BoW向量），其中每个元素记录了对应视觉词在该图像中出现的频率。&lt;br&gt;
将图向量输入 svm，一对多将图片分为15类&lt;/p&gt;
&lt;h1 id=&#34;roberta-问答系统&#34;&gt;RoBERTa 问答系统&lt;/h1&gt;
&lt;p&gt;SQuAD 数据集是斯坦福大学开发的一个流行的问答数据集，广泛用于自然语言处理中的机器阅读理解研究。SQuAD挑战模型根据给定的段落文本来回答问题。这些段落来自维基百科的文章，问题则是由人工撰写的。SQuAD的目标是推进计算机对自然语言的理解，特别是在问答系统的开发上。&lt;/p&gt;
&lt;p&gt;使用transformer中预训练的 RoBERTa&lt;/p&gt;
&lt;h1 id=&#34;kcf目标跟踪&#34;&gt;KCF目标跟踪&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;原理&lt;/code&gt;&lt;br&gt;
利用循环矩阵的特性来训练一个分类器，这个分类器用于区分目标和背景。它是基于前一帧的目标位置来预测当前帧的目标位置。这种方法允许算法在每一帧中快速更新模型，以适应目标的运动和外观的变化。&lt;/p&gt;
&lt;p&gt;相关滤波、循环矩阵、快速傅里叶变换、核技巧&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用循环矩阵对目标进行平移，生成训练样本（数据增强），训练一个能检测目标位置的相关滤波器&lt;/li&gt;
&lt;li&gt;使用相关滤波器，对连续视频帧中不同位置的候选区滤波并评分，得分最高的位置是目标的当前位置&lt;/li&gt;
&lt;li&gt;快速傅里叶变换被用来加速相关滤波的计算。通过将图像和滤波器都转换到频域，点乘操作可以用来替代复杂的卷积操作，从而显著提高算法的计算效率。&lt;/li&gt;
&lt;li&gt;通过选择合适的核函数（如高斯核），算法能够在高维特征空间中更好地区分目标和背景，即使目标的外观发生了较大变化。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;步骤&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;初始化&lt;/strong&gt;：在视频的第一帧中，在视频中选定一个框，KCF算法利用这个初始框来提取目标的特征。这些特征包括原始像素值、颜色直方图、特征信息等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;训练分类器&lt;/strong&gt;：用循环矩阵构建训练集，使得可以高效地利用所有平移版本的训练样本，训练滤波器找，到最佳的滤波器系数。这个过程中还可以通过引入核技巧来处理非线性特征映射。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;检测&lt;/strong&gt;：不断读取视频帧，在随后的每一帧中，KCF算法首先在目标的预期位置附近提取特征，然后使用之前训练的分类器（滤波器）对这些位置进行评分，以判断目标最可能的新位置。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模型更新&lt;/strong&gt;：通过设置一个学习率，使滤波器在更新位置的过程中在旧的信息基础上更新模型，来保证对新变化的适应性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;循环&lt;/strong&gt;：步骤3和步骤4在视频的每一帧中重复执行，以此实现对目标的连续跟踪。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;bpe&#34;&gt;BPE&lt;/h1&gt;
&lt;h1 id=&#34;kaggle-titanic&#34;&gt;kaggle Titanic&lt;/h1&gt;
&lt;p&gt;以不同乘客特征作为输入，判断是否死亡&lt;br&gt;
下载 train.csv、test.csv&lt;br&gt;
读取数据，展示中位数、众数，判断缺失值个数，选择是填充还是删除&lt;br&gt;
分析各个特征之间的关系，删除无用的，如果有效果相似的保留更好的，或者进行合并&lt;br&gt;
使用 MLP、随机森林、SVM、决策树 等模型对数据进行分类&lt;br&gt;
精度达到百分之九十左右&lt;/p&gt;
&lt;h1 id=&#34;linux-文件流&#34;&gt;Linux 文件流&lt;/h1&gt;
&lt;p&gt;记录一个pid或者prog进程访问了哪些文件和IP地址，记录file被哪些进程访问，列出进程的PID、程序名、日期时间、访问模式。展示进程之间的父子关系，记录CPU和内存的使用情况&lt;/p&gt;
">复试项目</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ba-gu-wen/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/366839763&#34;&gt;计算机网络八股文背诵版&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/373966882&#34;&gt;操作系统八股文背诵版&lt;/a&gt;&lt;/p&gt;
">八股文</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/dl-tu-shen-jing-wang-luo/"" data-c="
          &lt;p&gt;图神经网络（Graph Neural Networks，GNNs）是一类专门处理图结构数据的神经网络。在图结构数据中，数据以图的形式表示，由节点（nodes）和边（edges）组成，非常适合描述物体（或实体）及其间的复杂关系。图神经网络通过直接在图上进行操作，能够有效地捕捉这种结构信息，因此在社交网络分析、推荐系统、蛋白质结构预测、化学分子建模等领域得到了广泛应用。&lt;/p&gt;
&lt;h3 id=&#34;核心思想&#34;&gt;核心思想&lt;/h3&gt;
&lt;p&gt;GNN的核心思想是节点表示的更新，这通过聚合来自邻居节点的信息来实现。每个节点的表示都是通过考虑其邻居节点的特征（以及可能的边的特征）进行更新的，这个过程可以迭代进行，直到达到一个稳定状态或者预定的迭代次数。这种信息的聚合方式使得每个节点能够捕捉到其在图中的局部结构信息。&lt;/p&gt;
&lt;h3 id=&#34;关键组件&#34;&gt;关键组件&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;节点表示&lt;/strong&gt;：GNN的起点是节点的特征表示，这可以是节点的初始属性，也可以是节点的嵌入向量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;聚合函数&lt;/strong&gt;：用于聚合邻居节点信息的函数，这一步是GNN的核心。不同的GNN变体（如GCN、GAT等）在聚合函数的选择和设计上有所不同。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更新函数&lt;/strong&gt;：用于更新节点表示的函数。在每一次迭代中，节点的表示都会根据聚合的邻居信息进行更新。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;gnn的变体&#34;&gt;GNN的变体&lt;/h3&gt;
&lt;p&gt;GNN有多种变体，主要包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;图卷积网络（Graph Convolutional Networks, GCNs）&lt;/strong&gt;：通过将卷积的概念推广到图上，对节点的特征进行聚合，从而更新节点的状态。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图注意力网络（Graph Attention Networks, GATs）&lt;/strong&gt;：引入了注意力机制来动态地确定在聚合邻居节点信息时每个邻居的重要性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图自编码器（Graph Autoencoders, GAEs）&lt;/strong&gt;：用于学习图数据的低维表示，通常用于无监督学习任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图生成网络（Graph Generative Networks, GGNs）&lt;/strong&gt;：能够生成新的图结构数据，用于药物设计、蛋白质设计等领域。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用&#34;&gt;应用&lt;/h3&gt;
&lt;p&gt;GNN在多个领域都有广泛应用，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;社交网络分析&lt;/strong&gt;：通过分析社交网络中个体的关系图，进行好友推荐、信息传播分析等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推荐系统&lt;/strong&gt;：利用用户和物品之间的复杂关系进行更精准的推荐。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生物信息学&lt;/strong&gt;：在蛋白质结构预测、基因表达数据分析等领域有着重要应用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;化学和材料科学&lt;/strong&gt;：用于预测分子的性质、设计新的化合物等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GNN由于能够直接在图结构数据上操作，捕捉复杂的关系和依赖，因此在处理此类数据时比传统的神经网络模型有着明显的优势。随着研究的深入和技术的发展，GNN在更多领域的应用也在不断拓展。&lt;/p&gt;
">【DL】图神经网络</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ai-mian-shi/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/aienglish/&#34;&gt;AIenglish&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/fu-shi-ying-yu/&#34;&gt;复试英语&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/fu-shi-xiang-mu/&#34;&gt;复试项目&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;ai&#34;&gt;AI&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;请简要解释分类和回归的区别。&lt;br&gt;
分类输出离散的类别，回归输出连续的值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;您能列举一些常用的分类算法吗？请简要说明它们的工作原理。&lt;br&gt;
逻辑回归、决策树、随机森林、SVM、KNN、朴素贝叶斯、梯度提升决策树 (Gradient Boosted Decision Trees, GBDT)、CNN等&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同样地，您能列举一些常用的回归算法吗？请简要说明它们的工作原理。&lt;br&gt;
线性回归、岭回归、SVM、KNN、SGD、贝叶斯、高斯过程&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;既可以用于分类又可以回归的算法？&lt;br&gt;
决策树、随机森林、SVM、KNN、梯度提升决策树 (Gradient Boosted Decision Trees, GBDT)、CNN等&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在分类问题中，如何评估模型的性能？您能解释准确率、召回率、F1分数等指标吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在回归问题中，如何评估模型的性能？您能解释均方误差、均方根误差、决定系数等指标吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;过拟合和欠拟合是什么？如何避免这两种情况？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在分类或回归任务中，如何处理不平衡数据集？&lt;br&gt;
处理不平衡数据集是机器学习中的一个常见问题，特别是在分类任务中。不平衡数据集指的是数据集中不同类别的样本数量差异很大。这可能会导致模型对多数类别过拟合，而忽略少数类别。以下是一些常用的方法来处理不平衡数据集：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;1-重新采样技术&#34;&gt;1. &lt;strong&gt;重新采样技术&lt;/strong&gt;:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;过采样少数类&lt;/strong&gt;: 通过复制少数类样本或通过生成类似样本的方法（如SMOTE - 合成少数过采样技术）来增加少数类样本的数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;欠采样多数类&lt;/strong&gt;: 减少多数类样本的数量，以使多数类和少数类的样本数量大致相同。这可能导致信息丢失，应谨慎使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-修改损失函数&#34;&gt;2. &lt;strong&gt;修改损失函数&lt;/strong&gt;:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;为不同类别的样本引入不同的权重，使得模型在训练过程中更加关注少数类。这可以通过修改损失函数来实现，使得少数类样本的错误分类的代价更高。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-使用集成方法&#34;&gt;3. &lt;strong&gt;使用集成方法&lt;/strong&gt;:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;使用如随机森林、梯度提升树（GBT）等集成学习方法可以部分缓解不平衡数据带来的问题，因为它们通过构建多个模型并结合它们的预测结果来提高性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-选择合适的评估指标&#34;&gt;4. &lt;strong&gt;选择合适的评估指标&lt;/strong&gt;:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在不平衡数据集上，准确度不再是一个好的性能指标。应该使用混淆矩阵、精确度、召回率、F1分数、ROC-AUC曲线等更复杂的指标来评估模型性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-人工合成数据生成&#34;&gt;5. &lt;strong&gt;人工合成数据生成&lt;/strong&gt;:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;使用算法如SMOTE（合成少数过采样技术）或ADASYN（自适应合成采样方法）等来合成新的少数类样本，以解决不平衡问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-使用专门针对不平衡数据设计的算法&#34;&gt;6. &lt;strong&gt;使用专门针对不平衡数据设计的算法&lt;/strong&gt;:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一些算法如代价敏感学习（Cost-sensitive Learning）和异常检测算法在设计时考虑了不平衡数据的特点，可以直接应用于这类问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-数据层面的策略&#34;&gt;7. &lt;strong&gt;数据层面的策略&lt;/strong&gt;:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;收集更多数据，尤其是少数类的数据，有助于减少数据不平衡的问题，虽然这在实际中并不总是可行的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;选择哪种方法取决于具体问题、数据集的特性以及可用资源。在实践中，经常需要尝试多种方法，并结合问题的具体情况来确定最有效的策略。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;请解释特征选择和特征工程的重要性。&lt;/li&gt;
&lt;li&gt;在机器学习中，如何处理缺失数据和异常值？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;人工智能与大数据的区别和联系&lt;/strong&gt;&lt;br&gt;
AI：通过各种算法和技术实现机器模拟人类智能&lt;br&gt;
大数据：从大量的数据中提取有价值的信息，它包括数据采集、存储、管理和分析的技术，可以用传统机器学习算法进行处理。大量数据也可以被应用于模型的训练，实现AI&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;反向传播的过程&lt;/strong&gt;&lt;br&gt;
反向传播是神经网络中最小化损失函数的一种技术，通过计算损失函数的梯度来更新网络参数，从而逐步逼近损失函数的最小值。&lt;br&gt;
损失函数对网络中的每一项使用链式法则进行梯度计算，然后使用参数原值减去学习率乘以梯度，更新参数值。更新的参数值更接近使损失函数最小的值&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CNN中池化的作用&lt;/strong&gt;&lt;br&gt;
筛选出卷积得到的特征图中最有用的特征，一般使用最大池化或平均值池化，最大池化就是选择一定区域内的最大值作为该区域的代表，平均池化就是求一定区域内的平均值作为该区域的代表。池化后可以减小特征图的尺寸，降低特征维度，防止过拟合。&lt;br&gt;
增大网络中深层神经元的感受野，让深层神经元也能捕捉到更大范围的特征。提高特征不变性，比如最大池化提取了最主要的特征，在一定的缩放、平移下也能被检测到&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常用的损失函数以及对应的任务&lt;/strong&gt;&lt;br&gt;
分类：交叉熵、Hinge Loss&lt;br&gt;
回归：MSE（L2 Loss）、MAE（L1 Loss）、RMSE、Huber Loss&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有监督学习和无监督学习的区别&lt;/strong&gt;&lt;br&gt;
主要区别就是训练数据是否有标签。有监督使用带标签的数据，用标签监督模型对数据进行学习。每个训练样本都是一个输入/输出对，模型的目标是学习输入到输出的映射。例如分类、回归等&lt;br&gt;
无监督学习是模型自主在无标签的数据集上进行学习，自主学习到一些数据的内部特征。常见的任务比如聚类、降维&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常用的图像增强技术有什么&lt;/strong&gt;&lt;br&gt;
对图像进行几何变换，如旋转、翻转、平移、缩放、仿射变换；进行颜色变换，如饱和度、亮度、对比度；注入噪声，如高斯噪声、椒盐噪声；进行模糊处理，如高斯模糊、中值滤波；随即擦除、尺度变换&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;灰度图像是什么？有什么用？&lt;/strong&gt;&lt;br&gt;
每个像素仅表示亮度信息，不包含颜色信息。在灰度图像中，像素值通常范围从0到255，其中0代表黑色，255代表白色，而介于两者之间的值表示不同的灰度级别。&lt;br&gt;
作用：减少计算复杂性；有些任务不需要彩色图像，如边缘检测、图像分割、纹理分析&lt;/p&gt;
&lt;h1 id=&#34;数据结构&#34;&gt;数据结构&lt;/h1&gt;
&lt;p&gt;数据结构：按照某种逻辑关系组织在一起的数据，按一定储存方式储存在计算机存储器中，并在这些数据上定义了一组运算的集合&lt;br&gt;
数据结构包括：&lt;br&gt;
逻辑结构（集合、线性结构、树结构、图结构）&lt;br&gt;
物理结构、存储结构（顺序存储、链式存储）&lt;br&gt;
对数的操作和运算&lt;/p&gt;
&lt;p&gt;算法：解题方法。从计算机角度看：若干条指令组成的有穷序列&lt;br&gt;
算法特性：&lt;br&gt;
输入、输出、有穷性、可行性、确定性&lt;/p&gt;
&lt;p&gt;好的算法还应具备：&lt;br&gt;
健壮性/鲁棒性、高效性、可读性&lt;/p&gt;
&lt;h2 id=&#34;线性表&#34;&gt;线性表&lt;/h2&gt;
&lt;p&gt;栈：后进先出&lt;br&gt;
队列：先进先出&lt;/p&gt;
&lt;p&gt;栈顶指针 top 初始化为 -1，为 -1 时为空，为 stacksize-1 时为满&lt;br&gt;
栈的操作：入栈、出栈、取栈顶元素、判栈空、置空栈&lt;br&gt;
应用：符号匹配，递归问题&lt;/p&gt;
&lt;p&gt;用栈递归：&lt;br&gt;
当递归函数被调用时，每次将当前函数的状态（包括局部变量和返回地址）压入栈。直到进入最底层的递归，执行最底层的代码逻辑，然后之前压入栈的状态会依次弹出，并按照返回地址继续执行每个函数的剩余代码，直到最初的函数调用返回。&lt;/p&gt;
&lt;p&gt;循环队列初始化 front=rear，front 永远指向队列元素的前一个元素（空值）&lt;br&gt;
判满：(rear+1)%size==front&lt;br&gt;
判空：front=rear（初始化条件，初始就是空的）&lt;br&gt;
队长：(rear-front+size)%size&lt;br&gt;
应用：计算机内存管理（先来先服务）、广度优先搜索&lt;/p&gt;
&lt;p&gt;稀疏矩阵压缩方法：三元组表（把每个非零元素用三组数据表示，分别是 行号、列号、值）、十字链表&lt;/p&gt;
&lt;p&gt;串的模式匹配（找到子串的位置）&lt;br&gt;
BP：朴素匹配，一位位对照全体字符串，直到完全匹配&lt;br&gt;
KMP：先求 next 数组，保存了遇到哪个字母，将子串下标回溯到哪里。不需要回溯主串下标&lt;/p&gt;
&lt;h2 id=&#34;树&#34;&gt;树&lt;/h2&gt;
&lt;p&gt;树的度：一棵树中度最大结点的度&lt;br&gt;
树中的结点数等于所有结点度数之和+1&lt;/p&gt;
&lt;p&gt;顺序存储：左孩子 2i 右孩子 2i+1&lt;br&gt;
二叉链表：指向左右孩子&lt;br&gt;
三叉链表：增加一个指向双亲的指针&lt;/p&gt;
&lt;p&gt;前序 根左右&lt;br&gt;
中序 左根右&lt;br&gt;
后序 左右根&lt;br&gt;
层序 使用队列&lt;/p&gt;
&lt;p&gt;哈夫曼树：最优带权二叉树&lt;br&gt;
构造：&lt;br&gt;
如通信中使用哈夫曼编码，首先计算每个元素的权值，可以是该字符出现的频率。出现的频率越小，就把他放在树的最下面，编码长度长一些，而常用到的字符放在上面，编码长度短。&lt;br&gt;
每次在表中选择权值最小的两个元素作为兄弟节点，并将其权值加和，放回数组中。重复这个步骤，直到所有节点被选完。&lt;/p&gt;
&lt;h2 id=&#34;图&#34;&gt;图&lt;/h2&gt;
&lt;p&gt;DFS：沿着一个节点一直走到不能走为止，再出栈找到可以继续走的地方，重复上述。一般是递归实现&lt;br&gt;
BFS：访问一个节点的所有未被访问的相邻节点，然后再从相邻节点中拿出一个重复上述。用队列实现：结点入队，结点的旁边结点入队，依次出队，每出一个都把该结点的旁边结点入队&lt;/p&gt;
&lt;p&gt;最小生成树&lt;br&gt;
普利姆：从源点开始，每次选择到未在树上的点的最短边，将边和点都加入最小生成树，直到所有点被选&lt;br&gt;
克鲁斯卡尔：对边按权值排序，从小到大依次将边加入图中，每次检查是否有回路，无回路则加入，有则舍弃&lt;/p&gt;
&lt;p&gt;最短路径&lt;br&gt;
Dijkstra 算法（带权图、无权图）O(n²)&lt;br&gt;
求一个顶点到另外所有顶点的路径。从顶点开始，每次选择到顶点距离最短的点，然后记录当前每个点到顶点的距离，作为下一轮运算的起始点。&lt;br&gt;
初始化两个数组，一个保存源点到顶点i的距离，一个保存源点到顶点i的路径，不断迭代更新，最后距离数组中为源点到各个点的最短距离&lt;/p&gt;
&lt;p&gt;Floyd 算法（带权图、无权图）&lt;br&gt;
求任意两点之间的最短路径。初始化为图的邻接矩阵，每次检查两个顶点之间是否可以通过中转结点来获得更短的路径，在矩阵里更新路径长度。最后得到一个包含所有点到点最短路径长度的矩阵。&lt;/p&gt;
&lt;p&gt;拓扑排序：有向图，从头开始，每次选择入度为 0 的点，删除其所有的出边，将删除的点放入序列，得到拓扑排序结果&lt;/p&gt;
&lt;p&gt;关键路径：AOE网，active on the edge，边表示活动时间，从起点到终点的最长路径为关键路径，也就是完成一个事所需要的最长时间。其中一个算法是，每个边取相反数，然后用最短路径算法&lt;/p&gt;
&lt;p&gt;图的染色：解决了不同问题是否可以在同一时间段内发生，按度数降序排列，然后依次对结点着色。相邻两点颜色不能相同&lt;/p&gt;
&lt;h2 id=&#34;查找&#34;&gt;查找&lt;/h2&gt;
&lt;p&gt;二分查找：首先查找中间元素，判断是否相等，如果中间元素小于待查元素，那么在中间元素右边查找，反之在左边查找。递归的查找&lt;/p&gt;
&lt;p&gt;索引查找：也叫分块查找，先查找对应的块，再查找块内位置&lt;/p&gt;
&lt;p&gt;二叉排序树：左子树所有结点的值 &amp;lt; 根节点的值 &amp;lt; 右子树所有结点的值，中序遍历得到一个递增有序&lt;br&gt;
当前结点值大于 key 遍历左子树，当前结点值小于 key 遍历右子树&lt;/p&gt;
&lt;p&gt;平衡二叉树：左右子树高度之差不大于1，对二叉排序树的改进，防止树不平衡，导致查找长度太长，效率降低&lt;/p&gt;
&lt;p&gt;B-树：m叉平衡查找树&lt;/p&gt;
&lt;p&gt;散列表：给定一个关键字，通过一个Hash函数，映射到一个地址空间，理论的时间复杂度为 O(1)，&lt;br&gt;
常见哈希函数：除留余数法&lt;br&gt;
如果冲突，就按某种探测序列向后再找一个位置存放该元素，比如线性探测法、平方探测法&lt;br&gt;
拉链法&lt;/p&gt;
&lt;h2 id=&#34;排序&#34;&gt;排序&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;比较排序&lt;/strong&gt;&lt;br&gt;
冒泡：重复地遍历要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。直到不需要再交换，此时排序完成&lt;br&gt;
直接插入：将一个数据插入到已经排序的有序数据中，从而得到一个新的、个数加一的有序数据。首先，假定第一个元素已经被排序；接下来，从第二个元素开始，将每个元素插入到已经排序的数组中，直到整个列表排序完成。&lt;br&gt;
简单选择：每次从未排序的部分找出最小（或最大）的元素，然后将其放置到已排序部分的末尾。和原序列是否有序无关&lt;br&gt;
快速：通过一个轴值（pivot）将数组分为两个子数组，左边子数组的元素都比轴值小，右边子数组的元素都比轴值大，然后递归地对这两个子数组进行快速排序，直到整个数组排序完成。&lt;br&gt;
希尔：&lt;br&gt;
二路归并：用分治法的思想。将一个大数组分成两个小数组去解决。然后递归地将这两个小数组各自再分成两个更小的数组，如此继续，直到剩下的每个小数组只有一个元素或没有元素，认为每个小数组都已经排序。接下来是合并，将两个已经排序的小数组合并成一个有序的数组，重复这个过程，直到最后只剩下一个排序完成的大数组。&lt;br&gt;
堆排序：将数据调整为大/小根堆，每次输出堆顶元素，然后再次建堆，直到堆空。大根堆：每个结点的值大于左右孩子的值。建立堆：从n/2处开始筛选，递归的建堆&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;非比较排序&lt;/strong&gt;&lt;br&gt;
计数排序：找到原数据的最大最小值，以这个长度构建一个计数数组，遍历原数组，在计数数组响应位置增加计数。按顺序输出计数数组的下标，计了几个数就输出几个，得到有序序列&lt;br&gt;
桶排序：将待排序数据分到几个有序的桶里，每个桶里的数据再分别排序，最后将桶合并&lt;br&gt;
基数排序：先对个位排序，再对十位，再对百位&lt;/p&gt;
&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;
&lt;p&gt;拓扑排序&lt;/p&gt;
&lt;h1 id=&#34;计网&#34;&gt;计网&lt;/h1&gt;
&lt;p&gt;五层结构：物理层、数据链路层、网络层、传输层、应用层&lt;/p&gt;
&lt;h2 id=&#34;物理层&#34;&gt;物理层&lt;/h2&gt;
&lt;p&gt;电路交换：使用直通的物理线路，传输快，但无法并行&lt;br&gt;
报文交换：端到端中间需要中转时使用，可以并行，适合突发通信&lt;br&gt;
分组交换：将报文分组传输，可以并行，适合突发通信&lt;/p&gt;
&lt;p&gt;码间串扰：高频分量在传输过程中衰减，无法正确识别码元&lt;br&gt;
奈氏准则：码元在信道传输要小于一定速率，否则会码间串扰&lt;br&gt;
香农定理：只要传输速率低于信道的容量，理论上就可以做到无误差地传输信息&lt;/p&gt;
&lt;h2 id=&#34;数据链路层&#34;&gt;数据链路层&lt;/h2&gt;
&lt;p&gt;数据帧是数据链路层的基本传输单位，帧 = 帧首部 + IP数据报 + 帧尾部&lt;br&gt;
链路层检错编码：奇偶校验码、循环冗余码 CRC&lt;br&gt;
链路层纠错编码：海明码&lt;/p&gt;
&lt;p&gt;为什么流量控制？发送较快、接收较慢，造成传输错误；&lt;br&gt;
流量控制方法：停等协议（发一帧就等对方确认信号）、后退N帧协议（只要有没确认的帧就都重传）、选择重传协议（只重传没确认的帧）&lt;/p&gt;
&lt;p&gt;介质访问控制：采用一些措施，使得两对结点之间的通信不会互相干扰；&lt;br&gt;
多路复用：将多个信号放在一条物理信道传输，共享信道资源&lt;br&gt;
频分多路复用：分为不同频段&lt;br&gt;
时分多路复用：分为不同时段&lt;br&gt;
波分多路复用：分为不同波长&lt;br&gt;
码分多路复用：分为不同码序&lt;/p&gt;
&lt;p&gt;CSMA：“先听再说”发现信道空闲时再发送数据&lt;/p&gt;
&lt;p&gt;局域网：某一区域内 由多台计算机互联成的计算机组，使用 广播信道 ；&lt;br&gt;
广域网：覆盖范围广&lt;br&gt;
交换机只能单个网络内交换分组；&lt;br&gt;
路由器可以多个网络之间交换分组；&lt;br&gt;
局域网强调数据传输，广域网强调数据共享；&lt;/p&gt;
&lt;h2 id=&#34;网络层&#34;&gt;网络层&lt;/h2&gt;
&lt;p&gt;网络地址转换NAT：将私网IP映射为公网IP&lt;br&gt;
MAC地址（Media Access Control address）：物理地址（硬件地址）&lt;br&gt;
ARP协议：IP到MAC的映射&lt;br&gt;
DHCP：动态主机配置协议：使服务器（路由器、交换机等）自动向客户端分配IP地址和其他网络配置参数。这些参数包括子网掩码、默认网关、DNS服务器地址等&lt;br&gt;
ICMP：差错报告&lt;/p&gt;
&lt;p&gt;路由算法：选择最短、最佳路径；监测拥塞；提高安全性&lt;/p&gt;
&lt;p&gt;静态路由、动态路由、距离向量路由算法、链路状态路由算法、路径向量路由算法&lt;/p&gt;
&lt;h2 id=&#34;传输层&#34;&gt;传输层&lt;/h2&gt;
&lt;p&gt;IP地址 来区分主机，端口号 来区分进程。&lt;br&gt;
将 IP地址 + 端口号 就构成 套接字（socket），用来唯一地标识网络中的一台主机及其上的一个应用进程；&lt;/p&gt;
&lt;p&gt;传输协议：&lt;br&gt;
UDP：不需建立连接，不保证可靠性，传输速度快，无流量控制和拥塞控制&lt;br&gt;
TCP：需三次握手建立连接，可靠，传输慢，有流量控制和拥塞控制&lt;/p&gt;
&lt;p&gt;三次握手：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;发送端发送空的请求报文&lt;/li&gt;
&lt;li&gt;接收端收到后返回确认报文，允许连接&lt;/li&gt;
&lt;li&gt;发送端发送确认报文，并可携带数据&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;释放连接：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端发送释放报文&lt;/li&gt;
&lt;li&gt;服务器发送确认报文，并发送最后的数据&lt;/li&gt;
&lt;li&gt;客户端发送确认报文&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;超时重传：长时间未收到确认则重传&lt;/p&gt;
&lt;p&gt;采用滑动窗口机制进行流量控制，发送窗口 = Min {接收窗口，拥塞窗口}；&lt;/p&gt;
&lt;p&gt;拥塞控制：慢开始、拥塞避免、快重传、快恢复&lt;/p&gt;
&lt;h2 id=&#34;应用层&#34;&gt;应用层&lt;/h2&gt;
&lt;p&gt;P2P：每个主机既是客户机也是服务器，可扩展性强&lt;/p&gt;
&lt;p&gt;DNS 域名系统：使用 53 号端口，将域名如 baidu.com 解析为 IP 地址&lt;br&gt;
先查询本地域名服务器，若没有再查询更高层的域名服务器&lt;/p&gt;
&lt;p&gt;文件传输协议 FTP：使用两个并行的 TCP 链接传输文件&lt;br&gt;
电子邮件 SMTP 协议：也是基于 TCP 的&lt;br&gt;
超文本传输协议 HTTP：定义了浏览器怎样向万维网服务器（www）请求万维网文档，以及万维网服务器怎样将文档传回浏览器&lt;br&gt;
cookie：一些万维网站点希望可以识别用户主机，使用cookie记录用户一段时间内的访问记录。cookie是服务器产生的、储存在用户主机中的文本文件&lt;/p&gt;
&lt;h1 id=&#34;os&#34;&gt;OS&lt;/h1&gt;
&lt;p&gt;​操作系统是一组 控制和管理 计算机软硬件资源，合理地 组织 多道程序的运行，方便 用户使用的程序的集合&lt;/p&gt;
&lt;p&gt;操作系统的基本特征：并发、共享、虚拟、异步&lt;/p&gt;
&lt;p&gt;并发：在同一段时间间隔发生&lt;br&gt;
并行：在同时刻发生&lt;/p&gt;
&lt;p&gt;内核态：特权指令&lt;br&gt;
用户态：用户指令&lt;/p&gt;
&lt;p&gt;进程是动态的，具有并发性和独立性，存在形式是进程实体（PCB + 程序段 + 数据段）；程序是静态的&lt;br&gt;
三种状态：运行态、就绪态、阻塞态&lt;br&gt;
三种通信方式：共享储存、消息传递（将通信信息放在消息中）、管道通信&lt;/p&gt;
&lt;p&gt;进程与线程&lt;br&gt;
进程：资源分配的基本单位；进程内的线程共享进程分配的资源&lt;br&gt;
线程：并发调度的基本单位&lt;br&gt;
同一进程内切换线程不需要切换环境，系统开销小&lt;br&gt;
调度：外存→内存→CPU&lt;/p&gt;
&lt;p&gt;​ 一次仅允许一个进程使用的资源称为 临界资源；&lt;br&gt;
​ 对于 临界资源 的访问，必须是 互斥 进行的；每个进程中，访问临界资源的那段代码成为 临界区；&lt;br&gt;
信号量：将系统资源抽象为变量&lt;br&gt;
管程：封装了信号量（系统资源）和相关P/V操作，可以使用管城解决生产者-消费者问题&lt;/p&gt;
&lt;p&gt;死锁：两个以上的进程互相等待对方的资源，导致各进程都阻塞。(资源永远不会释放)&lt;br&gt;
解决：银行家算法：先判断是否会死锁，再决定是否分配资源。&lt;/p&gt;
&lt;h1 id=&#34;计组&#34;&gt;计组&lt;/h1&gt;
&lt;p&gt;计算机的工作流程&lt;br&gt;
​ 1、把程序和数据装入主存储器（内存）；&lt;br&gt;
​ 2、将源程序转换成可执行文件；&lt;br&gt;
​ 3、从可执行文件的首地址开始逐条执行指令；&lt;/p&gt;
&lt;p&gt;主存 - 辅存 结构解决 容量 问题；&lt;br&gt;
缓存 - 主存 结构解决 速度 问题；&lt;br&gt;
​主存和CPU两者的速度存在不匹配问题，故使用 cache缓存 进行解决&lt;/p&gt;
&lt;p&gt;CPU ↔ cache ↔ 主存 ↔ 辅存&lt;br&gt;
cache：CPU缓存，集成在 CPU 芯片中的高速存储器&lt;br&gt;
主存：也叫内存，随机存取存储器（RAM）允许数据的快速读写操作，但断电后其中的信息会丢失&lt;br&gt;
辅存：硬盘驱动器、固态驱动器，断电不消失&lt;br&gt;
DRAM：刷新 SRAM：不刷新&lt;/p&gt;
&lt;p&gt;RAM：读写&lt;br&gt;
ROM：只读&lt;/p&gt;
&lt;p&gt;cache替换算法：随机替换、先进先出、近期使用最少、最近不经常使用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;列出几个常用的存储方式&lt;/strong&gt;&lt;br&gt;
磁盘（机械硬盘），固态驱动器（无磁头）、USB、光盘、磁带、SRAM、DRAM、ROM、闪存、寄存器、cache&lt;/p&gt;
&lt;p&gt;常见寻址算法：直接、间接、寄存器、隐含、基址、变址&lt;/p&gt;
&lt;p&gt;CPU组成：运算器 (ALU) + 控制器 (CU) + 寄存器 + 中断系统&lt;br&gt;
CPU功能：指令控制、操作控制、时间控制、数据加工、中断处理&lt;/p&gt;
&lt;p&gt;总线：数据总线、地址总线、控制总线&lt;/p&gt;
&lt;p&gt;中断请求&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;发出中断信号&lt;/li&gt;
&lt;li&gt;响应中断，并设置中断屏蔽，不再响应其他中断请求&lt;/li&gt;
&lt;li&gt;保存中断点&lt;/li&gt;
&lt;li&gt;识别中断，进入中断服务程序&lt;/li&gt;
&lt;li&gt;中断程序结束，恢复CPU&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;DMA：硬件中断&lt;/p&gt;
&lt;h1 id=&#34;数据库&#34;&gt;数据库&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/zsheng_/article/details/105654588&#34;&gt;《数据库》_考研复试_面试篇&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/128107052&#34;&gt;计算机考研复试面试常问问题 数据库篇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;索引：是一个物理结构，相当于书的目录。比如 B+树索引、哈希索引&lt;br&gt;
键是一个逻辑概念，主键相当于书的页码&lt;br&gt;
视图是从一个或几个基本表中导出的表，用于简化用户操作，从多种角度看待同一数据&lt;br&gt;
存取控制是指确保只授权给有资格的用户访问数据库的权限，且令所有未被授权的人员无法接近数据&lt;/p&gt;
&lt;p&gt;数据库设计的基本步骤&lt;br&gt;
需求分析。了解和分析用户需求；&lt;br&gt;
概念结构设计。对用户需求进行抽象和归纳，形成一个独立于DBMS的概念模型（E-R图）；&lt;br&gt;
逻辑结构设计。将概念结构转换为数据模型，通常为关系模型；&lt;br&gt;
物理结构设计。为逻辑数据模型选取一个最适合存储结构和存取方法；&lt;br&gt;
数据库实施阶段。编写数据库，编写和调试应用程序；&lt;br&gt;
数据库运行和维护。正式投入运行。&lt;/p&gt;
&lt;p&gt;事物是什么？ACID特性包括？&lt;br&gt;
答：事物是数据库进行操作的一个基本单位。&lt;br&gt;
ACID特性包括：&lt;br&gt;
隔离性：一个事务的执行不能被其他事务所干扰；&lt;br&gt;
原子性：事务是一个不可分割的单位，要么全做，要么全不做；&lt;br&gt;
一致性：事务执行的结果必须使数据库从一个一致性状态变到另一个一致性状态；&lt;br&gt;
永久性：一旦事务被提交，它对数据库的改变就是永久的。&lt;/p&gt;
&lt;p&gt;什么是锁？有哪两种锁？&lt;br&gt;
答：锁是最常用的并发控制机构，是防止其他事务访问指定资源，实现并发控制的一种手段。&lt;br&gt;
排他锁（X写锁）：当数据被加上写锁，其他事务不能对该数据进行读和写；&lt;br&gt;
共享锁（S读锁）：当数据被加上读锁，允许其他事务对该数据进行读，不允许写。&lt;/p&gt;
&lt;h1 id=&#34;高数&#34;&gt;高数&lt;/h1&gt;
&lt;p&gt;零点存在定理：函数在闭区间连续，且左右异号，则函数在闭区间内有零点&lt;br&gt;
连续：左极限等于右极限等于函数值&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;中值定理&lt;/strong&gt;&lt;br&gt;
罗尔：闭区间连续，开区间可导，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;f(a)=f(b)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，则有 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;ξ&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;˙&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\dot{f(ξ)}=0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.23686em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord accent&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.9868600000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.04601em;&#34;&gt;ξ&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.319em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;accent-body&#34; style=&#34;left:-0.13889em;&#34;&gt;˙&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.25em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
拉格朗日：闭区间连续，开区间可导， &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;ξ&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;˙&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\dot{f(ξ)}=\frac{f(a)-f(b)}{a-b}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.23686em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord accent&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.9868600000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.04601em;&#34;&gt;ξ&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.319em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;accent-body&#34; style=&#34;left:-0.13889em;&#34;&gt;˙&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.25em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.413331em;vertical-align:-0.403331em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.01em;&#34;&gt;&lt;span style=&#34;top:-2.655em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.485em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.403331em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
柯西：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\frac{f(a)-f(b)}{g(a)-g(b)}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.53em;vertical-align:-0.52em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.01em;&#34;&gt;&lt;span style=&#34;top:-2.655em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;g&lt;/span&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;g&lt;/span&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.485em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.52em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;极值点：一阶导=0，且左右异号&lt;br&gt;
拐点：函数左右凹凸性相反的点，二阶导=0，且左右异号&lt;/p&gt;
&lt;p&gt;牛顿-莱布尼茨公式&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/msubsup&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\int_{a}^{b} f(x) \, dx = F(b) - F(a)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.399828em;vertical-align:-0.35582em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop&#34;&gt;&lt;span class=&#34;mop op-symbol small-op&#34; style=&#34;margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;&#34;&gt;∫&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.044008em;&#34;&gt;&lt;span style=&#34;top:-2.34418em;margin-left:-0.19445em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2579000000000002em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.35582em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;F&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;F&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;积分中值定理&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;msubsup&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/msubsup&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;f(c) = \frac{1}{b - a} \int_{a}^{b} f(x) \, dx&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.447339em;vertical-align:-0.403331em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.845108em;&#34;&gt;&lt;span style=&#34;top:-2.655em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.403331em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop&#34;&gt;&lt;span class=&#34;mop op-symbol small-op&#34; style=&#34;margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;&#34;&gt;∫&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.044008em;&#34;&gt;&lt;span style=&#34;top:-2.34418em;margin-left:-0.19445em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2579000000000002em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.35582em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;定积分几何意义：曲边梯形的面积&lt;br&gt;
二重积分的几何意义：曲顶柱体的体积&lt;br&gt;
三重积分：曲顶柱体的质量&lt;/p&gt;
&lt;p&gt;内积：a点乘b，a的模乘以b的模再乘以夹角余弦。向量a在b方向上的投影&lt;br&gt;
外积：&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;a&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;b&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;∣&lt;/mo&gt;&lt;mtable&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;i&lt;/mi&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;j&lt;/mi&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;k&lt;/mi&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;msub&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;msub&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;msub&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;msub&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo fence=&#34;true&#34;&gt;∣&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\boldsymbol{a} \times \boldsymbol{b} = \begin{vmatrix} \boldsymbol{i} &amp;amp; \boldsymbol{j} &amp;amp; \boldsymbol{k} \\ a_1 &amp;amp; a_2 &amp;amp; a_3 \\ b_1 &amp;amp; b_2 &amp;amp; b_3 \end{vmatrix}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.66666em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;×&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.69444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:3.636em;vertical-align:-1.5500299999999998em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen&#34;&gt;&lt;span class=&#34;delimsizing mult&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:2.08597em;&#34;&gt;&lt;span style=&#34;top:-1.05597em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-1.6619700000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.26797em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.87397em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.47997em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-4.08597em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.5500299999999998em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mtable&#34;&gt;&lt;span class=&#34;col-align-c&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:2.05em;&#34;&gt;&lt;span style=&#34;top:-4.21em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.0099999999999993em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-1.8099999999999994em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.5500000000000007em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;arraycolsep&#34; style=&#34;width:0.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;arraycolsep&#34; style=&#34;width:0.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;col-align-c&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:2.05em;&#34;&gt;&lt;span style=&#34;top:-4.21em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34; style=&#34;margin-right:0.0622em;&#34;&gt;j&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.0099999999999993em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-1.8099999999999994em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.5500000000000007em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;arraycolsep&#34; style=&#34;width:0.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;arraycolsep&#34; style=&#34;width:0.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;col-align-c&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:2.05em;&#34;&gt;&lt;span style=&#34;top:-4.21em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34; style=&#34;margin-right:0.01852em;&#34;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.0099999999999993em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-1.8099999999999994em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.5500000000000007em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;delimsizing mult&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:2.08597em;&#34;&gt;&lt;span style=&#34;top:-1.05597em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-1.6619700000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.26797em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.87397em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.47997em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-4.08597em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.606em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size1&#34;&gt;&lt;span&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.5500299999999998em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
得到一个垂直于原来的两个向量的新向量&lt;br&gt;
混合积：&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;a&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;b&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;c&lt;/mi&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;a&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;b&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mi mathvariant=&#34;bold-italic&#34;&gt;c&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;[\boldsymbol{a}, \boldsymbol{b}, \boldsymbol{c}] = \boldsymbol{a} \cdot (\boldsymbol{b} \times \boldsymbol{c})&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.44445em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;⋅&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;×&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord boldsymbol&#34;&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
表示平行六面体的体积。&lt;br&gt;
如果混合积为零，则这三个向量共面。&lt;/p&gt;
&lt;p&gt;格林公式：沟通了沿闭曲线的曲线积分与曲线所围区域上的二重积分之间的联系，将曲线积分转化成二重积分求解。&lt;br&gt;
高斯公式：建立了沿空间封闭曲面的曲面积分与曲面所围区域的三重积分之间的联系，将曲面积分转化为三重积分求解。&lt;br&gt;
斯托克斯公式：将三维上的曲线积分转化为曲面积分求解，它是格林公式的一般情形。&lt;/p&gt;
&lt;p&gt;一型线积分：弧长，变力作功&lt;br&gt;
一型面积分：面板质量&lt;br&gt;
二型线积分：流量&lt;br&gt;
二型面积分：流量&lt;/p&gt;
&lt;h1 id=&#34;线性代数&#34;&gt;线性代数&lt;/h1&gt;
&lt;h2 id=&#34;矩阵的几何意义&#34;&gt;矩阵的几何意义&lt;/h2&gt;
&lt;p&gt;表示对矩阵空间中向量的线性变换，定义了一个将输入向量映射到输出向量的规则&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;线性变换矩阵&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;二维或三维空间中的变换&lt;/strong&gt;：一个 (2 \times 2) 或 (3 \times 3) 矩阵可以表示平面或空间中的线性变换，如旋转、缩放、剪切、反射等。矩阵的列通常表示变换后基向量的方向和长度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更高维空间&lt;/strong&gt;：在更高维的空间中，矩阵表示的线性变换更加复杂，但基本思想是相似的：矩阵定义了一个将输入向量映射到输出向量的规则。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基变换矩阵&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;坐标变换&lt;/strong&gt;：当我们从一个坐标系统转换到另一个坐标系统时，基向量发生了变化。基变换矩阵描述了如何从旧坐标系统中的向量计算出新坐标系统中的向量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;投影矩阵&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;子空间投影&lt;/strong&gt;：一个投影矩阵可以将一个向量投影到向量空间的一个子空间上。这在机器学习和数据分析中非常有用，用于降维或特征提取。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;逆矩阵&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;逆变换&lt;/strong&gt;：一个矩阵的逆矩阵表示了该矩阵所定义的线性变换的逆。在几何上，这相当于将原始变换的效果“撤销”。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对称矩阵&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;二次型&lt;/strong&gt;：一个对称矩阵可以表示一个二次型，它在几何上对应于一个椭圆、双曲线或超椭圆的表面。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;正交矩阵&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;标准正交基&lt;/strong&gt;：正交矩阵的列组成一个标准正交基，这意味着它们是两两正交且长度为1的向量。在几何上，正交矩阵表示旋转或反射，同时保持向量的长度不变。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对角矩阵&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对角化&lt;/strong&gt;：对角矩阵表示一个线性变换，该变换在每个基向量上只进行标量乘法。这在几何上意味着每个基向量都被单独拉伸或压缩，而方向不变。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;n维向量&#34;&gt;ｎ维向量&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;向量组的定理辨析&lt;/strong&gt;&lt;br&gt;
梳理思路：从定义 到 方程组 到 方程组的直观理解 到 系数矩阵的秩 的解释&lt;/p&gt;
&lt;p&gt;🔺向量组线性相关 ⇔ 至少存在一组非零系数使向量组为 0 ⇔&lt;br&gt;
齐次方程组有非零解 ⇔ 行列式 = 0 ⇔ 未知数数量比方程组多 ⇔&lt;br&gt;
n 维列向量对应 n 个方程组，s 个列向量对应 s 个未知数，s &amp;gt; n  ⇔&lt;br&gt;
系数矩阵为扁长方形则一定相关 ⇔ 有效方程组数量（向量组的秩）小于未知数个数 s（列数）&lt;/p&gt;
&lt;p&gt;向量 α 和 β 线性相关，则 β=kα&lt;/p&gt;
&lt;p&gt;🔺向量组线性无关 ⇔ 当且仅当 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;k_1=k_2=...=k_s=0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.36687em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 向量组 = 0 ⇔&lt;br&gt;
齐次方程组只有零解 ⇔ 若为 nxn 则 行列式 ≠ 0（可逆）⇔ 未知数数量等于方程组&lt;br&gt;
⇔ 向量组的秩（有效方程组数量）等于列数（未知数个数），即列满秩（A 为 m x n 矩阵，则有 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;0 ≤ r(A) ≤ min(m,n)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.78041em;vertical-align:-0.13597em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;）⇔ 向量组中至少有一个向量可由其余的向量线性表出&lt;/p&gt;
&lt;p&gt;注意，有效方程组只能为扁长形和正方形，不能为竖长，竖长意味着方程组个数大于未知数，则无解&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;判定向量组线性无关&lt;/strong&gt;&lt;br&gt;
方程组只有零解 ⇔ 特殊情况：当矩阵为 nxn 时，行列式 ≠ 0 ⇔ 一般情况：矩阵满秩。行向量组线性无关 ⇔ 行满秩；列向量组线性无关 ⇔ 列满秩&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相关无关判定&lt;/strong&gt;&lt;br&gt;
部分组相关 ⇒ 整体组相关&lt;br&gt;
整体组无关 ⇒ 部分组无关&lt;/p&gt;
&lt;p&gt;缩短组无关 ⇒ 延伸组无关&lt;br&gt;
延伸组相关 ⇒ 缩短组相关&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;p68 定理 3.7 理解&lt;/strong&gt;&lt;br&gt;
相关的多数向量能用少数向量表出（少数向量是基底，多数向量为空间中的很多向量）&lt;br&gt;
无关的少数向量能用多数向量表出（空间中的很多向量通过变换可以求出基底）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;向量线性表出相关定理&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x_1α_1+x_2α_2+....=x_nα_n=β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.73333em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.73333em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.36687em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.58056em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 有非零解&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;[α_1,α_2,...,α_n,β]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 方程组有解，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)=r(\overline A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;高维可以表示低维：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1,α_2,...,α_t&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.2805559999999999em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可由 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β_1,β_2,...,β_t&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.2805559999999999em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 表出，则 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(α_1,α_2,...,α_t) ≤ r(β_1,β_2,...,β_t)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.2805559999999999em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.2805559999999999em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;向量组 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1,α_2,...α_m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 线性相关 向量组中至少有一个向量可由其余的 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;m-1&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.66666em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;个向量线性表出&lt;/li&gt;
&lt;li&gt;若向量组 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1,α_2,...α_m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 线性无关，而 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β,α_1,α_2,...α_m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 线性相关，则 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可由 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1,α_2,...α_m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 线性表出，并且表示法唯一&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;向量空间&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基底变换：由基 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;到&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1，α_2，α_3 到 β_1，β_2，β_3&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;到&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
对 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 矩阵 列变换，右乘过渡矩阵 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;C&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β=αC&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;坐标变换&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x=Cy&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8777699999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 是在 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 下的坐标，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;y&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 是在 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 下的坐标（交叉原则）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;方程组有解&#34;&gt;方程组有解&lt;/h2&gt;
&lt;p&gt;非齐次有解充要条件：A 的秩等于 A 增广的秩&lt;/p&gt;
&lt;h2 id=&#34;特征向量&#34;&gt;特征向量&lt;/h2&gt;
&lt;p&gt;定义：Aα = λα（α 非零）&lt;br&gt;
一个矩阵点乘一个向量就相当于对该向量进行旋转或者拉伸等一系列线性变换，特征向量在经过矩阵 A 的变换后，不改变方向，等价于由特征值 λ 进行缩放。如果特征值大于1，那么特征向量在变换后变长了；如果特征值小于1，特征向量变短了；如果特征值是负数，特征向量的方向会翻转。&lt;/p&gt;
&lt;p&gt;特征向量指示了在进行矩阵变换时，矩阵空间中不变的方向。通过研究特征值和特征向量，可以简化一些矩阵的运算，抓住矩阵空间中的不变信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;奇异值分解（Singular Value Decomposition，SVD）&lt;/strong&gt;&lt;br&gt;
特征值和特征向量是对方阵而言，对于非方阵（即行数和列数不相等的矩阵），通常不讨论特征向量和特征值，而是讨论奇异值分解（SVD）中的奇异向量和对角矩阵中的奇异值，这可以看作是特征值和特征向量的推广。奇异值分解是任何矩阵都可以进行的分解，它揭示了矩阵与特征值分解类似的某些性质，如数据压缩和结构简化。&lt;/p&gt;
&lt;p&gt;特征值和特征向量可以写为：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A = PDP^{-1}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8141079999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;  D为特征值矩阵，P为特征向量矩阵&lt;br&gt;
而奇异值分解定义为：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;U&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;Σ&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A = U \Sigma V^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10903em;&#34;&gt;U&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;Σ&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，U和V是正交矩阵，它们的列向量都是单位向量，且两两正交，U为 mxn，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;V^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;为 nxm；Σ是一个 n×n 的对角矩阵，对角线上的非零元素称为奇异值，按从大到小的顺序排列，其余位置上的元素都是0。&lt;/p&gt;
&lt;p&gt;最大的奇异值对应于数据中最主要的成分或特征，而较小的奇异值则对应于次要的成分。矩阵的秩等于其非零奇异值的数量。&lt;/p&gt;
&lt;p&gt;在数据分析和信号处理中，可以通过保留最大的奇异值和对应的奇异向量来近似原始数据矩阵，从而实现数据压缩。这种压缩可以去除噪声和不重要的信息，同时保留数据的主要特征；最小二乘问题，SVD可以用来找到最小范数解；可以用于图像去噪、压缩、特征提取；PCA 中使用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;矩阵的迹：tr(A)&lt;/strong&gt;&lt;br&gt;
迹：主对角线元素之和（不管怎么变化，矩阵的迹不会变），等于矩阵的特征值之和。&lt;/p&gt;
&lt;h2 id=&#34;几种特殊矩阵&#34;&gt;几种特殊矩阵&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;单位矩阵&lt;/strong&gt;&lt;br&gt;
对角线都是1，其余都是0&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实对称矩阵（对称矩阵）&lt;/strong&gt;&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A=A^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
n 阶实对称矩阵必可以相似对角化&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;反对称矩阵&lt;/strong&gt;&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A=-A^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.924661em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
对角线元素一定为 0&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;逆矩阵&lt;/strong&gt;&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;P^{-1}P = E&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8141079999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正交矩阵&lt;/strong&gt;&lt;br&gt;
转置等于其逆的矩阵&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A^TA=E&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
矩阵的行向量和列向量都是单位向量，且两两正交。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正定矩阵&lt;/strong&gt;&lt;br&gt;
对于任意非零向量 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，都有 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x^TAx&amp;gt;0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.880431em;vertical-align:-0.0391em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，则 A 正定&lt;br&gt;
性质：特征值全&amp;gt;0；顺序主子式全&amp;gt;0&lt;/p&gt;
&lt;h2 id=&#34;矩阵关系&#34;&gt;矩阵关系&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;判断是否可以相似于对角矩阵&lt;/strong&gt;&lt;br&gt;
充要条件只需记“n 个特征值对应 n 个线性无关的特征向量”&lt;br&gt;
注意，任何矩阵，不同特征值对应的特征向量线性无关（相同特征值不一定）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有 n 个不同的特征值&lt;/li&gt;
&lt;li&gt;k 重特征值对应 k 个线性无关的特征向量&lt;/li&gt;
&lt;li&gt;实对称矩阵一定可相似对角化。因为实对称不同特征值特征向量必正交，同一特征值的不同特征向量线性无关（但不一定正交），即 n 个特征值对应 n 个线性无关的特征向量&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;矩阵等价 &amp;amp; 向量组等价&lt;/strong&gt;&lt;br&gt;
矩阵等价：A 经过有限次初等变换可以变成 B ⇔ r(A)=r(B)&lt;br&gt;
向量组等价：两个向量组可以相互线性表出&lt;/p&gt;
&lt;p&gt;矩阵等价，其行列向量组都可以不等价；矩阵等价和行列向量组等价无关&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;矩阵的等价，相似，合同&lt;/strong&gt;&lt;br&gt;
关系：&lt;br&gt;
（（（相似）合同 ）等价 ）&lt;/p&gt;
&lt;p&gt;等价充要条件：存在可逆矩阵 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;、&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Q&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8777699999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 使得 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;PAQ=B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8777699999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;Q&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
等价性质：r(A)=r(B)&lt;br&gt;
合同充要条件：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;C^TAC=B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;C&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可逆&lt;br&gt;
相似充要条件：存在可逆矩阵 P，使 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;P^{-1}AP = B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8141079999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;（AB为方阵）&lt;/p&gt;
&lt;h1 id=&#34;概率论&#34;&gt;概率论&lt;/h1&gt;
&lt;h2 id=&#34;贝叶斯和全概率&#34;&gt;贝叶斯和全概率&lt;/h2&gt;
&lt;p&gt;当一个事件可以由几个互不相容的事件导致时，全概率公式用于计算该随机事件发生的总概率&lt;br&gt;
互不相容的事件称为完备事件组，假设互不相容的事件为 Bi，总事件为 A，全概率可以表示为，在 Bi 的条件下 A 发生的概率，乘以 Bi 发生的概率，然后对所有 Bi 求和&lt;/p&gt;
&lt;p&gt;贝叶斯公式：&lt;br&gt;
后验概率：总事件发生的条件下，是由单个原因导致的概率&lt;br&gt;
先验概率：与后验相对，没有后验概率就没有先验概率的概念。指的是单独考虑事件 A 发生的概率，而后验概率是，A 已经发生了，但是发现是在某个条件 B 下发生的，求这个概率&lt;/p&gt;
&lt;p&gt;贝叶斯公式就是求后验概率的过程，已知总事件发生，但是由多个原因导致的，求是由其中一个原因导致的的概率&lt;/p&gt;
&lt;h2 id=&#34;分布函数和概率密度&#34;&gt;分布函数和概率密度&lt;/h2&gt;
&lt;p&gt;分布函数 F(x) 表示的是 x 落在 (-∞，x) 上的概率&lt;br&gt;
分布函数在 [0,1] 之间，趋向于负无穷是 0，趋向正无穷是 1&lt;br&gt;
Fx 是单调不减的函数，右连续&lt;/p&gt;
&lt;p&gt;概率密度在负无穷到正无穷的积分为 1，且 f(x) 恒大于零&lt;/p&gt;
&lt;p&gt;离散型分布只有分布函数，没有概率密度&lt;/p&gt;
&lt;h2 id=&#34;常见概率分布&#34;&gt;常见概率分布&lt;/h2&gt;
&lt;p&gt;0-1 分布（伯努利分布）：投硬币模型，和二项分布的区别是0-1只进行一次实验&lt;br&gt;
二项分布：一件事的结果只有两种取值，进行n次独立重复实验&lt;br&gt;
泊松分布：用于描述在固定时间间隔或空间区域内发生某种事件的次数的概率分布。泊松分布特别适用于事件以恒定的平均速率随机且独立地发生的情况。&lt;br&gt;
几何分布：n 次伯努利试验中，首次成功的概率。&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;(1-p)^kp&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.099108em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.849108em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
正态分布：下面单独说&lt;br&gt;
均匀分布：随机变量在一个连续的区间内取值，而且在这个区间内的任何一个点取值概率是相等的。&lt;br&gt;
指数分布：适用于描述独立随机事件发生的时间间隔，其中事件以恒定的平均速率发生。例如灯泡使用寿命，具有无记忆性&lt;/p&gt;
&lt;h2 id=&#34;期望和方差&#34;&gt;期望和方差&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;DX = E(X-EX)^2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.064108em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;DX = EX^2-(EX^2)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.897438em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.064108em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
方差反映了数据点与其均值的偏差程度，方差越大，表示数据点之间的差异越大，数据的分散性也就越强。相反，方差越小，表示数据点围绕平均值更加集中，数据的分散性较弱。&lt;/p&gt;
&lt;p&gt;协方差反映随机变量XY的相关程度&lt;br&gt;
大于0：正相关；小于0：负相关；等于0：不相关&lt;/p&gt;
&lt;p&gt;相关系数：将协方差限制在 -1 到 1 之间，1 表示完全正相关，-1 表示完全负相关，0 表示没有线性相关&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;ρ&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mtext&gt;cov&lt;/mtext&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;ρ(X, Y) = \frac{\text{cov}(X, Y)}{\sigma_X \sigma_Y}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;ρ&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.455305em;vertical-align:-0.44530499999999995em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.01em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;σ&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.3448em;&#34;&gt;&lt;span style=&#34;top:-2.3567071428571427em;margin-left:-0.03588em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.14329285714285717em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;σ&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.3448em;&#34;&gt;&lt;span style=&#34;top:-2.3567071428571427em;margin-left:-0.03588em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.22222em;&#34;&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.14329285714285717em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.485em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord text mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;cov&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen mtight&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mpunct mtight&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.22222em;&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;mclose mtight&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.44530499999999995em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;三大分布和假设检验&#34;&gt;三大分布和假设检验&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;卡方&lt;/strong&gt;&lt;br&gt;
X服从标准正态，从X1加到Xn的平方和，服从卡方n分布&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;t-分布&lt;/strong&gt;&lt;br&gt;
X服从标准正态，Y服从卡方n，X比上根号下n分之Y&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;F分布&lt;/strong&gt;&lt;br&gt;
X服从卡方n1，Y服从卡方n2，X比上n1比上Y比n2&lt;/p&gt;
&lt;h2 id=&#34;假设检验&#34;&gt;假设检验&lt;/h2&gt;
&lt;p&gt;均用于假设检验&lt;/p&gt;
&lt;h2 id=&#34;大数定理和中心极限定理&#34;&gt;大数定理和中心极限定理&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;切比雪夫&lt;/strong&gt;&lt;br&gt;
切比雪夫不等式给出了随机变量偏离其期望值的概率的一个上界。可以提供一个关于随机变量行为的保守估计。μ是期望，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;σ^2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8141079999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;σ&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;是方差&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mo&gt;≥&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;ɛ&lt;/mi&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;ɛ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;P\{|X-μ|≥ɛ\}≤\frac{\sigma^2}{ɛ^2}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;μ&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≥&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;ɛ&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.36292em;vertical-align:-0.345em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.01792em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;ɛ&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7463142857142857em;&#34;&gt;&lt;span style=&#34;top:-2.786em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;σ&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913142857142857em;&#34;&gt;&lt;span style=&#34;top:-2.931em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.345em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;{&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;ɛ&lt;/mi&gt;&lt;mo&gt;}&lt;/mo&gt;&lt;mo&gt;≥&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;msup&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;ɛ&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;P\{|X-μ|≤ɛ\}≥1-\frac{\sigma^2}{ɛ^2}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;μ&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;ɛ&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≥&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.72777em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.36292em;vertical-align:-0.345em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.01792em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;ɛ&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7463142857142857em;&#34;&gt;&lt;span style=&#34;top:-2.786em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;σ&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913142857142857em;&#34;&gt;&lt;span style=&#34;top:-2.931em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.345em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大数定律&lt;/strong&gt;&lt;br&gt;
切比雪夫、辛钦大数定理：&lt;br&gt;
算数平均值（样本均值）依概率收敛于期望&lt;/p&gt;
&lt;p&gt;伯努利大数定理：&lt;br&gt;
重复独立的伯努利试验中，试验结果的频率趋近于试验的概率。&lt;br&gt;
也就是说，试验次数趋近于无穷的时候，P(A) 可以拿频率来近似计算&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;中心极限定理&lt;/strong&gt;&lt;br&gt;
高斯分布（正态分布）&lt;br&gt;
方差越大，图像越扁平&lt;br&gt;
均值只改变中轴在x轴的位置，均值为0以x=0为轴，均值为1以x=1为轴&lt;/p&gt;
&lt;p&gt;大量随机变量的和近似服从正态分布&lt;br&gt;
样本均值为正态分布的均值&lt;br&gt;
样本方差为正态分布的方差&lt;br&gt;
在批量归一化中使用&lt;/p&gt;
&lt;h2 id=&#34;参数估计&#34;&gt;参数估计&lt;/h2&gt;
&lt;h3 id=&#34;矩估计&#34;&gt;矩估计&lt;/h3&gt;
&lt;p&gt;一阶原点矩：E(X)&lt;br&gt;
二阶中心矩：D(X)&lt;/p&gt;
&lt;h3 id=&#34;极大似然&#34;&gt;极大似然&lt;/h3&gt;
&lt;p&gt;现在发生了的某个事件，似然函数就变成了这个样本的理论概率，而现在的采样结果代表某个事件已经确定发生了，那这个事发生的理论概率应该尽量大 (在这个事件发生的理论概率中最大的那种情况)，才会导致这个事件发生概率最大，所以要用极大似然函数估计。&lt;/p&gt;
&lt;p&gt;步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;样本概率相乘&lt;/li&gt;
&lt;li&gt;取对数求导找极值点&lt;/li&gt;
&lt;li&gt;极值点处对应的参数值为最大似然估计值&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;无偏性&lt;/strong&gt;&lt;br&gt;
E(估计值)=真实值&lt;/p&gt;
&lt;h1 id=&#34;高数-2&#34;&gt;高数&lt;/h1&gt;
&lt;p&gt;几何平均：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\sqrt{ab}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.04em;vertical-align:-0.10777999999999999em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord sqrt&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.93222em;&#34;&gt;&lt;span class=&#34;svg-align&#34; style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34; style=&#34;padding-left:0.833em;&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.89222em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;hide-tail&#34; style=&#34;min-width:0.853em;height:1.08em;&#34;&gt;&lt;svg width=&#39;400em&#39; height=&#39;1.08em&#39; viewBox=&#39;0 0 400000 1080&#39; preserveAspectRatio=&#39;xMinYMin slice&#39;&gt;&lt;path d=&#39;M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z&#39;/&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.10777999999999999em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;算数平均：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\frac{a+b}{2}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.2251079999999999em;vertical-align:-0.345em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8801079999999999em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.345em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;调和平均：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\frac{2ab}{a+b}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.283439em;vertical-align:-0.403331em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8801079999999999em;&#34;&gt;&lt;span style=&#34;top:-2.655em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.403331em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;  &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\frac{2}{\frac{1}{a}+\frac{1}{b}}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.4869279999999998em;vertical-align:-0.64182em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.845108em;&#34;&gt;&lt;span style=&#34;top:-2.59898em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mopen nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8443142857142858em;&#34;&gt;&lt;span style=&#34;top:-2.656em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2255000000000003em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line mtight&#34; style=&#34;border-bottom-width:0.049em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.384em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.344em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mopen nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8443142857142858em;&#34;&gt;&lt;span style=&#34;top:-2.656em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2255000000000003em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line mtight&#34; style=&#34;border-bottom-width:0.049em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.384em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.344em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.64182em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;F1值使用调和平均，调和平均给予较小的值更多的权重（取倒数）使得精确率和召回率能更好的平衡，否则若使用算数平均，较大的值对整体影响较大，无法起到调和的作用&lt;/p&gt;
">复试</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-seq2seq-beamsearch/"" data-c="
          &lt;h1 id=&#34;seq2seq&#34;&gt;Seq2Seq&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV16g411L7FG/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;62 序列到序列学习（seq2seq）【动手学深度学习v2】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/194308943&#34;&gt;Seq2Seq模型介绍&lt;/a&gt;&lt;br&gt;
Transformer：Seq2Seq model with attention&lt;/p&gt;
&lt;p&gt;encoder-decoder 架构，使用的都是 RNN&lt;/p&gt;
&lt;h1 id=&#34;beam-search-束搜索&#34;&gt;Beam Search 束搜索&lt;/h1&gt;
&lt;p&gt;在选择softmax输出时，使用贪心算法（每次选择概率最大值）不一定能达到最优&lt;br&gt;
每次搜索保存k个最好的候选。k=1 是贪心，k=n 是穷举&lt;/p&gt;
">【NLP】Seq2Seq | Beam Search</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/cv-gai-shu/"" data-c="
          &lt;p&gt;机器视觉算法是计算机视觉领域的关键组成部分，它使计算机能够通过图像和视频数据理解世界。这些算法可以根据它们的功能和用途进行分类。以下是一些常见的分类方式：&lt;/p&gt;
&lt;h3 id=&#34;1-图像处理算法&#34;&gt;1. 图像处理算法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;预处理&lt;/strong&gt;：包括去噪、对比度增强、颜色空间转换等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;滤波和锐化&lt;/strong&gt;：用于改善图像质量或提取特定特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;边缘检测&lt;/strong&gt;：如Sobel、Canny算法，用于检测图像中的边缘。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-特征提取算法&#34;&gt;2. 特征提取算法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;角点检测&lt;/strong&gt;：如Harris角点检测、Shi-Tomasi算法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;兴趣点检测&lt;/strong&gt;：如SIFT（尺度不变特征变换）、SURF（加速稳健特征）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特征描述子&lt;/strong&gt;：如ORB（Oriented FAST and Rotated BRIEF）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-图像分类-image-classification&#34;&gt;3. 图像分类 (Image Classification)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：将整个图像分配给一个或多个类别。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;AlexNet&lt;/li&gt;
&lt;li&gt;VGGNet&lt;/li&gt;
&lt;li&gt;ResNet&lt;/li&gt;
&lt;li&gt;Inception&lt;/li&gt;
&lt;li&gt;DenseNet&lt;/li&gt;
&lt;li&gt;EfficientNet&lt;/li&gt;
&lt;li&gt;转移学习：使用预训练的CNN模型进行微调以适应特定的图像分类任务。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-目标检测与识别-object-detection&#34;&gt;4. 目标检测与识别 (Object Detection)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：在图像中识别物体的位置，并将每个物体分类。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;R-CNN及其变体（Fast R-CNN, Faster R-CNN）&lt;/li&gt;
&lt;li&gt;YOLO系列（YOLOv1至YOLOv5）&lt;/li&gt;
&lt;li&gt;SSD (Single Shot MultiBox Detector)&lt;/li&gt;
&lt;li&gt;RetinaNet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;目标识别&lt;/strong&gt;：CNN 变体&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-图像分割-image-segmentation&#34;&gt;5. 图像分割 (Image Segmentation)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：将图像分割成多个区域或对象，可以进一步细分为语义分割和实例分割。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;FCN (Fully Convolutional Networks)&lt;/li&gt;
&lt;li&gt;U-Net&lt;/li&gt;
&lt;li&gt;Mask R-CNN（实例分割）&lt;/li&gt;
&lt;li&gt;DeepLab系列&lt;/li&gt;
&lt;li&gt;PSPNet (Pyramid Scene Parsing Network)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-姿态估计-pose-estimation&#34;&gt;6. 姿态估计 (Pose Estimation)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：估计图像中人或对象的姿态或关节位置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;OpenPose&lt;/li&gt;
&lt;li&gt;AlphaPose&lt;/li&gt;
&lt;li&gt;DensePose&lt;/li&gt;
&lt;li&gt;PoseNet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-物体跟踪-object-tracking&#34;&gt;7. 物体跟踪 (Object Tracking)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：在视频序列中跟踪一个或多个对象的运动。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;SiamFC (Siamese Fully Convolutional Network)&lt;/li&gt;
&lt;li&gt;SORT/Simple Online and Realtime Tracking&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-图像生成-image-generation&#34;&gt;8. 图像生成 (Image Generation)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：从现有的图像或随机噪声生成新图像。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;GANs (Generative Adversarial Networks) 及其变体（CGAN, DCGAN, StyleGAN）&lt;/li&gt;
&lt;li&gt;VAEs (Variational Autoencoders)&lt;/li&gt;
&lt;li&gt;PixelRNN/PixelCNN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-图像恢复-image-restoration&#34;&gt;9. 图像恢复 (Image Restoration)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：从损坏或降质的图像中恢复出清晰图像。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;SRCNN (Super-Resolution Convolutional Neural Network)&lt;/li&gt;
&lt;li&gt;VDSR (Very Deep Super-Resolution)&lt;/li&gt;
&lt;li&gt;GANs在图像超分辨率方面的应用&lt;/li&gt;
&lt;li&gt;Denoising Autoencoders&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;10-3d重建-3d-reconstruction&#34;&gt;10. 3D重建 (3D Reconstruction)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：从一系列图像中重建出三维场景或对象的结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;Multi-View Stereo (MVS)&lt;/li&gt;
&lt;li&gt;COLMAP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-行为分析-action-analysis&#34;&gt;11. 行为分析 (Action Analysis)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：分析视频中的人或物体的行为，比如行人的行走路线、人群的动态等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;C3D (Convolutional 3D Networks)&lt;/li&gt;
&lt;li&gt;I3D (Inflated 3D ConvNet)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12-视觉问答-visual-question-answering&#34;&gt;12. 视觉问答 (Visual Question Answering)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;任务说明&lt;/strong&gt;：根据给定图像和自然语言问题提供答案。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;基于注意力机制的模型&lt;/li&gt;
&lt;li&gt;LSTM (Long Short-Term Memory) 网络&lt;/li&gt;
&lt;li&gt;End-to-End模型&lt;/li&gt;
&lt;li&gt;Transformer模型及其在视觉问答中的应用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;13-优化和机器学习算法&#34;&gt;13. 优化和机器学习算法&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;- 用于提高识别准确率和效率的算法，如支持向量机（SVM）、随机森林、梯度提升决策树（GBDT）等。
- 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这些任务和算法展示了机器视觉领域的广泛性和深度，随着研究的进展，还会不断有新&lt;/p&gt;
&lt;p&gt;的任务和算法被提出。&lt;/p&gt;
&lt;h1 id=&#34;数据增强&#34;&gt;数据增强&lt;/h1&gt;
&lt;p&gt;对图片进行翻转、裁剪、变色（颜色、亮度、饱和度）等操作&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV17y4y1g76q/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;36 数据增广【动手学深度学习v2】&lt;/a&gt;&lt;/p&gt;
">【CV】概述</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-wen-ben-yu-chu-li/"" data-c="
          &lt;p&gt;数据预处理是自然语言处理（NLP）任务中至关重要的一步，它直接影响到模型训练的效果和最终结果的质量。预处理步骤的目的是将原始文本转换成一种更易于计算机理解和处理的格式。以下是数据预处理中常见的几个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;文本清洗&lt;/strong&gt;:&lt;br&gt;
移除无关内容（如HTML标签）、标点符号、数字等，或者将它们转换成有意义的代替文本。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;去除噪声&lt;/strong&gt;：移除文本中的无关信息，如HTML标签、非文本内容（图片链接、JavaScript代码等）、格式符号等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;规范化文本&lt;/strong&gt;：将文本统一为标准格式，例如，将所有字母转换为小写（或大写），以减少词汇的变体数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;去除特殊字符和标点&lt;/strong&gt;：根据任务需求，移除或替换文本中的特殊字符和标点符号，有时标点可以保留，因为它可能含有语义信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;分词 (Tokenization)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;词级分词&lt;/strong&gt;：将句子分割成单词或词汇单元，如短语。这是英文等西方语言中最常见的分词方式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;子词级分词&lt;/strong&gt;：将单词进一步分割成更小的单位（如词根、词缀）。这对于处理一些复合词或未见过的词特别有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;字符级分词&lt;/strong&gt;：将文本分割成字符。这种方法对于某些任务或语言（如中文）可能更合适。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;停用词去除&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;停用词是指在文本中频繁出现但对于理解文本意义贡献不大的词，如“的”、“是”、“在”等。去除这些词可以帮助减少数据噪声和特征维度。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;词干提取 (Stemming) 和词形还原 (Lemmatization)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;词干提取&lt;/strong&gt;：通过去除词缀来将词汇还原到基本形式（可能不是真正的词）。例如，“running”、“runs”词干提取后都变为“run”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;词形还原&lt;/strong&gt;：将词汇还原到其词典形式（lemma），考虑了词汇的词性。比如，“better”的词形还原结果是“good”。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据增强&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过词替换、句子重排等方法人为增加训练数据的多样性，有助于改善模型的泛化能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;向量化 (Vectorization)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;构建词汇表&lt;/strong&gt;：统计词频，小于某个词频的词将不会被加入词汇表&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Token 编码&lt;/strong&gt;：在构建了词汇表之后，每个唯一的token都会被分配一个唯一的数字ID。向量化的这一阶段涉及将文本中的每个token替换成对应的数字ID。这个过程实际上是一种编码，将文本数据转换为模型可以处理的数值形式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子/文本向量化（tokenize）&lt;/strong&gt;：完成token的数字编码后，整个句子或文本片段可以表示为一个数字序列。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;序列填充 (Padding) 和截断&lt;/strong&gt;：对于需要固定长度输入的模型（如很多深度学习模型），需要通过填充（通常用0或特殊标记&lt;code&gt;&amp;lt;PAD&amp;gt;&lt;/code&gt; ）或截断来使所有文本序列长度一致。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;词袋模型 (Bag of Words, BoW)&lt;/strong&gt;：将文本转换为词频向量，但这种方法不考虑词序和上下文。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TF-IDF (Term Frequency-Inverse Document Frequency)&lt;/strong&gt;：一种加权的词袋模型，考虑了词在文档集中的稀有程度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;词嵌入 (Word Embeddings)&lt;/strong&gt;：将词汇token映射到连续的向量空间中，这些向量捕获了词汇之间的语义关系。常见的词嵌入模型包括Word2Vec、GloVe和BERT等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;每个步骤的具体实现和必要性可能会根据具体的任务和语言而有所不同。例如，对于某些任务，保留标点符号可能是有意义的，因为它们可以携带情感或语法信息。而对于一些语言（如中文、日文），分词步骤会比英文复杂得多，可能需要特定的算法和词库。预处理的目的是清洗和转换数据，以提高模型训练的效率和效果。&lt;/p&gt;
">【NLP】文本预处理</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-gai-shu/"" data-c="
          &lt;h1 id=&#34;任务&#34;&gt;任务&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;文本分类（Text Classification）&lt;/strong&gt;：将文本数据分类到预定义的类别中。常见的应用包括垃圾邮件检测、情感分析和主题分类。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;朴素贝叶斯（Naive Bayes）&lt;/li&gt;
&lt;li&gt;支持向量机（SVM）&lt;/li&gt;
&lt;li&gt;随机森林（Random Forest）&lt;/li&gt;
&lt;li&gt;卷积神经网络（CNN）&lt;/li&gt;
&lt;li&gt;长短期记忆网络（LSTM）&lt;/li&gt;
&lt;li&gt;Transformer模型（如BERT）&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;命名实体识别（Named Entity Recognition, NER）&lt;/strong&gt;：识别文本中的命名实体，如人名、地点名、组织名等，并将其分类到预定义的类别。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;条件随机场（CRF）&lt;/li&gt;
&lt;li&gt;循环神经网络（RNN）&lt;/li&gt;
&lt;li&gt;长短期记忆网络（LSTM）+ CRF&lt;/li&gt;
&lt;li&gt;BERT及其变体&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;词性标注（Part-of-Speech Tagging, POS Tagging）&lt;/strong&gt;：为文本中的每个单词分配一个词性标签，如名词、动词、形容词等。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;隐马尔可夫模型（HMM）&lt;/li&gt;
&lt;li&gt;条件随机场（CRF）&lt;/li&gt;
&lt;li&gt;循环神经网络（RNN）&lt;/li&gt;
&lt;li&gt;Transformer模型（如BERT）&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;句法分析（Syntactic Parsing）&lt;/strong&gt;：分析句子的语法结构，确定单词之间的依赖关系和句子的语法树结构。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;基于规则的方法&lt;/li&gt;
&lt;li&gt;上下文无关文法（CFG）&lt;/li&gt;
&lt;li&gt;依存解析（Dependency Parsing）使用神经网络&lt;/li&gt;
&lt;li&gt;Transformer模型（如BERT、GPT）&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;语义分析（Semantic Analysis）&lt;/strong&gt;：理解句子或文本的含义，包括词义消歧和语义角色标注。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;潜在语义分析（LSA）&lt;/li&gt;
&lt;li&gt;潜在狄利克雷分配（LDA）&lt;/li&gt;
&lt;li&gt;词嵌入方法（如Word2Vec、GloVe）&lt;/li&gt;
&lt;li&gt;Transformer模型（如BERT、RoBERTa）&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;&lt;strong&gt;情感分析（Sentiment Analysis）&lt;/strong&gt;：判断文本的情感倾向，如正面、负面或中性。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;朴素贝叶斯（Naive Bayes）&lt;/li&gt;
&lt;li&gt;支持向量机（SVM）&lt;/li&gt;
&lt;li&gt;循环神经网络（RNN）&lt;/li&gt;
&lt;li&gt;长短期记忆网络（LSTM）&lt;/li&gt;
&lt;li&gt;Transformer模型（如BERT、XLNet）&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;&lt;strong&gt;文本摘要（Text Summarization）&lt;/strong&gt;：生成文本的简短且含义完整的摘要。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;抽取式摘要方法，如TF-IDF&lt;/li&gt;
&lt;li&gt;序列到序列模型（Seq2Seq），如LSTM&lt;/li&gt;
&lt;li&gt;注意力机制（Attention Mechanism）&lt;/li&gt;
&lt;li&gt;预训练语言模型（如GPT-3、BERT）&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;&lt;strong&gt;机器翻译（Machine Translation）&lt;/strong&gt;：将一种语言的文本翻译成另一种语言。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;统计机器翻译（SMT）&lt;/li&gt;
&lt;li&gt;序列到序列模型（Seq2Seq）&lt;/li&gt;
&lt;li&gt;注意力机制&lt;/li&gt;
&lt;li&gt;Transformer架构&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;&lt;strong&gt;问答系统（Question Answering）&lt;/strong&gt;：对自然语言形式的问题给出直接答案。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;信息检索技术&lt;/li&gt;
&lt;li&gt;长短期记忆网络（LSTM）&lt;/li&gt;
&lt;li&gt;注意力机制&lt;/li&gt;
&lt;li&gt;BERT和Transformer模型&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;&lt;strong&gt;对话系统和聊天机器人（Dialogue Systems and Chatbots）&lt;/strong&gt;：构建能够与人类用户进行自然对话的系统。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;序列到序列模型（Seq2Seq）&lt;/li&gt;
&lt;li&gt;循环神经网络（RNN）&lt;/li&gt;
&lt;li&gt;长短期记忆网络（LSTM）&lt;/li&gt;
&lt;li&gt;Transformer和GPT系列&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;11&#34;&gt;
&lt;li&gt;&lt;strong&gt;文本生成（Text Generation）&lt;/strong&gt;：基于某些输入生成自然语言文本，如新闻文章生成、故事创作等。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;马尔可夫模型&lt;/li&gt;
&lt;li&gt;循环神经网络（RNN）&lt;/li&gt;
&lt;li&gt;长短期记忆网络（LSTM）&lt;/li&gt;
&lt;li&gt;GPT系列&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;12&#34;&gt;
&lt;li&gt;&lt;strong&gt;语音识别（Speech Recognition）&lt;/strong&gt;：将语音信号转换为文本。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;隐马尔可夫模型（HMM）&lt;/li&gt;
&lt;li&gt;深度神经网络（DNN）&lt;/li&gt;
&lt;li&gt;长短期记忆网络（LSTM）&lt;/li&gt;
&lt;li&gt;端到端的深度学习模型&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;13&#34;&gt;
&lt;li&gt;&lt;strong&gt;自然语言理解（Natural Language Understanding, NLU）&lt;/strong&gt;：深入理解自然语言的含义和上下文。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;词嵌入（Word Embeddings）&lt;/li&gt;
&lt;li&gt;长短期记忆网络（LSTM）&lt;/li&gt;
&lt;li&gt;Transformer模型&lt;/li&gt;
&lt;li&gt;BERT及其变体&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;14&#34;&gt;
&lt;li&gt;&lt;strong&gt;自然语言生成（Natural Language Generation, NLG）&lt;/strong&gt;：从非语言数据生成人类可理解的语言。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;模板方法&lt;/li&gt;
&lt;li&gt;序列到序列模型（Seq2Seq）&lt;/li&gt;
&lt;li&gt;Transformer模型&lt;/li&gt;
&lt;li&gt;GPT系列&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;15&#34;&gt;
&lt;li&gt;&lt;strong&gt;关键词提取（Keyword Extraction）&lt;/strong&gt;：从文本中提取最相关的词汇或短语。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;TF-IDF&lt;/li&gt;
&lt;li&gt;TextRank&lt;/li&gt;
&lt;li&gt;LDA（潜在狄利克雷分配）&lt;/li&gt;
&lt;li&gt;BERT Embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;16&#34;&gt;
&lt;li&gt;&lt;strong&gt;主题建模（Topic Modeling）&lt;/strong&gt;：无监督地识别大量文档集中的潜在主题。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;潜在语义分析（LSA）&lt;/li&gt;
&lt;li&gt;潜在狄利克雷分配（LDA）&lt;/li&gt;
&lt;li&gt;非负矩阵分解（NMF）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于每种任务，选择最合适的算法通常取决于具体的应用场景、可用数据的量和质以及性能要求。随着深度学习技术的发展，基于Transformer的模型如BERT、GPT系列在多个NLP任务中取得了突破性的成果。&lt;/p&gt;
&lt;h1 id=&#34;算法&#34;&gt;算法&lt;/h1&gt;
&lt;p&gt;自然语言处理（NLP）领域中有多种算法和技术，这些方法旨在帮助计算机理解、解释和生成人类语言。以下是一些核心的NLP算法和技术：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基于规则的系统&lt;/strong&gt;：早期的NLP系统大多依赖于手写的规则来解析和理解文本。这些规则可以基于语法、句法和语义规则来设计。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;统计方法&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;隐马尔可夫模型（HMM）&lt;/strong&gt;：用于词性标注和命名实体识别等任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;条件随机场（CRF）&lt;/strong&gt;：用于序列建模，如标注问题和命名实体识别。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;机器学习算法&lt;/strong&gt;：随着机器学习的发展，许多传统算法被用于NLP任务，如朴素贝叶斯、决策树、支持向量机（SVM）等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;深度学习/神经网络方法&lt;/strong&gt;：近年来，深度学习在NLP中取得了重大进展，以下是一些关键的神经网络架构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;卷积神经网络（CNNs）&lt;/strong&gt;：虽然最初用于图像处理，但也被适用于处理文本数据，如句子分类任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;循环神经网络（RNNs）&lt;/strong&gt;：特别适合处理序列数据，如时间序列或文本。长短期记忆网络（LSTMs）和门控循环单元（GRUs）是RNN的变体，能够解决传统RNNs的梯度消失问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;注意力机制和Transformer架构&lt;/strong&gt;：注意力机制允许模型在处理序列数据时更加灵活地权衡不同部分的重要性，而Transformer架构则彻底改变了NLP领域，成为了多种任务的基础，如BERT、GPT系列、RoBERTa、T5等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;预训练语言模型&lt;/strong&gt;：利用大量无标签文本数据进行预训练，然后在特定任务上进行微调。BERT和GPT系列是这一范式下的两个典型例子。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;迁移学习和微调&lt;/strong&gt;：借助预训练的语言模型，通过在特定任务上的微调，可以显著提高性能。这种方法减少了对大量标记数据的依赖。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些算法和技术在各种NLP任务中被广泛应用，如文本分类、情感分析、机器翻译、语音识别、问答系统、文本摘要、自然语言生成等。随着研究的不断进展，新的算法和模型也在不断被提出和改进。&lt;/p&gt;
&lt;h1 id=&#34;nlp-任务的一般过程&#34;&gt;NLP 任务的一般过程&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;问题定义&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;明确任务目标：这可能是文本分类、情感分析、机器翻译、命名实体识别、问答系统等。&lt;/li&gt;
&lt;li&gt;确定输入输出：定义任务的输入数据（如文本、句子、段落）和期望的输出（如类别标签、文本响应等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据收集&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集足够的数据：根据任务需求，收集标注好的训练数据。对于一些任务，还可能需要收集未标注的数据进行无监督学习或半监督学习。&lt;/li&gt;
&lt;li&gt;来源：数据可以来自公共数据集、网络爬虫、社交媒体、公司数据库等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据预处理&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文本清洗：移除无关内容（如HTML标签）、标点符号、数字等，或者将它们转换成有意义的代替文本。&lt;/li&gt;
&lt;li&gt;分词：将文本分割成单词、短语或其他有意义的单位。&lt;/li&gt;
&lt;li&gt;规范化：包括小写转换、词干提取、词形还原等，旨在将单词规范到基本形式。&lt;/li&gt;
&lt;li&gt;去除停用词：移除常见但对于理解文本意义不大的词，如“的”、“是”、“在”等。&lt;/li&gt;
&lt;li&gt;向量化：将文本转换为数值形式，常见方法包括词袋模型、TF-IDF、词嵌入等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;特征工程&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特征提取：根据任务需求，选择或设计文本特征，如n-gram、词频、词嵌入向量等。&lt;/li&gt;
&lt;li&gt;降维：对高维特征空间应用降维技术，如PCA、t-SNE，以减少计算复杂度。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模型选择和训练&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;选择模型：根据任务类型选择合适的模型，可能是传统机器学习模型（如SVM、随机森林）或深度学习模型（如CNN、RNN、Transformer）。&lt;/li&gt;
&lt;li&gt;训练模型：使用训练数据训练模型，调整超参数以获得最佳性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;评估和优化&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用验证集评估模型性能，采用适当的评估指标（如准确率、召回率、F1分数、BLEU分数等）。&lt;/li&gt;
&lt;li&gt;根据评估结果调整模型结构、超参数等，可能包括使用更复杂的模型、增加更多训练数据、应用不同的预处理或特征工程技术。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;部署和监控&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将训练好的模型部署到生产环境，使其能够处理实时数据或新数据。&lt;/li&gt;
&lt;li&gt;监控模型性能，定期检查并重新训练模型以适应新数据或变化的数据分布。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;反馈循环&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据模型在实际应用中的表现，收集反馈，可能需要重新执行前面的步骤，如重新定义问题、收集更多或更高质量的数据、重新训练模型等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个流程不是一成不变的，具体的步骤和方法可能会根据具体的NLP任务、数据集、业务需求等因素有所不同。&lt;/p&gt;
&lt;h1 id=&#34;评估指标&#34;&gt;评估指标&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/ph12345687/article/details/130205151&#34;&gt;NLP常见任务及评估指标&lt;/a&gt;&lt;/p&gt;
">【NLP】概述</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/dl-qiang-hua-xue-xi/"" data-c="
          &lt;p&gt;强化学习是机器学习的一个领域，它主要关注如何使智能体（Agent）在环境（Environment）中学会采取行动（Action）以最大化某种累积奖励（Reward）。强化学习与其他类型的机器学习（如监督学习和无监督学习）的主要区别在于，它不依赖于预先标记的输入/输出对，而是通过智能体与环境的交互来学习。以下是这些概念的详细介绍：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;智能体（Agent）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;智能体是强化学习中的决策者，它通过观察环境来学习如何采取行动。智能体的目标是通过这些行动来最大化其长期奖励。它可以是任何能够感知其环境并根据这些观察做出决策的实体，如机器人、软件程序等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;环境（Environment）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;环境是智能体所处并与之互动的系统或问题域。环境接收智能体的行动并根据这些行动提供状态的反馈和奖励。环境的反馈可以是非常简单的，也可以是极其复杂且动态变化的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;状态（State）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;状态是对环境在某一时刻的描述。它可以是环境的完整描述，也可以只是环境的一部分。状态为智能体提供了决策的上下文，在给定状态下采取行动可以导致环境状态的变化。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;动作（Action）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;动作是智能体在给定状态下可以采取的决策或步骤。智能体的动作空间可以是离散的（如左转、右转）或连续的（如加速的量）。智能体的行动会影响环境，并导致状态的变化和奖励的给予。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;奖励（Reward）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;奖励是环境对智能体采取特定行动的即时评价。奖励通常是一个标量值，指示智能体的行动对于达成其目标的有用程度。智能体的目标是最大化在整个学习过程中获得的累积奖励。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;策略（Policy）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;策略是从状态到动作的映射，它定义了智能体在给定状态下应该采取什么行动。策略可以是简单的静态规则，也可以是复杂的动态函数，取决于智能体的学习算法和环境的性质。智能体的目标是学习一个最优策略，这个策略能在长期内最大化累积奖励。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;强化学习的过程过程可以通过多种算法来通常涉及智能体不断地通过与环境互动来尝试不同的策略，评估这些策略带来的奖励，并根据这些奖励来调整其策略，以学习如何最优地行动。这个实现，如Q学习、深度Q网络（DQN）、策略梯度方法等。&lt;/p&gt;
&lt;h1 id=&#34;常见算法&#34;&gt;常见算法&lt;/h1&gt;
&lt;h2 id=&#34;动态规划&#34;&gt;动态规划&lt;/h2&gt;
&lt;p&gt;动态规划（Dynamic Programming, DP）在强化学习中扮演着基础而重要的角色，尤其是在处理具有完全已知的环境模型（即状态转移概率和奖励函数已知）的问题时。DP方法依赖于贝尔曼方程，这是一组递归方程，用于描述状态值函数或动作值函数（即Q函数）之间的关系。在强化学习中，动态规划法主要用于两个方面：策略评估（Policy Evaluation）和策略提升（Policy Improvement），这两个步骤循环交替执行以找到最优策略。&lt;/p&gt;
&lt;h3 id=&#34;策略评估policy-evaluation&#34;&gt;策略评估（Policy Evaluation）&lt;/h3&gt;
&lt;p&gt;策略评估的目标是计算某策略下的状态值函数，即在遵循特定策略的条件下，从某状态开始所能获得的预期回报。通过迭代地应用贝尔曼期望方程，我们可以评估当前策略的效果：&lt;/p&gt;
&lt;p class=&#39;katex-block&#39;&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;V^{\pi}(s) = \sum_{a \in A} \pi(a|s) \sum_{s&amp;#x27;, r} P(s&amp;#x27;, r | s, a)[r + \gamma V^{\pi}(s&amp;#x27;)]
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7143919999999999em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.480098em;vertical-align:-1.430093em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.050005em;&#34;&gt;&lt;span style=&#34;top:-1.8556639999999998em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mrel mtight&#34;&gt;∈&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.0500049999999996em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop op-symbol large-op&#34;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.321706em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;π&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.050005em;&#34;&gt;&lt;span style=&#34;top:-1.8560149999999997em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.6828285714285715em;&#34;&gt;&lt;span style=&#34;top:-2.786em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct mtight&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.0500049999999996em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop op-symbol large-op&#34;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.430093em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.801892em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.051892em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05556em;&#34;&gt;γ&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7143919999999999em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.801892em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中，$$  V^{\pi}(s) $$ 是在状态 ( s ) 下遵循策略 ( \pi ) 所得到的价值，( \pi(a|s) ) 是在状态 ( s ) 下采取动作 ( a ) 的概率，( P(s&#39;, r | s, a) ) 是从状态 ( s ) 采取动作 ( a ) 转移到状态 ( s&#39; ) 并得到奖励 ( r ) 的概率，( \gamma ) 是折扣因子，用于计算未来奖励的现值。&lt;/p&gt;
&lt;h3 id=&#34;策略提升policy-improvement&#34;&gt;策略提升（Policy Improvement）&lt;/h3&gt;
&lt;p&gt;策略提升的目标是生成一个新策略，该策略在每个状态下都可以选择使动作价值最大化的动作。通过这个过程，我们可以从当前策略产生一个更好的策略。策略提升通常使用贝尔曼最优方程：&lt;/p&gt;
&lt;p class=&#39;katex-block&#39;&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Q^{\pi}(s, a) = \sum_{s&amp;#x27;, r} P(s&amp;#x27;, r | s, a)[r + \gamma V^{\pi}(s&amp;#x27;)]
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;Q&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7143919999999999em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.480098em;vertical-align:-1.430093em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.050005em;&#34;&gt;&lt;span style=&#34;top:-1.8560149999999997em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.6828285714285715em;&#34;&gt;&lt;span style=&#34;top:-2.786em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct mtight&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.0500049999999996em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop op-symbol large-op&#34;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.430093em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.801892em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.051892em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05556em;&#34;&gt;γ&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7143919999999999em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.801892em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然后，新的策略 ( \pi&#39; ) 在每个状态下选择最大化 ( Q^{\pi}(s, a) ) 的动作：&lt;/p&gt;
&lt;p class=&#39;katex-block&#39;&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;arg&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/munder&gt;&lt;msup&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\pi&amp;#x27;(s) = \arg\max_a Q^{\pi}(s, a)
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.051892em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;π&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.801892em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.45em;vertical-align:-0.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop&#34;&gt;ar&lt;span style=&#34;margin-right:0.01389em;&#34;&gt;g&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.43056em;&#34;&gt;&lt;span style=&#34;top:-2.1em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.7em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop&#34;&gt;max&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;Q&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7143919999999999em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.03588em;&#34;&gt;π&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;策略迭代policy-iteration&#34;&gt;策略迭代（Policy Iteration）&lt;/h3&gt;
&lt;p&gt;策略迭代结合了策略评估和策略提升，通过迭代这两个步骤直到策略收敛到最优策略。每次迭代包括完全评估当前策略（直到值函数收敛），然后进行策略提升。&lt;/p&gt;
&lt;h3 id=&#34;值迭代value-iteration&#34;&gt;值迭代（Value Iteration）&lt;/h3&gt;
&lt;p&gt;值迭代是策略迭代的一种简化形式，它结合了策略评估的一步操作和策略提升。值迭代直接迭代更新每个状态的最大动作价值，直到价值函数收敛：&lt;/p&gt;
&lt;p class=&#39;katex-block&#39;&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/munder&gt;&lt;munder&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo mathvariant=&#34;normal&#34;&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;V(s) = \max_a \sum_{s&amp;#x27;, r} P(s&amp;#x27;, r | s, a)[r + \gamma V(s&amp;#x27;)]
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:2.480098em;vertical-align:-1.430093em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.43056em;&#34;&gt;&lt;span style=&#34;top:-2.1em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.7em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop&#34;&gt;max&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop op-limits&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.050005em;&#34;&gt;&lt;span style=&#34;top:-1.8560149999999997em;margin-left:0em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.6828285714285715em;&#34;&gt;&lt;span style=&#34;top:-2.786em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct mtight&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.0500049999999996em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.05em;&#34;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&#34;mop op-symbol large-op&#34;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.430093em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.801892em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.051892em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05556em;&#34;&gt;γ&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.801892em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;动态规划方法在理论上可以得到最优策略，但其应用受限于环境模型的已知性以及状态和动作空间的规模。当状态和动作空间非常大或环境模型未知时，直接应用动态规划变得不可行，这时通常会&lt;/p&gt;
&lt;h2 id=&#34;马尔可夫&#34;&gt;马尔可夫&lt;/h2&gt;
&lt;h2 id=&#34;蒙特卡洛&#34;&gt;蒙特卡洛&lt;/h2&gt;
&lt;p&gt;蒙特卡洛方法在强化学习中的应用提供了一种在不完全知道环境模型（即转移概率和奖励函数未知）的情况下学习最优策略的方法。与动态规划不同，蒙特卡洛（MC）方法不需要知道环境的具体动态，而是通过从环境中采样完成的序列（或称为“情节”）来学习。这些方法特别适用于具有高度不确定性或模型未知的环境。MC方法的关键特点是它们依赖于经验平均来估计值函数，这些平均值是从一系列完整情节中获得的。&lt;/p&gt;
&lt;h3 id=&#34;mc策略评估&#34;&gt;MC策略评估&lt;/h3&gt;
&lt;p&gt;在策略评估过程中，MC方法通过对从当前策略生成的一系列完整情节的回报进行平均来估计状态的值。每个情节包含一系列的状态、动作和奖励，以及情节的最终结果。通过对同一状态多次访问得到的回报进行平均，MC方法可以估计该状态的值，即该状态的长期回报期望。&lt;/p&gt;
&lt;h3 id=&#34;mc控制&#34;&gt;MC控制&lt;/h3&gt;
&lt;p&gt;为了找到最优策略，MC方法采用了一种称为MC控制的方法。MC控制通常涉及两个主要步骤：探索和利用。一个常见的策略是使用ε-贪婪策略，其中智能体大部分时间选择当前最佳动作（利用），但有时也随机选择其他动作（探索），以确保长期学习。&lt;/p&gt;
&lt;p&gt;MC控制方法通过不断交替执行策略评估和策略提升来工作。在策略评估阶段，智能体使用其当前策略在环境中执行动作，并记录下来每个情节的结果。接着，使用这些情节的结果来更新值函数。在策略提升阶段，智能体根据估计的值函数更新其策略，通常是通过选择使得估计值函数最大化的动作。&lt;/p&gt;
&lt;h3 id=&#34;优点与局限&#34;&gt;优点与局限&lt;/h3&gt;
&lt;p&gt;MC方法的一个主要优点是它们不依赖于环境的先验知识，使其适用于模型未知的情况。此外，MC方法直接从最终回报中学习，而不依赖于其他状态的值估计，这有助于减少累积的估计误差。&lt;/p&gt;
&lt;p&gt;然而，MC方法也有其局限性。首先，它们只适用于情节性任务，即那些有明确开始和结束的任务。其次，MC方法可能需要很多情节才能获得可靠的值估计，尤其是在回报信号稀疏或噪声很大的情境中。此外，MC方法只在情节结束时更新值函数和策略，这可能导致学习速度较慢。&lt;/p&gt;
&lt;p&gt;总的来说，蒙特卡洛方法在强化学习中提供了一种强大的工具，尤其是在那些模型未知或难以精确建模的情况下。通过适当的策略和技巧（如重要性采样）的改进，可以进一步增强MC方法的应用范围和效率。&lt;/p&gt;
&lt;h2 id=&#34;时序差分法&#34;&gt;时序差分法&lt;/h2&gt;
&lt;h3 id=&#34;q-learning&#34;&gt;Q-Learning&lt;/h3&gt;
">【DL】强化学习</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-shi-xu-mo-xing-yu-ma-er-ke-fu-mo-xing/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_39653948/article/details/105571760&#34;&gt;原理+论文+实战：60篇由浅入深的时间序列预测/分类教程汇总&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;时序模型&#34;&gt;时序模型&lt;/h1&gt;
&lt;p&gt;t 时刻的状态和前面的数据相关&lt;br&gt;
自回归：预测（同一序列）后面的值，是根据（同一序列）前面的值来预测，即使用自身过去数据预测未来&lt;/p&gt;
&lt;h1 id=&#34;潜变量模型&#34;&gt;潜变量模型&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710309825352.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
h&#39; 包含了 h 和 x 的信息，也就是之前状态的信息&lt;/p&gt;
&lt;h1 id=&#34;马尔可夫模型&#34;&gt;马尔可夫模型&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Mr4y1f7Nm?p=1&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;火遍油管！终于有大神把【马尔可夫链】给做成动画了！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;马尔可夫性质：系统的下一个状态只依赖于当前状态，而与之前的状态无关。具有“无记忆性”&lt;/p&gt;
&lt;p&gt;马尔可夫假设：第N个词的出现只与前面N-1个词相关，而与其它任何词都不相关。N-gram模型就是基于该假设构建的&lt;/p&gt;
&lt;h1 id=&#34;马尔科夫链&#34;&gt;马尔科夫链&lt;/h1&gt;
&lt;p&gt;是依赖于马尔可夫假设的最基本的模型，用于模拟随即系统的状态转移&lt;br&gt;
未来的状态只取决于现在的状态，和之前的步骤无关&lt;br&gt;
任何状态所有出箭头概率之和为1&lt;br&gt;
转移状态矩阵：类似于有向图&lt;br&gt;
要找到在 n 步转移中，由状态 i 转移到状态 j 的概率，只需要找到 n 阶状态转移矩阵第 i 行 j 列&lt;/p&gt;
&lt;h1 id=&#34;隐马尔可夫模型-hmm&#34;&gt;隐马尔可夫模型 HMM&lt;/h1&gt;
&lt;p&gt;HMM 在马尔可夫链的基础上增加了“隐状态”和“观测状态”的概念。HMM 在马尔可夫链的基础上加入了观测数据，用于处理观测与状态间存在某种隐含关系的情况。&lt;/p&gt;
&lt;p&gt;在 HMM 中，系统的真实状态（隐状态）不能直接观测，只能通过一些观测到的事件（观测状态）间接推断。&lt;/p&gt;
&lt;p&gt;HMM 被广泛应用于序列数据的建模，如语音识别、生物序列分析等，其中系统的内部状态不是直接可见的。&lt;/p&gt;
&lt;p&gt;隐马尔可夫模型（Hidden Markov Model, HMM）是一种统计模型，它用于描述一个观测序列背后的一个不可观测（隐含）状态序列。这个模型假设隐含状态生成观测数据的过程具有马尔可夫性质，即每个状态的发生仅依赖于它之前的一个状态。隐马尔可夫模型在语音识别、自然语言处理、生物信息学和其他许多领域有广泛的应用。&lt;/p&gt;
&lt;p&gt;隐马尔可夫模型主要包含以下几个组成部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;隐状态集合&lt;/strong&gt;：模型中不可直接观测到的内部状态的集合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;观测集合&lt;/strong&gt;：每个隐状态可以生成的观测数据的集合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;状态转移概率矩阵&lt;/strong&gt;：隐状态之间转移的概率，表示为一个矩阵。矩阵的每个元素 aij 表示从状态 i 转移到状态 j 的概率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;观测概率分布&lt;/strong&gt;：也称为发射概率，它表示在给定某个隐状态的情况下，生成某个观测值的概率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;初始状态概率分布&lt;/strong&gt;：模型在开始时每个隐状态的初始概率分布。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;隐马尔可夫模型的基本假设包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;马尔可夫假设&lt;/strong&gt;：每个隐状态仅依赖于它之前的一个隐状态。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;观测独立性假设&lt;/strong&gt;：任何时刻的观测值仅依赖于当前的隐状态，与其他隐状态或观测值无关。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;隐马尔可夫模型的三个基本问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;评估问题&lt;/strong&gt;：给定模型参数和观测序列，计算观测序列出现的概率。这通常通过前向算法或后向算法解决。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解码问题&lt;/strong&gt;：给定模型参数和观测序列，找出最有可能产生这些观测的隐状态序列。这通常通过Viterbi算法解决。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学习问题&lt;/strong&gt;：给定观测序列，估计模型参数（状态转移概率、观测概率和初始状态概率），使得观测序列的概率最大。这可以通过Baum-Welch算法（一种特殊的期望最大化算法）来解决。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;马尔可夫决策过程&#34;&gt;马尔可夫决策过程&lt;/h1&gt;
&lt;p&gt;马尔可夫决策过程（Markov Decision Process, MDP）是一种数学框架，用于形式化描述在不确定性环境中的决策制定问题。MDP 适用于那些决策结果部分依赖于决策者并且部分依赖于随机因素的情形。MDP 主要用于需要做出一系列决策的场景，如自动控制、经济学决策、强化学习等，目标是找到最优策略，以最大化长期奖励。&lt;/p&gt;
&lt;p&gt;MDP 在马尔可夫链的基础上加入了“决策”的元素，引入了动作（Actions）、状态转移概率和奖励（Reward）。不仅关注状态的转移，还关注在给定状态下采取不同动作所导致的后果和收益。&lt;/p&gt;
&lt;p&gt;一个 MDP 主要由以下四个元素组成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;状态（S）&lt;/strong&gt;：描述决策过程中可能到达的所有状态的集合。每个状态提供了决策环境的完整描述。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;动作（A）&lt;/strong&gt;：对于每个状态，都有一组可能的动作（或决策）。动作决定了状态转移的可能性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;状态转移概率（P）&lt;/strong&gt;：表示为 P(s&#39;|s, a)，即在状态 s 下采取动作 a 后转移到状态 s&#39; 的概率。这个概率捕捉了环境的动态性和不确定性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;奖励（R）&lt;/strong&gt;：函数 R(s, a, s&#39;) 表示从状态 s 采取动作 a 并转移到状态 s&#39; 所得到的即时奖励（或成本）。奖励函数评估每个动作的即时效用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;目标是找到一个&lt;strong&gt;策略&lt;/strong&gt;（Policy），即从每个状态到动作的映射，以最大化某种性能标准，通常是预期收益的总和。这种性能标准可以是累积奖励的总和，也可能涉及对未来奖励的贴现（Discounting）。&lt;/p&gt;
&lt;p&gt;在解决 MDP 问题时，通常涉及到两种主要的策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;价值迭代（Value Iteration）&lt;/strong&gt;：通过不断迭代更新状态值函数来逼近最优解，直到达到稳定状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;策略迭代（Policy Iteration）&lt;/strong&gt;：包含两个步骤，策略评估（计算当前策略的值）和策略改进（基于当前值函数更新策略），这两个步骤交替进行直到策略收敛。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MDP 提供了一种强大的框架来模拟和解决决策问题，尤其是在考虑时间和不确定性时。在强化学习中，智能体通过与环境的交互来学习最优策略，通常是在没有初始知识的情况下通过试错学习。&lt;/p&gt;
&lt;h1 id=&#34;马尔可夫随机场&#34;&gt;马尔可夫随机场&lt;/h1&gt;
&lt;p&gt;马尔可夫随机场（Markov Random Field，MRF），也被称为概率无向图模型，是一种用于建模多元随机变量联合分布的统计模型，其中变量间的关系用一个无向图来表示。在这个图中，每个节点代表一个随机变量，而边则表示变量之间的潜在依赖关系。&lt;/p&gt;
&lt;p&gt;MRF 主要用于建模那些变量间具有空间或者其他形式相互依赖性的系统，广泛应用于图像处理、空间数据分析和计算机视觉等领域。MRF 的一个关键特性是局部性原理，即给定某个变量的邻居（在图中直接与之相连的节点）后，该变量条件独立于其它所有变量。这种性质被称为马尔可夫性质。&lt;/p&gt;
&lt;h3 id=&#34;关键概念&#34;&gt;关键概念&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;节点&lt;/strong&gt;：图中的每个节点代表一个随机变量，可以是观测到的数据点或是隐藏变量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;边&lt;/strong&gt;：节点之间的边表示变量间的直接依赖关系。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;团和最大团&lt;/strong&gt;：在图中，任何相互连接的节点集合称为团。不可能加入更多节点的团称为最大团。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;势函数&lt;/strong&gt;：用于量化节点或节点组合的概率分布，通常定义在最大团上。势函数表达了变量之间的相互作用强度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;马尔可夫性质&#34;&gt;马尔可夫性质&lt;/h3&gt;
&lt;p&gt;MRF 的核心是马尔可夫性质，即在给定一个节点的邻居的情况下，该节点与图中其他节点条件独立。这意味着，节点的局部环境提供了足够的信息来预测该节点的行为，而无需考虑更远的节点。&lt;/p&gt;
&lt;h3 id=&#34;hammersley-clifford-定理&#34;&gt;Hammersley-Clifford 定理&lt;/h3&gt;
&lt;p&gt;这个定理是 MRF 理论中的一个关键结果，它指出：在满足一定条件下，一个分布可以被表示为一个马尔可夫随机场，如果且仅如果它可以被表示为一个图上的势函数的乘积形式。&lt;/p&gt;
&lt;h3 id=&#34;应用示例&#34;&gt;应用示例&lt;/h3&gt;
&lt;p&gt;在图像处理中，MRF 可以用于图像恢复、分割和纹理合成。比如，在噪声图像恢复中，每个像素点可以视为一个随机变量，相邻像素间的相关性可以用 MRF 来建模，以此推断最可能的干净图像。&lt;/p&gt;
&lt;h3 id=&#34;求解方法&#34;&gt;求解方法&lt;/h3&gt;
&lt;p&gt;MRF 的推断和学习通常是计算密集型的，常用的方法包括吉布斯采样（Gibbs Sampling）、模拟退火（Simulated Annealing）和置信传播（Belief Propagation）等。这些方法旨在通过迭代过程来近似地估计或优化目标函数，从而解决相关的最优化问题。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_40986693/article/details/104179088&#34;&gt;Belief Propagation信念传播算法详解&lt;/a&gt;&lt;br&gt;
马尔科夫随机场提供了一种建模多变量依赖关系的框架，而信念传播算法则是一种在这种框架下进行有效推理的方法。通过在马尔科夫随机场上运用信念传播算法，可以进行高效的概率推断和决策。&lt;/p&gt;
&lt;h1 id=&#34;关于马尔可夫模型的问答&#34;&gt;关于马尔可夫模型的问答&lt;/h1&gt;
&lt;h3 id=&#34;基础理解&#34;&gt;基础理解&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;请解释什么是马尔可夫链以及它的基本性质。&lt;br&gt;
马尔可夫链是一种随机过程，其中下一个状态的概率仅依赖于当前状态，这被称为无记忆性。基本性质包括状态空间、初始状态概率和状态转移概率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;描述隐马尔可夫模型（HMM）及其与马尔可夫链的主要区别。&lt;br&gt;
HMM是一种统计模型，它用来描述观测序列背后的一个不可见的状态序列。与马尔可夫链不同，HMM包含隐状态和观测状态，且观测状态的概率分布依赖于隐状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;马尔可夫链的“无记忆性”或“马尔可夫性”是什么意思？请给出一个实际应用的例子。&lt;br&gt;
马尔可夫性指的是系统的下一个状态仅依赖于当前状态，而与之前的历史无关。例如，天气模型中，明天是晴天还是雨天仅依赖于今天的天气，而不是之前的天气历史。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在隐马尔可夫模型中，什么是隐状态？什么是观测状态？&lt;br&gt;
在HMM中，隐状态是模型中不直接可见的内部状态，而观测状态是由隐状态生成的、可以直接观察到的状态。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;数学与算法&#34;&gt;数学与算法&lt;/h3&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;
&lt;p&gt;如何表示和计算马尔可夫链的状态转移概率矩阵？&lt;br&gt;
状态转移概率矩阵是一个方阵，其元素 aij 表示从状态 i 转移到状态 j 的概率。（邻接矩阵）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解释隐马尔可夫模型中的前向算法和后向算法的作用。&lt;br&gt;
前向算法用于计算在给定模型参数的情况下，观测序列出现的概率。后向算法也用于相似的目的，但是从序列的末尾开始计算。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;什么是Viterbi算法？它在隐马尔可夫模型中用来解决什么问题？&lt;br&gt;
Viterbi算法是一种动态规划算法，用于找出最有可能产生给定观测序列的隐状态序列，在HMM中用于解决解码问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;描述Baum-Welch算法在隐马尔可夫模型中的应用及其目的。&lt;br&gt;
Baum-Welch算法是一种特殊的EM算法，用于未知参数的HMM中。它通过迭代过程优化模型参数以最大化给定观测序列的概率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;应用与实践&#34;&gt;应用与实践&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;描述一个使用隐马尔可夫模型的自然语言处理应用案例。&lt;br&gt;
在自然语言处理中，HMM可用于词性标注，其中隐状态代表单词的词性，观测状态代表实际的单词。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;深度与挑战&#34;&gt;深度与挑战&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在处理非平稳时间序列数据时，马尔可夫链模型有哪些局限性，如何克服？&lt;br&gt;
马尔可夫链假设转移概率不随时间变化。对于非平稳数据，可以使用时间依赖的马尔可夫模型或通过增加状态来模拟时间变化的影响。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于有大量状态的系统，隐马尔可夫模型的性能和可行性如何？存在哪些优化或替代方案？&lt;br&gt;
当状态空间很大时，HMM的计算复杂性会显著增加。可能的优化包括使用近似方法、约简状态空间或采用更高效的算法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;讨论在实际应用中构建和训练隐马尔可夫模型时可能遇到的挑战及其解决方案。&lt;br&gt;
实际应用中的挑战包括数据稀疏性、参数初始化以及模型选择。解决方案可能包括使用平滑技术、合理的启发式初始化策略和交叉验证来选择模型。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
">【NLP】时序模型与马尔可夫模型</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ml-softmax/"" data-c="
          &lt;p&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710168281390.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
Softmax 函数如上图所示，分子 xi 是每个数据的值，将其指数化，将输出的数值拉开距离。分母是所有数据指数之和，这是一种概率形式，表达为样本占所有值的概率。&lt;br&gt;
它可以用作 Softmax 回归、Softmax 激活函数在神经网络中往往用在最后一层，特别是在处理分类问题时，将网络的原始输出转换为更直观的概率形式。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/105722023&#34;&gt;一文详解Softmax函数&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Softmax 从字面上来说，可以分成soft和max两个部分。
max故名思议就是最大值的意思。Softmax的核心在于soft，而soft有软的含义，与之相对的是hard硬。
很多场景中需要我们找出数组所有元素中值最大的元素，实质上都是求的hardmax。
hardmax 是求一组数据中唯一的最大值，而 Softmax 是输出概率，可以自己选择概率最大的前几个值
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV18u411L7tU/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;什么是softmax回归，如何使用softmax回归，解决多分类任务&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Softmax 激活函数：通常用于多分类问题的输出层（最后一层），将 logits（即最后一个线性层的输出）转换成概率分布。&lt;br&gt;
隐藏层激活函数不用 Softmax，用 ReLU、tanh 和 sigmoid 等，用于增加网络的非线性，帮助模型学习复杂的特征表示。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;拓展&lt;/code&gt;&lt;br&gt;
Sigmoid 函数可以用于二分类，而 Softmax 是多分类&lt;br&gt;
Sigmoid 表达式如下&lt;/p&gt;
&lt;h2 id=&#34;sigmax-frac11-e-x&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\sigma(x) = \frac{1}{1 + e^{-x}}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;σ&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.2484389999999999em;vertical-align:-0.403331em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.845108em;&#34;&gt;&lt;span style=&#34;top:-2.655em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.7026642857142857em;&#34;&gt;&lt;span style=&#34;top:-2.786em;margin-right:0.07142857142857144em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.5em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.403331em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Sigmoid函数的输出值范围在0到1之间，这使得它能够输出一个概率值。因此，Sigmoid函数常用于二分类问题，其中输出值可以解释为样本属于正类的概率。&lt;br&gt;
在二分类问题中，如果一个样本的Sigmoid函数输出接近1，则可以认为该样本属于正类；如果输出接近0，则认为该样本属于负类。通常，我们会设置一个阈值（例如0.5），如果输出值大于这个阈值，则预测为正类；否则，预测为负类。&lt;/p&gt;
">【ML】Softmax</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/dl-transformer/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1MY41137AK/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【Transformer模型】曼妙动画轻松学，形象比喻贼好记&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1ih4y1J7rx/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;超强动画，一步一步深入浅出解释Transformer原理！&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1Kq4y1H7FL?p=1&#34;&gt;68 Transformer【动手学深度学习v2】&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/338817680&#34;&gt;Transformer模型详解（图解最完整版）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/403433120&#34;&gt;【Transformer】10分钟学会Transformer | Pytorch代码讲解 | 代码可运行&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;Transformer论文逐段精读【论文精读】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/194308943&#34;&gt;Seq2Seq模型介绍&lt;/a&gt;&lt;br&gt;
Transformer：Seq2Seq model with attention&lt;/p&gt;
&lt;h1 id=&#34;结构介绍&#34;&gt;结构介绍&lt;/h1&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710839949031.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;attention&#34;&gt;Attention&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1264y1i7R1/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;64 注意力机制【动手学深度学习v2】&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1QW4y167iq/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;09 Transformer 之什么是注意力机制（Attention）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1q3411U7Hi/?spm_id_from=333.788.recommend_more_video.5&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;Attention、Transformer公式推导和矩阵变化&lt;/a&gt;&lt;br&gt;
和RNN的区别：RNN 是串行的，attention 是并行的。时序模型会占用很大的内存，而且容易遗忘前面学过的东西，transformer使用attention矩阵运算，使得数据可以并行计算，提升了效率&lt;/p&gt;
&lt;p&gt;Query，Key，Value 的概念取自于信息检索系统，举个简单的搜索的例子来说。当你在某电商平台搜索某件商品（年轻女士冬季穿的红色薄款羽绒服）时，你在搜索引擎上输入的内容便是 Query。&lt;br&gt;
然后搜索引擎根据 Query 为你匹配 Key（例如商品的种类，颜色，描述等）。&lt;br&gt;
然后根据 Query 和 Key 的&lt;code&gt;相似度&lt;/code&gt;，用 softmax 选择概率最大的，将结果和V相乘，得到 Value 中最匹配的内容。&lt;/p&gt;
&lt;p&gt;相似度计算：QK 求内积（余弦相似度）&lt;/p&gt;
&lt;p&gt;多头注意力机制是指，有n个自注意力模块，每个自注意力模块都有 QKV 三个矩阵。多头注意力的作用可以类比多卷积核，为了更好的提取特征&lt;/p&gt;
&lt;p&gt;分为注意力、自注意力、带有mask的注意力&lt;br&gt;
注意力：简单的 QKV&lt;br&gt;
自注意力：QKV都来自于序列自己&lt;br&gt;
带有mask的注意力：attention 每一次都可以看见完整的输入，而训练 decoder 的时候，由于要预测 t 时刻后的输入，所以 decoder 的 attention 是带 mask 的，保证在 t 时间输入后不会看见 t 时间之后的输入，确保模型在生成每个词时只能依赖于它之前的词，从而保持自回归特性。&lt;/p&gt;
&lt;h2 id=&#34;feed-forward&#34;&gt;Feed Forward&lt;/h2&gt;
&lt;p&gt;全连接层&lt;/p&gt;
&lt;h2 id=&#34;addnorm&#34;&gt;Add&amp;amp;Norm&lt;/h2&gt;
&lt;p&gt;Add 是一个残差块，和 ResNet 中的一样，使得网络能做很深&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710840452631.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
为什么采用 layer norm 而不是 batch norm：因为在语言 embedding 中，每个样本的长度可能不一样，所以以 batch 为单位进行标准化会有无用信息；而 layer norm 是将每个特征做标准化，效果更好&lt;/p&gt;
&lt;h2 id=&#34;encoder-decoder&#34;&gt;encoder-decoder&lt;/h2&gt;
&lt;p&gt;encoder和decoder是一一对应的，且encoder的输出维度等于decoder的输入维度&lt;br&gt;
编码器的输出，将其作为解码器中第二层注意力的 key 和 value，其 query 来自目标序列&lt;/p&gt;
&lt;p&gt;原文 encoder 和 decoder 都用了6个&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思维导图&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1686115237621.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1686115244889.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1686115251026.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1686115255439.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;变体&#34;&gt;变体&lt;/h1&gt;
&lt;p&gt;Transformer 模型自从在 &amp;quot;Attention is All You Need&amp;quot; 论文中被首次提出以来，已经孕育出许多变体，这些变体针对不同的应用场景和性能优化进行了设计。以下是一些比较著名的 Transformer 模型变体：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;BERT (Bidirectional Encoder Representations from Transformers)&lt;/strong&gt;: 由 Google 提出，BERT 通过双向训练的方式来更好地理解语言上下文，广泛应用于文本分类、命名实体识别、问答系统等领域。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GPT (Generative Pre-trained Transformer)&lt;/strong&gt;: OpenAI 开发的一系列模型，包括 GPT、GPT-2、GPT-3 等，主要用于文本生成任务，如文本续写、机器翻译、对话系统等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transformer-XL&lt;/strong&gt;: 这个变体通过使用一个特殊的序列建模方式解决了标准 Transformer 在处理长序列时的限制，它能够在长序列文本上获得更好的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;XLNet&lt;/strong&gt;: 结合了 Transformer-XL 和 GPT 的优点，使用了双向上下文和排列语言模型的训练方式，表现在很多自然语言处理任务中超越了 BERT。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RoBERTa (Robustly Optimized BERT approach)&lt;/strong&gt;: 是 BERT 的一个优化版本，通过更大规模的数据集和更长时间的训练，以及调整了一些超参数，来提高模型的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ALBERT (A Lite BERT)&lt;/strong&gt;: 通过参数共享和因子化嵌入矩阵，显著减少了模型的大小，同时保持或超越了 BERT 的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;T5 (Text-to-Text Transfer Transformer)&lt;/strong&gt;: 将各种自然语言处理任务统一为一个文本到文本的框架，通过简化任务格式提高了模型的通用性和灵活性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Electra&lt;/strong&gt;: 通过引入更有效率的预训练任务（类似于GAN的判别器任务），在较小的计算预算下达到或超过了 BERT 的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DeBERTa (Decoding-enhanced BERT with Disentangled Attention)&lt;/strong&gt;: 通过改进 BERT 的注意力机制，引入解耦注意力和增强的掩码解码器，提高了模型处理自然语言理解任务的能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ViT (Vision Transformer)&lt;/strong&gt;: 将 Transformer 应用于图像分类任务，通过将图像分割成多个小块（patches）并将它们作为序列输入到 Transformer 中，展示了 Transformer 架构在非NLP任务上的潜力。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
">【DL】Transformer</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/dl-mo-xing-fu-yong/"" data-c="
          &lt;p&gt;模型复用，通常在机器学习和深度学习领域称为迁移学习（Transfer Learning），是一种非常有效的方法，可以将在一个任务上训练好的模型应用到另一个相关但不同的任务上。这种方法特别有用，因为从头开始训练一个复杂模型通常需要大量的计算资源和大量的标记数据，而这两者在很多情况下都是昂贵或难以获得的。&lt;/p&gt;
&lt;h1 id=&#34;fine-tuning&#34;&gt;Fine Tuning&lt;/h1&gt;
&lt;h3 id=&#34;模型复用的基本思想&#34;&gt;模型复用的基本思想&lt;/h3&gt;
&lt;p&gt;模型复用的核心思想是，对于不同但相关的任务，模型学习到的特征或知识在一定程度上是通用的。例如，一个在大型图像数据集（如ImageNet）上训练好的卷积神经网络（CNN）学会了识别各种视觉模式和结构，这些模式和结构对于其他视觉识别任务也是有用的。&lt;/p&gt;
&lt;h3 id=&#34;迁移学习的主要步骤&#34;&gt;迁移学习的主要步骤&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;预训练模型选择&lt;/strong&gt;：选择一个与目标任务相似或相关领域的预训练模型。例如，对于图像识别任务，人们常用在ImageNet数据集上预训练的模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;特征提取&lt;/strong&gt;：使用预训练模型的一部分（通常是除最后一层之外的所有层）作为特征提取器。这些层已经学会了从输入数据中提取有用的特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;微调&lt;/strong&gt;：根据具体任务，可以对预训练模型的顶层或所有层进行微调。微调是通过在新的目标任务上继续训练模型来完成的，这通常需要较小的学习率，以避免破坏已经学到的特征表示。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;冻结层&lt;/strong&gt;：在微调过程中，可以选择冻结预训练模型的一部分，以保留在原始任务上学到的特征。通常，只有模型的一部分（如顶层）被解冻以进行微调。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;模型复用的优点&#34;&gt;模型复用的优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据需求降低&lt;/strong&gt;：迁移学习允许使用较少的标记数据来训练模型，因为模型已经从预训练任务中学习了很多有用的特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练时间缩短&lt;/strong&gt;：由于模型不是从零开始训练，因此训练时间通常会大大缩短。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提高性能&lt;/strong&gt;：迁移学习可以帮助提高模型在特定任务上的性能，尤其是当原始数据集非常大且多样时。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景&lt;/h3&gt;
&lt;p&gt;迁移学习在许多领域都有应用，包括但不限于图像识别、自然语言处理（NLP）、语音识别和增强现实等。在NLP中，预训练的语言模型如BERT和GPT系列已经成为许多下游任务的基础。&lt;/p&gt;
&lt;p&gt;模型复用利用了已有知识，可以加速模型的开发过程，并提高模型在特定任务上的表现，尤其是在数据有限的情况下。&lt;/p&gt;
&lt;h1 id=&#34;model-ensemble&#34;&gt;Model Ensemble&lt;/h1&gt;
&lt;p&gt;将多个小模型结合起来解决不同的问题并实现模型复用，通常涉及到模型集成和多任务学习的策略。这些方法允许模型共享知识，并提高整体性能，特别是在数据稀缺或每个单独任务的数据不足以训练一个复杂模型的情况下。&lt;/p&gt;
&lt;h3 id=&#34;模型集成model-ensemble&#34;&gt;模型集成（Model Ensemble）&lt;/h3&gt;
&lt;p&gt;模型集成涉及到将多个模型的预测结果结合起来，以提高整体的预测性能。这些模型可以是针对同一个任务的不同模型，也可以是针对不同任务的模型。集成方法包括但不限于：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;简单平均（Simple Averaging）&lt;/strong&gt;：对所有模型的预测结果进行算术平均。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;加权平均（Weighted Averaging）&lt;/strong&gt;：根据每个模型的性能给予不同的权重，然后进行加权平均。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;投票法（Voting）&lt;/strong&gt;：对于分类问题，每个模型为每个类别投票，最终决策基于最多投票的类别。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;堆叠（Stacking）&lt;/strong&gt;：在堆叠方法中，多个模型的预测结果被用作另一个模型（称为元学习器或二级模型）的输入，以进行最终预测。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;多任务学习multi-task-learning&#34;&gt;多任务学习（Multi-task Learning）&lt;/h3&gt;
&lt;p&gt;多任务学习是一种同时解决多个相关任务的方法，通过共享底层表示，这种方法可以提高各个任务的学习效率和预测性能。多任务学习的关键在于找到一种方式让模型的不同部分专注于不同的任务：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;共享底层&lt;/strong&gt;：在这种方法中，模型的底层（例如，神经网络的前几层）被多个任务共享，而顶层被设计为任务特定的层。这允许模型学习到可以跨多个任务通用的特征或表示。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;软参数共享&lt;/strong&gt;：在软参数共享中，不同任务的模型有自己的参数，但是这些参数之间通过某种方式（如正则化）相互约束，以鼓励它们学到相似的表示。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;任务特定的分支&lt;/strong&gt;：在这种结构中，模型从一个共享层分叉出多个分支，每个分支负责不同的任务。这种方法在多模态学习和多任务学习中尤其常见，其中不同的输入类型或不同的任务要求模型有不同的处理分支。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;模型复用策略&#34;&gt;模型复用策略&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;预训练和微调&lt;/strong&gt;：可以通过在一个通用任务上预训练模型，然后在特定任务上微调模型的某些层来实现模型复用。这在自然语言处理和图像处理领域尤为常见。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;特征提取&lt;/strong&gt;：利用预训练模型作为特征提取器，提取的特征可以用于不同任务的模型训练中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模型蒸馏（Model Distillation）&lt;/strong&gt;：通过模型蒸馏，可以将一个大型模型的知识转移到多个小型模型中。这些小型模型可以针对不同的任务进行优化，同时保持较小的模型大小和更快的推理速度。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;将多个小模型结合起来解决不同的问题，需要仔细考虑每个模型的输出如何能为其他任务提供有价值的信息，以及如何在不同模型间高效地共享知识。这通常需要对任务之间&lt;/p&gt;
">【DL】模型复用</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/fen-lei-he-hui-gui/"" data-c="
          &lt;h1 id=&#34;分类&#34;&gt;分类&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;目标变量&lt;/strong&gt;：分类任务中的目标变量是离散的，也就是说，它将输入数据映射到预定义的类别或标签中。这些类别通常是有限的且不连续的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用场景&lt;/strong&gt;：邮件是否为垃圾邮件、图像中是否含有特定物体、患者是否患有某种疾病等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;决策树（如CART, ID3, C4.5）&lt;/li&gt;
&lt;li&gt;支持向量机（SVM）&lt;/li&gt;
&lt;li&gt;逻辑回归&lt;/li&gt;
&lt;li&gt;K最近邻（KNN）&lt;/li&gt;
&lt;li&gt;随机森林&lt;/li&gt;
&lt;li&gt;梯度提升决策树（如XGBoost, LightGBM, CatBoost）&lt;/li&gt;
&lt;li&gt;神经网络&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;回归&#34;&gt;回归&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;目标变量&lt;/strong&gt;：回归任务中的目标变量是连续的数值。模型的目的是预测出一个具体的数值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用场景&lt;/strong&gt;：房价预测、股票价格预测、温度预测等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;常用算法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;线性回归&lt;/li&gt;
&lt;li&gt;多项式回归&lt;/li&gt;
&lt;li&gt;决策树回归&lt;/li&gt;
&lt;li&gt;支持向量回归（SVR）&lt;/li&gt;
&lt;li&gt;随机森林回归&lt;/li&gt;
&lt;li&gt;梯度提升决策树回归（如XGBoost, LightGBM）&lt;/li&gt;
&lt;li&gt;神经网络&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;主要区别&#34;&gt;主要区别&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;输出类型&lt;/strong&gt;：分类是预测离散标签，而回归是预测连续数值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估标准&lt;/strong&gt;：分类任务通常使用准确率、精确度、召回率、F1分数等指标进行评估；回归任务则常用均方误差（MSE）、均方根误差（RMSE）、平均绝对误差（MAE）等指标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;决策边界&lt;/strong&gt;：分类任务通常涉及到找到决策边界来区分不同的类别；回归任务则是找到一个最佳拟合线或曲面来预测连续值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;主要联系&#34;&gt;主要联系&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;监督学习&lt;/strong&gt;：无论是分类还是回归，它们都属于监督学习范畴，这意味着它们都使用已标注的训练数据来学习输入和输出之间的映射关系。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型构建与预测&lt;/strong&gt;：分类和回归都涉及到使用训练数据构建模型，并使用这些模型来对新的、未见过的数据进行预测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;损失函数&lt;/strong&gt;：两者都通过最小化损失函数来训练模型。虽然使用的具体损失函数可能不同（如分类通常使用交叉熵损失，回归通常使用均方误差损失），但最小化损失函数的基本思想是一致的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;从回归到分类的转变&#34;&gt;从回归到分类的转变&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在某些情况下，可以通过引入阈值将回归问题转化为分类问题。例如，在一个二元分类问题中，模型的输出可以是一个连续的概率值，当这个概率值超过某个阈值时，可以将其视为一个类别，否则视为另一个类别。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;从分类到回归的转变&#34;&gt;从分类到回归的转变&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在某些情况下，分类问题也可以转换为回归问题，特别是当类别之间存在天然顺序（有序分类）时。通过预测一个连续的数值并将其映射到最接近的类别，可以处理这类问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总的来说，虽然分类和回归处理的是不同类型的问题，但它们在许多方面是相似的，使用相似的方法，很多算法和技术可以在这两种任务之间转换和重用。&lt;/p&gt;
&lt;h1 id=&#34;既可分类又可回归的算法&#34;&gt;既可分类又可回归的算法&lt;/h1&gt;
&lt;h2 id=&#34;支持向量机&#34;&gt;支持向量机&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/ml-zhi-chi-xiang-liang-ji-svm&#34;&gt;【ML】支持向量机（SVM）&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;knnk-最近邻&#34;&gt;KNN（K-最近邻）&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Ma411F7Y4/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/codedz/article/details/108862498&#34;&gt;KNN算法详解及实现&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/341572059&#34;&gt;史上最全面K近邻算法/KNN算法详解+python实现&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;由距离待决策样本最近的k个元素投票决定样本类别&lt;/p&gt;
&lt;p&gt;&lt;code&gt;总结：&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有监督学习&lt;/li&gt;
&lt;li&gt;用于分类和回归任务&lt;/li&gt;
&lt;li&gt;物体类别由旁边最近的K个样本决定&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;决策树和随机森林&#34;&gt;决策树和随机森林&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/ml-jue-ce-shu/&#34;&gt;【ML】决策树和随机森林&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;梯度提升决策树-gradient-boosted-decision-trees-gbdt&#34;&gt;梯度提升决策树 (Gradient Boosted Decision Trees, GBDT)&lt;/h2&gt;
&lt;p&gt;梯度提升决策树（Gradient Boosted Decision Trees，GBDT）是一种强大的机器学习算法，用于回归和分类问题，属于集成学习方法的一种。它通过结合多个简单的模型（通常是决策树）来构建一个复杂的模型，以此来提高预测的准确性。GBDT 的核心思想是逐步添加模型（通常是决策树），每次添加的模型都试图纠正前面所有模型的预测残差。&lt;/p&gt;
&lt;h3 id=&#34;工作原理&#34;&gt;工作原理:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;初始化&lt;/strong&gt;: GBDT 首先使用一个基本模型（通常是一个常数值）来进行初始化，作为第一个基学习器，对所有数据做一个初步预测。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;迭代添加决策树&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在每一轮迭代中，GBDT 都会添加一个新的决策树来对之前所有树的预测残差进行拟合。&lt;/li&gt;
&lt;li&gt;新添加的树试图补偿或改正之前所有树的总体预测中的错误。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;梯度下降&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“梯度提升”中的“梯度”指的是损失函数的梯度，GBDT 通过计算损失函数关于模型预测的梯度来确定残差的方向。&lt;/li&gt;
&lt;li&gt;新树的目标是减少残差，这类似于梯度下降法中参数更新的过程。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;学习率&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GBDT 引入了一个学习率（也称作缩减系数）来控制每棵树对最终模型的贡献程度，以避免过拟合。&lt;/li&gt;
&lt;li&gt;学习率较小意味着需要更多的树来构建模型，但模型的泛化能力通常更好。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;停止准则&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GBDT 的训练会在达到指定的树的数量、达到一定的误差改善阈值或满足其他停止条件时结束。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;特点&#34;&gt;特点:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;准确性高&lt;/strong&gt;：通过逐步减少残差，GBDT 能够构建非常精确的预测模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;：可以用于分类、回归甚至排序任务，并且能处理各种类型的数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可解释性&lt;/strong&gt;：虽然不如单一决策树，但相比于很多其他复杂模型，GBDT 的结果更容易理解。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GBDT 在许多领域都有应用，包括但不限于搜索引擎（如排名算法）、生态模型、金融风险管理等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;流行的gbdt实现&#34;&gt;流行的GBDT实现:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;XGBoost&lt;/strong&gt;: 扩展梯度提升，优化了速度和效率，增加了正则化项以控制模型的复杂度，从而避免过拟合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LightGBM&lt;/strong&gt;: 微软开发的框架，优化了大规模数据的处理，通过梯度单边采样（GOSS）和互斥特征捆绑（EFB）技术提高了效率和速度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CatBoost&lt;/strong&gt;: Yandex 开发，特别优化了类别特征的处理，提供了更好的准确性和训练速度。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GBDT 由于其高效性和灵活性，在工业界和各种数据科学竞赛中非常受欢迎。&lt;/p&gt;
&lt;h2 id=&#34;高斯过程-gaussian-processesgp&#34;&gt;高斯过程 Gaussian Processes(GP)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/46631426&#34;&gt;如何通俗易懂地介绍 Gaussian Process？&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;随机过程&lt;/strong&gt;&lt;br&gt;
在机器学习和深度学习领域，随机过程的概念和方法学被广泛应用于算法的开发和数据分析中，主要应用包括但不限于以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;随机优化方法&lt;/strong&gt;：在机器学习模型的训练过程中，随机梯度下降（SGD）及其变体是非常流行的优化算法。这些算法利用随机性来有效地搜索参数空间，以找到使损失函数最小化的参数。随机性有助于算法跳出局部最小值，更可能找到全局最小值或较好的局部最小值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;贝叶斯方法&lt;/strong&gt;：贝叶斯方法在机器学习中用于推理和决策，它们本质上依赖于随机过程的概念。例如，高斯过程是一种用于回归和分类任务的贝叶斯非参数方法，它可以提供关于预测的不确定性的信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;序列模型&lt;/strong&gt;：在自然语言处理（NLP）、语音识别、时间序列分析和其他序列数据处理领域，随机过程模型如隐马尔可夫模型（HMMs）和循环神经网络（RNNs）及其变体（如长短期记忆网络LSTM和门控循环单元GRU）被用来捕捉序列数据中的时间依赖性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;增强学习&lt;/strong&gt;：在增强学习中，马尔可夫决策过程（MDPs）提供了一个框架，用于建模决策制定者（智能体）与环境之间的交互。每个决策或行动都会导致状态的变化和一定的奖励，智能体的目标是通过学习最佳策略来最大化其获得的总奖励。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;随机网络&lt;/strong&gt;：在深度学习中，一些网络结构引入了随机性以增强模型的泛化能力和鲁棒性。例如，Dropout技术通过在训练过程中随机忽略神经网络中的一部分神经元，来防止模型的过拟合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生成模型&lt;/strong&gt;：在生成对抗网络（GANs）和变分自编码器（VAEs）等生成模型中，随机性被用来生成新的、与训练数据相似的数据实例。这些模型在图像生成、文本到图像的转换和其他生成任务中表现出色。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些应用显示了随机过程在现代机器学习和深度学习算法设计和数据分析中的广泛影响。随机性不仅增加了模型的灵活性，还有助于提高算法的效率和鲁棒性。&lt;/p&gt;
&lt;p&gt;高斯过程（Gaussian Process, GP）是一种非参数贝叶斯模型，广泛应用于机器学习中的回归、分类和其他任务。在高斯过程中，对于给定的数据集，模型假设数据可以由一个具有连续输入空间的随机过程生成，且该过程的任意有限集合的联合分布都是高斯分布的。换句话说，高斯过程提供了一种优雅的方法来描述函数的分布，使我们能够在数据点之间进行平滑插值，预测新的数据点，并量化预测的不确定性。&lt;/p&gt;
&lt;h3 id=&#34;核心概念&#34;&gt;核心概念&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;非参数方法&lt;/strong&gt;：尽管称为“非参数”，这并不意味着高斯过程中没有参数。相反，这意味着它们不依赖于固定维数的参数向量，模型复杂度可以随着数据量的增加而增加。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;随机过程&lt;/strong&gt;：高斯过程是一种随机过程，其中每个点 x 都被映射到一个随机变量 f(x) ，而这些随机变量的任意有限集合的联合分布都是高斯的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;均值函数和协方差函数&lt;/strong&gt;：高斯过程由均值函数和协方差函数完全定义。均值函数定义了过程的平均水平，通常可以设置为零或其他简单形式。协方差函数（或核函数）定义了任意两点间的协方差，从而编码了函数值之间的相似性或平滑度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;高斯过程回归gpr&#34;&gt;高斯过程回归（GPR）&lt;/h3&gt;
&lt;p&gt;在高斯过程回归（Gaussian Process Regression, GPR）中，目标是根据一组观测数据来预测新数据点的值。GPR的强大之处在于其能够提供预测的不确定性估计，这对于许多应用（如优化和控制）来说是非常宝贵的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;先验分布&lt;/strong&gt;：在观察到任何数据之前，假设函数遵循一个高斯过程先验分布，具有特定的均值和协方差函数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;后验分布&lt;/strong&gt;：给定观测数据，使用贝叶斯规则更新对函数的信念，从而得到后验分布。后验分布考虑了观测数据，可以用来进行预测。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;预测和不确定性&lt;/strong&gt;：在新的输入点，后验分布提供了对应函数值的最佳估计以及估计的不确定性（通常表现为置信区间）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;优缺点&#34;&gt;优缺点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：能够提供预测的不确定性度量；适应性强，可以通过选择合适的协方差函数来捕捉复杂的数据模式；非参数特性使得模型复杂度可以随数据量自动调整。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：对于大数据集，计算成本可能非常高，因为需要对协方差矩阵进行求逆或其他线性代数操作，这些操作的计算复杂度通常是数据点数目的三次方。此外，选择和调整协方差函数的形式可能比较困难，需要专业知识和经验。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;常用于分类的算法&#34;&gt;常用于分类的算法&lt;/h1&gt;
&lt;h2 id=&#34;logistic回归逻辑回归&#34;&gt;Logistic回归（逻辑回归）&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1gA411i7SR/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【五分钟机器学习】机器分类的基石：逻辑回归Logistic Regression&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;线性回归输出一个连续值，适用于预测问题，如房价；逻辑回归输出一个概率值，适用于分类问题。&lt;br&gt;
逻辑回归使用 Sigmoid 函数，将线性回归的输出映射为 0 到 1 之间的概率。Sigmoid 函数也叫做 Logistic 函数，所以叫 Logistic 回归；&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710232480219.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
逻辑回归用的是交叉熵函数，来判断模型的优劣；&lt;/p&gt;
&lt;h2 id=&#34;朴素贝叶斯&#34;&gt;朴素贝叶斯&lt;/h2&gt;
&lt;p&gt;朴素：每个特征相互独立&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/26262151&#34;&gt;带你理解朴素贝叶斯分类算法&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;半监督学习&#34;&gt;半监督学习&lt;/h2&gt;
&lt;p&gt;介于监督学习和无监督学习之间，算法利用大量的未标记数据和少量的标记数据来进行模型训练。这种方法在实际应用中非常有用，因为在许多情况下，获取未标记的数据相对容易和成本较低，而获取大量准确的标记数据则更加困难和昂贵。&lt;/p&gt;
&lt;h3 id=&#34;核心思想&#34;&gt;核心思想&lt;/h3&gt;
&lt;p&gt;半监督学习的核心思想是利用未标记数据的分布信息来辅助标记数据的学习过程，以此提高学习的准确性和效率。它基于这样一个假设：相似的数据点可能具有相同的输出标签。&lt;/p&gt;
&lt;h3 id=&#34;常见方法&#34;&gt;常见方法&lt;/h3&gt;
&lt;p&gt;半监督学习包括多种不同的方法，其中一些主要方法包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;自训练（Self-training）&lt;/strong&gt;：首先使用少量的标记数据训练一个监督模型，然后用这个模型对未标记数据进行预测，将预测结果中置信度高的作为新的标记数据加入训练集，反复迭代这个过程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生成模型（Generative Models）&lt;/strong&gt;：使用未标记数据学习数据的生成分布，然后利用这个分布来辅助监督学习任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;协同训练（Co-training）&lt;/strong&gt;：当数据有多个独立的视图（feature sets）时，可以分别在每个视图上训练一个分类器，然后让这些分类器在未标记数据上互相教学。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;图基方法（Graph-based Methods）&lt;/strong&gt;：构建一个图，其中节点代表标记和未标记的数据点，边反映数据点之间的相似性。然后使用图中的信息来推断未标记点的标签。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;半监督支持向量机（Semi-supervised SVM）&lt;/strong&gt;：这是支持向量机的一种变体，它利用未标记数据来寻找决策边界，使得边界尽可能地远离所有数据点，包括未标记和标记的数据点。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;应用场景-2&#34;&gt;应用场景&lt;/h3&gt;
&lt;p&gt;半监督学习在实际应用中非常有价值，特别是在以下情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;标记数据稀缺或获取成本高昂，而未标记数据丰富且易于获取。&lt;/li&gt;
&lt;li&gt;完全监督学习由于标记数据不足而表现不佳。&lt;/li&gt;
&lt;li&gt;需要提高学习算法的泛化能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优缺点-2&#34;&gt;优缺点&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能够利用丰富的未标记数据，减少对标记数据的依赖。&lt;/li&gt;
&lt;li&gt;通常比纯监督学习方法具有更好的泛化能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;半监督学习的有效性依赖于未标记数据的质量和与标记数据的关联性。&lt;/li&gt;
&lt;li&gt;不当的使用可能导致模型偏差，特别是当未标记数据的分布与标记数据不一致时。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;常用于回归的算法&#34;&gt;常用于回归的算法&lt;/h1&gt;
&lt;h2 id=&#34;线性回归最小二乘法&#34;&gt;线性回归——最小二乘法&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/MoreAction_/article/details/106443383?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163978851616780269814649%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;amp;request_id=163978851616780269814649&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-6-106443383.pc_search_result_cache&amp;amp;utm_term=%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95&amp;amp;spm=1018.2226.3001.4187&#34;&gt;一文让你彻底搞懂最小二乘法（超详细推导）&lt;/a&gt;&lt;br&gt;
解决线性回归的常用方法，拟合函数时，让整体数据误差的平方和最小（损失函数），损失函数求导令其等于0就可以解出参数 θ&lt;/p&gt;
&lt;h2 id=&#34;多项式回归用基函数扩展线性模型&#34;&gt;多项式回归：用基函数扩展线性模型&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_44225602/article/details/112752565&#34;&gt;多项式回归详解 从零开始 从理论到实践&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;岭回归&#34;&gt;岭回归&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/MoreAction_/article/details/125004112?spm=1001.2014.3001.5502&#34;&gt;详解岭回归与L2正则化&lt;/a&gt;&lt;br&gt;
当样本数据矩阵不可逆时，即数据中存在特征冗余，某些特征可以根据其它特征的线性组合来得到，或者，矩阵为病态矩阵，即求解方程组时对数据的微小扰动比较敏感的矩阵，这两种情况时，最小二乘法无法使用或效果不好，使用岭回归。&lt;br&gt;
岭回归即对应着在最小二乘法基础上增加了一个L2正则化，求导导数=0即可解出参数 θ&lt;/p&gt;
&lt;h2 id=&#34;贝叶斯回归&#34;&gt;贝叶斯回归&lt;/h2&gt;
&lt;p&gt;贝叶斯回归是一种统计方法，它在回归分析的基础上应用了贝叶斯定理，允许我们在预测中考虑参数的不确定性。与传统的回归方法（如线性回归）不同，贝叶斯回归不仅给出了预测值，还提供了预测的不确定性估计，这在很多需要进行风险评估的应用中非常有用。&lt;/p&gt;
&lt;p&gt;在贝叶斯回归中，我们不再寻找一组固定的最优参数值来拟合数据，而是考虑参数的概率分布。这种方法的基本步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;先验分布&lt;/strong&gt;：首先，我们需要对模型参数设置一个先验分布，这反映了我们在观察数据之前对参数的信念。先验可以是无信息的（即不偏向任何特定值的宽泛分布），也可以是有信息的（基于先前研究或专家知识的分布）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;似然函数&lt;/strong&gt;：似然函数描述了给定模型参数时数据出现的概率。在回归分析中，这通常涉及到假设数据中的误差项遵循某种分布，例如正态分布。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;后验分布&lt;/strong&gt;：应用贝叶斯定理结合先验分布和似然函数来计算参数的后验分布。后验分布反映了在考虑了观测数据之后对参数的信念更新。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;预测&lt;/strong&gt;：使用后验分布，我们可以对新的数据点进行预测，并为这些预测提供置信区间或预测区间，从而量化预测的不确定性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;贝叶斯回归的优点&#34;&gt;贝叶斯回归的优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;不确定性量化&lt;/strong&gt;：贝叶斯回归自然地提供了对预测不确定性的量化，这对于风险管理和决策制定非常重要。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;先验知识的整合&lt;/strong&gt;：贝叶斯方法允许我们在分析中显式地使用先前的知识或专家意见，这在数据稀缺的情况下特别有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;：贝叶斯方法可以扩展到复杂的模型，包括非线性模型、层次模型等，且可以较好地处理过拟合问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;贝叶斯回归的挑战&#34;&gt;贝叶斯回归的挑战&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;计算成本&lt;/strong&gt;：贝叶斯分析通常比传统方法更为计算密集，尤其是在后验分布难以解析求解时，可能需要采用数值方法（如马尔可夫链蒙特卡罗方法）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;先验的选择&lt;/strong&gt;：先验分布的选择可能对分析结果有较大影响，选择不当的先验可能会导致误导性的结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型和算法的复杂性&lt;/strong&gt;：实现贝叶斯回归和解释结果可能比传统的回归方法更加复杂。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;尽管存在挑战，贝叶斯回归因其提供预测不确定性的能力以及先验知识整合的优点，在统计分析和机器学习领域中得到了广泛应用。&lt;/p&gt;
">【ML】分类和回归</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/fu-shi-ying-yu/"" data-c="
          &lt;p&gt;Postgraduate是大学毕业（graduate）后继续深造、但未拿到学位（Master或Doctor）之前的身份，Master是硕士学位&lt;/p&gt;
&lt;p&gt;中文：&lt;br&gt;
英文自我介绍&lt;/p&gt;
&lt;p&gt;我叫张继隆，我的英文名叫Jerome，我今年21岁了。我来自天津市，我喜欢我的家乡。我本科就读于北京邮电大学，主修人工智能专业&lt;/p&gt;
&lt;p&gt;我很喜欢人工智能，大学期间，我系统地学习了专业知识，我的线性代数、概率论、机器学习、深度学习、计算机视觉等课程均达到90分以上。我还参加了许多创新比赛，比如数学竞赛，并取得了奖项。做过很多人工智能相关的项目，提升了我的专业素养和专业能力。&lt;br&gt;
我通过了大学英语四六级考试，其中CET6的成绩在550分以上。我一直是一个勤奋好学，不断提升自己的学生，&lt;/p&gt;
&lt;p&gt;我还积极参加各种活动，我喜欢做运动，因为我相信拥有健康的身体可以让我更加积极地学习和工作。同时，我还喜欢音乐和艺术，本科期间是社团的社长，这段经历提升了我的沟通能力，以及对事情的规划能力。对不同领域的探索扩展了我的思维，让我的头脑更加灵活，更能专注于研究工作。&lt;/p&gt;
&lt;p&gt;我选择继续在北邮深造的原因，是因为我深爱着北邮的学术氛围。老师们有很好的品德素养和专业能力，在我学习过程中给予了我很大的帮助。同时我们学校在社会上的认可度一直是很高的，我爱北邮。&lt;/p&gt;
&lt;p&gt;如果给我一个机会，我会继续努力提高自己。如果我的研究能力在研究生期间得到导师的认可，我将继续攻读博士学位。&lt;/p&gt;
&lt;p&gt;最后，我会尽最大努力发掘自己最大的潜力，脚踏实地地做好每件事。这就是我的自我介绍。我真诚地感谢您的聆听&lt;/p&gt;
&lt;p&gt;Dear professors, good morning/afternoon! Thank you for giving me this opportunity to attend the interview. I hope I can make a good performance today. Now I will briefly introduce myself.&lt;/p&gt;
&lt;p&gt;My name is Zhang Jilong, and my English name is Jerome. I am 21 years old this year. I come from Tianjin, and I love my hometown. I completed my undergraduate studies at Beijing University of Posts and Telecommunications. My major is Artificial Intelligence.&lt;/p&gt;
&lt;p&gt;I have a strong passion for artificial intelligence. During my university years, I systematically studied professional knowledge, and my grades in courses such as linear algebra, probability theory, machine learning, deep learning, and computer vision all exceeded 90 points. I also participated in many innovation competitions, such as math competitions, english competitions and won awards. I have worked on many artificial intelligence-related projects, which improved my professional quality and abilities. I passed the College English Test (CET) Levels 4 and 6, with a score of over 550 in CET6. I have always been a diligent and eager student, constantly striving to improve myself.&lt;/p&gt;
&lt;p&gt;Additionally, I actively participated in various activities. I enjoy doing sports because I believe having a healthy body allows me to study and work more positively. At the same time, I also love music and art. During my undergraduate studies, I was the president of a club, which enhanced my communication skills and ability to plan events. Exploring different fields expanded my thinking, making my mind more flexible and more focused on research work.&lt;/p&gt;
&lt;p&gt;The reason I chose to continue my studies at BUPT is my deep love for the academic atmosphere here. The teachers have good moral character and professional abilities, which have been of great help to me in my studies. At the same time, our school&#39;s social recognition has always been very high. I love BUPT.&lt;/p&gt;
&lt;p&gt;If given the opportunity, I will continue to work hard to improve myself. If my research abilities are recognized by my advisors during my graduate studies, I will continue to pursue a Ph.D.&lt;/p&gt;
&lt;p&gt;In conclusion, I will do my best to uncover my greatest potential and earnestly accomplish everything I undertake. This is my self-introduction. I sincerely thank you for listening.&lt;/p&gt;
&lt;p&gt;另外&lt;br&gt;
I will strive to issue some papers on some influencial journals&lt;/p&gt;
">复试英语</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/cv-PhotometricStereo/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://github.com/jeromezjl/PhotometricStereoTutorial&#34;&gt;github链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;多视角、多光照&lt;/p&gt;
&lt;p&gt;多光照：输入多光照图像，输出三维&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Mt4y1a7e6/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【”UE5夯实基础”每日2更系列】13朗伯漫反射理论&lt;/a&gt;&lt;/p&gt;
">【CV】光度立体法 Photometric Stereo</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ml-ji-chu-gai-lan/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://c.d2l.ai/stanford-cs329p/&#34;&gt;Practical Machine Learning&lt;/a&gt;&lt;br&gt;
&lt;code&gt;ML、DL 地图&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1711101084064.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;参数和超参数&#34;&gt;参数和超参数&lt;/h1&gt;
&lt;h2 id=&#34;参数&#34;&gt;参数&lt;/h2&gt;
&lt;p&gt;在深度学习中，参数通常是指神经网络中的权重和偏差。&lt;br&gt;
这些参数是通过&lt;code&gt;反向传播&lt;/code&gt;算法，根据训练数据中的梯度信息自动调整的，以最小化&lt;code&gt;损失函数&lt;/code&gt;。&lt;br&gt;
参数的学习是模型训练的过程，目标是找到最佳的参数配置。&lt;/p&gt;
&lt;h2 id=&#34;超参数&#34;&gt;超参数&lt;/h2&gt;
&lt;p&gt;超参数是在训练开始前设置的参数，与模型的参数（权重和偏置）不同，参数是通过训练数据学习得到的。以下是一些常见的深度学习超参数：&lt;/p&gt;
&lt;p&gt;深度学习模型的性能很大程度上依赖于其超参数的选择。超参数是在训练过程开始前设置的参数，与模型的参数（权重和偏置）不同，后者是通过训练数据学习得到的。以下是一些常见的深度学习超参数：&lt;/p&gt;
&lt;h3 id=&#34;1-学习率-learning-rate&#34;&gt;1. 学习率 (Learning Rate)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;决定模型参数在每次更新时调整的幅度。学习率过高可能导致训练不稳定，过低则训练速度缓慢。&lt;br&gt;
可以动态调整学习率，如使用cos函数学习率&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-批大小-batch-size&#34;&gt;2. 批大小 (Batch Size)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;每次传递给网络以进行一次参数更新的样本数量。批大小影响模型的内存需求和训练稳定性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Batch size 是指在训练神经网络时，每次迭代（每次前向传播和后向传播过程）中用于计算和更新网络参数的样本数量。Batch size 是深度学习中的一个重要超参数，对模型的训练过程和性能有着重要的影响。&lt;/p&gt;
&lt;h4 id=&#34;batch-size-的影响参考梯度下降&#34;&gt;Batch Size 的影响：（参考梯度下降）&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;内存使用&lt;/strong&gt;：较大的 batch size 会增加在每次迭代中处理的数据量，这会导致更高的内存（RAM或GPU内存）使用。如果内存不足，可能无法使用大的 batch size。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;训练速度&lt;/strong&gt;：理论上，较大的 batch size 可以提高计算效率，因为并行处理的数据量更多。然而，每次迭代处理更多的数据也意味着每次参数更新需要更长的时间。实际的训练速度还会受到硬件能力和数据加载速度的影响。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;收敛性和性能&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;较小的 batch size&lt;/strong&gt; 可能导致训练过程中的更多噪声（每次更新的方向变化更大），这有时可以帮助模型跳出局部最小值，可能导致更好的泛化能力。但同时，训练过程可能更不稳定，收敛速度可能较慢。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;较大的 batch size&lt;/strong&gt; 提供了更准确的梯度估计，可能导致更快的收敛。但是，这也可能使模型更容易陷入局部最小值或鞍点，尤其是在损失曲面复杂的情况下。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;泛化能力&lt;/strong&gt;：一些研究表明，使用较小的 batch size 训练的模型可能具有更好的泛化能力，尽管这并不是绝对的，且可能取决于具体的任务和数据集。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;如何选择-batch-size&#34;&gt;如何选择 Batch Size：&lt;/h4&gt;
&lt;p&gt;选择合适的 batch size 通常需要考虑多个因素，包括可用的内存资源、训练的稳定性和速度、以及模型的最终性能。实践中，通常会通过实验来确定特定任务和模型结构下的最佳 batch size，有时也会使用一些启发式方法来进行选择。此外，也有一些技术，如梯度累积，可以在内存限制的情况下间接实现较大的有效 batch size，以提高训练的稳定性和效率。&lt;/p&gt;
&lt;h3 id=&#34;3-迭代次数-epochs&#34;&gt;3. 迭代次数 (Epochs)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;整个训练数据集被遍历和学习的总次数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-优化器-optimizer&#34;&gt;4. 优化器 (Optimizer)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用于更新网络权重的算法，如SGD (随机梯度下降)、Adam、RMSprop等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-权重初始化-weight-initialization&#34;&gt;5. 权重初始化 (Weight Initialization)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;网络参数的初始赋值策略，如随机初始化、Xavier/Glorot初始化、He初始化等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-正则化参数-regularization-parameters&#34;&gt;6. 正则化参数 (Regularization Parameters)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如L1和L2正则化，用于控制模型复杂度和防止过拟合的参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-激活函数-activation-function&#34;&gt;7. 激活函数 (Activation Function)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;神经网络中使用的非线性函数，如 ReLU、Sigmoid、Tanh 等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-网络架构-network-architecture&#34;&gt;8. 网络架构 (Network Architecture)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;涉及模型的层数、每层的神经元数目、卷积核大小等结构性参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-dropout率-dropout-rate&#34;&gt;9. Dropout率 (Dropout Rate)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;训练过程中随机丢弃神经元的比率，用于防止过拟合。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;10-学习率衰减-learning-rate-decay&#34;&gt;10. 学习率衰减 (Learning Rate Decay)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;随着训练的进行，逐渐减小学习率的策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;11-梯度裁剪-gradient-clipping&#34;&gt;11. 梯度裁剪 (Gradient Clipping)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;限制梯度值的范围，防止梯度爆炸。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;辨析&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/66021413&#34;&gt;快速搞定 epoch, batch, iteration&lt;/a&gt;&lt;br&gt;
进行一次参数更新和完成一个epoch是两个不同的概念，在深度学习的训练过程中它们扮演着不同的角色。&lt;/p&gt;
&lt;h3 id=&#34;参数更新&#34;&gt;参数更新&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在深度学习中，一次参数更新通常指的是基于一批数据（一个batch）计算损失函数的梯度，然后使用这个梯度来更新网络的权重和偏置。这个过程是学习的基本步骤，通过反向传播算法实现。&lt;/li&gt;
&lt;li&gt;参数更新的频率取决于批大小（batch size）。例如，如果批大小设置为32，则每处理32个样本后模型的参数就会更新一次。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;一个epoch&#34;&gt;一个Epoch&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一个epoch指的是整个训练数据集被完整地遍历一次的过程。这意味着每个训练样本都已被用于训练模型，参与了一次或多次的参数更新（取决于批大小和数据集大小）。&lt;/li&gt;
&lt;li&gt;完成一个epoch通常包括多次参数更新。例如，如果有1000个训练样本，批大小为100，则一个epoch包含10次参数更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;简而言之，一次参数更新是基于一批数据调整模型参数的单个步骤，而一个epoch是整个训练数据集被完整遍历一次的过程，通常包含多次参数更新。Epoch的概念用于控制训练的总体进度，而参数更新是训练过程中的基本操作。&lt;/p&gt;
&lt;h1 id=&#34;损失函数&#34;&gt;损失函数&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/261059231&#34;&gt;损失函数（Loss Function）&lt;/a&gt;&lt;br&gt;
也可称为代价函数（Cost Function）&lt;br&gt;
计算预测值f(x)与真实值Y的差异程度&lt;br&gt;
&lt;strong&gt;不同问题常用的损失函数&lt;/strong&gt;&lt;br&gt;
分类：交叉熵、Hinge Loss（铰链损失函数，常用于 SVM）&lt;br&gt;
回归：MSE（L2 Loss）、MAE（L1 Loss）、RMSE、Huber Loss&lt;/p&gt;
&lt;p&gt;交叉熵：衡量模型输出与实际标签之间的差异&lt;br&gt;
hinge loss：使模型能正确分类，且使分类距离越大越好。如果分类确信度不够高，会给予大损失&lt;/p&gt;
&lt;p&gt;MAE：记忆：里面是 A，所以是 L1，MSE 因为有平方，所以是2，L2。&lt;br&gt;
L1 Loss 零点不平滑，用的较少&lt;br&gt;
L2 Loss 因为有平方，所以对离群点敏感&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正则化（规范化）&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_41960890/article/details/104891561&#34;&gt;一篇文章完全搞懂正则化（Regularization）&lt;/a&gt;&lt;br&gt;
在损失函数中添加一个正则项，限制其较高次的参数大小不能过大，使模型学习到更加稀疏的权重分布，防止过拟合。常见的有L1正则化和L2正则化。&lt;/p&gt;
&lt;p&gt;L2正则化对于绝对值较大的权重予以很重的惩罚，对于绝对值很小的权重予以非常非常小的惩罚，当权重绝对值趋近于0时，基本不惩罚。&lt;/p&gt;
&lt;p&gt;L1正则化对于所有权重（不论参数大小）予以同样的惩罚&lt;br&gt;
L1要在稀疏条件下使用&lt;/p&gt;
&lt;h1 id=&#34;向前传播和反向传播&#34;&gt;向前传播和反向传播&lt;/h1&gt;
&lt;p&gt;了解反向传播，先了解梯度下降：&lt;a href=&#34;https://jeromezjl.github.io/post/ti-du-xia-jiang-gradient-descent/&#34;&gt;【ML】以梯度下降（Gradient Descent）展开的优化器总结&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;向前传播：数据在神经网络中从输入层流向输出层的过程。在这个过程中，每一层的神经元会根据前一层的输入、自身的权重（weights）和偏置（biases），通过激活函数计算出自己的输出。这个输出会作为下一层的输入继续传递。这个过程一直持续到达输出层，最终产生模型的预测结果。&lt;/p&gt;
&lt;p&gt;反向传播：从输出层流向输入层的过程。根据模型输出和实际值之间的误差来调整模型参数（即权重和偏置）。这个过程是通过链式法则计算损失函数的梯度并使用这些梯度来更新模型参数来实现的。一旦计算出梯度，就使用优化算法（如SGD、Adam等）来更新网络中的权重和偏置，目的是减小损失函数的值。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1yG411x7Cc/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;5分钟深度学习-反向传播算法&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/447113449&#34;&gt;【深度学习篇】：前向传播（forward）和反向传播（backward）&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;激活函数&#34;&gt;激活函数&lt;/h1&gt;
&lt;p&gt;增加神经网络的非线性表达能力，使之能更好的拟合非线性模型，常见的有 Sigmoid、Tanh、ReLU&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1qB4y1e7GJ/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;5分钟深度学习-激活函数&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/364620596&#34;&gt;深度学习笔记：如何理解激活函数？（附常用激活函数）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;特点&lt;/code&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;连续可导（梯度下降）；&lt;/li&gt;
&lt;li&gt;取值范围是全体实数，将全体实数映射到特定的范围；&lt;/li&gt;
&lt;li&gt;只需增加非线性的因素，而不需改变对输入的响应状态，所以是单增的，随输入增大而增大&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;梯度消失（梯度弥散）&lt;/strong&gt;：sigmoid趋近无穷时，梯度趋近于0，若某次输入过大，梯度几乎为0，导致参数几乎不更新，导致整个网络学习能力下降&lt;br&gt;
sigmoid：非零均值函数→同时更新正负→神经网络不易收敛；饱和函数→梯度消失，使用tanh函数可以&lt;br&gt;
&lt;strong&gt;梯度爆炸&lt;/strong&gt;：使用ReLU函数时，由于函数无上界，如果输出过大，会导致梯度累积，超出上限&lt;/p&gt;
&lt;h1 id=&#34;批量归一化和层归一化&#34;&gt;批量归一化和层归一化&lt;/h1&gt;
&lt;p&gt;批量归一化（Batch Normalization, BN）和层归一化（Layer Normalization, LN）都是深度学习中用于改进神经网络训练的标准化技术，通常是在网络架构中作为特定的层来实现。&lt;/p&gt;
&lt;p&gt;BN和LN都旨在通过标准化神经网络中的激活值来减少内部协变量偏移，加速训练并提高模型的性能。BN通过归一化一批样本中相同特征的值来实现，而LN则是对单个样本中所有特征的值进行归一化。&lt;/p&gt;
&lt;h3 id=&#34;解决的问题&#34;&gt;解决的问题&lt;/h3&gt;
&lt;p&gt;提高模型的训练效率和泛化能力，但批量归一化一般不改变模型精度&lt;br&gt;
&lt;strong&gt;1. 内部协变量偏移（Internal Covariate Shift）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;问题&lt;/strong&gt;：在训练深度神经网络时，每一层的输入分布可能会因为前面层参数的更新而改变，这种现象被称为内部协变量偏移。这导致训练过程不稳定，需要更小的学习率和更仔细的参数初始化策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解决方式&lt;/strong&gt;：BN通过对每一批数据的每个特征进行标准化（确保输入层的均值为0，方差为1），减少了内部协变量偏移，使得网络能够使用更高的学习率，加速训练过程。而LN通过对单个数据样本的所有特征进行标准化，也可以减少这种偏移，特别是在RNN和Transformer等模型中效果显著。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. 梯度消失/梯度爆炸（Vanishing/Exploding Gradients）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;问题&lt;/strong&gt;：在深层网络中，梯度可能随着传播逐渐变小（消失）或变得非常大（爆炸），这使得网络难以训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解决方式&lt;/strong&gt;：通过归一化处理，BN和LN可以在一定程度上缓解梯度消失或爆炸的问题，因为它们保证了网络中每一层的输入分布的一致性，从而有助于维持梯度的稳定。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. 训练过程中的参数敏感性和不稳定性&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;问题&lt;/strong&gt;：深度网络中的参数更新可能会对后续层产生放大的效应，导致训练过程中的不稳定性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解决方式&lt;/strong&gt;：BN和LN通过对激活进行标准化，减少了单个参数变化对整个网络的影响，从而增强了模型的稳定性，使得网络对参数初始化的敏感度降低。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4. 过拟合（Overfitting）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;问题&lt;/strong&gt;：深度网络可能会过度学习训练数据中的细节，从而导致在未见过的数据上表现不佳。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解决方式&lt;/strong&gt;：虽然BN和LN的主要目标不是解决过拟合问题，但它们引入的轻微噪声（比如BN中来自小批量统计的噪声）可以带来轻微的正则化效果，有助于减少过拟合。不过，过拟合通常还需要通过其他正则化技术（如Dropout、权重衰减等）来更有效地控制。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;批量归一化batch-normalization-bn&#34;&gt;批量归一化（Batch Normalization, BN）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;归一化对象&lt;/strong&gt;：BN是对同一层内不同样本的同一特征进行归一化。对于给定的一批数据，BN分别计算这批数据在每个特征维度上的均值和方差，然后使用这些统计信息来标准化每个样本的每个特征（中心极限定理）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用场景&lt;/strong&gt;：BN通常用在卷积层或全连接层之后，激活函数之前。它在批量较大时表现较好，因为均值和方差的估计更为稳定。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;依赖批量大小&lt;/strong&gt;：BN的性能依赖于批量的大小，当批量大小很小时，BN的性能可能会受到影响，因为均值和方差的估计会变得不准确。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;层归一化layer-normalization-ln&#34;&gt;层归一化（Layer Normalization, LN）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;归一化对象&lt;/strong&gt;：LN是对同一样本内不同特征进行归一化。对于单个样本，LN计算所有特征的均值和方差，然后使用这些统计信息来标准化该样本的所有特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用场景&lt;/strong&gt;：LN不依赖于批量的大小，因此特别适用于批量大小较小或动态变化的情况，如自然语言处理中的循环神经网络（RNN）和Transformer模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;独立于批量大小&lt;/strong&gt;：由于LN是在样本级别上进行的，因此它的性能不受批量大小的影响，这使得LN在批量大小受限或变化较大的应用场景中更为有用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;在网络中的实现&#34;&gt;在网络中的实现：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;批量归一化（BN）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BN层通常置于卷积层（Convolutional Layer）或全连接层（Fully Connected Layer）之后，激活函数（如ReLU）之前。&lt;/li&gt;
&lt;li&gt;在PyTorch中，BN可以通过&lt;code&gt;torch.nn.BatchNorm2d&lt;/code&gt;（对于2D卷积层）或&lt;code&gt;torch.nn.BatchNorm1d&lt;/code&gt;（对于全连接层）来实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;层归一化（LN）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LN层可以应用于网络中几乎任何地方，但在某些架构（如Transformer模型）中，它通常在每个子层的输出上使用，并在激活函数之前应用。&lt;/li&gt;
&lt;li&gt;在PyTorch中，LN可以通过&lt;code&gt;torch.nn.LayerNorm&lt;/code&gt;来实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;示例代码pytorch&#34;&gt;示例代码（PyTorch）：&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;对于批量归一化&lt;/strong&gt;：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5)
        self.bn1 = nn.BatchNorm2d(num_features=20)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        return x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;对于层归一化&lt;/strong&gt;：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        self.linear1 = nn.Linear(in_features=10, out_features=20)
        self.ln1 = nn.LayerNorm([20])
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.linear1(x)
        x = self.ln1(x)
        x = self.relu(x)
        return x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;拓展&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;批量归一化与dropout的关系&#34;&gt;批量归一化与Dropout的关系&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dropout&lt;/strong&gt;：是一种正则化技术，通过在训练过程中随机“丢弃”一部分神经元（即将它们的输出设置为0）来防止模型过拟合。这种随机性有助于使模型更加健壮，减少对特定训练样本的依赖。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;批量归一化&lt;/strong&gt;：主要用于加速训练和提高训练过程的稳定性，虽然有时也能起到轻微的正则化效果，但并不是其主要目的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在使用批量归一化后，有些研究和实践经验表明，可能不那么需要依赖Dropout来防止过拟合，因为批量归一化本身就引入了一定的噪声（由于每个小批量的均值和方差的估计），这可能有助于正则化模型。此外，批量归一化使得网络能够使用更高的学习率，从而加速训练，而Dropout可能会降低训练速度。&lt;/p&gt;
&lt;p&gt;尽管批量归一化和Dropout可以共存于同一个网络中，但在实际应用中，根据具体任务和网络结构的不同，可能会选择调整它们的使用。有时，为了简化模型并减少计算开销，如果批量归一化足以稳定训练并防止过拟合，就可能不使用Dropout。反之，在一些情况下，特别是在批量归一化不足以完全防止过拟合的情况下，仍然可以使用Dropout作为额外的正则化手段。实际操作中，这通常需要通过实验来确定最佳的策略。&lt;/p&gt;
&lt;h1 id=&#34;分类和回归&#34;&gt;分类和回归&lt;/h1&gt;
&lt;p&gt;本质都是对输入值进行预测的问题，分类输出离散的、对预测类别的置信度，回归输出连续的预测值&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/fen-lei-he-hui-gui/&#34;&gt;【ML】分类和回归&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/shuiyixin/article/details/88816416&#34;&gt;【机器学习小常识】“分类” 与 “回归”的概念及区别详解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1m4421F7Fg/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;详解逻辑回归、softmax回归和神经网络，三种模型的关联和区别&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ml-softmax&#34;&gt;【ML】Softmax&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;训练集-验证集-测试集&#34;&gt;训练集、验证集、测试集&lt;/h1&gt;
&lt;p&gt;三者必须无交集&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qlkaicx/article/details/134767111#:~:text=%E5%8F%82%E6%95%B0%20%E6%98%AF%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%8F%AF%E8%A2%AB%E5%AD%A6%E4%B9%A0%E5%92%8C%E8%B0%83%E6%95%B4%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%8C%E9%80%9A%E8%BF%87%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%AD%A6%E4%B9%A0%E5%92%8C%E4%BC%98%E5%8C%96%EF%BC%9B,%E8%80%8C%20%E8%B6%85%E5%8F%82%E6%95%B0%20%E5%88%99%E6%98%AF%E6%89%8B%E5%8A%A8%E8%AE%BE%E7%BD%AE%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%8C%E7%94%A8%E4%BA%8E%E6%8E%A7%E5%88%B6%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%8C%E4%B8%BA%E5%92%8C%E6%80%A7%E8%83%BD%EF%BC%8C%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E9%80%89%E6%8B%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%AF%B9%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E6%9C%89%E9%87%8D%E8%A6%81%E5%BD%B1%E5%93%8D%E3%80%82&#34;&gt;还搞不懂什么是参数，超参数吗？三分钟快速了解参数与超参数的概念和区别！！！&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_41895003/article/details/104811371&#34;&gt;训练集、测试集、验证集之间的区别及理解&lt;/a&gt;&lt;br&gt;
训练集：通过训练自动更新参数&lt;br&gt;
验证集：手动更新超参数&lt;br&gt;
测试集：测试生成的模型的泛化能力&lt;/p&gt;
&lt;p&gt;k折交叉验证：将数据集分成k份，每次拿出其中的一份作为验证集，剩下k-1份作为训练集&lt;br&gt;
通过平均误差判断超参数好坏&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Q&amp;amp;A&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Q：如果loss很低，是不是就不用设置验证集了
A：在深度学习训练中，即使训练损失（loss）很低，也不意味着可以忽略验证集的设置。这里有几个原因解释为什么验证集依然很重要：

1. 过拟合（Overfitting）：一个很低的训练损失可能意味着模型在训练集上表现得很好，但这也可能是过拟合的一个迹象。过拟合发生时，模型学习到了训练数据中的噪声和细节，而不是底层模式，这会导致模型在未见过的数据上表现不佳。验证集可以帮助检测过拟合情况，因为它提供了模型在非训练数据上的性能评估。

2. 模型选择（Model Selection）：在开发深度学习模型时，我们通常会尝试多种不同的架构、超参数设置等。验证集用于评估这些不同设置的性能，帮助我们选择最佳模型。

3. 调参（Hyperparameter Tuning）：除了选择模型外，我们还需要调整模型的超参数（如学习率、批量大小等）。验证集对于这一过程至关重要，因为它可以帮助我们了解不同超参数设置对模型性能的影响。

4. 泛化能力（Generalization Ability）：最终，我们关心的是模型在实际应用中的表现，即在新的、未见过的数据上的表现。验证集提供了一个近似的泛化能力评估，帮助我们估计模型在现实世界数据上的表现。

因此，即使训练损失很低，也不应该忽视验证集的设置。验证集是深度学习训练过程中不可或缺的一部分，对于确保模型的泛化能力和避免过拟合至关重要。在模型训练的最后阶段，还应该使用独立的测试集对模型进行最终评估，以进一步验证模型的泛化能力。
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Q：验证集在所有任务中都是必须的吗？
A：虽然验证集在许多深度学习和机器学习任务中非常重要，但是否“必须”使用验证集取决于具体的任务、数据的可用性以及目标。在大多数情况下，使用验证集是一种最佳实践，但也有一些情况或任务可能不那么依赖于验证集：

1. 数据量极其有限：在某些情况下，如果可用的数据非常有限，可能无法划分出单独的验证集。在这种情况下，可能会采用交叉验证的方法，这种方法将数据集分为多个小分组，然后依次将其中一个分组作为验证集，其他分组作为训练集，从而有效利用有限的数据。

2. 在线学习或持续学习：对于一些在线学习任务，模型会持续地接收数据并不断更新。在这种情况下，模型可能不会有一个固定的验证集，而是不断地用新数据评估和调整。

3. 使用预训练模型进行微调：当使用预训练模型并对其进行微调以适应特定任务时，如果任务非常接近原始预训练任务，且数据集较小，可能会直接在训练数据上进行微调而不单独设置验证集。然而，这种情况下仍然推荐使用验证集来监控过拟合和模型性能。

4. 简单任务或明确的成功标准：在一些简单的任务或当成功标准非常明确且容易评估时（如明确的数学问题），可能不需要单独的验证集来调整模型参数。

即便在这些特殊情况下，最终还是需要一个独立的测试集来评估模型的性能，确保模型能够在未见过的数据上良好工作。综上所述，虽然在某些特定场景下可以不使用验证集，但在大多数情况下，为了保证模型的泛化能力和避免过拟合，使用验证集都是一种非常重要的实践。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;超参数调整&lt;/strong&gt;&lt;br&gt;
利用验证集调整超参数的一些策略&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在每个epoch后或几个epoch后使用验证集验证模型的loss，确保模型权重可以被保存在本地，手动调整超参数后继续训练&lt;/li&gt;
&lt;li&gt;使用早停技术：在每个epoch结束时评估模型在验证集上的性能，并在性能不再提升时停止训练&lt;/li&gt;
&lt;li&gt;使用自动化超参数优化（Hyperparameter Optimization, HPO）&lt;/li&gt;
&lt;li&gt;设置模型检查点（Model Checkpointing）&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;过拟合&#34;&gt;过拟合&lt;/h1&gt;
&lt;p&gt;在训练集上学习的太好，导致学到了噪声，使得在测试集上表现不佳&lt;br&gt;
过拟合：认为只有和训练数据一样的才是&lt;br&gt;
欠拟合：认为树也是叶子&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/158869433&#34;&gt;机器学习模型的容量，过拟合与欠拟合&lt;/a&gt;&lt;br&gt;
dropout：前向传播的时候，让某个神经元的激活值以一定的概率 p 停止工作，这样可以使模型泛化性更强，防止过拟合&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;过拟合解决方法&lt;/strong&gt;&lt;br&gt;
正则化、交叉验证、dropout、早停、批量归一化、调整学习率、数据增强&lt;/p&gt;
&lt;h1 id=&#34;算法分类&#34;&gt;算法分类&lt;/h1&gt;
&lt;p&gt;机器学习算法通常根据学习方式和应用场景被分类为几大类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;监督学习（Supervised Learning）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;包括分类和回归任务。算法从标记的训练数据中学习，每个训练样本都有一个与之对应的标签或输出。&lt;/li&gt;
&lt;li&gt;常见的算法包括线性回归、逻辑回归、支持向量机（SVM）、决策树、随机森林、神经网络等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;无监督学习（Unsupervised Learning）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在无监督学习中，算法试图从未标记的数据中找出模式。因为没有指导，所以这种类型的学习试图通过数据本身的结构来理解数据。&lt;/li&gt;
&lt;li&gt;典型的算法包括聚类算法（如K-means、层次聚类）、降维算法（如主成分分析PCA、t-SNE）、关联规则学习算法（如Apriori、Eclat）等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;半监督学习（Semi-Supervised Learning）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这种学习方式介于监督学习和无监督学习之间。它使用少量的标记数据和大量的未标记数据进行训练。通过这种方式，算法可以提高其性能和准确性。&lt;/li&gt;
&lt;li&gt;半监督学习方法通常包括自训练、多视图学习、图基方法等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;强化学习（Reinforcement Learning）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在强化学习中，算法（通常称为智能体）通过与环境交互来学习如何达到目标。智能体从环境中获得奖励或惩罚，并使用这些反馈来指导其未来的行为。&lt;/li&gt;
&lt;li&gt;常见的强化学习算法包括Q-learning、SARSA、深度Q网络（DQN）、策略梯度方法等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;自监督学习（Self-Supervised Learning）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这是一种特殊类型的无监督学习，其中数据的一部分被用作监督信号。在自监督学习中，模型试图从数据的未标记部分预测数据的标记部分，从而在没有显式标签的情况下学习数据的表示。&lt;/li&gt;
&lt;li&gt;应用示例包括预训练的语言模型、图像特征学习等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;迁移学习（Transfer Learning）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这种学习方法涉及将从一个任务中学到的知识应用到另一个不同但相关的任务上。这是通过重用预训练模型的一部分并对其进行微调来实现的，以适应新任务。&lt;/li&gt;
&lt;li&gt;这在深度学习中尤其常见，例如使用预训练的卷积神经网络（CNN）进行图像分类任务。&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/dl-mo-xing-fu-yong&#34;&gt;【DL】模型复用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生成式对抗网络（GANs）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GANs是一种框架，用于通过两个网络（一个生成器和一个鉴别器）之间的对抗过程来训练生成模型。生成器生成新的数据实例，而鉴别器评估它们是来自于真实数据集还是生成器产生的。&lt;/li&gt;
&lt;li&gt;GANs广泛用于图像生成、图像转换、增强现实等领域。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
">【ML】基础概念</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/linux-shen-du-xue-xi-pei-zhi/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_45484237/article/details/123514175&#34;&gt;实现Linux服务器配置深度学习环境并跑代码完整步骤&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;使用nvidia-smi完全查看显卡型号&lt;br&gt;
nvidia-smi --format=csv --query-gpu=index,name,driver_version,memory.total,memory.used,memory.free&lt;br&gt;
或使用&lt;br&gt;
pip install gpustat&lt;br&gt;
gpustat&lt;br&gt;
来查看&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/102449309&#34;&gt;Linux下Anaconda环境安装/创建/激活/退出/删除/管理&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/Aorg1/article/details/134800426&#34;&gt;conda环境下安装nvcc -V&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/m0_50181189/article/details/122440985&#34;&gt;【详细】Ubuntu18.04安装更新显卡驱动、安装CUDA及cuDNN、CUDA版本切换&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;退出 python：&amp;gt;&amp;gt;&amp;gt; quit（）&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_59047731/article/details/135634418&#34;&gt;pyCharm专业版破解激活（超详细）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/486360176&#34;&gt;一文读懂 PyTorch 显存管理机制&lt;/a&gt;&lt;/p&gt;
">【Linux】深度学习配置</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/bi-she/"" data-c="
          &lt;p&gt;Linux运行python文件&lt;br&gt;
python3 script.py&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hugging Face&lt;/strong&gt;&lt;br&gt;
&amp;quot;NLP 界的 GitHub&amp;quot;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1YU4y1g753/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;Hugging Face 系列视频（一）：Hugging Face 及 Transformer/Datasets/Tokenizers库&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/a1920993165/article/details/128082968&#34;&gt;Huggingface的介绍，使用（CSDN最强Huggingface入门手册）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fine tuning 微调&lt;/strong&gt;&lt;br&gt;
将模型迁移学习，影响因素：新数据集的大小、新数据和原数据集的相似程度&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35890660&#34;&gt;CNN入门讲解：什么是微调（Fine Tune）？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_42137700/article/details/82107208&#34;&gt;什么是fine-tuning？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/620618701&#34;&gt;预训练大语言模型的三种微调技术总结：fine-tuning、parameter-efficient fine-tuning和prompt-tuning的介绍和对比&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用 COCO 数据集进行预训练的 VIT-GPT2 模型&lt;/strong&gt;&lt;br&gt;
COCO：起源于微软的、大型的、丰富的物体检测数据集&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_41185868/article/details/82939959&#34;&gt;Dataset之COCO数据集：COCO数据集的简介、下载、使用方法之详细攻略&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://huggingface.co/nlpconnect/vit-gpt2-image-captioning&#34;&gt;vit-gpt2-image-captioning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CLIP&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/521151393&#34;&gt;详解CLIP (一) | 打通文本-图像预训练实现ImageNet的zero-shot分类，比肩全监督训练的ResNet50/101&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/lsb2002/article/details/132275132&#34;&gt;openai多模态大模型：clip详解及实战&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/493489688&#34;&gt;神器CLIP：连接文本和图像，打造可迁移的视觉模型&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;VIT&lt;br&gt;
embedding：通过矩阵乘法，将token升降维，从而让计算机理解。将一个东西映射为向量&lt;/p&gt;
&lt;p&gt;linear层：1. 将每个patch变成一维  2. 使一维向量的维度和 transformer 输入维度相符&lt;/p&gt;
&lt;p&gt;位置编码和embedding相加&lt;/p&gt;
&lt;p&gt;是一个特征提取器&lt;br&gt;
先将图像分割为不同的patch&lt;br&gt;
然后将每个patch拉成一个向量，加入位置信息&lt;/p&gt;
&lt;p&gt;transformer必须在大量数据&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_44966641/article/details/118733341&#34;&gt;Vision Transformer（ViT）PyTorch代码全解析（附图解）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://juejin.cn/post/7238148905095839804&#34;&gt;用🤗 Transformers微调ViT图像分类&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;deepfashion&lt;br&gt;
图片：750x1101，共44096个&lt;/p&gt;
">毕设</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/kao-yan-ying-yu-dan-ci-he-ci-zu/"" data-c="
          &lt;p&gt;&lt;strong&gt;时间安排&lt;/strong&gt;&lt;br&gt;
下午 14：00~17：00 考试，三个小时&lt;br&gt;
小作文：15min&lt;br&gt;
大作文：35min&lt;br&gt;
阅读：70min（17分钟一篇）&lt;br&gt;
新题型：20min&lt;br&gt;
翻译：20min&lt;br&gt;
完形填空：20min&lt;/p&gt;
&lt;h1 id=&#34;单词&#34;&gt;单词&lt;/h1&gt;
&lt;p&gt;measurement 测量&lt;br&gt;
lean 倾斜、倚靠、精瘦&lt;br&gt;
likewise 同样的&lt;br&gt;
absently 心不在焉地&lt;br&gt;
concede admit acknowledge confess allow grant 让步、承认&lt;br&gt;
sitter 摆姿势让人画像的人&lt;br&gt;
miserably 痛苦地&lt;br&gt;
stiff、stiffly 僵硬的&lt;br&gt;
notoriously 臭名昭著、众所周知&lt;br&gt;
copper 铜&lt;br&gt;
limbs 肢体、四肢&lt;br&gt;
grin 露齿笑&lt;br&gt;
contemplate 考虑、沉思 too...to contemplate 太...去考虑（无法想象）&lt;br&gt;
notion 概念、观念 the notion is that 意思是说/人们认为&lt;br&gt;
compell 强迫&lt;br&gt;
privilege 给特权&lt;br&gt;
intensify 强化&lt;br&gt;
crisp 脆的&lt;br&gt;
crust 皮，外壳&lt;br&gt;
mandate 授权&lt;/p&gt;
&lt;h1 id=&#34;词组&#34;&gt;词组&lt;/h1&gt;
&lt;p&gt;over a six-year period 在六年的时间里&lt;br&gt;
be superior to 优于&lt;br&gt;
be resistant to 不受损害的&lt;br&gt;
increase the level 提高水平&lt;br&gt;
government grant 政府拨款&lt;br&gt;
take for granted 认为...理所应当&lt;br&gt;
justify doing sth. 证明做...（是正确的）&lt;br&gt;
judge by/from 从...判定&lt;br&gt;
starved of 缺乏、挨饿&lt;br&gt;
at high temperature 在高温下&lt;br&gt;
come across 遇到、给人留下印象&lt;/p&gt;
&lt;h1 id=&#34;长难句&#34;&gt;长难句&lt;/h1&gt;
&lt;p&gt;its campaign risks coming across as being pushy.&lt;br&gt;
risk 是宾语，有...的风险&lt;br&gt;
coming across as being pushy 给人留下咄咄逼人的印象（遇到被认为咄咄逼人）come across 有给人留下印象的意思&lt;br&gt;
译为，它的活动有可能给人留下咄咄逼人的印象&lt;/p&gt;
">【考研】英语单词和词组</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/kao-yan-ying-yu-zuo-wen/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/liu-ji/&#34;&gt;六级整理的作文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/380341976&#34;&gt;考研英语一的各题型，怎么分配时间合理？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;小作文&lt;br&gt;
大作文&lt;/p&gt;
&lt;h1 id=&#34;小作文&#34;&gt;小作文&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;常考题目有四种&lt;/strong&gt;&lt;br&gt;
私人书信、公务书信、通知和告示（去年考的）、会议纪要&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;审题三要素&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;故事背景：打散+改写背景信息&lt;/li&gt;
&lt;li&gt;体裁（letter/email+notice）+ 内容要求&lt;/li&gt;
&lt;li&gt;正式（I am / It is）/非正式（I&#39;m / It&#39;s） + 格式&lt;br&gt;
都写正式肯定没错&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;小作文三段式简易思路&lt;/strong&gt;&lt;br&gt;
小作文：说事说明白就行，不要求句型很复杂&lt;br&gt;
段首1-2句&lt;br&gt;
a. 写给熟人：首句寒暄，二句目的；&lt;br&gt;
b. 写给陌生人或机构：自我介绍和目的&lt;/p&gt;
&lt;p&gt;中间 4-6 句&lt;br&gt;
按题目要求写相应内容，并辅以感谢、强调、对比、建议、说明等功能表达完成写作&lt;/p&gt;
&lt;p&gt;段尾 1 句&lt;br&gt;
再次致歉、感谢、期待、展望等&lt;/p&gt;
&lt;p&gt;正文缩进四个字符&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;书信&lt;/strong&gt;&lt;br&gt;
dear 称呼&lt;br&gt;
Yours sincerely&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;告示&lt;/strong&gt;&lt;br&gt;
标题&lt;/p&gt;
&lt;p&gt;the purpose of sth. / sth. aims(targets) to 目的是&lt;br&gt;
use their best endeavors to do 尽最大努力做&lt;br&gt;
attach emphasis to sth. 认为...很重要&lt;br&gt;
utmost emphasis should be attached to...&lt;br&gt;
contribute to / induce 是导致...的原因&lt;br&gt;
complete one&#39;s work 完成工作&lt;br&gt;
joint efforts 共同努力&lt;br&gt;
I am deeply obliged for your hard work 我十分感谢您的努力&lt;/p&gt;
&lt;h1 id=&#34;可用单词&#34;&gt;可用单词&lt;/h1&gt;
&lt;p&gt;character 角色&lt;br&gt;
plight 困境&lt;br&gt;
vigorous 有活力的&lt;br&gt;
tremendous 巨大的&lt;br&gt;
eminent 优秀的&lt;br&gt;
eminently = exceedingly = Immensely 非常&lt;br&gt;
advantageous 有利的，有好处的&lt;br&gt;
miraculous 奇迹般的&lt;br&gt;
gorgeous 美丽的&lt;br&gt;
pervasive = universal 普遍的&lt;br&gt;
enhance = promote = strengthen = optimize 加强、优化、促进&lt;br&gt;
deal with = resolve sth. = tackle sth. = cope with 解决，应对，处理&lt;br&gt;
cultivate = foster 培养&lt;br&gt;
fulfill 完成&lt;br&gt;
contamination 污染&lt;br&gt;
obligation 责任&lt;br&gt;
accelerate 加速&lt;br&gt;
adequate 充足&lt;br&gt;
rational 合理的&lt;br&gt;
feasible 可行的&lt;br&gt;
considerable 相当多的&lt;br&gt;
critical / essential / be extremely vital to us 至关重要的&lt;br&gt;
severe、critical 严重的&lt;br&gt;
terrible / harmful&lt;br&gt;
defect 缺点&lt;br&gt;
eliminate 消除&lt;br&gt;
therefore = hence 因此&lt;br&gt;
demonstrate / illustrate “说明，表明”，用在图表作文中替代show，reveal等单词&lt;br&gt;
depict / portray “描述，描绘”，在漫画作文中替代describe&lt;br&gt;
punctuality 准时 / punctually 准时地&lt;br&gt;
prestigious 有声望的&lt;br&gt;
hospitality 热情好客 / hospitable 热情好客的&lt;br&gt;
imperative 迫切的&lt;br&gt;
magnificent = splendid 壮丽的&lt;br&gt;
innumerable 无数的&lt;br&gt;
deleterious 有害的&lt;br&gt;
pursue 追求&lt;br&gt;
primary 首要的&lt;br&gt;
academic 学术的&lt;br&gt;
indispensable 不可或缺的&lt;br&gt;
severely 严重地&lt;/p&gt;
&lt;h1 id=&#34;可用词组&#34;&gt;可用词组&lt;/h1&gt;
&lt;p&gt;I&#39;m writing to request that 我写信恳求（t不双写）&lt;br&gt;
I have several request&lt;br&gt;
表达喜欢{&lt;br&gt;
students who share a love for English 共同热爱&lt;br&gt;
be keen on sth.&lt;br&gt;
have a profound affection  有深厚的感情/浓厚的兴趣&lt;br&gt;
be passionate about&lt;br&gt;
have a peculiar interest in 对...有特殊的兴趣&lt;br&gt;
}&lt;br&gt;
the Internet has become an increasingly important tool for students&lt;br&gt;
Not only do professors require us to... but ... (前后连接复杂句，do 起强调作用)&lt;br&gt;
much of the communication between...  communication 不可数&lt;br&gt;
I cordially invite you to join us 我诚挚地邀请您来参加我们的活动&lt;br&gt;
on behalf of&lt;br&gt;
we are hoping that you will be available for a lecture on January 4th.&lt;br&gt;
there will be 45 minutes allocated for you&lt;br&gt;
in their spare time&lt;br&gt;
sth be in great request 非常需要 sth&lt;br&gt;
compensate for / compensate sb. for sth. 弥补、补偿&lt;br&gt;
urge sb to do 敦促某人做&lt;br&gt;
guarantee sb. sth. 向某人保证某事&lt;br&gt;
remains to do 仍需做某事&lt;br&gt;
be inspired  by 受到启发、鼓舞&lt;br&gt;
A be conducive to B / do sth A有利于B/做某事&lt;br&gt;
be detrimental to 不利于，对...有害&lt;br&gt;
manifest improvement 明显的进步&lt;br&gt;
a wholesome drink 有益健康的饮料&lt;br&gt;
Prevailing among the general public 在一般人群中盛行&lt;br&gt;
be triggered by 由...引起的&lt;br&gt;
If tedious tasks could be eradicated, the world would be a much better place.&lt;br&gt;
如果可以消灭那些单调乏味的工作，世界将会变得更加美好&lt;br&gt;
We must eradicate the unhealthy tendency of cheating in exams.&lt;br&gt;
我们一定要杜绝考试作弊的歪风邪气&lt;br&gt;
The noise pollution badly jeopardizes the health of the operating workers.&lt;br&gt;
噪声污染严重地危害人们的身体健康（jeopardize：危害）&lt;br&gt;
alleviating psychological pressure 缓解心理压力（alleviate 减轻、缓解）&lt;br&gt;
Some people assert that nothing is impossible.&lt;br&gt;
一些人断言没有什么事是不可能的（assert：断言、声称）&lt;br&gt;
stimulate sb. to do sth. 激励某人做&lt;br&gt;
the merits of sth. 某事的好处&lt;br&gt;
be saturated with 充斥着&lt;br&gt;
strive for = spare no efforts for = endeavor to do 努力做&lt;br&gt;
embark on sth. 开始做 sth.&lt;br&gt;
in contemporary society 在当代社会&lt;br&gt;
a multitude of = a vast amount of 大量&lt;br&gt;
there are numerous ways of doing 有许多做...的方法&lt;br&gt;
the majority of 大多数&lt;br&gt;
an alternative is that… 作为替代的是...&lt;br&gt;
cannot afford to 不应当做&lt;br&gt;
attach importance to sth 强调...&lt;br&gt;
obstacle 阻碍&lt;br&gt;
in such circumstances 在这样的情况下&lt;br&gt;
in contrast = conversely 相反地&lt;br&gt;
employ the policy of sth 采取...政策&lt;br&gt;
It is generally established that 众所周知&lt;br&gt;
enduring classic 经久不衰的经典&lt;br&gt;
the inner world 内心世界&lt;br&gt;
I am referring to that 我指的是&lt;br&gt;
have a fascination with 对...感兴趣&lt;br&gt;
a range of 一系列&lt;br&gt;
be involved in 参加&lt;br&gt;
extracurricular activities 课外活动&lt;br&gt;
interpersonal relations 人际关系&lt;br&gt;
i regret to tell you that 我很遗憾的告诉你&lt;br&gt;
particular details 具体细节&lt;br&gt;
one of the most magnificent tourist destination in China&lt;br&gt;
China boasts of a splendid history 中国有辉煌的历史&lt;br&gt;
In addition 无所谓连接&lt;br&gt;
What&#39;s more 最好连着前面 比如 Initially，&lt;br&gt;
Further more 最好用在最后，前面必须连&lt;br&gt;
be ascribed to 归因于&lt;br&gt;
If... ever perished from..., it would be a tragedy of immeasurable proportions 如果... 从... 消失，那将是不可估量的悲剧&lt;br&gt;
indulge in / indulgence in 沉浸在&lt;br&gt;
derive from 源于&lt;br&gt;
mental fitness 心理健康&lt;br&gt;
enjoy striking popularity among / be in vogue 流行&lt;br&gt;
demonstrate a social phenomena of 反映了...的社会现象&lt;br&gt;
briefly speaking 简言之&lt;br&gt;
provoke heated debates 引起激烈讨论&lt;br&gt;
double-edged sword&lt;br&gt;
exert profound influence on 产生深远影响&lt;br&gt;
bridge / narrow the gap between&lt;br&gt;
be adopted to 被采纳用于&lt;br&gt;
repent（doing）后悔做&lt;br&gt;
it is imperative for us to take drastic measures. 当务之急是采取严厉措施&lt;br&gt;
enhance the public awareness 提高公众意识&lt;br&gt;
a combination of ... 的结合&lt;br&gt;
this tendency is rather disturbing 这种倾向很令人担忧&lt;br&gt;
give a helping hand&lt;br&gt;
a minority of&lt;br&gt;
every individual&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;道歉信&lt;/strong&gt;&lt;br&gt;
I have recently been diagnosed with a serious cold&lt;br&gt;
If possible, i would like to postpone the interview to another day later in the week&lt;br&gt;
I sincerely apologize for any inconvenience this may cause you (may have caused)&lt;br&gt;
Please excuse me for not being able to inform you of my situation sooner.&lt;/p&gt;
&lt;p&gt;as a... , i am severely disappointed to find that the service you have recently provided us is far from satisfactory&lt;br&gt;
i am writing to draw you attention to sth.&lt;br&gt;
take...into serious concideration&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;感谢信&lt;/strong&gt;&lt;br&gt;
comforting&lt;br&gt;
Benevolence = kind deed&lt;br&gt;
I am writing this letter to express my heartfelt gratitude to you for the meticulous care you provided during my time in the hospital.&lt;br&gt;
The comforting scenes always remind me of the period you took such good care of me.&lt;br&gt;
If it had not been for your timely assistance in giving me first aid, I fear that the consequences might have been very serious&lt;br&gt;
What impressed me the most was&lt;br&gt;
Your appearance has uplifted me/cheered me up&lt;br&gt;
I would like to extend my thanks once again&lt;br&gt;
Your kind deeds are like pearls that will forever be treasured in my mind.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;求职、申请&lt;/strong&gt;&lt;br&gt;
I am writing to apply for the job of doing / your recently advertised position for a teacher&lt;br&gt;
I would like to apply for admission to...&lt;br&gt;
I hold the belief that I am well qualified for this position for several reasons.&lt;br&gt;
Enclosed with this note is my resume, which details my previous academic qualifications and relevant work experiences.&lt;br&gt;
the experiences make me a perfect candidate&lt;br&gt;
cheerful personality&lt;br&gt;
If you could grant me an interview, i would appreciate it.&lt;br&gt;
at your earliest convenience&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;活动&lt;/strong&gt;&lt;br&gt;
To enhance the ability and enrich after-class activities&lt;br&gt;
which is to be held on...&lt;br&gt;
Those who have a fascination with ... are welcome to participate in this activity&lt;br&gt;
If the would-be candidates have any questions, please do not hesitate to contact us&lt;br&gt;
this club serves as a platform to demonstrate your marvelous abilities&lt;br&gt;
are eminently beneficial in multiple regards 在多方面都很有益处&lt;br&gt;
improve your level of proficiency 提高你的熟练程度&lt;br&gt;
A good command of English will enable you to get an edge over your peers&lt;br&gt;
好的英语水平让你比同龄人更胜一筹&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;纪要&lt;/strong&gt;&lt;br&gt;
during the latest meeting，the following issues were addressed.&lt;br&gt;
If you find any errors or omissions, please contact me&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;询问信&lt;/strong&gt;&lt;br&gt;
I am writing to seek your assistance to help...&lt;br&gt;
I hope you can kindly furnish me with specific details regarding the above-mentioned questions.&lt;br&gt;
I wonder if it would be convenient for you to do...&lt;/p&gt;
&lt;h1 id=&#34;大作文&#34;&gt;大作文&lt;/h1&gt;
&lt;p&gt;第一段：不用提出论点，只描述即可&lt;br&gt;
总体描述画面&lt;br&gt;
挖掘细节&lt;/p&gt;
&lt;p&gt;第二段&lt;br&gt;
主题句，点题，引出下文&lt;br&gt;
论证+论据{&lt;br&gt;
背景、事实（现象）、反方观点、原因、结果&lt;br&gt;
因果、分类、举例&lt;br&gt;
}&lt;br&gt;
总结扣题&lt;/p&gt;
&lt;p&gt;第三段&lt;br&gt;
结论&lt;br&gt;
两点建议/评论&lt;br&gt;
展望&lt;/p&gt;
&lt;h1 id=&#34;大作文积累&#34;&gt;大作文积累&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;第一段&lt;/strong&gt;&lt;br&gt;
As is vividly depicted in the caricature&lt;br&gt;
The caricature depicts ....&lt;br&gt;
the caption indicates that... 文字说明...&lt;br&gt;
diagram 图表&lt;br&gt;
excerpt 选段&lt;br&gt;
the author assumes that&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二段&lt;/strong&gt;&lt;br&gt;
the caricature is to illustrate that&lt;br&gt;
what the drawing intends to convey is that&lt;br&gt;
I cling to the idea that 我坚持... 的观点&lt;br&gt;
from my perspective&lt;br&gt;
it is of vital significance to be&lt;br&gt;
Take an example to illustrate....&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第三段&lt;/strong&gt;&lt;br&gt;
To sum up&lt;br&gt;
Only by doing so can we&lt;br&gt;
we should always be ready to&lt;/p&gt;
&lt;p&gt;Love is a pearl  which will never perish from my heart&lt;/p&gt;
">【考研】英语作文</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/some-words/"" data-c="
          &lt;p&gt;要有清醒的自我认知&lt;br&gt;
不要看到别人很牛，就误认为自己也很牛&lt;br&gt;
要制定与自己能力相当的计划，才能达到和别人相同的目标&lt;/p&gt;
&lt;p&gt;制定计划固然是好的，但总比不上现在就把它完成&lt;/p&gt;
&lt;p&gt;学习和认知事物时，先感性的把握，再理性的把握；先定性分析，再定量分析&lt;/p&gt;
&lt;p&gt;快速阅读，同时在脑中处理看到的信息，抑制杂念的产生，用学习的东西主动排除杂念&lt;/p&gt;
&lt;p&gt;做事、学习就像递归调用，永远是这步完成，才能继续下一步。所以永远不要急于求成，不要做着这步，想马上就做会后面几步。不论什么时候，都告诉自己慢慢来，把这步做好了，后面的事情自然也能做好了&lt;/p&gt;
&lt;p&gt;在前进的步履艰难的时候，停下来回头看看，一定是有些该做的事情还没做好&lt;/p&gt;
&lt;p&gt;人在压力大的时候容易屈服于多巴胺的诱惑，比如放纵一下，打游戏，干别的和工作无关的事情&lt;br&gt;
感受到压力的原因：能力不能完全hold住任务，比如去教一个三岁小孩数学肯定不会感觉到压力&lt;br&gt;
强大的心理素质的条件：&lt;br&gt;
希望（目标明确且坚定，在自己能力范围内）&lt;br&gt;
自我效能感：对自己能否完成某事的自信程度，需要提高自己的能力，来增加这种感觉。或者通过完成一点点的小事来给自己正向反馈，例如多邻国的奖励机制&lt;br&gt;
提升心理韧性：接纳自己的暂时性失误，给自己一定的试错机会；和朋友分享感受；做快乐的事，比如听歌、吃饭、运动、冥想、早睡早起、吃早饭&lt;br&gt;
不与别人作比较，和自己比较即可（我的人生只有我）&lt;br&gt;
一切靠自己，自身强大才是王道&lt;br&gt;
压力转化为动力，将事情化为一个个小事，逐一击破，不断给自己正向反馈，到最后击破最大的任务，此时回望经历的一切，都会内化为自身的能力，成为再攀高峰的资本&lt;/p&gt;
&lt;p&gt;心理素质&lt;br&gt;
专注度：身体静止，减少碎片信息摄入&lt;br&gt;
大脑、身体状态：早睡才能早起，无痛早起，而不是被闹钟叫起才能有好的状态；三餐按时，适量运动，做冥想&lt;br&gt;
身心是否和一：别抖腿，尽量保持身体静止，有助于专注的提升；眼睛看的时候大脑也要转，大脑要经常使用才灵活&lt;/p&gt;
">Some Words</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/gao-shu/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1zL411o7PD/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【考研441分】24考研数学全年规划！B站最全！&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/390928056&#34;&gt;考生必记：三角函数公式汇总+记忆（没有比这更全）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.desmos.com/calculator?lang=zh-CN&#34;&gt;在线函数作图&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/99945521&#34;&gt;10幅图帮助理解拉格朗日乘数法的原理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数学竞赛小 tips&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;两项形式相似想夹逼，放缩，最大最小值&lt;/p&gt;
&lt;p&gt;真    题    嗅    探&lt;br&gt;
2020年前：证明喜欢中值定理&lt;br&gt;
2020年后：证明喜欢泰勒&lt;/p&gt;
&lt;p&gt;n 项和展开公式：二项式定理&lt;/p&gt;
&lt;p&gt;A=&amp;gt;B，A 能推出 B，则 A 是 B 的充分条件（B 的充分条件是 A），B 是 A 的必要条件（A 的必要条件是 B）&lt;/p&gt;
&lt;p&gt;A 能推出 B，则 A 发生，B 一定发生，则事件 A ∈ B （小充分，小的是充分条件，大必要，大的是必要条件）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;函数极限和数列极限的辨析&lt;/strong&gt;&lt;br&gt;
🔸函数&lt;br&gt;
极限可以取在任意位置&lt;/p&gt;
&lt;p&gt;🔸数列 （定义在 0, +∞）极限的定义理解：&lt;br&gt;
n 趋于正无穷时，xn 趋于 a&lt;br&gt;
&lt;code&gt;注&lt;/code&gt;&lt;br&gt;
数列的极限一定是 n 趋向于无穷，因为数列中的 n 是指自然序列，也就是 n=1，2，...... 以此类推，也就是说，n 只取正整数，所以求数列的极限 n 只能趋于正无穷大。有限数列没有极限，只有无穷数列才有极限&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;函数有界和数列有界的辨析&lt;/strong&gt;&lt;br&gt;
🔸函数有界&lt;br&gt;
f(x) 在 (a,b) 上连续，且 f(a+) f(b-) 均存在。区间可以拓展到无穷，只要保证两端极限均存在即有界。&lt;/p&gt;
&lt;p&gt;🔸数列有界&lt;br&gt;
任意一项均小于一个数 &amp;amp;&amp;amp; 大于一个数。比如 xn = 1/n，上界：1，下界：0&lt;br&gt;
有界数列一定有上界和下界；只有上界/下界的数列不是有界数列&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;极限和有界的联系&lt;/strong&gt;&lt;br&gt;
🔸函数&lt;br&gt;
函数有极限 a，则在 a 的邻域内局部有界（可以拓展为无穷）&lt;br&gt;
函数有界不能推出函数有极限，比如 sin cos&lt;/p&gt;
&lt;p&gt;🔸数列&lt;br&gt;
如果一个数列“收敛”（有极限），那么这个数列一定有界&lt;br&gt;
如果一个数列有界，这个数列未必收敛。例如数列 ：“1，-1，1，-1，……，(-1)n+1”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;无穷小和有界&lt;/strong&gt;&lt;br&gt;
函数在 x-&amp;gt;x0 无穷小，则 x0 点极限为 0，且在 x0 邻域内局部有界。（显而易见，为了和数列做对比）&lt;br&gt;
无穷小数列，n-&amp;gt;+∞ ，an = 0；无穷小数列同时是有界和收敛数列&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;综上分析：&lt;/strong&gt;&lt;br&gt;
数列 xn = 1/n，上界：1，下界：0；极限 n-&amp;gt;∞ xn = 0；1/n 是无穷小数列&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;经典反例&lt;/strong&gt;&lt;br&gt;
在判断无穷和有界的题目中，经典反例如下&lt;/p&gt;
&lt;p&gt;xn = 0 n奇；n n偶；yn = n n奇；0 n偶；&lt;br&gt;
xn，yn 的无穷极限不存在；都是无界值；xn 和 yn 相乘为0；&lt;/p&gt;
&lt;p&gt;xn = 1，1，3，1，....  yn = 1，2，1，4，....&lt;br&gt;
xn，yn 无穷极限不存在，但 xn 和 yn 乘积极限为无穷；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可去间断点&lt;/strong&gt;&lt;br&gt;
f(x) 在 x₀ 处得到左、右极限均存在且相等的间断点，称为可去间断点。 需要注意的是，可去间断点需满足 f(x) 在 x₀ 处无定义，或在 x₀ 处有定义但不等于函数 f(x) 在 x₀ 的左右极限。&lt;/p&gt;
&lt;p&gt;拉格朗日中值求极限要保证 f′(ξ) 不为 0 / ∞&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/yuxuezhang/article/details/120242578&#34;&gt;一文彻底搞懂拉格朗日中值定理秒杀复杂极限问题（内含高级秒杀结论）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;注意，n 阶可导，洛必达只能到 n-1 阶。&lt;br&gt;
因为 n 阶可导，只能保证 n-1 阶导数存在且连续。而不知道 n 阶导数是否连续。不连续是不能用洛必达的。&lt;br&gt;
若 n 阶连续可导，则可以洛到 n 阶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;驻点&lt;/strong&gt;&lt;br&gt;
驻点是一阶导数等于零的点，拐点是指函数凹凸性发生改变的点。 驻点要么是极值点（二阶导不等于零）要么是拐点（二阶导等于零）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;拐点&lt;/strong&gt;&lt;br&gt;
函数在某点的二阶导数为零或不存在，且二阶导数在该点两侧符号相反，该点即为函数的拐点。若二阶导数在该点两侧符号相同，则不是拐点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;渐近线&lt;/strong&gt;&lt;br&gt;
先找间断点，看有没有铅直渐近线&lt;br&gt;
再把x趋向于无穷，看有没有水平渐近线&lt;br&gt;
有水平渐近线的地方没有斜渐近线&lt;br&gt;
没有水平渐近线的一侧，找斜渐近线&lt;/p&gt;
&lt;h1 id=&#34;积分&#34;&gt;积分&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;不定积分：原函数的存在定理&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;fx 连续，则原函数 Fx 一定存在&lt;/li&gt;
&lt;li&gt;fx 不连续，fx 存在第一类间断点，则 Fx 不存在；fx 仅存在震荡间断点，Fx 可能存在（x²sin(1/x)）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;连续 -&amp;gt; 有原函数；有原函数 !-&amp;gt; 连续&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定积分的可积性&lt;/strong&gt;&lt;br&gt;
必要条件：可积函数必有界&lt;br&gt;
充分条件：在闭区间 [a, b] 上&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;fx 连续&lt;/li&gt;
&lt;li&gt;fx 有界，且只有有限个间断点&lt;/li&gt;
&lt;li&gt;fx 只有有限个第一类间断点（间断点对定积分无影响）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意&lt;br&gt;
fx 可积指的是在一定区间上的定积分，而是否存在原函数指的是不定积分，二者不同&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1G4411U7X9/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;&lt;strong&gt;快速学会“极坐标积分换序”&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
最简单的方法就是把 θ 和 r 换在直角坐标中，然后使用直角坐标的思路进行换限。&lt;br&gt;
注意换完限之后也要加 rdrdθ&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;积分不等式比较&lt;/strong&gt;&lt;br&gt;
常用结论&lt;br&gt;
sinx &amp;lt; x &amp;lt; tanx (x∈[0, pai])&lt;/p&gt;
&lt;p&gt;积分不等式证明常用思路&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;拆积分限，使两边积分限相等，再做比较&lt;/li&gt;
&lt;li&gt;变量代换，使两边积分限相等&lt;/li&gt;
&lt;li&gt;积分中值定理&lt;/li&gt;
&lt;li&gt;fx 单调性已知，构造变上限积分&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;反常积分审敛&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定义法：直接求积分&lt;/li&gt;
&lt;li&gt;和 p 积分相比较：① 直接将原式化为 p 积分进行判断 ②和 p 积分作比求极限&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;带绝对值的积分&lt;/strong&gt;&lt;br&gt;
由定积分推得二重积分，都需要分区间讨论，二重积分的区间就是被积区域，通过几何关系讨论正负&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1QP41177nx/?vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;带绝对值的定积分：分区间讨论&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1UP4y137TN/?vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;被积函数带有绝对值的二重积分&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三角函数&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/162297688&#34;&gt;三角函数的另外三个伙伴—cot，sec，csc&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;极坐标换元&lt;/strong&gt;&lt;br&gt;
x = rcosθ&lt;br&gt;
y = rsinθ&lt;br&gt;
θ 范围直接看就行，把 r 和 θ 带入原方程，求得 r 的范围。&lt;br&gt;
如：x^2 + y^2 &amp;lt;= 2x；带入得：r^2 &amp;lt;= 2rcosθ；r &amp;lt;= 2cosθ&lt;br&gt;
注：r 恒大于 0&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/364642276&#34;&gt;变量代换求解微分方程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;质心&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_42578970/article/details/106419646?ydreferer=aHR0cHM6Ly9jbi5iaW5nLmNvbS8%3D&#34;&gt;质心计算公式&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;收敛域和收敛区间&lt;/strong&gt;&lt;br&gt;
收敛区间是个开区间，而收敛域就是判断在收敛区间的端点上是否收敛&lt;/p&gt;
&lt;p&gt;收敛半径一定存在&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二重积分的奇偶性&lt;/strong&gt;&lt;br&gt;
有积分区域 D&lt;br&gt;
x 奇偶看 D 是否关于 y 轴对称；y 奇偶看 D 是否关于 x 轴对称&lt;br&gt;
关于 x/y 为奇函数，积分为 0；关于 x/y 为偶函数，则积分为二倍&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Qs4y1e75h/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;三重积分的对称性（奇偶＋轮换）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;计算第二型曲面积分的方法&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;若曲线封闭，用格林公式&lt;/li&gt;
&lt;li&gt;若与路径无关，改换路径/找原函数&lt;/li&gt;
&lt;li&gt;补线用格林&lt;/li&gt;
&lt;li&gt;直接换元计算&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;判断是否与路径无关：若 ∂P/∂y = ∂Q/∂x，则与路径无关，反之不是&lt;br&gt;
改换路径：沿坐标轴走直线，可先沿x再沿y，也可先沿y再沿x，看哪个更简单&lt;br&gt;
找原函数：凑微分，直接带值&lt;/p&gt;
&lt;p&gt;补线用格林：补一条路径，形成封闭曲线，再把补的减掉&lt;br&gt;
注意格林公式使用条件，P、Q 在封闭曲线上有连续一阶偏导。若在某点（比如0点）没有定义&lt;/p&gt;
&lt;h1 id=&#34;无穷级数&#34;&gt;无穷级数&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Va411V7bm/?is_story_h5=false&amp;amp;p=1&amp;amp;share_from=ugc&amp;amp;share_plat=ios&amp;amp;share_session_id=A7B70058-1BD8-42A6-9025-7B71CDEE01A4&amp;amp;share_tag=s_i&amp;amp;unique_k=sOfyyCn&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;级数选择题中的反例汇总（不只是反例，更是思想方法！）&lt;/a&gt;&lt;br&gt;
收敛+发散 必发散&lt;br&gt;
收敛+收敛 必收敛&lt;br&gt;
都发散，和敛散性不定，比如两数列恰好抵消，则为收敛&lt;/p&gt;
&lt;p&gt;加括号会提高级数收敛的可能性&lt;br&gt;
收敛级数加括号仍收敛&lt;br&gt;
若级数加括号收敛，则原级数不一定收敛&lt;br&gt;
加括号后发散，原级数一定发散&lt;br&gt;
原因：加括号可能抵消一些项，可能会使级数收敛&lt;/p&gt;
&lt;p&gt;审敛法只是充分条件，非必要条件，且只适用于正项级数&lt;br&gt;
比如当比值/根值等于1时，就判断不出来了&lt;/p&gt;
&lt;p&gt;加绝对值会提高发散的可能性，由于都变为正项，整体值变大&lt;br&gt;
正项级数变为交错级数，提高收敛可能性&lt;br&gt;
提高阶数，提高收敛可能性&lt;/p&gt;
&lt;p&gt;条件收敛也是收敛，指的是级数本身收敛，但加了绝对值不收敛&lt;br&gt;
绝对收敛是，加了绝对值都收敛，那么原级数更收敛，二者都是收敛&lt;br&gt;
落脚点都在原级数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;和函数计算&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;求收敛域，也就是和函数的定义域（因为逐项可导、逐项可积都是在开区间上成立）&lt;/li&gt;
&lt;li&gt;在收敛区间（开区间上求和函数）&lt;/li&gt;
&lt;li&gt;单独判断端点，若不能合并，需要分段&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;已知 S&#39;(x) 求 S(x) 需要使用变上限积分  ∫x S(t)dt&lt;/li&gt;
&lt;li&gt;只要对 x 的 n 次方进行改变的时候，就要判断 n 从 0 还是 1 开始取&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1eb4y1U7fP/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;如何选择恰当的××（区域），使得你的××（积分）最大！&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;曲线曲面积分&#34;&gt;曲线曲面积分&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_47187147/article/details/124933148?spm=1001.2014.3001.5506&#34;&gt;各类重积分 | 二重积分、三重积分、线面积分 —— 大总结&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;是否可以带入边界方程&lt;/strong&gt;&lt;br&gt;
曲线曲面积分可直接带入边界方程，而二重、三重积分不可；使用格林、斯托克公式将线面积分化为二三重积分后也不可带入&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对称性、奇偶性&lt;/strong&gt;&lt;br&gt;
一型线面积分都有奇偶性、轮换对称性；二型线面无&lt;br&gt;
🔺判断曲线对称性的小方法&lt;br&gt;
将曲线线方程中的 x 换 -x 后，方程不变，则该曲线关于 x=0（即 y 轴）对称&lt;br&gt;
当然最靠谱的是配方，然后看相对标准曲线的偏移&lt;br&gt;
&lt;strong&gt;一型线积分&lt;/strong&gt;&lt;br&gt;
得到的是弧长 / 周长；有对称性，可以直接带入边界方程&lt;br&gt;
&lt;strong&gt;二型线积分&lt;/strong&gt;（今年概率大）&lt;br&gt;
对线坐标的积分，无对称性，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;x y 的参数式，直接计算（考的情况很少）&lt;/li&gt;
&lt;li&gt;补线用格林（必须封闭）且是：∂Q/∂x - ∂P/∂y （别反了）
&lt;ol&gt;
&lt;li&gt;面积在线左侧为正&lt;/li&gt;
&lt;li&gt;区域内点必须有定义，否则单独圈出来处理&lt;/li&gt;
&lt;li&gt;线积分与路径无关：∂Q/∂x =∂P/∂y&lt;br&gt;
&lt;strong&gt;一型面积分&lt;/strong&gt;&lt;br&gt;
得到曲面面积；对称性&lt;br&gt;
&lt;strong&gt;二型面积分&lt;/strong&gt;（去年考的这个）&lt;br&gt;
注意：只有用高斯公式时才需要考虑曲面是否封闭，投影法不需要&lt;br&gt;
投影法可以考虑的点：&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;若投到面上为一条线，则积分为 0&lt;/li&gt;
&lt;/ol&gt;
">高等数学</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/cai-keng-wifi-lian-bu-shang-wang-luo-gua-pei-qi-cuo-wu/"" data-c="
          &lt;p&gt;总是出现 WIFI 图标消失的问题，原因是网卡被禁用，处理方式是去 Intel 官网下载符合型号的官方驱动，进行修复。&lt;/p&gt;
&lt;p&gt;查看设备管理器：&lt;br&gt;
运行窗口输入 devmgmt.msc&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/hhxy_wlzx/article/details/103749207?ydreferer=aHR0cHM6Ly9jbi5iaW5nLmNvbS8%3D&#34;&gt;AC9560网卡等类似驱动无法正常启动解决方法&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/419468589&#34;&gt;Windows 踩坑——Intel(R) Wireless-AC 9560 160MHz 报错无法连接 WiFi&lt;/a&gt;&lt;/p&gt;
">【踩坑】WIFI连不上——网络适配器错误</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/wei-xin-xiao-cheng-xu-kai-fa/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/jackson-yqj/p/9843696.html&#34;&gt;微信小程序开发的基本流程&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/baidu_31788709/article/details/107348402&#34;&gt;微信小程序开发全流程记录（从前台到后台，到发布）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/m0_64875238/article/details/127796691&#34;&gt;微信小程序开发（超详细保姆式教程）&lt;/a&gt;&lt;/p&gt;
">微信小程序开发</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/kao-yan-xin-xi-zheng-he/"" data-c="
          &lt;h1 id=&#34;北邮&#34;&gt;北邮&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://ai.bupt.edu.cn/kxyj/yjfx.htm&#34;&gt;研究方向&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;北邮人论坛&lt;/strong&gt;&lt;br&gt;
导师推荐&lt;br&gt;
https://bbs.byr.cn/#!article/StudyShare/203152&lt;/p&gt;
&lt;p&gt;何召锋、&lt;/p&gt;
&lt;p&gt;杨洁：海量泛在感知数据的智能分析与处理方法，以及基于感知信息的智能决策计算理论与技术；泛在网络感知大数据智能计算、智能网络优化与路由算法、公共安全智能图像计算、多模态天基感知数据智能计算、人机协同智能辅助诊断&lt;/p&gt;
&lt;p&gt;复试：&lt;br&gt;
数据结构&lt;br&gt;
人工智能算法&lt;br&gt;
英文自我介绍&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/615652800&#34;&gt;23复试分析|清华大学-深圳研究院！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/615696688&#34;&gt;2023年北京邮电大学计算机考研考情分析！！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/536212509&#34;&gt;考研如何备考北京邮电大学人工智能专业809方向？&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;香港留学&#34;&gt;香港留学&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/496130863&#34;&gt;香港前五的大学里，哪些计算机硕士专业人工智能强一点？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/611773896&#34;&gt;24考研PDF无水印电子书汇总&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/612655797&#34;&gt;考研英语黄皮书选择与使用方法指南（非常全）&lt;/a&gt;&lt;/p&gt;
">【考研】信息整合</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/gai-lu-lun/"" data-c="
          &lt;p&gt;概率为 0 的事件与任意事件相互独立&lt;br&gt;
&lt;strong&gt;全概率公式做题步骤&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;确定要求的事件A&lt;/li&gt;
&lt;li&gt;找完备事件组，列出各种情况Bi(i=1,2,3...)&lt;/li&gt;
&lt;li&gt;在情况Bi下，事件A发生的概率，P(A) = ∑P(Bi)P(A|Bi) = ∑P(ABi)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意，事件A零碎分布于事件B，所以需要将B的各种情况合起来计算&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1689308727900.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;将自然语言和数学语言相互转化，找到对应的值&lt;/p&gt;
&lt;h1 id=&#34;分布函数&#34;&gt;分布函数&lt;/h1&gt;
&lt;p&gt;分布函数端点值的辨析：&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_24451605/article/details/44115311&#34;&gt;理解分布函数(概率论)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;&lt;br&gt;
只有连续型分布有分布函数和概率密度，离散型没有&lt;br&gt;
混合型概率分布只有分布函数，没有概率密度&lt;/p&gt;
&lt;p&gt;分布函数连续 ⇔ 连续型随机变量&lt;br&gt;
分布函数必须右连续，只是针对点而言，右连续的函数也可以不是连续函数&lt;/p&gt;
&lt;h1 id=&#34;联合概率&#34;&gt;联合概率&lt;/h1&gt;
&lt;p&gt;注意，已知边缘分布，不能推得联合分布，当且仅当边缘分布相互独立的时候，可以通过相乘来确定联合分布&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;用联合概率密度求 Z(x,y)&lt;/strong&gt;&lt;br&gt;
当作二重积分算，积分区域是 xy 的范围，被积函数是 f(x,y)，要移动的图像是 P{} 内的函数&lt;br&gt;
比如 P{X+Y&amp;gt;1} ，选定一个要积的变量，比如x，则 y&amp;gt;1-x&lt;br&gt;
作图，在积分区域里积分，得到概率值。&lt;/p&gt;
&lt;p&gt;🔺注意：不管积分区域是什么样，也就是 P{} 括号内的函数是什么样，和联合分布函数无关。联合分布函数都是 f(x, y) （被积函数）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;求 z = g(x, y) 的分布函数&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;xy都是离散型，很简单，直接看就行&lt;/li&gt;
&lt;li&gt;xy都是连续型，则把 z 看作常数，讨论 z 的范围，然后再用上面联合概率密度求概率的方法&lt;/li&gt;
&lt;li&gt;x是离散型，y是连续型（离连型）全概率公式+分布函数法&lt;br&gt;
先写出 P{ X + Y ≤ Z } ，然后用全概率公式，分为 P{ X + Y ≤ Z ，X=0} P{ X + Y ≤ Z ，X=1} 等区间&lt;br&gt;
然后带入 X=0，X=1，化简表达式，变成  P{ X=0，Y ≤ Z }，P{ X=1，Y ≤ Z-1 }&lt;br&gt;
然后讨论 z 的范围，根据 X+Y=Z 来估计。比如 0&amp;lt;X&amp;lt;1，0&amp;lt;Y&amp;lt;1，那么 讨论 Z ∈（0，2）比如      z&amp;lt;0 时，Fz(z)=0&lt;br&gt;
当 z 的取值在积分区域里时，用二重积分计算概率值&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/kangkanglhb88008/article/details/90750074&#34;&gt;关于概率论里的Z=max{X,Y}，min{ X,Y }分布的理解与计算方法&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;数字特征&#34;&gt;数字特征&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;连续型求期望&lt;/strong&gt;&lt;br&gt;
先求密度：先用 P{U≤u} 卡出分布函数，然后求导&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;判断相关和独立&lt;/strong&gt;&lt;br&gt;
X Y 不相关 ⇔ EXY = EXEY (ρ=0)&lt;br&gt;
X Y 独立 ⇔ FXY = FXFY 或者 f(xy) = f(x)f(y)&lt;/p&gt;
">概率论</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/xian-xing-dai-shu/"" data-c="
          &lt;h1 id=&#34;行列式&#34;&gt;行列式&lt;/h1&gt;
&lt;p&gt;性质&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;行列式的性质对于行和列都满足&lt;/li&gt;
&lt;li&gt;行列式中相邻的两行(列)互换，行列式值反号。注意，不是相邻的行(列)不能直接交换，必须一行一行或者一列一列的交换。&lt;/li&gt;
&lt;li&gt;某一行乘 k，行列式乘 k；所有行都乘 k，行列式乘 k 的 n 次方&lt;/li&gt;
&lt;li&gt;有两行(列)一样 / 成倍数（提出一个 k 还是一样）行列式值为 0&lt;/li&gt;
&lt;li&gt;若行列式的某一列（行）的元素都是两数之和，则此行列式等于两个行列式之和&lt;/li&gt;
&lt;li&gt;矩阵可逆 行列式 ≠ 0&lt;/li&gt;
&lt;li&gt;矩阵转置行列式的值不变&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;∣&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;|kA|  = k^n |A|&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.664392em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;∣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;矩阵&#34;&gt;矩阵&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;与矩阵的秩有关的结论&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A 为 m x n 矩阵，则有 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;0 ≤ r(A) ≤ min(m,n)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.78041em;vertical-align:-0.13597em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 为 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 的转置，则有 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A) = r(A^T) = r(AA^T) = r(A^TA)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.0913309999999998em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.0913309999999998em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.0913309999999998em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;若 A 与 B 相似即 A~B，则有 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A) = r(B)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(AB) ≤ min(r(A),r(B))&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A + B) ≤ max(r(A),r(B)) ≤ r(A,B) ≤ r(A) + r(B)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;若 P，Q 可逆，则有 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(PAQ) = r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;Q&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;若 A 可逆， &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(AB)=r(BA)=r(B)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;A 为 m x n 矩阵，且 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A) = n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;（列满秩），则  &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(AB)= r(B)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;A 为 m x n 矩阵，B 为 n x s 矩阵，且 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;AB = O&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;O&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，则  &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A) + r(B) ≤ n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;伴随矩阵 A* 的秩：0、1、n&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1VW4y1o7D2/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【矩阵】分块矩阵！那些&amp;quot;考研机构&amp;quot;舍不得讲的内容...&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;n维向量&#34;&gt;ｎ维向量&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;向量组的定理辨析&lt;/strong&gt;&lt;br&gt;
梳理思路：从定义 到 方程组 到 方程组的直观理解 到 系数矩阵的秩 的解释&lt;/p&gt;
&lt;p&gt;🔺向量组线性相关 ⇔ 至少存在一组非零系数使向量组为 0 ⇔&lt;br&gt;
齐次方程组有非零解 ⇔ 行列式 = 0 ⇔ 未知数数量比方程组多 ⇔&lt;br&gt;
n 维列向量对应 n 个方程组，s 个列向量对应 s 个未知数，s &amp;gt; n  ⇔&lt;br&gt;
系数矩阵为扁长方形则一定相关 ⇔ 有效方程组数量（向量组的秩）小于未知数个数 s（列数）&lt;/p&gt;
&lt;p&gt;向量 α 和 β 线性相关，则 β=kα&lt;/p&gt;
&lt;p&gt;🔺向量组线性无关 ⇔ 当且仅当 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;k_1=k_2=...=k_s=0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.36687em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 向量组 = 0 ⇔&lt;br&gt;
齐次方程组只有零解 ⇔ 若为 nxn 则 行列式 ≠ 0（可逆）⇔ 未知数数量等于方程组&lt;br&gt;
⇔ 向量组的秩（有效方程组数量）等于列数（未知数个数），即列满秩（A 为 m x n 矩阵，则有 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;0 ≤ r(A) ≤ min(m,n)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.78041em;vertical-align:-0.13597em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;）⇔ 向量组中至少有一个向量可由其余的向量线性表出&lt;/p&gt;
&lt;p&gt;注意，有效方程组只能为扁长形和正方形，不能为竖长，竖长意味着方程组个数大于未知数，则无解&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;判定向量组线性无关&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用定义，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;k_1=k_2=...=k_s=0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.36687em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，利用已知条件对式子做变换（左乘、右乘 / 相加减）&lt;/li&gt;
&lt;li&gt;方程组只有零解 ⇔ 特殊情况：当矩阵为 nxn 时，行列式 ≠ 0 ⇔ 一般情况：矩阵满秩&lt;br&gt;
行向量组线性无关 ⇔ 行满秩&lt;br&gt;
列向量组线性无关 ⇔ 列满秩&lt;/li&gt;
&lt;li&gt;整体组无关，部分组无关&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;相关无关判定&lt;/strong&gt;&lt;br&gt;
部分组相关 ⇒ 整体组相关&lt;br&gt;
整体组无关 ⇒ 部分组无关&lt;/p&gt;
&lt;p&gt;缩短组无关 ⇒ 延伸组无关&lt;br&gt;
延伸组相关 ⇒ 缩短组相关&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;p68 定理 3.7 理解&lt;/strong&gt;&lt;br&gt;
相关的多数向量能用少数向量表出（少数向量是基底，多数向量为空间中的很多向量）&lt;br&gt;
无关的少数向量能用多数向量表出（空间中的很多向量通过变换可以求出基底）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;向量线性表出相关定理&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x_1α_1+x_2α_2+....=x_nα_n=β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.73333em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.73333em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.36687em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.58056em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 有非零解&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;[α_1,α_2,...,α_n,β]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 方程组有解，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)=r(\overline A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;高维可以表示低维：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1,α_2,...,α_t&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.2805559999999999em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可由 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β_1,β_2,...,β_t&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.2805559999999999em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 表出，则 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(α_1,α_2,...,α_t) ≤ r(β_1,β_2,...,β_t)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.2805559999999999em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.2805559999999999em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;向量组 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1,α_2,...α_m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 线性相关 向量组中至少有一个向量可由其余的 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;m-1&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.66666em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;个向量线性表出&lt;/li&gt;
&lt;li&gt;若向量组 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1,α_2,...α_m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 线性无关，而 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β,α_1,α_2,...α_m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 线性相关，则 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可由 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;.&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1,α_2,...α_m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.151392em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 线性表出，并且表示法唯一&lt;/li&gt;
&lt;li&gt;向量组 B 能由向量组 A 线性表出 ⇔ &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A,B)=r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;  （B是由A表出的，所以 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A,B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8777699999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 的秩还是 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 的秩 / &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)=r(\overline A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;向量空间&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基底变换：由基 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;到&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1，α_2，α_3 到 β_1，β_2，β_3&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;到&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
对 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 矩阵 列变换，右乘过渡矩阵 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;C&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β=αC&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;坐标变换&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x=Cy&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8777699999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 是在 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 下的坐标，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;y&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 是在 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 下的坐标（交叉原则）&lt;/li&gt;
&lt;li&gt;求 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;γ&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05556em;&#34;&gt;γ&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 在 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 下的坐标&lt;br&gt;
列为：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x_1α_1+x_2α_2+x_3α_3=γ&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.73333em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.73333em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.58056em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05556em;&#34;&gt;γ&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，将左侧化为单位矩阵，右边则为 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;γ&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;γ&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05556em;&#34;&gt;γ&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 在 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 下的坐标&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;线性方程组&#34;&gt;线性方程组&lt;/h1&gt;
&lt;p&gt;化简线性方程组不能列变换&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;线性方程组有解辨析&lt;/strong&gt;&lt;br&gt;
对于 m×n 矩阵，分为三种情况，m&amp;gt;n、m&amp;lt;n、m=n，讨论在这三种情况下 齐次 和 非齐次 解的情况&lt;br&gt;
核心思想：对于 β 一列，经过变换后无法判断尾部是否为 0&lt;br&gt;
🔺对于 m&amp;gt;n，即 行&amp;gt;列，方程组个数大于未知数个数。设系数矩阵为 A&lt;br&gt;
若 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)=n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 即列满秩（ &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 恒小于等于 n ），此时 n 个有效方程组，n 个未知数，则方程组 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Ax=0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 有唯一 0 解；&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Ax=β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可能有解也可能无解。有解时：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(\overline A)≤r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;；无解时：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(\overline A)&amp;gt;r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;🔺对于 m&amp;lt;n，即 行&amp;lt;列，方程组个数小于未知数个数。此时 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Ax=0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 一定有非零解；&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Ax=β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可能有解也可能无解。若 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)=m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 即 A 行满秩（ &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 恒小于等于 m ），r(&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\overline A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8833300000000001em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;) 恒等于 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，则一定有解；若 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)&amp;lt;m&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，有解时：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(\overline A)≤r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;；无解时：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(\overline A)&amp;gt;r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;🔺对于 m=n，即 行=列，方程组个数等于未知数个数。&lt;br&gt;
若 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)=n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 即 A 满秩，方程组 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Ax=0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 只有 0 解，此时 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(\overline A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 恒等于 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Ax=β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 有唯一解；若 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)&amp;lt;n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.43056em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，方程组 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Ax=0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 有无穷个非 0 解，此时对于 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;β&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Ax=β&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05278em;&#34;&gt;β&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ：有解时：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;≤&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(\overline A)≤r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;≤&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;；无解时：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(\overline A)&amp;gt;r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;💠综上，没说明行列关系时，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 推不出 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy=&#34;true&#34;&gt;‾&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;r(\overline A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.13333em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord overline&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8833300000000001em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.80333em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;overline-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，由 齐次 解的情况推不出 非齐次 解的情况&lt;/p&gt;
&lt;p&gt;&lt;code&gt;注&lt;/code&gt;&lt;br&gt;
方程组基础解系：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;α_1 α_2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.58056em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
求方程组的通解：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;k_1α_1+k_2α_2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
重特征值的特征向量：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;k_1α_1+k_2α_2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;特征值与特征向量&#34;&gt;特征值与特征向量&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;几何意义&lt;/strong&gt;&lt;br&gt;
特征向量的定义：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;λ&lt;/mi&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Aα = λα&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.69444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;λ&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;（α 非零）&lt;br&gt;
一个矩阵点乘一个向量就相当于对该向量进行旋转或者拉伸等一系列线性变换，特征向量在经过矩阵 A 的变换后，不改变方向，等价于由特征值 λ 进行缩放。如果特征值大于1，那么特征向量在变换后变长了；如果特征值小于1，特征向量变短了；如果特征值是负数，特征向量的方向会翻转。&lt;/p&gt;
&lt;p&gt;特征向量指示了在进行矩阵变换时，矩阵空间中不变的方向。通过研究特征值和特征向量，可以简化一些矩阵的运算，抓住矩阵空间中的不变信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;奇异值分解（Singular Value Decomposition，SVD）&lt;/strong&gt;&lt;br&gt;
特征值和特征向量是对方阵而言，对于非方阵（即行数和列数不相等的矩阵），通常不讨论特征向量和特征值，而是讨论奇异值分解（SVD）中的奇异向量和对角矩阵中的奇异值，这可以看作是特征值和特征向量的推广。奇异值分解是任何矩阵都可以进行的分解，它揭示了矩阵与特征值分解类似的某些性质，如数据压缩和结构简化。&lt;/p&gt;
&lt;p&gt;特征值和特征向量可以写为：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A = PDP^{-1}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8141079999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;D&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;  D为特征值矩阵，P为特征向量矩阵&lt;br&gt;
而奇异值分解定义为：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;U&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;Σ&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A = U \Sigma V^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.10903em;&#34;&gt;U&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;Σ&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，U和V是正交矩阵，它们的列向量都是单位向量，且两两正交，U为 mxn，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;V^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;V&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;为 nxm；Σ是一个 n×n 的对角矩阵，对角线上的非零元素称为奇异值，按从大到小的顺序排列，其余位置上的元素都是0。&lt;/p&gt;
&lt;p&gt;最大的奇异值对应于数据中最主要的成分或特征，而较小的奇异值则对应于次要的成分。矩阵的秩等于其非零奇异值的数量。&lt;/p&gt;
&lt;p&gt;在数据分析和信号处理中，可以通过保留最大的奇异值和对应的奇异向量来近似原始数据矩阵，从而实现数据压缩。这种压缩可以去除噪声和不重要的信息，同时保留数据的主要特征；最小二乘问题，SVD可以用来找到最小范数解；可以用于图像去噪、压缩、特征提取；PCA 中使用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;求特征值特征向量注意的问题&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;带入特征值化简时可先根据秩消去一行&lt;/li&gt;
&lt;li&gt;特征向量是基础解系加系数 k，如 kα&lt;/li&gt;
&lt;li&gt;重根的特征向量是基础解系相加，如 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;msub&gt;&lt;mi&gt;α&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;k_1α_1+k_2α_2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.84444em;vertical-align:-0.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.0037em;&#34;&gt;α&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.30110799999999993em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;A-1的特征值是 1/λ，特征向量还是 α 不变&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;矩阵的迹：tr(A)&lt;/strong&gt;&lt;br&gt;
迹：主对角线元素之和（不管怎么变化，矩阵的迹不会变），等于矩阵的特征值之和。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;反对称矩阵&lt;/strong&gt;&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A=-A^T&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.924661em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实对称矩阵&lt;/strong&gt;&lt;br&gt;
实对称矩阵不同特征值的特征向量一定正交&lt;br&gt;
实对称矩阵同一特征值的不同特征向量线性无关，但不一定正交，&lt;br&gt;
在要求求对应的正交矩阵时，要施密特正交化&lt;/p&gt;
&lt;p&gt;又因为 n 阶方阵可相似对角化 ⇔ A 有 n 个线性无关的特征向量&lt;br&gt;
所以 n 阶实对称矩阵必可以相似对角化&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正交矩阵&lt;/strong&gt;&lt;br&gt;
转置等于其逆的矩阵&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A^TA=E&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05764em;&#34;&gt;E&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
在求正交矩阵的时候，不同特征值的特征向量一定正交。相同特征值对应的特征向量不一定正交，所以要进行施密特正交化。&lt;br&gt;
然后把所有特征向量单位化，按列排列成正交矩阵。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;判断可相似对角化&lt;/strong&gt;&lt;br&gt;
充要条件只需记“n 个特征值对应 n 个线性无关的特征向量”&lt;br&gt;
注意，任何矩阵，不同特征值对应的特征向量线性无关（相同特征值不一定）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有 n 个不同的特征值&lt;/li&gt;
&lt;li&gt;k 重特征值对应 k 个线性无关的特征向量&lt;/li&gt;
&lt;li&gt;实对称矩阵一定可相似对角化（因为实对称不同特征值特征向量必正交）&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/413697441&#34;&gt;&lt;strong&gt;矩阵满足什么条件才能相似对角化！（相似于对角矩阵）&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;矩阵等价 &amp;amp; 向量组等价&lt;/strong&gt;&lt;br&gt;
矩阵等价：A 经过有限次初等变换可以变成 B ⇔ r(A)=r(B)&lt;br&gt;
向量组等价：两个向量组可以相互线性表出&lt;/p&gt;
&lt;p&gt;矩阵等价，其行列向量组都可以不等价；矩阵等价和行列向量组等价无关&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;矩阵的等价，相似，合同&lt;/strong&gt;&lt;br&gt;
关系：&lt;br&gt;
（（（相似）合同 ）等价 ）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;判断等价&lt;/strong&gt;&lt;br&gt;
r(A)=r(B)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;判断合同&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;充要条件：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;C^TAC=B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;C&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可逆；非对称只能找是否有一个对称阵，一般题目给的都不难找&lt;/li&gt;
&lt;li&gt;两个实对称矩阵合同的充要条件才是有相同的正负惯性指数（在标准型中看）&lt;br&gt;
由于 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;C^TAC=B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07153em;&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，若 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 为实对称，则 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 也为实对称，实对称矩阵的合同矩阵一定也对称&lt;br&gt;
非对称一定不和对称合同&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;判断相似&lt;/strong&gt;&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;P^{-1}AP = B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8141079999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.05017em;&#34;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
实对称矩阵相似 ⇔ 特征值相等&lt;br&gt;
非实对称：没有充要条件，只能用必要条件判断&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;判定矩阵之迹&lt;/li&gt;
&lt;li&gt;判定行列式是否相等&lt;/li&gt;
&lt;li&gt;判定特征值是否相等&lt;/li&gt;
&lt;li&gt;判定重特征值是否对应相同个数的特征向量&lt;br&gt;
（也就是 λE-A 的秩）&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/151231495&#34;&gt;“拨开迷雾”，如何判定矩阵相似？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/77007052&#34;&gt;线性代数——相似矩阵的可逆变换矩阵P是否唯一&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从上往下，判断合同必须满足等价，判断相似必须满足合同&lt;/p&gt;
&lt;h1 id=&#34;二次型&#34;&gt;二次型&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/read/cv6499426/&#34;&gt;（数一）二次曲面类型与二次型的正负惯性指数的关系&lt;/a&gt;&lt;br&gt;
求二次型对应的二次曲面，求出标准型，然后判断对应的曲线即可&lt;br&gt;
🔺标准型的求法&lt;br&gt;
① 配方法：一般是一次方程相乘，特别注意，经坐标变换，x=Cy，若 |C|=0，则不是坐标变换，不能用配方法&lt;br&gt;
② 特征值法：一般有平方项了&lt;br&gt;
🔺直观判断曲面的方法&lt;br&gt;
分别看 xy xz yz 在 xoy，xoz，yoz 面上都是什么曲线，然后连起来即可&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正定矩阵性质&lt;/strong&gt;&lt;br&gt;
对称、可逆&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;判断正定&lt;/strong&gt;&lt;br&gt;
充要条件&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;正惯性指数为 n（特征值均大于零）&lt;/li&gt;
&lt;li&gt;A 与 E 合同&lt;/li&gt;
&lt;li&gt;各阶顺序主子式大于零&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;二次型求标准型 ⇔ 二次型矩阵求特征值&lt;br&gt;
所用正交矩阵就是矩阵正交的特征向量&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;证明正定&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;检验 A 对称&lt;/li&gt;
&lt;li&gt;证明正定（用判断条件证明）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;求二次型最值&lt;/strong&gt;&lt;br&gt;
最大值：最大特征值 乘以 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x^Tx&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 的值&lt;br&gt;
最小值：最小特征值 乘以 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;x^Tx&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8413309999999999em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8413309999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 的值&lt;/p&gt;
">线性代数</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/gong-ju/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://poe.com/ChatGPT&#34;&gt;ChatGPT 其他接口&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.94speed.com/?token=94speed666&#34;&gt;百度网盘快速下载解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bili.iiilab.com/&#34;&gt;b站下载&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://xn--ehq00hgtfdmt.xyz/#/dashboard&#34;&gt;三分机场&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://xn--4gq62f52gdss.art/#/dashboard&#34;&gt;一元机场&lt;/a&gt;&lt;/p&gt;
">【工具】</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/she-ying-ren-xiang-si-lu/"" data-c="
          &lt;p&gt;最近拍毕业照，总结一下毕业照思路和注意事项&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;单人&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;老生常谈一个场景多拍几张，防止表情管理失败&lt;/li&gt;
&lt;li&gt;可以准备书本、花束等道具；更多还可以准备气球、泡泡机等道具&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;拍摄思路&lt;br&gt;
在学校地标性街道/建筑前拍一个最常规的照片，比如抱着花束拍照，背景虚化&lt;br&gt;
和帽子、书本、花束等产生互动。戴摘帽子、端着帽子、扔帽子、抱着书本等&lt;br&gt;
站立姿势上，可以从头到脚进行一些变化。歪头、侧头，歪身侧头、看上下左右&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多人&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多人表情管理失败概率增大，而且人摆姿势往往第一遍是最自然的，解决方案就是&lt;br&gt;
使用 Mid 挡的连拍，让人摆好姿势之后，说看镜头，321，确保大家都看镜头，然后连拍几张。&lt;br&gt;
这样既可以确保姿势的自然，又可以确保选出表情管理成功的照片。&lt;/li&gt;
&lt;li&gt;一个场景拍摄结束，要给客户看一下构图、神态等等是否满意，否则如果结束后客户不满意就不好搞了。退钱自己有损失，不退钱口碑会有损失。&lt;/li&gt;
&lt;li&gt;多人讲究互动感，构建一个场景让大家互动起来，才自然融洽&lt;/li&gt;
&lt;/ol&gt;
">【摄影】人像思路</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/sui-xiang/"" data-c="
          &lt;p&gt;网上的文章分为informative文章和查阅型文章，&lt;br&gt;
informative是指深入浅出、娓娓道来&lt;br&gt;
查阅型是指全面的列出来，自己可以查阅&lt;br&gt;
入门应该看informative&lt;/p&gt;
&lt;p&gt;写微信小程序赚钱&lt;/p&gt;
">随想</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/cv-mu-biao-zhui-zong/"" data-c="
          &lt;p&gt;目标追踪是计算机视觉中的一个重要领域，它涉及在视频序列中连续定位和识别特定目标。目标追踪算法可以分为两大类：生成式（generative）方法和判别式（discriminative）方法。以下是一些常用的目标追踪算法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;生成式方法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;均值漂移（Mean Shift）&lt;/strong&gt;：通过迭代寻找概率密度函数的峰值来进行目标定位。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;粒子滤波（Particle Filter）&lt;/strong&gt;：使用一组随机样本（粒子）来表示目标状态的概率分布，并通过重采样和权重更新来追踪目标。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;判别式方法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;基于深度学习的方法&lt;/strong&gt;：使用卷积神经网络（CNN）来学习目标和背景的特征表示，如Siamese网络、孪生网络（Siamese Network）和基于深度强化学习的方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在线序列判别式分析方法（OSDA）&lt;/strong&gt;：通过在线学习目标模型和背景模型，并计算目标与模型的匹配度来进行追踪。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于相关滤波的方法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;最小均方误差（Minimum Output Sum of Squared Error, MOSSE）滤波器&lt;/strong&gt;：一种快速且高效的相关滤波追踪方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;核化相关滤波器（Kernelized Correlation Filters, KCF）&lt;/strong&gt;：扩展了MOSSE滤波器，引入了核技巧来提高追踪性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多通道滤波器&lt;/strong&gt;：如空间加权通道特征（CSK）和颜色名称（CN）滤波器，它们利用了颜色和其他特征通道来提高追踪的鲁棒性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于模型的方法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模板匹配&lt;/strong&gt;：使用目标模板在当前帧中进行滑动窗口搜索，寻找最佳匹配。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于模型的方法&lt;/strong&gt;：构建目标的3D模型，并通过匹配模型和观测数据来进行追踪。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;其他方法&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;光流法（Optical Flow）&lt;/strong&gt;：通过分析图像序列中的像素运动来追踪目标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于特征的方法&lt;/strong&gt;：如尺度不变特征变换（SIFT）、加速鲁棒特征（SURF）和定向梯度直方图（HOG），它们提取图像特征并进行匹配以追踪目标。&lt;br&gt;
目标追踪算法的选择取决于应用场景、性能要求、计算资源等因素。在实际应用中，可能需要根据具体情况选择或设计合适的追踪算法。随着深度学习技术的发展，基于深度学习的追踪方法在性能上取得了显著提升，成为目标追踪领域的热点研究方向。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Augurlee/article/details/104995171&#34;&gt;KCF论文理解与源码解析&lt;/a&gt;&lt;/p&gt;
">【CV】目标追踪</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/zheng-ze-biao-da-shi/"" data-c="
          &lt;h1 id=&#34;测试&#34;&gt;测试&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://c.runoob.com/front-end/854/&#34;&gt;在线测试工具1&lt;/a&gt;&lt;br&gt;
注意这个工具的表示：&lt;br&gt;
如果显示匹配部分都是粉色的，则只有这一种匹配方式；&lt;br&gt;
如果显示匹配部分粉色蓝色交替，则表示可以有单个粉色、蓝色这种匹配方式&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://regexr.com/&#34;&gt;RegExr -- 正则表达式在线测试工具&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;学习&#34;&gt;学习&lt;/h1&gt;
&lt;p&gt;忘了的时候用这个过一遍：&lt;br&gt;
&lt;a href=&#34;https://regexlearn.com/zh-cn/learn/regex101&#34;&gt;正则表达式学习网站&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当作字典查找：&lt;br&gt;
&lt;a href=&#34;https://www.runoob.com/regexp/regexp-tutorial.html&#34;&gt;正则表达式 - 教程&lt;/a&gt;&lt;/p&gt;
">正则表达式</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/linux-qi-mo-fu-xi/"" data-c="
          &lt;h1 id=&#34;linux概述&#34;&gt;Linux概述&lt;/h1&gt;
&lt;p&gt;安卓就是一种Linux，上层使用Java&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/495025002&#34;&gt;Linux 终端新手指南 | Linux 中国&lt;/a&gt; {Linux 终端是一个基于文本的交互界面，它是用来控制 Linux 计算机的。}&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/nyist_zxp/article/details/103940686&#34;&gt;Linux 终端之物理终端、虚拟终端和伪终端的区别&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一台物理上的字符终端必须具备：显示器、串行通信口，键盘。不必须具备磁盘存储器&lt;/p&gt;
&lt;p&gt;‎C语言编写的应用程序，通过printf打印一个换行符\n，但在终端上执行的是回车加换行\r\n，把换行符替换为回车换行是由Linux内核中的行律模块完成的。在Linux内核中，终端设备通常以行为单位进行输入和输出。当你在C语言程序中使用 printf 打印一个换行符 \n 时，终端设备会将其解释为换行操作，并自动添加回车符 \r。这样做是为了在输出文本时在终端中正确实现换行的效果。&lt;/p&gt;
&lt;p&gt;使用PuTTY或SecureCRT仿真终端登录Linux，将终端类型设置为linux，输入echo -e &amp;quot;\033[1;31mHello&amp;quot;命令后文字变为红色。输入echo -e &amp;quot;\033[1;33mHello&amp;quot;文字变为黄色。&lt;/p&gt;
&lt;p&gt;终端仅仅是Linux主机的一个外部设备，不分担存储和计算工作&lt;br&gt;
传统的终端与Linux主机之间传输的是字节流&lt;/p&gt;
&lt;p&gt;‌终端转义序列的意义在于终端收到某一特定字符序列后执行一些约定好的控制功能，而不是把这些字符显示在显示器上。比如执行换行符、退格符&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/611470376&#34;&gt;5 个有用的 Linux Shell 转义序列 | Linux 中国&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;开始使用linux&#34;&gt;开始使用Linux&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;用户登录和联机手册的查阅&lt;/strong&gt;&lt;br&gt;
root用户（超级用户）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;root不受权限的制约，可随意修改和删除文件&lt;/li&gt;
&lt;li&gt;root用户误删重要文件可能带来严重后果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;创建新用户&lt;/strong&gt;&lt;br&gt;
由root用户创建（useradd命令），用户信息存放在/etc/passwd文件中，&lt;br&gt;
包括用户名和用户ID，以及Home目录，登录shell&lt;br&gt;
登录shell：一般为bash，也可以选其他shell，其他系统程序，甚至自设&lt;br&gt;
计的程序&lt;br&gt;
用户可以从普通终端或者网络虚拟终端登录进入系&lt;/p&gt;
&lt;p&gt;普通用户：$  |  root用户：#&lt;br&gt;
组成命令的英文字母大小写敏感&lt;/p&gt;
&lt;p&gt;几个基本命令：&lt;br&gt;
man查阅手册：各种命令说明、系统调用使用手册等&lt;br&gt;
date日期和时间&lt;br&gt;
ntpdate通过NTP协议校对系统时间&lt;br&gt;
cal日历&lt;br&gt;
bc计算器，缺省精度为小数点后20位&lt;br&gt;
passwd修改口令（密码）&lt;br&gt;
超级用户root&lt;br&gt;
修改口令之前不验证旧的口令&lt;br&gt;
可修改自己的口令，还可强迫设置/查看其它用户口令&lt;/p&gt;
&lt;p&gt;几个了解系统状态的命令&lt;br&gt;
who：确定谁在系统中&lt;br&gt;
uptime：了解系统启动时间和忙碌程度&lt;br&gt;
top：列出资源占用（CPU）排名靠前的进程&lt;br&gt;
free：了解&lt;s&gt;总体&lt;/s&gt;内存使用情况&lt;br&gt;
vmstat：了解系统负载情况&lt;br&gt;
ps：查阅进程状态（关于进程的属性都可以） ps -SZ：进程逻辑内存大小&lt;/p&gt;
&lt;h1 id=&#34;文本文件的处理&#34;&gt;文本文件的处理&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;文本文件及处理工具&lt;/strong&gt;&lt;br&gt;
文本信息包含：&lt;br&gt;
文本文件：C语言，Java语言等编程文件的源程序语言；文本格式的数据文件；文本格式的文字信息&lt;br&gt;
程序输出&lt;br&gt;
系统配置信息&lt;br&gt;
文本型的网络协议&lt;br&gt;
文本文件的处理命令&lt;/p&gt;
&lt;p&gt;重定向与管道机制&lt;br&gt;
输出重定向：ls -l&amp;gt;filelist.txt&lt;br&gt;
输入重定向：sort &amp;lt; filelist.txt&lt;/p&gt;
&lt;p&gt;一个“&amp;gt;”是输入&lt;br&gt;
两个“&amp;gt;&amp;gt;”是追加&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;读取文件内容&lt;/strong&gt;&lt;br&gt;
Linux中和文本处理有关的命令：vi more grep yacc lex awk sed&lt;br&gt;
介绍几个文本文件读取与处理的命令&lt;br&gt;
 more/less：逐屏显示文件&lt;br&gt;
 cat与od：列出文件内容&lt;br&gt;
 head与tail：显示文件的头部或者尾部&lt;br&gt;
 tee：三通&lt;br&gt;
 wc：字计数&lt;br&gt;
 sort：对文件内容排序&lt;br&gt;
 tr：翻译字符&lt;br&gt;
 uniq：筛选文件中的重复行&lt;/p&gt;
&lt;p&gt;tail命令&lt;/p&gt;
&lt;p&gt;‏使用more命令逐屏显示文本文件时，使得显示内容上滚一行而不是滚动一屏，应按下回车键&lt;br&gt;
使用less命令逐屏显示文本文件时，使得显示内容上滚一行而不是滚动一屏，应按下向下的箭头&lt;br&gt;
‌Linux中用来实现计数功能，比如：统计系统有多少个登录用户，实现计数功能的命令是：wc -l&lt;/p&gt;
&lt;p&gt;uniq命令可以通过无选项运行uniq bar.txt，或者使用选项-d运行uniq -d bar.txt，两种情况的输出结果中都不会出现相邻两行内容完全相同的情况。&lt;/p&gt;
&lt;p&gt;uniq bar.txt逐行检查bar.txt中的文本行，如果本行与上一行完全相同则不输出，否则输出；&lt;br&gt;
uniq -d bar.txt的选项d是duplicate，如果本行与下一行不同却与上一行相同，才输出，结果只输出连续两次或多次出现的行。&lt;br&gt;
-c选项是counter计数器。&lt;/p&gt;
&lt;p&gt;一个应用程序的C语言源程序通过printf语句在标准输出输出信息，运行时只要使用输出重定向机制，不需要修改原先的程序加入文件操作的代码，就可以把输出结果存入指定名字的文件。&lt;/p&gt;
&lt;p&gt;‌od命令可以实现用16进制方式逐字节打印一个文件内容的功能，但并不要求文件的每个字节必须是可打印字符，不可打印也能输出。&lt;/p&gt;
&lt;p&gt;tail命令的-f选项可以让tail命令持续运行下去，持续地将它操作的文本文件新增的数据显示出来。如果这个文本文件被其他进程随时间推移断断续续追加几行，tail也会断断续续地输出这些新增的内容。&lt;/p&gt;
&lt;p&gt;‎可以为tee命令提供一个文件名abc.log，例如：xyz | tee abc.log 那么，通过管道的方式可以把前面xyz命令的输出结果在当前终端上显示的同时也存入磁盘文件abc.log，可供事后查阅。如果以某用户正在使用的终端的设备文件名(如/dev/pts/2)代替文件名abc.log，那么，这个xyz命令执行时的输出就会同时在两个终端上实时显示。就算是把前面的xyz命令换成vi也是完全可能的，也就是说完全可能在第二个终端上实时看到第一个终端上的编辑画面。&lt;/p&gt;
&lt;p&gt;uniq 命令只能消除相邻的重复行。如果文件中有多个相同的行，但它们不是相邻的，那么 uniq 命令不会消除它们。&lt;/p&gt;
&lt;p&gt;‏信息由一个个字节组成，tr命令处理这些信息时，可以将256种字节值中的任何一种取值“翻译”为另一个字节值，并且不限于可打印字符之间的转译，比如把换行符替换为斜线。&lt;/p&gt;
&lt;h1 id=&#34;正则表达式的概念和相关命令&#34;&gt;正则表达式的概念和相关命令&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;正则表达式语法&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/zheng-ze-biao-da-shi/&#34;&gt;正则表达式&lt;/a&gt;&lt;br&gt;
正则表达式中6个元字符（特殊字符）： . * [ \ ^ $&lt;br&gt;
用反斜线可以取消特殊字符的特殊含义：正则表达式*与字符串*匹配，与字符串*不匹配&lt;br&gt;
转义字符后除以上六种之外的不该出现其他字符&lt;/p&gt;
&lt;p&gt;“.”匹配任意单字符&lt;br&gt;
“[ ]”在该位置上匹配括号内任意一个单字符：例如 [abcd] 与a或b,c,d匹配（只能匹配一位）&lt;br&gt;
圆点、星号在方括号内时，代表它们自己：[*.] 匹配 * 和 .&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Linux中的正则表达式&lt;/strong&gt;&lt;br&gt;
三个与正则表达式相关的处理命令&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;grep/egrep/fgrep：在文件中查找字符串（筛选）&lt;/li&gt;
&lt;li&gt;sed：流编辑（加工）&lt;/li&gt;
&lt;li&gt;awk：逐行扫描进行文本处理的一门语言（筛选与加工）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;🔺grep（Global regular expression print）&lt;br&gt;
&lt;a href=&#34;https://cloud.tencent.com/developer/article/1554542&#34;&gt;是真的很详细了！Linux中的Grep命令使用实例&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/65515740&#34;&gt;grep命令的思维导图&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;‌grep和fgrep都可以从一个文本文件中搜索出指定的字符串。&lt;/p&gt;
&lt;p&gt;egrep 使用扩展正则表达式ERE描述模式，在指定模式方面比grep更灵活&lt;br&gt;
fgrep 快速搜索指定字符串，按字符串搜索而不是按模式搜索。&lt;/p&gt;
&lt;p&gt;🔺sed（Stream Editor） 一个强大的流式文本编辑器&lt;br&gt;
常用功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;文本替换：sed最常用的功能是进行文本替换。使用s/模式/替换字符串/命令，sed可以根据正则表达式模式匹配文本，并将匹配到的部分替换为指定的字符串。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;删除行：sed可以根据正则表达式模式删除符合条件的行。使用d命令，sed可以删除匹配到的行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;插入和追加行：sed可以在指定位置插入或追加文本行。使用i命令可以在匹配行之前插入行，而使用a命令可以在匹配行之后追加行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;打印行：sed可以根据匹配条件选择性地打印文本行。使用p命令，sed可以打印匹配到的行，或者使用-n选项来禁止自动输出，只有通过命令显式打印才会输出结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;转换命令：sed提供了一些转换命令，可以对文本进行处理。例如，y命令可以进行字符替换，tr命令可以进行字符转换，y/abc/ABC/将会把输入中的小写字母a、b、c分别替换为大写字母A、B、C。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多行处理：sed可以处理包含多行的文本数据。通过使用N命令，可以将多行文本合并为一行进行处理，或者使用/pattern/{commands}语法在匹配模式的范围内执行一系列命令。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文件处理：sed可以直接在文件中进行文本处理，也可以通过管道接收输入数据。使用-i选项，sed可以直接在原始文件上进行修改，而不需要创建新文件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;脚本模式：除了直接在命令行中使用sed命令，还可以将sed命令保存在脚本文件中进行批处理。通过在命令行中使用-f选项指定脚本文件，可以执行包含多个sed命令的脚本。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;http://c.biancheng.net/linux/sed.html&#34;&gt;sed命令_Linux sed命令：替换、删除、更新文件中的内容&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;判断&lt;/code&gt;&lt;br&gt;
​fgrep，grep，egrep三个命令在指定待查找字符串的模式方面，依次越来越灵活，后面的命令可以覆盖前面命令的功能，并且模式描述的语法也是完全兼容的。（错）&lt;/p&gt;
&lt;p&gt;‎命令cat pm.txt | sed ‘s/[[^][]*]//g’  可以把pm.txt中所有用方括号括起来的内容（包括方括号自身）类似“ [参考文献23] ”这样的字符串片段删除。&lt;/p&gt;
&lt;p&gt;​grep可以筛选出包括某些特定模式的文本行，awk不仅可以筛出指定模式的行，还可以筛掉文本型表格中的部分列。&lt;/p&gt;
&lt;p&gt;正则表达式&amp;lt;[^&amp;lt;&amp;gt;]*&amp;gt;可以匹配一个HTML格式数据中的诸如&lt;span class=&#34;src-time&#34;&gt;这样的用尖括号包裹起来的标签信息。&lt;/p&gt;
&lt;p&gt;‏awk是一门小型的文本数据处理语言，有类似C语言一样的语法，可以使用自定义的变量，变量之间可以进行算术运算、关系运算和逻辑运算，还可以进行正则表达式匹配运算，支持条件、循环等流程控制。&lt;/p&gt;
&lt;h1 id=&#34;文件比较&#34;&gt;文件比较&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;两文件逐字节比较：cmp&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.runoob.com/linux/linux-comm-cmp.html&#34;&gt;Linux cmp 命令&lt;/a&gt;&lt;br&gt;
🔺用法&lt;br&gt;
cmp file1 file2&lt;br&gt;
🔺功能&lt;br&gt;
逐字节比较两个文件是否完全相同。&lt;br&gt;
两个文件完全相同时，不给出任何提示；两个文件不同时，打印出第一个不同之处&lt;br&gt;
在Windows中有类似的命令COMP&lt;/p&gt;
&lt;p&gt;md5sum计算出位于两台不同计算机上的两文件的校验和是相同的，我们就认为两个文件的内容是完全相同的，无论这两个文件有多大。两计算机之间仅交换16字节的校验和就可以完成文件内容的比较。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;求出两个文件的差别：diff&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.runoob.com/linux/linux-comm-diff.html&#34;&gt;Linux diff 命令&lt;/a&gt;&lt;br&gt;
🔺用法&lt;br&gt;
diff file1 file2&lt;br&gt;
diff –u file1 file2&lt;br&gt;
🔺功能&lt;br&gt;
比较两个版本的文本文件，以寻找两者间差别&lt;br&gt;
输出格式 normal，unified (-u)&lt;br&gt;
normal格式：列出一个如何将file1转化为file2的指令。这些指令有a（Add），c（Change）和d（Delete）&lt;/p&gt;
&lt;p&gt;&lt;code&gt;判断&lt;/code&gt;&lt;br&gt;
diff命令只可以求出两个文件中文本文件的差异，二进制的数据文件不可以&lt;/p&gt;
&lt;p&gt;diff -u 的输出格式和git相同，而不是normal格式&lt;br&gt;
normal 列出将file1转化为file2的指令&lt;/p&gt;
&lt;h1 id=&#34;vi编辑器&#34;&gt;vi编辑器&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.runoob.com/linux/linux-vim.html&#34;&gt;Linux vi/vim&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/cyl101816/article/details/82026678&#34;&gt;Linux—vi命令详解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;刚进入vi时，进入命令状态。按 i 进入文本输入状态。再按下Esc按键可以返回命令状态&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常用命令&lt;/strong&gt;&lt;br&gt;
🔺删除&lt;br&gt;
删除当前字符：x&lt;br&gt;
删除从当前光标开始的5个字符：5x&lt;/p&gt;
&lt;p&gt;🔺替换命令：r&lt;br&gt;
ra命令将当前光标处字符替换为a&lt;br&gt;
将当前光标处开始的三个字符依次替换为abc，则需要按命令rarbrc&lt;/p&gt;
&lt;p&gt;🔺取消上一次的编辑操作(undo) u&lt;br&gt;
如：误删了一段正文，用u命令可撤销删除&lt;br&gt;
如：把文件中的所有abc字符串替换成xyz字符串， 用u命令可撤销替换&lt;/p&gt;
&lt;p&gt;🔺重复上一次的编辑操作 .&lt;br&gt;
按圆点键，可以重复上一次的编辑操作&lt;br&gt;
例如：按3dd命令删除了三行，然后按圆点键就再删除三行，接着连续按&lt;br&gt;
圆点键，每按一次删三&lt;/p&gt;
&lt;p&gt;🔺存盘退出命令&lt;br&gt;
方法一：首先需要按ESC键回到命令模式，然后按“:wq回车”。&lt;br&gt;
方法二：按住shift再按两下’z‘键。&lt;/p&gt;
&lt;p&gt;🔺存盘不退出&lt;br&gt;
:w&lt;/p&gt;
&lt;p&gt;🔺不存盘退出&lt;br&gt;
:q!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;操作失误导致的问题&lt;/strong&gt;&lt;br&gt;
Ctrl-S 在 Linux 中用于流量控制，而不是保存文件。使用 Ctrl-Q 流量控制解除&lt;br&gt;
vi存盘命令Shift-ZZ，误操作为Ctrl-ZZ&lt;br&gt;
当前终端的“行律”设置不正确，导致退格键(Backspace)无法使用&lt;br&gt;
由于 /bin/bash 文件不是文本文件，是二进制文件。cat /bin/bash或head -n 1 /bin/bash导致屏幕乱码&lt;br&gt;
Linux：行尾处仅存换行字符；Windows：行尾处存回车和换行两个字符&lt;br&gt;
许多Linux默认中文编码方案：UTF8；Windows默认中文编码方案：GBK。迁移文件时不兼容导致乱码&lt;/p&gt;
&lt;h1 id=&#34;文件名和文件通配符&#34;&gt;文件名和文件通配符&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;文件和目录的命名规则&lt;/strong&gt;&lt;br&gt;
一般允许1－255字符&lt;br&gt;
除斜线“/”外的所有字符都是命名的合法字符&lt;/p&gt;
&lt;p&gt;🔺系统配置信息&lt;br&gt;
/etc目录：供系统维护管理用的命令和配置文件&lt;br&gt;
🔺临时目录&lt;br&gt;
/tmp：临时文件&lt;br&gt;
/var：系统运行时要改变的数据，系统日志 syslog 等&lt;br&gt;
🔺可运行程序和设备文件&lt;br&gt;
/bin：系统常用命令，如ls，ln，cp，cat等&lt;br&gt;
/usr/bin：存放一些常用命令，如ssh,ftp，make，gcc，git等&lt;br&gt;
/sbin,/usr/sbi：系统管理员专用命令&lt;br&gt;
/dev：设备文件，如终端设备，磁带机，打印机&lt;br&gt;
🔺头文件和库文件&lt;br&gt;
/usr/include (usr=Unix System Resource）：C语言头文件存放目录&lt;br&gt;
/lib,/usr/lib：存放各种库文件，指C语言的链接库文件，以及terminfo终端库等等&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文件通配符规则&lt;/strong&gt;&lt;br&gt;
🔺星号 *&lt;br&gt;
匹配任意长度的文件名字符串(包括空字符串)&lt;br&gt;
点字符(.)，当它作为文件名或路径名分量的第一个&lt;br&gt;
字符时，必须显式匹配&lt;br&gt;
斜线(/)也必须显式匹配&lt;br&gt;
例：*file匹配file，makefile，不匹配.profile文件&lt;br&gt;
🔺问号 ?&lt;br&gt;
匹配任一单字符&lt;br&gt;
🔺方括号 [ ]&lt;br&gt;
匹配括号内任一字符，也可以用减号指定一个范围&lt;br&gt;
例: [A-Z]* *.[ch] [Mm]akefile&lt;br&gt;
🔺波浪线 ~&lt;br&gt;
（Bash特有的）&lt;br&gt;
~ 当前用户的主目录(home)&lt;br&gt;
~kuan 用户kuan的主目录(home)&lt;/p&gt;
&lt;p&gt;文件名通配符规则与正则表达式的规则不同，应用场合不同&lt;br&gt;
不同种类shell通配符规则会略有些差别&lt;/p&gt;
&lt;p&gt;&lt;code&gt;选择题&lt;/code&gt;&lt;br&gt;
在windows中*.&lt;em&gt;可以匹配所有文件，但在Linux有的文件名与&lt;/em&gt;.*不匹配，下列哪个不匹配？&lt;br&gt;
abc Makefile .profile comp.exe sort.c find.obj readme.text admin-ver3.1.2sp.tar&lt;br&gt;
A、readme.txt&lt;br&gt;
B、comp.ext&lt;br&gt;
C、abc&lt;br&gt;
D、admin-ver3.1.2sp.tar&lt;br&gt;
&lt;code&gt;解析&lt;/code&gt; 匹配的名称必须有“ . ”，选 C&lt;/p&gt;
&lt;h1 id=&#34;文件管理和目录管理&#34;&gt;文件管理和目录管理&lt;/h1&gt;
&lt;p&gt;ls选项-l: 长格式列表&lt;br&gt;
第1列：文件属性；第一个字符为文件类型，后面为文件访问权限&lt;br&gt;
第2列：文件link数，涉及到此文件的目录项数&lt;br&gt;
第3列，第4列：文件主的名字和组名&lt;br&gt;
第5列：文件大小/目录表大小&lt;br&gt;
第6列：文件最后一次被修改的日期和时间&lt;br&gt;
第7列：文件名&lt;/p&gt;
&lt;p&gt;注意：ls -l 未列出 文件占用多少存储空间&lt;/p&gt;
&lt;p&gt;ls是ls指令的普通模式，列出当前目录下的普通文件的文件名&lt;br&gt;
ls * 中的 * 会在shell中进行替换，替换成可以匹配到的所有的文件名，相当于命令 ls file_name&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;cp: 拷贝文件&lt;/strong&gt;&lt;br&gt;
命令的两种格式和功能&lt;br&gt;
cp file1 file2 cp file1 file2 ... filen dir&lt;br&gt;
其中file1，……，filen为文件名，dir为已有目录名&lt;br&gt;
第二种格式中： dir必须已经存在并且是一个目录&lt;br&gt;
第一种格式中： file2不存在，则创建；file2存在且是文件，则覆盖； file2&lt;br&gt;
存在且是目录，则按格式二处理&lt;br&gt;
例:cp a.c a.bak&lt;br&gt;
cp a.c b.c backup.d&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mv: 移动文件&lt;/strong&gt;&lt;br&gt;
格式&lt;br&gt;
mv file1 file2&lt;br&gt;
mv file1 file2 ... filen dir&lt;br&gt;
mv dir1 dir2&lt;br&gt;
功能&lt;br&gt;
使用mv命令可以将文件和目录改名&lt;br&gt;
可以将文件和子目录从一个目录移动到另一个目录&lt;br&gt;
mv dir1 dir2 两种执行情况（同文件系统，不同文件系统）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;rm: 删除文件&lt;/strong&gt;&lt;br&gt;
命令格式&lt;br&gt;
rm file1 file2 ... filen&lt;br&gt;
例&lt;br&gt;
rm core a.out&lt;br&gt;
rm *.o *.tmp&lt;br&gt;
rm * .bak&lt;br&gt;
选项&lt;br&gt;
-r 递归地(Recursive)删除实参表中的目录，也就是删除一整棵目录树。&lt;br&gt;
-i 每删除一个文件前需要操作员确认(Inform)&lt;br&gt;
-f 强迫删除(Force)。只读文件也被删除并且无提示&lt;br&gt;
注：正在运行的可执行程序文件不能被删除&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目录管理&lt;/strong&gt;&lt;br&gt;
pwd (print working directory)：打印当前工作目录&lt;br&gt;
cd (Change Directory)：改变当前工作目录&lt;br&gt;
mkdir：创建目录&lt;br&gt;
rmdir：删除目录&lt;br&gt;
cp: 复制目录&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;–r，递归地复制一个目录&lt;/li&gt;
&lt;li&gt;–v，冗长(verbose)方式：复制目录时实时列出正在复制的文件的名字&lt;/li&gt;
&lt;li&gt;选项–u，增量拷贝(update)，便于备份目录&lt;br&gt;
rsync：数据备份工具（增量拷贝工具）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;例题&lt;/code&gt;&lt;br&gt;
cd只能是内部命令，但是pwd是可以设计成外部命令的&lt;br&gt;
rm命令的–r选项是递归（recursion）的意思，-f是强制删除的意思，rm -rf *命令能把当前目录下的所有文件都删除。（x）&lt;br&gt;
错误一：*并不能匹配到所有的文件，例如.profile就不能匹配到&lt;br&gt;
错误二：-f虽然是强制删除的意思，但实际作用是省去了删除时的提示信息，对没有权限删除的文件，它是不会删除的&lt;br&gt;
rm命令的-f选项是force：“强制删除”，可能会将只读文件强制删除不给出任何提示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;find:遍历目录树&lt;/strong&gt;&lt;br&gt;
🔺功能&lt;br&gt;
find命令从指定的查找范围开始，递归地查找子目录，凡满足条件的文件或目录，执行规定的动作&lt;br&gt;
🔺举例&lt;br&gt;
find verl.d ver2.d -name &#39;*.c&#39; -print&lt;br&gt;
范围：当前目录的子目录 ver1.d 和 ver2.d&lt;br&gt;
条件：与名字 *.c 匹配。注：*.c 应当用引号括起&lt;br&gt;
动作：把查找到的文件的路径名打印出来&lt;br&gt;
🔺条件选项&lt;br&gt;
-name wildcard：文件名与wildcard匹配，&lt;br&gt;
注意：必需的引号；这里的“文件名”仅指路径名的最后一部分；对通配符的解释由find完成&lt;br&gt;
-regex pattern：整个路径名与正则表达式pattern匹配&lt;br&gt;
🔺动作选项&lt;br&gt;
-print&lt;br&gt;
打印查找的文件的路径名&lt;br&gt;
-exec&lt;br&gt;
对查找到的目标执行某一命令&lt;br&gt;
在-exec及随后的分号之间的内容作为一条命令&lt;br&gt;
在这命令的命令参数中，{}代表遍历到的目标文件的路径名&lt;br&gt;
-ok&lt;br&gt;
与-exec类似，只是对查找到符合条件的目标执行一个命令前需要经过操作员确认&lt;/p&gt;
&lt;p&gt;注：使用find命令的-exec选项启用一个命令处理符合条件的文件，比find结合xargs的方式，花费更多的CPU时间&lt;/p&gt;
&lt;p&gt;tar命令输出文件的后缀必须符合规定，为.tar，.tar.gz, .tgz, .tar.bz2等，否则无法解包。（x）&lt;br&gt;
文件名后缀.tar,.tar.gz,.tar.bz2仅仅是惯例，不是系统级强制要求&lt;/p&gt;
&lt;h1 id=&#34;应用程序获取信息的方法&#34;&gt;应用程序获取信息的方法&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;命令获取信息的方法&lt;/strong&gt;&lt;br&gt;
易变性从小到大为&lt;br&gt;
配置文件：较复杂的程序&lt;br&gt;
环境变量：与“环境”相关的配置或选项信息&lt;br&gt;
命令行参数：程序启动之前指定&lt;br&gt;
交互式键盘输入：程序启动之后通过计算机与操作员之间的人机交互获取信息&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;命令行参数的三种风格&lt;/strong&gt;&lt;br&gt;
类似dd命令的风格&lt;br&gt;
类似find和gcc的风格&lt;br&gt;
类似ls和grep的风格：现今流行的格式&lt;/p&gt;
&lt;h1 id=&#34;文件系统&#34;&gt;文件系统&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;文件系统的创建与安装&lt;/strong&gt;&lt;br&gt;
🔺根文件系统 (root filesystem)&lt;br&gt;
根文件系统是整个文件系统的基础，不能“脱卸(umount)”&lt;br&gt;
🔺子文件系统&lt;br&gt;
子文件系统，包括硬盘，软盘，CD-ROM，USB盘，网络文件系统NFS以根文件系统中某一子目录的身份出现(不似Windows逻辑盘）&lt;br&gt;
🔺独立的存储结构&lt;br&gt;
根文件系统和子文件系统都有其自己独立的文件系统存储结构，甚至文件系统的格式也不同&lt;/p&gt;
&lt;p&gt;mkfs和mount：文件系统的创建和安装&lt;br&gt;
umount：文件系统的卸载&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文件系统的存储结构&lt;/strong&gt;&lt;br&gt;
引导块(0号块)：用于启动系统，只有根文件系统的引导块有效&lt;br&gt;
专用块(1号块)：也叫管理块，或者超级块。存放文件系统的管理信息&lt;br&gt;
i节点区：i节点(index node，简记为i-node)：每块可容若干个i节点，每个i节点包括：指向文件存储区数据块的一些索引（index）指针；文件类型&lt;br&gt;
文件存储区：用于存放文件数据的区域，包括目录表。文件名也存放在磁盘的文件存储区&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;inode&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV17J41147a8/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【小知识】第12期 linux中的iNode介绍&lt;/a&gt;&lt;br&gt;
inode：存储文件的元数据信息，比如类型、owner、权限、时间信息、连接数、文件内容所在的位置&lt;br&gt;
inode 以数组的方式存储。inode一般是128/256 byte&lt;br&gt;
初始化数组之后会生成一个目录表（Map），存放 inode-index 和文件名的对应关系（目录项：“文件名-节点号”对）&lt;/p&gt;
&lt;p&gt;示例：如何通过文件名找到 inode&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;假定要找 /etc/1.txt 文件，首先用文件名在 Map 中找到对应的 inode-index&lt;/li&gt;
&lt;li&gt;利用 inode-index 找到 inode 数组中对应的 inode&lt;/li&gt;
&lt;li&gt;查看 inode 中的信息，查看是否有 读写权限&lt;/li&gt;
&lt;li&gt;如果具有读/写信息，则找到 inode 中文件内容所在的位置（磁盘上块的下标）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;扇区（sector）：磁盘制造的时候就定好了（硬件层面）&lt;br&gt;
磁盘上的块（block）：包含多个扇区（逻辑层面）&lt;/p&gt;
&lt;p&gt;inode用尽：由于 inode 数组的大小在声明的时候就定好了，所以如果 inode 数组被完全占用，则称为 inode 用尽&lt;/p&gt;
&lt;p&gt;一个文件名只能对应一个inode，但一个inode可以被多个文件名同时指向。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/llife/p/11470668.html&#34;&gt;Linux inode 详解（包括硬链接和软链接）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;硬链接&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;例&lt;/code&gt;&lt;br&gt;
现在有 filename1，在 Map 中对应 inode_index1，这种对应关系称为一个硬链接。此时使用如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ln filename2 inode_index1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;建立 filename2 文件名与 inode_index1 的对应关系。此操作为创建硬链接。此操作后 inode 中硬链接数+1（同一 inode 被目录项引用的次）&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/klb561/p/9240758.html&#34;&gt;Linux命令——ln命令创建和删除软、硬链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;由此可见，Linux 可以在同一目录或者不同目录中的两个目录项，有相同的 i 节点号。&lt;br&gt;
可以类比 C 语言中，不同指针指向同一个地址号。如果对地址内容（inode对应的地址块）进行修改，那么所有的文件名对应的文件都会改变。&lt;br&gt;
删除一个文件名，不会对 inode 造成影响。除非删除所有的文件名。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;注&lt;/code&gt;&lt;br&gt;
‎命令 ln 只允许对同一文件系统的普通文件建立硬链接，不允许对目录用 ln 命令建立硬链接，防止形成环状目录结构，难以处理。目录的 link 数=直属子目录数+2（包括自身目录 . 和上级目录 .. ）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;符号链接（软链接）&lt;/strong&gt;&lt;br&gt;
类似于Windows中的快捷方式。是一个文件，包含的有另一文件的位置信息。使用如下代码建立软链接&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;ln -s 源文件或目录 目标文件或目录
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;符号链接的内容可以是“绝对路径”也可以是“相对路径”，相对路径指的是相对于符号链接文件所处位置，而不是相对于进程的当前工作目录。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;比较&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/67366919&#34;&gt;Linux软连接和硬链接&lt;/a&gt;&lt;br&gt;
🔺硬连接&lt;br&gt;
在数据结构层次上实现&lt;br&gt;
只适用于文件，不适用于目录&lt;br&gt;
同文件系统之间也不行&lt;br&gt;
🔺符号连接&lt;br&gt;
在算法软件上实现&lt;br&gt;
硬连接能够完成的功能软连接都可以做到（软&amp;gt;硬）&lt;br&gt;
适用于目录，也适用于不同的文件系统&lt;br&gt;
同硬连接相比要占用操作系统内核的一部分开销（因为单独创建了文件）&lt;br&gt;
循环式符号连接，以及处理方法（解析路径时设置符号链接解析计数器）&lt;br&gt;
无论采用符号链接还是硬链接，都可以实现将只存储一份的数据文件同时加入到两个或两个以上不同目录中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统调用&lt;/strong&gt;&lt;br&gt;
系统调用以C语言函数调用的方式提供&lt;br&gt;
操作系统内核提供的编程界面&lt;br&gt;
应用程序(ap)和操作系统(kernel)进行交互的唯一手段&lt;br&gt;
例如：文件操作的open，read，write，close&lt;br&gt;
种类：早期UNIX有50多个，后来扩充到120个，Linux有300个左&lt;/p&gt;
&lt;p&gt;返回值&lt;br&gt;
一般返回一个整数值&lt;br&gt;
返回值大于或等于零：成功&lt;br&gt;
返回值为-1：失败&lt;/p&gt;
&lt;p&gt;strerror&lt;br&gt;
char *strerror(int errno);&lt;br&gt;
errno是个整数，便于程序识别错误原因，不便于操作员理解失败原因。&lt;br&gt;
库函数strerror将数字形式的错误代码转换成一个可阅读的字符串&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;访问i节点和目录&lt;/strong&gt;&lt;br&gt;
系统调用stat/fstat：从i节点获得文件的状态信息&lt;br&gt;
结构体stat包括access时间、modification时间、change时间&lt;/p&gt;
&lt;h1 id=&#34;文件和目录的权限&#34;&gt;文件和目录的权限&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;文件权限&lt;/strong&gt;&lt;br&gt;
🔺权限的三个级别&lt;br&gt;
文件主，同组用户，其他用户&lt;br&gt;
每个文件有唯一的属主&lt;br&gt;
🔺普通文件的权限&lt;br&gt;
读、写、可执行&lt;br&gt;
不可写文件也可能会被删&lt;/p&gt;
&lt;p&gt;两类可执行文件：程序文件、脚本文件&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目录权限&lt;/strong&gt;&lt;br&gt;
若无读权限，”目录表“文件不许读取，ls 会失败&lt;br&gt;
若无写权限，”目录表“文件不许写&lt;br&gt;
目录无写权限不是指目录下所有文件都禁止写&lt;br&gt;
有执行权限（x）意味着分析路径名过程中可检索该目录&lt;br&gt;
STICKY权限（黏着位）：目录有写权限并且带STICKY属性，此目录下的文件仅文件主可以删除，其他用户删除操作会失败&lt;/p&gt;
&lt;p&gt;在Linux中用户可以把他的某个文件设置为他本人不可以读、写、执行，但是与他同组的人可以读、可以执行，即使他是该组的成员之一也无法读取文件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;权限相关命令&lt;/strong&gt;&lt;br&gt;
ls -l ：查询当前目录下所有文件和子目录权限&lt;br&gt;
chmod：修改已有文件的权限&lt;br&gt;
umask命令：控制文件/目录的初始权限。进程新创建的文件的权限受其影响&lt;/p&gt;
&lt;h1 id=&#34;shell的基本机制&#34;&gt;shell的基本机制&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/xq151750111/article/details/114491731&#34;&gt;Linux基础篇（一）-- Shell与Bash的区别和联系&lt;/a&gt;&lt;br&gt;
Bash是Shell的一种&lt;/p&gt;
&lt;p&gt;交互方式：直接在窗口输入命令。熟悉shell的替换机制、转义机制，掌握循环等控制流程，可以编写复合命令&lt;br&gt;
非交互方式：编写shell脚本程序，把一系列的操作变成一个脚本文件，批量处理&lt;/p&gt;
&lt;p&gt;交互式bash的命令提示符下输入!v并按下回车，其功能是引用历史机制，重复执行最近输入的以v开头的命令&lt;/p&gt;
&lt;p&gt;bash的重定向符&amp;lt;&amp;lt;&amp;lt;的作用是：将重定向符后面的单词作为这个命令的标准输入&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;程序的标准输入/输出&lt;/strong&gt;&lt;br&gt;
标准输入：stdin，fd=0&lt;br&gt;
标准输出：stdout，fd=1；标准错误输出：stderr，fd=2&lt;/p&gt;
&lt;p&gt;stdout 输出重定向&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;filename：将stdout重定向到文件filename，文件已存在则覆盖&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;filename：将stdout重定向追加到filename尾&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;命令执行时在终端上显示的信息有些属于标准输出stdout，有些属于标准错误输出stderr。显示信息到底属于stdout还是stderr，这取决于命令提供者如何设计的程序，与操作员无关。&lt;/p&gt;
&lt;h1 id=&#34;变量&#34;&gt;变量&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;变量赋值及应用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在脚本中编辑文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;环境变量&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;替换&#34;&gt;替换&lt;/h1&gt;
&lt;p&gt;shell的替换工作：先替换命令在执行命令&lt;br&gt;
变量替换、命令替换、文件名替换&lt;/p&gt;
&lt;p&gt;方便交互使用的功能：历史替换与别名替换&lt;/p&gt;
&lt;h1 id=&#34;元字符和转义&#34;&gt;元字符和转义&lt;/h1&gt;
&lt;p&gt;bash的元字符有：&lt;/p&gt;
&lt;p&gt;单引号、双引号&lt;/p&gt;
&lt;h1 id=&#34;shell流程控制条件-循环与函数&#34;&gt;shell流程控制：条件、循环与函数&lt;/h1&gt;
&lt;h1 id=&#34;进程的基本概念&#34;&gt;进程的基本概念&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/zhybiancheng/article/details/120312400&#34;&gt;【Linux】进程详解一：进程概念&lt;/a&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1686833745625.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h1 id=&#34;进程的创建和重定向&#34;&gt;进程的创建和重定向&lt;/h1&gt;
&lt;h1 id=&#34;重定向-信号&#34;&gt;重定向、信号&lt;/h1&gt;
&lt;p&gt;重定向与管道机制&lt;/p&gt;
&lt;h1 id=&#34;进程间协作&#34;&gt;进程间协作&lt;/h1&gt;
&lt;h1 id=&#34;socket概述&#34;&gt;Socket概述&lt;/h1&gt;
">【Linux】期末复习</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/tree/"" data-c="
          &lt;h1 id=&#34;ml&#34;&gt;ML&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://scikit-learn.org.cn/&#34;&gt;sklearn中文社区（机器学习算法索引）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ml-ji-chu-gai-lan&#34;&gt;【ML】基础概念&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ml-softmax&#34;&gt;【ML】Softmax&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/shu-ju-gui-yi-hua-chu-li&#34;&gt;【ML】数据预处理&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/mo-xing-ping-gu&#34;&gt;【ML】模型的评估&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ml-ANN-MLP-linear&#34;&gt;【ML】人工神经网络、MLP、全连接层&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ti-du-xia-jiang-gradient-descent/&#34;&gt;【ML】以梯度下降（Gradient Descent）展开的优化器总结&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ml-zhi-chi-xiang-liang-ji-svm/&#34;&gt;【ML】支持向量机（SVM）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/fen-lei-he-hui-gui&#34;&gt;【ML】分类和回归&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/jul-ei&#34;&gt;【ML】聚类&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ml-jue-ce-shu/&#34;&gt;【ML】决策树和随机森林&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ml-he-fang-fa-he-han-shu&#34;&gt;【ML】核方法和核函数&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/te-zheng-jiang-wei&#34;&gt;【ML】特征降维&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ml-mei-tian-yi-dian-numpy-xiao-ji-qiao&#34;&gt;【ML】每天一点 Numpy 小技巧&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/sklearn-mei-tian-yi-dian-sklearn&#34;&gt;【ML】每天一点 sklearn&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/keshihua&#34;&gt;【ML】可视化&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;dl&#34;&gt;DL&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/shen-du-xue-xi-de-yi-ban-bu-zou&#34;&gt;【DL】深度学习的一般步骤&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/dl-qiang-hua-xue-xi&#34;&gt;【DL】强化学习&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/dl-shen-du-sheng-cheng-mo-xing&#34;&gt;【DL】深度生成模型&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/dl-transformer&#34;&gt;【DL】Transformer&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/dl-tu-shen-jing-wang-luo&#34;&gt;【DL】图神经网络&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/dl-mo-xing-fu-yong&#34;&gt;【DL】模型复用&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;cv&#34;&gt;CV&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/cv-gai-shu&#34;&gt;【CV】概述&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ji-qi-shi-jue&#34;&gt;【CV】从零开始机器视觉&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/cnn-juan-ji-shen-jing-wang-luo&#34;&gt;【CV】CNN 卷积神经网络&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/mnist-shou-xie-shu-zi-shi-bie&#34;&gt;【CV】MNIST 手写数字识别&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/opencv-qian-ji&#34;&gt;【CV】OpenCV 浅记&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/cv-PhotometricStereo&#34;&gt;【CV】光度立体法 Photometric Stereo&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/shi-pin-mu-biao-jian-ce&#34;&gt;【CV】视频目标检测&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/cv-mu-biao-zhui-zong&#34;&gt;【CV】目标追踪&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;nlp&#34;&gt;NLP&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-gai-shu&#34;&gt;【NLP】概述&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-wen-ben-yu-chu-li&#34;&gt;【NLP】文本预处理&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-ci-qian-ru&#34;&gt;【NLP】词嵌入&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-seq2seq-beamsearch&#34;&gt;【NLP】Seq2Seq | Beam Search&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/bpe&#34;&gt;【NLP】BPE子词分割&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-shi-xu-mo-xing-yu-ma-er-ke-fu-mo-xing&#34;&gt;【NLP】时序模型与马尔可夫模型&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-wen-ben-xiang-si-du-fen-xi&#34;&gt;【NLP】文本相似度分析&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-rnn-lstm-gru&#34;&gt;【NLP】RNN | GRU | LSTM&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-bilstm-crf-suan-fa&#34;&gt;【NLP】BiLSTM-CRF算法&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/nlp-bert&#34;&gt;【NLP】BERT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;linux&#34;&gt;Linux&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/linux-ubuntu&#34;&gt;【Linux】Ubuntu配置与安装&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/linux-shell&#34;&gt;【Linux】Shell&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/linux-chang-yong-ming-ling-zong-jie&#34;&gt;【Linux】常用命令总结&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/linux-qi-mo-fu-xi&#34;&gt;【Linux】期末复习&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/linux-nei-he-mo-kuai-kai-fa&#34;&gt;【Linux】内核模块开发&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/linux-shen-du-xue-xi-pei-zhi&#34;&gt;【Linux】深度学习配置&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;基础&#34;&gt;基础&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/gao-shu&#34;&gt;高等数学&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/xian-xing-dai-shu&#34;&gt;线性代数&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/gai-lu-lun&#34;&gt;概率论&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/shu-ju-jie-gou&#34;&gt;数据结构&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/python-shui-de-python-xue-de-bu-zha-shi&#34;&gt;【Python】谁 Python 学的不扎实？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/zheng-ze-biao-da-shi/&#34;&gt;正则表达式&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/xing-shi-yu-yan-python-shi-xian-e-nfa-greater-dfa&#34;&gt;【形式语言】python实现 ε-ΝFA -&amp;gt; DFA&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/xing-shi-yu-yan-yu-zi-dong-ji-bi-ji&#34;&gt;《形式语言与自动机》笔记&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ji-wang-qi-mo-fu-xi&#34;&gt;【计网】期末复习&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ji-wang-bian-cheng-shi-yan&#34;&gt;【计网】可靠运输协议编程实验&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ji-wang-socket-bian-cheng-shi-yan&#34;&gt;【计网】Socket 编程实验&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/cao-zuo-xi-tong-bi-ji&#34;&gt;操作系统笔记&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/ba-gu-wen&#34;&gt;八股文&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/sql&#34;&gt;SQL&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/sql-fu-xi&#34;&gt;SQL 复习&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;项目和比赛&#34;&gt;项目和比赛&lt;/h1&gt;
&lt;h1 id=&#34;其他&#34;&gt;其他&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/pykeyboard-he-pymouse-zi-dong-hua-cao-zuo&#34;&gt;Pykeyboard 和 Pymouse 自动化操作&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;杂记&#34;&gt;杂记&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/lian-qin/&#34;&gt;【音乐】即兴练习思路&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/she-ying-diao-se-si-lu/&#34;&gt;【摄影】调色思路&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/le-li/&#34;&gt;【音乐】乐理&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;工具&#34;&gt;工具&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/gong-ju/&#34;&gt;【工具】&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/markdown-yu-fa&#34;&gt;Markdown 语法&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/git-shi-yong&#34;&gt;Github 使用&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/github-desktop-guan-li-ben-di-dai-ma&#34;&gt;Github Desktop 管理本地代码&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/jupyter-notebook-de-anaconda-pei-zhi&#34;&gt;Jupyter notebook 的 Anaconda 配置&lt;/a&gt;&lt;/p&gt;
">索引</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-bert/"" data-c="
          &lt;p&gt;Bidirectional Encoder Representation from Transformer（双向连接的多个 encoder）&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1NS4y1e7gz/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【BERT模型】暴力的美学，协作的力量&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1yU4y1E7Ns/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;69 BERT预训练【动手学深度学习v2】&lt;/a&gt;&lt;br&gt;
针对微调设计&lt;br&gt;
基于transformdr的encoder进行修改：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;模型更大，训练数据更多&lt;/li&gt;
&lt;li&gt;输入句子对，片段嵌入，可学习的位置编码&lt;/li&gt;
&lt;li&gt;训练时使用两个任务：带掩码的语言模型；下一个句子的预测&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;实战&#34;&gt;实战&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/347061440&#34;&gt;教你用PyTorch玩转Transformer英译中翻译模型！&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihsu.com/p/524487313&#34;&gt;保姆级教程，用PyTorch和BERT进行文本分类&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/473157694&#34;&gt;基于BERT预训练模型的SQuAD问答任务&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/Chen_Meng_/article/details/103212519&#34;&gt;基于BERT模型的知识库问答(KBQA)系统&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;变体&#34;&gt;变体&lt;/h1&gt;
&lt;p&gt;BERT（Bidirectional Encoder Representations from Transformers）自推出以来，催生了许多变体，这些变体旨在通过不同的方法提高性能、增强泛化能力或降低资源消耗。以下是一些著名的 BERT 变体的简述：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RoBERTa (Robustly Optimized BERT Approach)&lt;/strong&gt;: RoBERTa 对 BERT 的预训练过程进行了改进，包括去除了 Next Sentence Prediction (NSP) 任务，增加了训练数据量，使用了更大的 batch size 和更长的训练时间。这些优化显著提高了模型在多个自然语言处理任务上的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ALBERT (A Lite BERT)&lt;/strong&gt;: ALBERT 通过引入参数共享和因子化词嵌入技术来减少模型大小，这使得 ALBERT 在保持与 BERT 相似的性能的同时，具有更少的参数，从而减少了内存消耗和提高了训练速度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DistilBERT&lt;/strong&gt;: DistilBERT 是一个更小、更快、更轻量的 BERT 模型，通过知识蒸馏技术从 BERT 模型中提取知识，保持了相当部分的性能，但参数量却大大减少，适用于资源受限的环境。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TinyBERT&lt;/strong&gt;: TinyBERT 通过两阶段的转换过程进一步减小了模型尺寸，同时保持了良好的性能。在第一阶段，通过一般性蒸馏方法训练一个小型的通用 TinyBERT 模型；在第二阶段，对特定任务进行微调蒸馏，使其更适合特定的下游任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DeBERTa (Decoding-enhanced BERT with Disentangled Attention)&lt;/strong&gt;: DeBERTa 通过引入解耦注意力机制和增强的掩码解码器来改进 BERT 的注意力机制。这些改进使得 DeBERTa 在多个自然语言处理基准测试中取得了领先的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
">【NLP】BERT</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/lian-qin/"" data-c="
          &lt;p&gt;B站琴友原文链接：&lt;br&gt;
&lt;a href=&#34;https://t.bilibili.com/798087679282511889?share_from=dynamic&amp;amp;share_medium=android&amp;amp;share_plat=android&amp;amp;share_source=WEIXIN&amp;amp;share_tag=s_i&amp;amp;timestamp=1685638014&amp;amp;unique_k=JbGgziL&#34;&gt;自学乐器真的有硬伤，那就是乐理真的感觉很难学......&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;你先尝试扒二十首歌，我说的扒不是你能跟着弹下来那么简单，你得知道你弹的什么，这一句旋律是什么，是套在哪个和弦里的。当你扒够100首歌的时候，你这些问题就都不是问题了&lt;/p&gt;
&lt;p&gt;即兴呢其实就是要在前面的各种乐理基础上，加上你积累出的各种句子以及演奏技巧，跟着感觉弹出来的。&lt;br&gt;
所以现在问题就明了了，你的即兴苦恼源于没有这些基础和积累。最好找一个老师带着你&lt;/p&gt;
&lt;p&gt;1、基础乐理—熟悉指板+即兴—和声学+即兴—配器法—实战编曲—混音、母带&lt;br&gt;
2、多听曲子，多学曲子，多扒曲子，海纳百川&lt;br&gt;
3、保持热爱&lt;/p&gt;
&lt;p&gt;先在一个调里把指板吃透了就行 主要还是要掌握大小调已经各种调式音阶的相对音程 一味地练别人的solo一点用都没有（除非你会乐理知道人家在弹什么）&lt;/p&gt;
&lt;p&gt;小调里的三五七和弦都会按吗 这个也比较基础&lt;/p&gt;
&lt;p&gt;制定计划逼着自己去学，特别是乐理和编曲，乐理得实际应用才记得住，编曲得大量编才能熟练，制定计划每天练多少、课看多少、资料找多少。&lt;/p&gt;
&lt;p&gt;学乐理就是少走弯路，但要是自己玩靠耳朵慢慢积累也不是不行，只是弹出来的东西可能就有点固定走不出自己听的最多的五声音阶，我原来学琴的时候老师不怎么讲乐理只有后来自己自学一点点基本属于文盲了[喜极而泣]，但是耳朵还不错 弹久了指板熟了基本听到什么想到什么能弹出来自己玩玩还挺乐。&lt;br&gt;
当年学的时候坑比老师很多，以至于我跟的最久的不怎么讲乐理的老师我还觉得教的很好了[喜极而泣]，多年之后重新学乐理挺头疼的，现在教学环境比原来好了如果是新入门钱包足有条件还是找个好老师少走弯路，但是自学好资源也多了 找不到好老师的话，自学也挺好 ，看自己能不能坚持吧&lt;br&gt;
然后多跟同好交流，即使没有老师和爱好者互相交流帮助也挺大的。&lt;/p&gt;
&lt;p&gt;b站找lick library的视频，精通指板。我全自学的音乐，都半职业水平了&lt;/p&gt;
&lt;p&gt;是的，乐理就是十二平均律和各种排列组合，不难，难的是持续的兴趣，精力投入，坐住板凳&lt;/p&gt;
&lt;p&gt;别练什么视唱练耳，扒歌这些东西，你现在最要紧的是赶紧用你学的五声音阶即兴起来，跟着伴奏弹几个音比你练什么吉他曲子都有效果，把他玩起来才是你学会即兴的最重要的一步，指板不是说练几个乐句，重复练爬几百上千遍音阶可以记住的，只有你即兴的多了，你才能想弹什么音就立马弹出来，找老师是最没有性价比的，浪费时间浪费金钱，你先试着跟着你喜欢的歌弹点旋律吧。这是我的经验之谈，我就是这样从只会弹唱到可以即兴的，不说很厉害，但是已经可以在各种流行歌曲里随意即兴了。&lt;/p&gt;
&lt;p&gt;可以试试steve vai写的《吉他巫师 史蒂夫范的独门演奏心法》正版有点小贵，经济不允许可以某宝上买复印版四十几，比较通俗易懂不过是繁体，台湾出版的&lt;/p&gt;
&lt;p&gt;买本人民音乐出版社的《吉他指板手册》，看不懂不翻页看完之后最基础的乐理就没啥问题了。但是想学更多的就得买别的教材了，到时候你就根据喜好自己找吧。&lt;/p&gt;
">【音乐】即兴练习思路</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-rnn-lstm-gru/"" data-c="
          &lt;h1 id=&#34;rnn&#34;&gt;RNN&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1z5411f7Bm/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【循环神经网络】5分钟搞懂RNN，3D动画深入浅出&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30844905&#34;&gt;一文搞懂RNN（循环神经网络）基础篇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;假定不同时间层之间共享一个权重矩阵W，有效的减少训练参数&lt;br&gt;
正常的神经元输出：S=Wx+b，其中 S 代表隐藏层的输出&lt;br&gt;
RNN 的输出：St=Wx+WSt-1+b，即基础上加入了 t-1 时刻的输入，作为当前 t 时刻的输出&lt;br&gt;
即：RNN 的隐藏层的值 S 不仅仅取决于当前这次的输入 x，还取决于上一次隐藏层的值 St-1&lt;br&gt;
要注意的是，在计算时，每一步使用的参数U、W、b都是一样的，也就是说每个步骤的参数都是共享的，这是RNN的重要特点。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/bestrivern/article/details/90723524&#34;&gt;RNN详解(Recurrent Neural Network)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_45727931/article/details/114369073&#34;&gt;Pytorch循环神经网络（RNN）快速入门与实战&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Encoder-Decoder，也叫Seq2Seq，是RNN的一个重要变种。&lt;/p&gt;
&lt;h1 id=&#34;gru&#34;&gt;GRU&lt;/h1&gt;
&lt;h1 id=&#34;lstm&#34;&gt;LSTM&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Sz4y1E7oL/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;3分钟带你搞清LSTM 的计算过程和计算图&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;某时刻输入：xt，某时刻输出某时刻输出：ht&lt;br&gt;
为解决 RNN 不能记忆长时间信息的问题，LSTM 中加入了一个记忆信息的元素 ct&lt;/p&gt;
&lt;p&gt;LSTM细胞中主要的三个门：&lt;br&gt;
&lt;code&gt;遗忘门&lt;/code&gt;前一时刻的隐藏状态 ht-1 和当前时刻的输入 xt 经过 Sigmoid 处理，接近 0 表示遗忘，接近 1 表示保留。forgetgate = Sigmoid(W[xt,ht-1]+b)&lt;br&gt;
&lt;code&gt;输入门&lt;/code&gt;负责更新细胞状态。它由两部分组成：一个 Sigmoid 层和一个 tanh 层。Sigmoid 层决定我们将更新哪些值，tanh 层则创建一个新的候选值向量，将被加到细胞状态中。这两个向量的结合更新了细胞的状态。forgetgate = Sigmoid(W[xt,ht-1]+b)&lt;br&gt;
&lt;code&gt;输出门&lt;/code&gt;负责基于细胞的当前状态决定输出什么。首先，一个 Sigmoid 层决定细胞状态的哪一部分将输出。然后，细胞状态通过 tanh 进行处理（使值位于-1到1之间）并与 Sigmoid 门的输出相乘，决定最终的输出。forgetgate = Sigmoid(W[xt,ht-1]+b)&lt;/p&gt;
&lt;p&gt;某时刻输出由这一时刻的记忆信息 ct 来获得：ht = outputgate(ct)&lt;br&gt;
ct 由这一时刻的输入 xt 和上一时刻的记忆信息 ct-1 共同获得&lt;br&gt;
ct = forgetgate(ct-1)+inputgate(xt)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1fp4y1t7Xb/?p=3&amp;amp;spm_id_from=pageDriver&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;RNN &amp;amp; LSTM (时间序列模型）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Fe41157Gh/?spm_id_from=333.788.recommend_more_video.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;动态可视化LSTM&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;bi-lstm&#34;&gt;Bi-LSTM&lt;/h1&gt;
&lt;h1 id=&#34;问答&#34;&gt;问答&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基础概念：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请解释什么是RNN，它如何工作？&lt;/li&gt;
&lt;li&gt;LSTM网络是什么，它与传统的RNN有什么区别？&lt;/li&gt;
&lt;li&gt;RNN中的“梯度消失”和“梯度爆炸”问题是什么？如何解决？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;原理和架构：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSTM的核心组件是什么？它们各自承担什么样的角色？&lt;/li&gt;
&lt;li&gt;请解释LSTM中的遗忘门、输入门和输出门的作用。&lt;/li&gt;
&lt;li&gt;如何通过调整RNN的架构来提高其记忆能力？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;应用和实例：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请举例说明RNN和LSTM在自然语言处理（NLP）中的应用。&lt;/li&gt;
&lt;li&gt;RNN和LSTM在时间序列预测中的优势在哪里？&lt;/li&gt;
&lt;li&gt;在实际应用中，你如何决定是使用传统的RNN，还是LSTM或GRU（门控循环单元）？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;性能和优化：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在训练RNN时，如何处理长序列数据带来的挑战？&lt;/li&gt;
&lt;li&gt;如何评估RNN模型的性能？有哪些常用的指标？&lt;/li&gt;
&lt;li&gt;解释一下在RNN/LSTM模型中常用的正则化技术。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;高级话题：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请讨论一下RNN和LSTM在处理多任务学习时的潜力。&lt;/li&gt;
&lt;li&gt;RNN和LSTM如何与其他类型的神经网络，例如卷积神经网络（CNN），结合使用？&lt;/li&gt;
&lt;li&gt;介绍一种你认为对RNN或LSTM有重大改进的最新研究或技术。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些问题覆盖了从基本概念到高级应用的各个方面，旨在评估候选人对RNN和LSTM的理解深度和广度。&lt;/p&gt;
">【NLP】RNN | GRU | LSTM</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ji-qi-shi-jue/"" data-c="
          &lt;p&gt;&lt;a href=&#34;cv-xueba.club&#34;&gt;北邮鲁鹏资源&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;像素&#34;&gt;像素&lt;/h1&gt;
&lt;p&gt;分辨率是 1024 x 768 则图像有 1024 x 768 个像素点（pixel）&lt;/p&gt;
&lt;p&gt;二进制图像：每个点用一个bit表示&lt;br&gt;
灰度图：每个点用一个Byte表示，范围 0-255&lt;br&gt;
RGB图像：每个点由R\G\B三个信息表示，三个Byte，范围 0-255&lt;/p&gt;
&lt;h1 id=&#34;卷积核和噪声&#34;&gt;卷积核和噪声&lt;/h1&gt;
&lt;h2 id=&#34;卷积核滤波核filter-kernel&#34;&gt;卷积核/滤波核：filter kernel&lt;/h2&gt;
&lt;p&gt;常见线性滤波： 方框滤波（boxFilter）、均值滤波（blur）、高斯滤波（GaussianBlur）；另一类是非线性滤波器，包括中值滤波（medianBlur）和双边滤波（bilateralFilter）&lt;/p&gt;
&lt;p&gt;卷积运算：对应点相乘再相加（对核内数据进行加权，然后赋给中心点）&lt;/p&gt;
&lt;p&gt;在利用均值核对图像进行平滑处理的时候，考虑到距离中心点越远的点 对中心值影响越小。所以考虑使用高斯分布设置核内权重。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;高斯核&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/u013066730/article/details/123112159&#34;&gt;CSDN 文字讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV15B4y1D7QJ/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站高斯分布复习&lt;/a&gt;&lt;br&gt;
标准差σ越大，高斯分布的图像越扁平。对应高斯核可取值的范围就会增大。若在这同时增大高斯核的大小，则被用于计算的均值的范围变大，则得到的图像就会越模糊。&lt;br&gt;
当使用高斯滤波器进行图像处理时，W代表窗口的大小（也称为卷积核的尺寸），σ代表高斯函数的标准差（方差的平方根）。经验上，有一个常见的规则是W/2=3σ，它表示窗口的一半尺寸大约等于3倍的标准差。&lt;br&gt;
这个经验规则可以用于选择适当的窗口大小和标准差，以确保高斯滤波器在平滑图像的同时保持图像细节。具体而言，较大的窗口尺寸和较大的标准差可以产生更强烈的平滑效果，但可能会导致图像细节的丢失。相反，较小的窗口尺寸和较小的标准差可以保留更多的细节，但平滑效果会较弱。&lt;br&gt;
根据经验，W/2=3σ提供了一种简单的方法来选择窗口大小和标准差的相对关系，以获得平衡的结果。但需要注意的是，这只是一个经验规则，具体的选择还取决于特定的应用和图像处理的需求。在实际应用中，可能需要进行实验和调整以找到最适合的参数。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/zjh12312311/article/details/109649188&#34;&gt;cv2中的滤波，均值，高斯，中值，高通，低通，傅里叶变换&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;噪声&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/poisonchry/article/details/110847127&#34;&gt;数字图像学笔记——6. 噪音生成（椒盐噪音、高斯噪音、泊松噪音）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_42856191/article/details/123706076?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171093113016800182180772%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;amp;request_id=171093113016800182180772&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-3-123706076-null-null.142%5Ev99%5Econtrol&amp;amp;utm_term=%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA&amp;amp;spm=1018.2226.3001.4187&#34;&gt;【OpenCV-Python】：基于均值、中值、方框、双边和高斯滤波的图像去噪&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;canny算法边缘检测&#34;&gt;Canny算法——边缘检测&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1nz4y197Qv?p=3&amp;amp;spm_id_from=pageDriver&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;鲁鹏讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/minjiuhong/article/details/89320225&#34;&gt;CSDN文字讲解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;算法原理概述&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1685450396261.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/m0_51402531/article/details/121066693&#34;&gt;OpenCV——Canny边缘检测（cv2.Canny()）&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;edges = cv.Canny( image, threshold1, threshold2[, apertureSize[, L2gradient]])
# threshold1为低阈值，threshold2为高阈值
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;图像拟合-fitting&#34;&gt;图像拟合 fitting&lt;/h1&gt;
&lt;h2 id=&#34;最小二乘法拟合&#34;&gt;最小二乘法拟合&lt;/h2&gt;
&lt;p&gt;假设需要拟合一条线，通过最小二乘法可以求得这条线的方程，从而将像素点拟合成一条平滑的曲线。这样的应用场景很多，比如图像的边缘检测、图像的灰度平滑和曲线的修正等&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/MoreAction_/article/details/106443383?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163978851616780269814649%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;amp;request_id=163978851616780269814649&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-6-106443383.pc_search_result_cache&amp;amp;utm_term=%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95&amp;amp;spm=1018.2226.3001.4187&#34;&gt;一文让你彻底搞懂最小二乘法（超详细推导）&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;鲁棒性最小二乘法&#34;&gt;鲁棒性最小二乘法&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1685457722865.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;ransac随机一致性采样&#34;&gt;RANSAC——随机一致性采样&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/45532306&#34;&gt;文字讲解&lt;/a&gt;&lt;br&gt;
在使用RANSAC找到内点之后，再利用找到的点，使用最小二乘法找到直线&lt;/p&gt;
&lt;p&gt;&lt;code&gt;RANSAC的利弊&lt;/code&gt;&lt;br&gt;
优点&lt;br&gt;
简单、适用于许多不同的问题，经常在实践中效果很好&lt;br&gt;
缺点&lt;br&gt;
有很多参数需要调整，对于较低的初始比率不能很好地工作(要迭代太多次，或者可能完全失败)&lt;br&gt;
在较小的样本数上不能总是得到一个良好的初始化模型&lt;/p&gt;
&lt;h2 id=&#34;霍夫变换-hough-transform&#34;&gt;霍夫变换 Hough transform&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/leonardohaig/article/details/87907462&#34;&gt;CSDN 文字讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1nz4y197Qv?p=4&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;鲁鹏讲解&lt;/a&gt;&lt;br&gt;
软投票法：给相邻的也投一票&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/on2way/article/details/47028969&#34;&gt;Python下opencv使用笔记（十一）（详解hough变换检测直线与圆）&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;特征提取&#34;&gt;特征提取&lt;/h1&gt;
&lt;h2 id=&#34;harris-corner-detection角点检测&#34;&gt;Harris corner detection(角点检测)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wb411b79B/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/max_LLL/article/details/119728338&#34;&gt;OpenCV中的几种角点检测方法&lt;/a&gt;&lt;br&gt;
典型的数学建模过程，将实际问题用数学模型来表示，从而量化，让计算机理解。&lt;br&gt;
适用于：光照情况、位置、旋转、平移等变化ss&lt;br&gt;
不适用于：大小的变化&lt;/p&gt;
&lt;h2 id=&#34;blob-detection&#34;&gt;Blob detection&lt;/h2&gt;
&lt;p&gt;Blob检测是一种在数字图像中寻找连通区域（即blob）的方法，这些区域与周围区域在颜色、亮度或纹理上有所不同。Blob通常指的是图像中的斑点、团块或任何不规则的形状。在计算机视觉中，blob检测被广泛应用于对象识别、图像分析、机器视觉等领域。&lt;br&gt;
Blob检测的基本步骤通常包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;图像预处理&lt;/strong&gt;：这可能包括灰度转换、二值化、滤波等，以减少噪声并突出感兴趣的区域。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;阈值化&lt;/strong&gt;：通过设定亮度或颜色的阈值，将图像转换为仅包含黑白两色的二值图像。这有助于分离前景（blob）和背景。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;连通区域标记&lt;/strong&gt;：在这一步中，算法会遍历二值图像，将相互连接的白色像素分组，并为每个连通区域分配一个唯一的标签。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特征提取&lt;/strong&gt;：对于每个检测到的blob，可以计算其特征，如面积、重心、周长、圆形度、惯性矩等。这些特征有助于进一步分析和识别不同的blob。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;过滤和筛选&lt;/strong&gt;：根据设定的标准（如blob的大小、形状或其他特征），可以过滤掉不感兴趣的blob，只保留满足条件的blob。&lt;br&gt;
在OpenCV中，blob检测可以使用&lt;code&gt;SimpleBlobDetector&lt;/code&gt;或通过自定义的算法实现。&lt;code&gt;SimpleBlobDetector&lt;/code&gt;是一个基于特征的检测器，它允许用户设置各种参数来定义什么是blob，包括颜色、大小、形状、凹凸性等。&lt;br&gt;
Blob检测在许多应用中都非常有用，例如在工业自动化中检测零件，在医学影像中识别细胞，在交通监控中跟踪车辆，以及在机器人导航中识别路径或障碍物。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;siftscale-invariant-feature-transform尺度不变特征变换&#34;&gt;SIFT(Scale Invariant Feature Transform)尺度不变特征变换&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV13v411E7M7/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【学习笔记】SIFT&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;大致步骤&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用不同方差的卷积核卷积，构建高斯金字塔&lt;/li&gt;
&lt;li&gt;相邻特征图做差，找到一些可能为极值点的点，与上下两层相邻的26个点比较，确定是否为极值点&lt;/li&gt;
&lt;li&gt;进行泰勒展开（曲面拟合）、设定阈值等操作，找到真正的特征点&lt;/li&gt;
&lt;li&gt;在高斯金字塔上还原该点，以该点为中心的一定范围内，高斯加权，构建梯度直方图，选择最多的梯度方向作为主方向，第二多的为副方向&lt;/li&gt;
&lt;li&gt;计算两幅图中关键点方向描述向量的距离，距离小则表示匹配（KNN）&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1685946237448.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
高斯金字塔：图像的尺度空间，用于模拟观察者距离物体的远近程度及模糊程度&lt;br&gt;
差分的目的：找到在不同尺度下都稳定的特征点，对应着差分尺度空间的极值点，这些点在缩放、旋转和一定程度的亮度和对比度变化是不变的。&lt;br&gt;
&lt;code&gt;参数&lt;/code&gt;&lt;br&gt;
层数 octave：O = [log2(min(M,N))]-3   M、N：原图片的宽和高&lt;br&gt;
每层的图片数：S = n + 3   n：能找到的特征图数&lt;br&gt;
n 的解释：&lt;br&gt;
假如每层用了五个不同的高斯核进行卷积，那么每层得到五个高斯后的图片（S）。&lt;br&gt;
相邻两个做差，得到四张差分后的图片。差分后的图片需要求梯度来找特征点，但是最上和最下两张找不到。所以 n 为 S-3 = 2。也可以理解为，三个差分图为一组，对中间的那张进行计算，所以四张图片能找到上下两个组。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;SIFT 和 CNN 在图像检索任务上的比较&lt;/strong&gt;&lt;br&gt;
SIFT（尺度不变特征转换）和CNN（卷积神经网络）在图像检索任务中具有不同的特点和应用场景。下面是它们之间的一些比较：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;特征表示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SIFT：SIFT算法提取的特征是局部特征，主要关注图像中的关键点和它们的描述子。这些特征具有旋转不变性和尺度不变性，适用于处理图像中的局部变化和几何变换。&lt;/li&gt;
&lt;li&gt;CNN：卷积神经网络通过多层卷积和池化操作，从整个图像中学习到的特征表示。这些特征是全局的，能够捕捉到图像中的语义信息和高层次的抽象特征。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;训练需求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SIFT：SIFT算法不需要大规模标注的训练数据，因为它是一种手工设计的特征提取算法。&lt;/li&gt;
&lt;li&gt;CNN：卷积神经网络需要大规模的标注数据进行训练，以便通过反向传播算法学习到适合任务的特征表示。这需要大量的计算资源和训练时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;鲁棒性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SIFT：SIFT算法在旋转、缩放和仿射变换等情况下具有较强的鲁棒性。它对于图像中的局部变化和几何变换能够提取稳定的特征。&lt;/li&gt;
&lt;li&gt;CNN：卷积神经网络在大规模训练的情况下可以具有一定的鲁棒性，但对于缩放和旋转等变换相对较敏感。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SIFT：SIFT算法在传统的图像检索任务中表现良好，并且在计算机视觉领域经过多年的研究和验证。它在小规模图像数据库上具有较高的检索准确性。&lt;/li&gt;
&lt;li&gt;CNN：卷积神经网络在大规模图像数据集上进行端到端的训练，能够学习到更复杂的特征表示，并在一些特定的图像检索任务中达到更好的性能。例如，对于基于图像分类的图像检索任务，CNN通常能够获得更好的结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;综上所述，SIFT适用于小规模图像数据库和对局部特征关注较多的场景，而CNN在大规模图像数据集和需要全局语义信息的任务中具有优势。实际应用中，可以根据具体任务的需求和数据的特点选择适合的方法或结合两者的优势进行&lt;/p&gt;
&lt;h1 id=&#34;纹理&#34;&gt;纹理&lt;/h1&gt;
&lt;p&gt;常见任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从图像纹理估计表面方向或形状&lt;/li&gt;
&lt;li&gt;根据纹理线索进行分割/分类 分析，表示纹理&lt;/li&gt;
&lt;li&gt;将纹理一致的图像区域分组&lt;/li&gt;
&lt;li&gt;生成新的纹理/图像&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用不同方向的卷积核卷积图像，每个核为输出向量的一维，向量中的最大值对应的卷积核方向，就是该纹理的方向。&lt;/p&gt;
&lt;h1 id=&#34;分割-segmentation&#34;&gt;分割  Segmentation&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Mean shift&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/google19890102/article/details/51030884&#34;&gt;简单易学的机器学习算法——Mean Shift聚类算法&lt;/a&gt;&lt;br&gt;
找局部密度最高的点&lt;/p&gt;
&lt;p&gt;Mean shift算法是一种非参数的聚类算法，其主要用于数据聚类和密度估计。以下是Mean shift算法的基本流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化：选择一个初始种子点，作为每个聚类的中心点，并确定一个窗口大小。&lt;/li&gt;
&lt;li&gt;密度估计：对于每个种子点，计算在窗口内的数据点的密度估计。可以使用核函数来衡量数据点在窗口内的密度，通常使用高斯核函数。&lt;/li&gt;
&lt;li&gt;平移向量计算：计算每个数据点相对于种子点的平移向量。平移向量的计算方式是通过计算数据点在窗口内的质心（mean）和当前种子点的差异。&lt;/li&gt;
&lt;li&gt;平移：将种子点沿着平移向量进行平移，更新种子点的位置。&lt;/li&gt;
&lt;li&gt;收敛判断：重复步骤3和步骤4，直到种子点收敛于局部最大值（即平移向量接近于零）。这表示种子点已经找到了局部密度最大的聚类中心。&lt;/li&gt;
&lt;li&gt;聚类：将收敛的种子点作为聚类的中心点，并将其他数据点分配到最近的聚类中心。&lt;/li&gt;
&lt;li&gt;重复步骤1到步骤6，直到所有数据点都被分配到聚类中心。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Mean shift算法的核心思想是通过不断迭代调整种子点的位置，使其向高密度区域移动，直到收敛于局部最大值。这样可以找到数据中的聚类中心，并将数据点分配到对应的聚类中心。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;归一化图割 Normalized cut&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_38476684/article/details/80553850&#34;&gt;图像处理--归一化切割--(normalized cut)--Python实现&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以下是Normalization Cut算法的完整详细步骤：&lt;/p&gt;
&lt;p&gt;输入：图像（以像素矩阵表示），标准差σ&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将像素转换为向量：将图像中的每个像素表示为一个向量。对于灰度图像，可以使用像素的灰度值作为向量的元素；对于彩色图像，可以使用像素的颜色通道值作为向量的元素。&lt;/li&gt;
&lt;li&gt;计算两两像素的距离：对于每对像素向量，使用选定的距离函数（如欧氏距离或曼哈顿距离）计算它们之间的距离。得到一个距离矩阵，其中每个元素表示两个像素之间的距离。&lt;/li&gt;
&lt;li&gt;将距离映射到[0, 1]范围内：将距离映射到[0, 1]的范围内，可以使用公式 d&#39; = (d - min_distance) / (max_distance - min_distance)，其中 d 是原始距离，d&#39; 是映射后的距离，min_distance 和 max_distance 分别是所有像素对之间距离的最小值和最大值。&lt;/li&gt;
&lt;li&gt;利用高斯核函数计算相似度：使用高斯核函数将距离转换为相似度。计算每对像素之间的相似度，可以使用公式 similarity = exp(-d&#39;^2 / (2 * σ^2))，其中 d&#39; 是映射后的距离，σ 是标准差。&lt;/li&gt;
&lt;li&gt;生成相似度矩阵W（邻接矩阵）：将计算得到的相似度值填充到一个相似度矩阵中。矩阵的每个元素表示两个像素之间的相似度。注意，W是对称的。且对角线为0，因为相同点间距离为0。&lt;/li&gt;
&lt;li&gt;构建拉普拉斯矩阵：根据相似度矩阵，构建拉普拉斯矩阵。拉普拉斯矩阵可以有多种形式，例如对称归一化拉普拉斯矩阵或非对称拉普拉斯矩阵。定义对角矩阵D，D的第n行不为0的元素为W第n行数值之和。&lt;/li&gt;
&lt;li&gt;对拉普拉斯矩阵进行特征值分解：对构建的拉普拉斯矩阵进行特征值分解，得到特征值和对应的特征向量。(D-W)y = λDy；取第二小的特征值对应的y向量。&lt;/li&gt;
&lt;li&gt;利用特征向量进行聚类或分割：根据特征向量的特定特征值，进行聚类或分割操作。可以使用聚类算法（如谱聚类）或基于特征向量的阈值操作来实现。设置门限值，假设为1，低于1的为一类，高于1的为另一类。&lt;/li&gt;
&lt;li&gt;输出分割结果：根据聚类或分割的结果，将图像中的像素分为不同的区域或类别。可以根据特征向量的某个阈值或聚类算法的结果将像素分配到不同的分割区域或类别。&lt;/li&gt;
&lt;li&gt;可选的后处理：根据需要，可以进行一些后处理步骤来进一步优化分割结果。例如，可以应用边缘平滑技术来消除分割边界上的噪声或不连续性。&lt;/li&gt;
&lt;li&gt;输出最终结果：将最终的图像分割结果作为算法的输出，可以是标记每个像素所属区域或类别的图像。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Minimum Cut&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/mmm_jsw/article/details/83787395&#34;&gt;图像分割经典算法--《最小割最大流》（Minimum Cut——Max Flow）&lt;/a&gt;&lt;br&gt;
去除图中权重最小的边&lt;/p&gt;
&lt;h1 id=&#34;识别-recognition&#34;&gt;识别 Recognition&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;BOW词袋模型应用于图像识别分类&lt;/strong&gt;&lt;br&gt;
词袋模型将图片分成小块，从而一定程度上解决了遮挡等问题&lt;br&gt;
一般步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;特征提取&lt;br&gt;
类比一下上面文本特征的提取，把文本1这句话切成一个个单词，这个过程就是在提取这个文本的特征，那么在图像中提取特征也类似，就是把图像切成一个个的片（patch），每片当成该图像的特征。常用的特征提取方法有SIFT、LBP、SURF等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生成字典/词袋（codebook）&lt;br&gt;
在上一步特征提取中我们得到了很多的特征点，我们不能把每个点都放进词袋吧，那么就需要想一个招找到这些点中具有代表性的几类点，这一般需要聚类方法来完成的。对全部特征点进行聚类，得到了几个聚类中心，这些聚类中心就是这些点的特征向量。这一步之后就得到了词袋。（不理解的可以类比一下上面文本形成词袋的过程，上面文本形成词袋是把所有单词都放进去了，但是对图像来说特征点太多不可能全部放进去，所以使用聚类把聚类中心就当成词袋中的点）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;根据词袋生成特征直方图&lt;br&gt;
对于每张图片都有大量的特征点，那么就把这些点对照着上面得到的词袋统计出来，这样每张图片都会得到一个特征直方图，可以参考一下上面文本直方图。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;空间金字塔算法（Spatial Pyramid）&lt;/strong&gt;&lt;br&gt;
一种用于图像分类和目标识别的传统机器视觉算法，可以有效地处理不同尺度和大小的图像内容。下面是Spatial Pyramid算法的实现过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;提取特征：首先，对输入图像进行特征提取。常用的特征提取方法包括SIFT（尺度不变特征变换）、HOG（方向梯度直方图）和LBP（局部二值模式）等。这些方法可以提取图像中的局部特征，用于后续的分析和处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;划分金字塔：接下来，将图像划分为不同层级的金字塔结构。每个金字塔层级对应着不同的尺度和大小。通常，金字塔层级的数量和大小是预先定义好的，例如2层、3层或更多。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分块统计：对于每个金字塔层级，将图像分割为固定大小的块。这些块可以是正方形或矩形的区域。然后，在每个块内计算特征的统计信息。这可以包括直方图、均值、方差等。通过这种方式，可以捕捉到图像在不同空间位置的局部特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特征融合：将每个金字塔层级中的特征统计信息进行融合。一种常见的方法是将不同层级的特征串联起来，形成一个综合的特征向量。这样可以保留不同尺度和大小的信息，从而更好地描述图像的内容。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分类器训练：使用融合后的特征向量来训练分类器，例如支持向量机（SVM）、随机森林（Random Forest）或神经网络等。分类器可以根据提供的训练数据学习图像类别的模式，并用于对新图像进行分类和识别。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图像分类：对于待分类的新图像，首先进行与训练图像相同的特征提取和金字塔分块过程。然后，将提取到的特征输入训练好的分类器中进行预测。分类器会输出图像所属的类别标签。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Spatial Pyramid算法通过在不同层级和块上进行特征统计和融合，可以有效地捕捉到图像的局部和全局信息。这种方法在处理尺度变化和多尺度目标时具有优势，并且对于不同大小的图像也具有较好的鲁棒性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Boosting（增强学习算法）&lt;/strong&gt;&lt;br&gt;
一种集成学习方法，旨在通过组合多个弱分类器来构建一个更强大的分类器。Boosting算法通过迭代的方式逐步改进分类器的准确性，将先前分类器的错误样本权重增加，并对分类错误的样本进行重点关注。&lt;/p&gt;
&lt;p&gt;以下是Boosting算法的简要实现过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;初始化权重：对于包含N个训练样本的训练集，初始化每个样本的权重为相等值（1/N）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;迭代训练：进行T轮迭代，每一轮迭代中都训练一个弱分类器。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;弱分类器训练：在每一轮迭代中，根据当前样本权重，使用训练集训练一个弱分类器。弱分类器通常是一个性能较差的分类器，如决策树桩（仅有一层决策树）或者简单的线性分类器。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分类器权重：根据弱分类器的错误率（分类错误的样本比例）计算其权重。错误率越低的弱分类器获得的权重越高，能够对分类结果做出更大的贡献。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更新样本权重：根据弱分类器的权重调整训练样本的权重。被错误分类的样本权重会增加，而被正确分类的样本权重会减少。这样，下一轮迭代时，错误分类的样本会受到更多关注。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;结合弱分类器：将每个弱分类器按照其权重进行加权组合，得到最终的强分类器。强分类器通过累加弱分类器的预测结果，以投票或加权平均的方式进行最终分类。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重复迭代：重复步骤3至步骤6，直到达到预定的迭代次数T或者满足某个停止条件（如达到预期准确率）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Boosting算法通过多次迭代，逐步改进分类器的性能，重点关注那些难以分类的样本。它的优点在于能够构建出具有较高准确性的分类器，并且对于噪声和复杂数据集有一定的鲁棒性。著名的Boosting算法包括AdaBoost（自适应Boosting）和Gradient Boosting（梯度提升）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Viola-Jones算法&lt;/strong&gt;&lt;br&gt;
一种用于实时目标检测的传统机器视觉算法。它由Paul Viola和Michael Jones于2001年提出，被广泛应用于人脸检测。Viola-Jones算法基于Haar特征和级联分类器的概念，其实现过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Haar特征：Haar特征是一种基于图像局部区域的特征描述符。它可以用于描述图像中的边缘、线段、角等特征。Haar特征可以通过在图像上滑动不同大小和位置的滑窗，并计算窗口内不同区域的像素和来表示。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;积分图像：为了加速特征计算，Viola-Jones算法使用积分图像（Integral Image）进行快速计算。积分图像可以在常数时间内计算出任意矩形区域的像素和，使得特征计算的复杂度降低。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adaboost训练：使用Adaboost算法，Viola-Jones算法训练了一个级联分类器。级联分类器由多个弱分类器组成，每个弱分类器都是一个基于Haar特征的简单二分类器。Adaboost算法通过迭代训练，在每一轮迭代中调整样本的权重，使得错误分类的样本得到更多关注。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特征选择：在每一轮迭代中，Viola-Jones算法通过选择具有最小错误率的特征来构建弱分类器。这样可以选择最具区分性的特征，以便有效地区分目标和非目标区域。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;级联结构：为了提高检测速度，Viola-Jones算法采用了级联的结构。级联分类器将所有弱分类器按顺序组织成级联的多个阶段。每个阶段都具有不同的分类器数量和阈值，以逐步过滤出非目标区域，减少检测的计算量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;移动窗口检测：在测试阶段，Viola-Jones算法使用移动窗口技术在图像上滑动不同大小的窗口，对每个窗口进行分类器的评估。通过级联结构和快速特征计算，可以高效地排除大多数非目标窗口，并快速识别出目标窗口。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Viola-Jones算法具有高速和高准确性的特点，尤其在人脸检测方面表现出色。它被广泛应用于实时的图像和视频处理应用中，如人脸识别、表情分析和眼部追踪等。然而&lt;/p&gt;
&lt;h1 id=&#34;三维重建&#34;&gt;三维重建&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;摄像机模型&lt;/strong&gt;&lt;br&gt;
通过多张图片重构三维场景。无人驾驶车、地图等。&lt;br&gt;
摄像机几何&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相机标定&lt;/strong&gt;&lt;br&gt;
找到二维和三维点之间的对应关系，用于计算相机的内参数&lt;/p&gt;
&lt;h1 id=&#34;计算摄影学&#34;&gt;计算摄影学&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/tardis/zm/art/51490200?source_id=1005&#34;&gt;计算摄影学及本专栏介绍&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.zhihu.com/question/427425910&#34;&gt;计算成像(computational photography)方向的就业前景如何？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1VA4y1Z7DG/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;iPhone 13系列解读之二——让我们聊聊计算摄影&lt;/a&gt;&lt;/p&gt;
">【CV】从零开始机器视觉</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shen-du-xue-xi-de-yi-ban-bu-zou/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://nndl.github.io/&#34;&gt;邱锡鹏版&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zh-v2.d2l.ai/&#34;&gt;《动手学深度学习》&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.deeplearningbook.org/&#34;&gt;Deep Learning Book&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://pytorch.org/&#34;&gt;pyTorch 英文官网&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.pytorch123.com/&#34;&gt;pyTorch 教程中文&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.w3cschool.cn/pytorch/&#34;&gt;pyTorch w3cschool&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_53904578/article/details/124414068?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166971072916800184193705%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;amp;request_id=166971072916800184193705&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-124414068-null-null.142%5Ev67%5Econtrol,201%5Ev3%5Econtrol_2,213%5Ev2%5Et3_esquery_v2&amp;amp;utm_term=%E6%95%B0%E6%8D%AE%E9%9B%86&amp;amp;spm=1018.2226.3001.4187&#34;&gt;深度学习数据集汇总&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://link.zhihu.com/?target=http%3A//playground.tensorflow.org&#34;&gt;深度学习模拟网站，可观察参数变化对训练的影响&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;使用PyTorch进行深度学习的一般步骤可以概括为以下几个主要阶段：&lt;/p&gt;
&lt;h3 id=&#34;1-准备数据集&#34;&gt;1. 准备数据集&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;加载数据&lt;/strong&gt;：使用PyTorch的&lt;code&gt;torch.utils.data.Dataset&lt;/code&gt;和&lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt;来加载和准备数据集，可能包括数据的预处理、增强等操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-构建模型&#34;&gt;2. 构建模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义模型结构&lt;/strong&gt;：继承&lt;code&gt;torch.nn.Module&lt;/code&gt;类来定义自己的模型，实现&lt;code&gt;__init__&lt;/code&gt;方法来定义模型的层，实现&lt;code&gt;forward&lt;/code&gt;方法来指定数据的前向传递路径。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-定义损失函数和优化器&#34;&gt;3. 定义损失函数和优化器&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;选择损失函数&lt;/strong&gt;：根据任务（如分类、回归等）选择合适的损失函数，如&lt;code&gt;torch.nn.CrossEntropyLoss&lt;/code&gt;用于分类任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;选择优化器&lt;/strong&gt;：选择一个优化算法来更新模型的参数，如&lt;code&gt;torch.optim.Adam&lt;/code&gt;、&lt;code&gt;torch.optim.SGD&lt;/code&gt;等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-训练模型&#34;&gt;4. 训练模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;训练循环&lt;/strong&gt;：编写训练循环，其中包括前向传播、损失计算、反向传播和参数更新。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型评估&lt;/strong&gt;：定期在验证集上评估模型，监控指标如准确率、损失等，以防止过拟合。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-测试模型&#34;&gt;5. 测试模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;评估模式&lt;/strong&gt;：将模型设置为评估模式（&lt;code&gt;model.eval()&lt;/code&gt;），以禁用特定于训练的操作，如Dropout。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能评估&lt;/strong&gt;：在测试集上评估模型性能，通常使用指标如准确率、精确率、召回率等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-保存和加载模型&#34;&gt;6. 保存和加载模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;保存模型&lt;/strong&gt;：使用&lt;code&gt;torch.save&lt;/code&gt;保存模型的参数或整个模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;加载模型&lt;/strong&gt;：使用&lt;code&gt;torch.load&lt;/code&gt;加载模型参数或整个模型，用于推理或继续训练。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;示例代码&#34;&gt;示例代码&lt;/h3&gt;
&lt;p&gt;以下是一个简化的示例，展示了这些步骤的基本结构：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# 1. 准备数据集
transform = transforms.Compose([transforms.ToTensor()])
train_dataset = datasets.MNIST(root=&#39;./data&#39;, train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 2. 构建模型
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(28*28, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model = Net()

# 3. 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters())

# 4. 训练模型
for epoch in range(10):  # loop over the dataset multiple times
    for data, target in train_loader:
        optimizer.zero_grad()  # zero the parameter gradients
        output = model(data)  # forward pass
        loss = criterion(output, target)  # compute loss
        loss.backward()  # backward pass
        optimizer.step()  # update parameters

print(&#39;Finished Training&#39;)

# 5. 保存模型
torch.save(model.state_dict(), &#39;model.pth&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个例子展示了使用PyTorch进行深度学习项目的基本框架，包括数据准备、模型定义、训练和保存模型等步骤。实际项目中可能需要添加额外的步骤，如更复杂的数据预处理、更细致的训练过程控制、模型评估和调参等。&lt;/p&gt;
&lt;p&gt;在使用像PyTorch这样的深度学习框架时，反向传播（计算梯度并更新模型参数的过程）通常是写在训练循环中，而不是直接写在模型类中。这是因为反向传播和参数更新是训练过程的一部分，而模型类主要负责定义前向传播的逻辑。&lt;/p&gt;
">【DL】深度学习的一般步骤</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shen-du-xue-xi-gpu-de-bu-shu/"" data-c="
          &lt;p&gt;查看 GPU 是否可用，返回 True 则具有能够使用的 GPU&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;torch.cuda.is_available()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看本机 GPU 数量&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch
n_gpu = torch.cuda.device_count()

print(n_gpu)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将模型部署到 GPU&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;device = torch.device(&amp;quot;cuda:0&amp;quot; if torch.cuda.is_available() else &amp;quot;cpu&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
">【PyTorch】GPU 的使用</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-bilstm-crf-suan-fa/"" data-c="
          &lt;h1 id=&#34;crf-随机条件场&#34;&gt;CRF 随机条件场&lt;/h1&gt;
&lt;p&gt;条件随机场（CRF，Conditional Random Field）是一种统计建模方法，常用于标注和分割序列数据，如自然语言处理（NLP）中的词性标注、命名实体识别（NER）等。CRF是一种判别式模型，用于计算给定观察序列条件下，最可能的输出序列的条件概率。&lt;/p&gt;
&lt;p&gt;CRF模型的核心思想是，在给定观测序列的情况下，构建一个输出序列的条件概率模型，该模型不仅考虑当前位置的特征，还考虑相邻位置之间的依赖关系。这使得CRF特别适合于序列数据的建模，因为序列中的元素通常不是独立的，而是彼此依赖的。&lt;/p&gt;
&lt;p&gt;CRF分为两大类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;线性链CRF（Linear CRF）&lt;/strong&gt;：最常见的CRF形式，用于序列建模。在线性链CRF中，假设输出标签序列形成一个线性链，并且每个标签仅与它的直接前后标签相关联。这种结构简化了计算，使得模型训练和解码（找到最可能的标签序列）变得可行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;一般CRF（General CRF）&lt;/strong&gt;：在这个更广泛的类别中，标签之间的依赖结构可以采用任何形式，不仅限于线性链。这使得一般CRF更为灵活，但同时计算复杂度也大大增加，因此在实际应用中不如线性链CRF常见。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CRF的训练通常涉及最大化对数似然函数，这可以通过各种优化算法实现，如梯度下降法。在预测时，给定一个观测序列，CRF模型会利用维特比算法（Viterbi Algorithm）或其他解码算法来找出最可能的标签序列。&lt;/p&gt;
&lt;p&gt;CRF模型的优势在于其能够捕捉到标签之间的依赖关系，以及观测数据与标签之间的复杂关系，这使得它在各种序列数据建模任务中表现优异。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/u010366748/article/details/113784204&#34;&gt;BiLSTM-CRF实现中文命名实体识别（NER）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;br&gt;
BiLSTM-CRF（Bidirectional Long Short-Term Memory - Conditional Random Field）是一种深度学习算法，常用于序列标注任务，如命名实体识别、词性标注等。BiLSTM-CRF结合了双向长短时记忆网络（BiLSTM）和条件随机场（CRF）两种技术，具有较强的建模能力和预测准确性。&lt;/p&gt;
&lt;p&gt;BiLSTM是一种递归神经网络，可以捕捉序列中前后文的依赖关系。它由两个LSTM（Long Short-Term Memory）层组成，分别从左向右和从右向左处理输入序列，然后将它们的输出拼接起来。这样，每个时间步的输出包含了当前时刻及其前后若干时刻的信息，更好地表达了序列的语义。&lt;/p&gt;
&lt;p&gt;CRF是一种概率模型，用于对序列标注结果进行建模，考虑标签之间的关联性和约束条件，可以使得标注结果更加合理和连贯。在BiLSTM-CRF中，CRF层接受BiLSTM层的输出作为输入，并且通过联合学习的方式，将BiLSTM层的输出和CRF层的标注结果进行训练，以最大化标注的准确性。&lt;/p&gt;
&lt;p&gt;BiLSTM-CRF的训练过程通常采用反向传播算法，以最小化模型对标注数据的损失。在测试阶段，通过在CRF层上使用维特比算法，找到最可能的标注序列，作为模型的预测结果。&lt;/p&gt;
&lt;p&gt;总之，BiLSTM-CRF算法在序列标注任务中表现出了良好的性能，能够捕捉序列中的长距离依赖关系和标签之间的约束关系，从而提高了模型的预测准确性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;命名实体&lt;/strong&gt;&lt;br&gt;
在自然语言处理中，命名实体（Named Entity）是指具有特定语义的实体，如人名、地名、组织机构名、时间、数量、货币等。命名实体识别（Named Entity Recognition，NER）是一种信息抽取技术，用于自动识别文本中的命名实体，并将其分类为预定义的类型。&lt;/p&gt;
&lt;p&gt;命名实体识别在信息检索、机器翻译、问答系统、自然语言生成等领域中有着广泛的应用。例如，在搜索引擎中，将用户查询中的命名实体与数据库中的实体进行匹配，可以帮助用户更快地找到所需信息。在机器翻译中，识别源文本中的命名实体可以帮助翻译系统更准确地理解句子的含义，从而提高翻译质量。&lt;/p&gt;
&lt;p&gt;命名实体识别通常使用基于规则、基于统计的方法或基于深度学习的方法。其中，基于深度学习的方法，如BiLSTM-CRF等模型，因其在序列标注任务中的优越表现，已经成为了命名实体识别的主流方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;序列标注任务&lt;/strong&gt;&lt;br&gt;
序列标注任务是一种自然语言处理任务，旨在将输入序列中的每个元素标注为特定的类别。常见的序列标注任务包括词性标注、命名实体识别、情感分析、语义角色标注等。&lt;/p&gt;
&lt;p&gt;在序列标注任务中，输入序列通常是一个由单词或字符组成的序列，每个单词或字符都要被标注为特定的类别。标注的类别可以是预定义的固定类别，例如名词、动词、形容词等，也可以是根据任务需要定义的自定义类别，例如人名、地名、组织机构名等。&lt;/p&gt;
&lt;p&gt;序列标注任务通常使用监督学习的方法进行模型训练，例如最大熵模型、条件随机场、递归神经网络等。在最近几年，基于深度学习的方法，如卷积神经网络（CNN）、循环神经网络（RNN）和其变体，如LSTM、GRU等，已经成为序列标注任务中最有效的方法之一，取得了很好的效果。&lt;/p&gt;
&lt;p&gt;序列标注任务在自然语言处理中有着广泛的应用，如文本分类、机器翻译、信息抽取、问答系统等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BIO-三位序列标注法（BIO-3）&lt;/strong&gt;&lt;br&gt;
BIO-三位序列标注法（BIO-3）是一种常用于序列标注任务的标注方法，特别在命名实体识别（NER）任务中广泛应用。该方法将每个标记分为三个部分：B（Beginning）、I（Inside）、O（Outside）。下面对BIO-3的含义进行解释：&lt;/p&gt;
&lt;p&gt;B（Beginning）：表示实体的起始位置。在一个实体的第一个字上标记为B，例如&amp;quot;B-Person&amp;quot;表示一个人名实体的起始位置。&lt;/p&gt;
&lt;p&gt;I（Inside）：表示实体的中间位置。在一个实体的非起始字上标记为I，例如&amp;quot;I-Person&amp;quot;表示一个人名实体的中间或结束位置。&lt;/p&gt;
&lt;p&gt;O（Outside）：表示不属于任何实体的标记，即普通文本部分。&lt;/p&gt;
&lt;p&gt;通过使用BIO-3标记法，我们可以准确地表示实体在文本中的起始和结束位置。这种方法的主要优点是灵活性，因为它可以处理不同长度和类型的实体。&lt;/p&gt;
&lt;p&gt;除了BIO-3，还有其他常见的序列标注方法，包括：&lt;/p&gt;
&lt;p&gt;IOB（Inside-Outside-Beginning）：与BIO-3类似，但使用I（Inside）和B（Beginning）标记来表示实体的起始和中间位置。&lt;/p&gt;
&lt;p&gt;IOB2：与IOB方法类似，但在一段连续的实体标记序列中，每个实体的第一个字都标记为B，而后续的字标记为I。&lt;/p&gt;
&lt;p&gt;IOE（Inside-Outside-End）：与BIO-3类似，但使用I（Inside）和E（End）标记来表示实体的中间和结束位置。&lt;/p&gt;
&lt;p&gt;IO：只有I（Inside）和O（Outside）两个标记，没有明确的起始标记。&lt;/p&gt;
&lt;p&gt;这些标注方法都是为了在序列标注任务中准确表示实体的位置和边界。具体选择哪种标注方法取决于任务的需求和数据集的特点。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/367995480&#34;&gt; 测试集、训练集、开发集的区别&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/148813079&#34;&gt;CRF条件随机场的原理、例子、公式推导和应用&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/44042528&#34;&gt;最通俗易懂的BiLSTM-CRF模型中的CRF层介绍&lt;/a&gt;&lt;/p&gt;
">【NLP】BiLSTM-CRF算法</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/jul-ei/"" data-c="
          &lt;h1 id=&#34;k-meansk-均值&#34;&gt;K-means（K-均值）&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1mf4y1k7UC/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.zhihu.com/tardis/zm/art/158776162?source_id=1005&#34;&gt;K-means（K-均值）算法的原理、Python实现和应用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;K-means算法是一种广泛使用的聚类算法，是无监督学习，用于将数据分成 K 个簇，以便于数据分析。其步骤简要如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;选择K个随机点作为初始的簇中心。&lt;/li&gt;
&lt;li&gt;对于每一个数据点，计算它与每个簇中心的欧几里得距离，并将其分配给最近的簇中心所代表的簇。&lt;/li&gt;
&lt;li&gt;对于每一个簇，重新计算簇中所有点的平均值，并将该平均值作为新的簇中心。&lt;/li&gt;
&lt;li&gt;重复步骤2和3，直到簇中心不再发生变化，或者变化非常小，或者达到预定的迭代次数。&lt;/li&gt;
&lt;li&gt;算法结束，输出最终的簇划分和簇中心。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;K-means算法简单而有效，但其结果可能受到初始簇中心选择的影响，可能需要多次运行以获取最佳结果。此外，K-means假设簇是凸形和相似大小，因此对某些类型的数据分布可能不是最佳选择。&lt;/p&gt;
&lt;p&gt;欧几里得距离：两点之间距离公式的扩展&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;KNN 和 k-means 辨析&lt;/strong&gt;&lt;br&gt;
相似点：&lt;br&gt;
K-means和KNN都是基于距离度量的算法。它们使用距离来衡量数据点之间的相似性或距离。&lt;br&gt;
K-means和KNN都使用K值来控制算法的行为。K-means中的K代表聚类的数量，KNN中的K代表邻居的数量。&lt;/p&gt;
&lt;p&gt;不同点：&lt;br&gt;
目标：K-means旨在将数据点划分为不同的聚类，使同一聚类内的数据点相似度较高，不同聚类之间的相似度较低。而KNN旨在通过找到最近的K个邻居来进行分类或回归预测。&lt;br&gt;
学习方式：K-means是一种迭代的聚类算法，通过最小化聚类内部的方差来更新聚类中心，直到达到收敛条件。KNN是一种基于实例的学习方法，通过存储和比较训练集中的实例来进行预测。&lt;br&gt;
数据需求：K-means通常要求数据点能够表示为数值向量，且距离度量可定义。KNN对数据的要求较少，可以处理不同类型的特征和度量方法。&lt;br&gt;
算法复杂度：K-means的计算复杂度较低，但对初始聚类中心的选择敏感，可能会收敛到局部最优解。KNN的计算复杂度较高，因为需要计算每个测试样本与所有训练样本之间的距离。&lt;/p&gt;
&lt;p&gt;总结而言，K-means和KNN是不同类型的机器学习算法，K-means用于聚类，而KNN用于分类和回归预测。它们在目标、学习方式、数据需求和算法复杂度等方面有显著的区别。&lt;/p&gt;
&lt;h1 id=&#34;mean-shift&#34;&gt;Mean-shift&lt;/h1&gt;
&lt;p&gt;Mean Shift算法是一种基于特征空间中的梯度上升方法的聚类技术，它不需要事先指定簇的数量，与K-means等需要预先指定簇个数的算法不同。Mean Shift的核心思想是对于给定的样本点，通过迭代移动到密度更高的区域，直至收敛到密度最大处的局部峰值。这个过程类似于“爬山”，每个样本点都朝着最陡的方向上山，直到达到山顶。这里的“山”是由特征空间中的数据点分布决定的多维概率密度函数。&lt;/p&gt;
&lt;p&gt;Mean Shift算法的基本步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;选择核函数和带宽&lt;/strong&gt;：Mean Shift算法需要一个核函数（如高斯核）和一个带宽参数，这个参数决定了搜索窗口的大小，影响着局部密度估计的范围。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;对每个数据点执行Mean Shift向量计算&lt;/strong&gt;：对于每一个数据点，Mean Shift算法计算以该点为中心，带宽为半径的超球体内所有点的质心（即均值）。这个质心是当前点和其邻域内其他点位置的加权平均，权重由核函数决定。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;更新数据点位置&lt;/strong&gt;：将每个数据点移动到计算得到的质心位置。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;重复迭代&lt;/strong&gt;：重复步骤2和步骤3，直到所有点的移动距离小于某个阈值，或者达到预设的迭代次数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;识别并合并簇&lt;/strong&gt;：由于多个数据点可能会收敛到相同的局部最大值点，因此最后需要根据一定的准则（如距离阈值）来识别和合并这些收敛点，形成最终的簇。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Mean Shift算法的优点包括不需要指定簇的数量，以及对簇的形状和大小没有严格的假设。然而，它的性能很大程度上依赖于带宽参数的选择，而且计算复杂度较高，特别是在处理大数据集时。&lt;/p&gt;
&lt;h1 id=&#34;高斯混合模型&#34;&gt;高斯混合模型&lt;/h1&gt;
&lt;p&gt;高斯混合模型（Gaussian Mixture Model, GMM）是一种软聚类方法，相对于硬聚类（如K-means，每个点只能属于一个类），GMM允许数据点以概率形式属于多个聚类。&lt;/p&gt;
&lt;p&gt;GMM假设数据是由多个高斯分布混合而成的，每个高斯分布代表一个聚类。每个高斯分布由三个参数定义：均值（mean）决定了其在特征空间中的位置，协方差矩阵（covariance matrix）决定了其形状，混合系数（mixture coefficient）表示该高斯分布在所有数据点中的占比。&lt;/p&gt;
&lt;p&gt;GMM聚类的步骤大致如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;初始化&lt;/strong&gt;：随机选择K个高斯分布的参数（均值、协方差矩阵和混合系数）或通过其他方法（如K-means聚类结果）进行初始化。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;期望步骤（E-step）&lt;/strong&gt;：基于当前的参数，计算每个数据点属于每个高斯分布的概率，这一步骤通过贝叶斯定理来完成。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;最大化步骤（M-step）&lt;/strong&gt;：利用E-step得到的概率，重新估计每个高斯分布的参数（均值、协方差矩阵和混合系数），使得数据的似然概率最大化。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;迭代&lt;/strong&gt;：重复E-step和M-step直到收敛（即参数的变化小于某个阈值或达到最大迭代次数）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;GMM聚类的优点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能够适应聚类的不同形状，因为每个聚类可以具有不同的协方差结构。&lt;/li&gt;
&lt;li&gt;每个数据点不是被硬性分配到一个聚类中，而是以概率形式表达其属于各个聚类的程度，提供了更多的信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但GMM也有一些局限性，如对初始值敏感，可能收敛到局部最优解，以及当数据维度高时计算量大、可能出现奇异协方差矩阵等问题。&lt;/p&gt;
&lt;h1 id=&#34;期望最大化&#34;&gt;期望最大化&lt;/h1&gt;
&lt;p&gt;EM聚类是基于期望最大化（Expectation-Maximization，简称EM）算法的聚类方法。EM算法是一种迭代优化算法，用于含有隐变量（latent variables）的概率模型参数估计问题。在聚类的上下文中，隐变量通常指的是数据点的类别标签。EM聚类特别适合于模型参数不易直接估计的混合模型，如高斯混合模型（GMM）。&lt;/p&gt;
&lt;p&gt;EM聚类算法主要包括两个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;期望步骤（E-step）&lt;/strong&gt;：固定模型参数，计算或更新每个数据点对于各个聚类的“责任度”，即该数据点属于各个聚类的概率。这一步骤涉及到根据当前模型参数，使用贝叶斯定理计算后验概率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;最大化步骤（M-step）&lt;/strong&gt;：固定E-step中计算得到的责任度，优化模型参数（如均值、协方差等），使得给定这些责任度下数据的似然概率最大化。这一步通常涉及到对似然函数的求导和优化。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;EM算法通过迭代执行这两个步骤直至收敛，即模型参数的变化小于某个阈值或达到最大迭代次数。EM聚类算法的优点在于能够自然地处理混合模型以及软聚类（soft clustering）问题，其中数据点可以以不同的概率属于多个聚类。&lt;/p&gt;
&lt;p&gt;然而，EM聚类也有一些局限性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对初始参数敏感，不同的初始化可能导致不同的聚类结果。&lt;/li&gt;
&lt;li&gt;可能收敛到局部最优而非全局最优解。&lt;/li&gt;
&lt;li&gt;在处理高维数据时，计算成本可能会非常高，且容易受到“维度的诅咒”的影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于其在统计建模和概率推理方面的基础，EM聚类广泛应用于各种领域，如图像处理、生物信息学和语音识别等。&lt;/p&gt;
&lt;h1 id=&#34;密度聚类&#34;&gt;密度聚类&lt;/h1&gt;
&lt;p&gt;密度聚类（Density-Based Clustering）是一种根据数据点的紧密程度进行聚类的方法，旨在发现被低密度区域分隔的高密度区域。这种方法的优点是可以发现任意形状的聚类，并且能够处理噪声和异常值。最著名的密度聚类算法是DBSCAN（Density-Based Spatial Clustering of Applications with Noise）。&lt;/p&gt;
&lt;h2 id=&#34;dbscan&#34;&gt;DBSCAN&lt;/h2&gt;
&lt;p&gt;DBSCAN算法基于两个主要概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心点&lt;/strong&gt;：在指定半径（(\epsilon)）内包含足够数量（(MinPts)）的点的点被称为核心点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;边界点和噪声点&lt;/strong&gt;：在半径(\epsilon)内少于(MinPts)的点被认为是边界点或噪声点，边界点是达到核心点的点，噪声点则是既不是核心点也不是边界点的点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DBSCAN的步骤包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对每个点，计算其(\epsilon)-邻域内的点数。&lt;/li&gt;
&lt;li&gt;标记满足(MinPts)条件的点为核心点，不满足的点为边界点或噪声点。&lt;/li&gt;
&lt;li&gt;对每个核心点，如果它还没有被分配到任何聚类中，就创建一个新的聚类，并通过核心点的邻域递归扩展这个聚类。&lt;/li&gt;
&lt;li&gt;迭代进行，直到所有的点都被访问过。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;谱聚类&#34;&gt;谱聚类&lt;/h1&gt;
&lt;p&gt;谱聚类（Spectral Clustering）是一种基于图论的聚类方法，它使用数据的相似性矩阵构建图，然后根据图的特征向量进行聚类。谱聚类特别适合于发现复杂结构的聚类，即使聚类形状非常不规则，也能获得很好的性能。&lt;/p&gt;
&lt;p&gt;谱聚类的基本步骤包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;构建相似性矩阵&lt;/strong&gt;：首先根据数据点之间的相似度（如高斯核函数计算的距离）构建一个相似性矩阵。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;构建图的拉普拉斯矩阵&lt;/strong&gt;：利用相似性矩阵构建图的拉普拉斯矩阵，拉普拉斯矩阵反映了图的拓扑结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算拉普拉斯矩阵的特征值和特征向量&lt;/strong&gt;：计算拉普拉斯矩阵的特征值和相应的特征向量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用特征向量进行聚类&lt;/strong&gt;：选择前(k)个特征向量（(k)是预先设定的聚类数目），利用这些特征向量的值将数据点映射到低维空间中，然后在这个低维空间中使用传统的聚类算法（如K-means）进行聚类。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;谱聚类的优点是能够识别各种形状的聚类，并且对数据的缩放和旋转具有一定的鲁棒性。然而，它的计算成本较高，特别是在处理大规模数据集时，计算和存储相似性矩阵及其特征向量可能会非常耗时和占用大量内存。&lt;/p&gt;
">【ML】聚类</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/mo-xing-ping-gu/"" data-c="
          &lt;h1 id=&#34;交叉验证&#34;&gt;交叉验证&lt;/h1&gt;
&lt;p&gt;交叉验证作为一种统计学方法，既可以用于调整超参数，也可以用于评估模型的泛化能力，这两个应用虽然相关，但侧重点不同。&lt;/p&gt;
&lt;h3 id=&#34;超参数调整&#34;&gt;超参数调整&lt;/h3&gt;
&lt;p&gt;在调整超参数时，交叉验证用于比较不同超参数设置下模型的性能。通过在训练集的不同子集上训练并在验证集上评估模型，可以确定哪一组超参数能够带来最佳的模型性能。这个过程通常涉及到：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;定义超参数空间&lt;/strong&gt;：确定需要调整的超参数以及它们可能的取值范围。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;选择交叉验证策略&lt;/strong&gt;：最常用的是K折交叉验证。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能评估&lt;/strong&gt;：对每一组超参数，使用交叉验证来评估模型性能。这通常涉及到对每一折的数据进行训练和验证，并计算验证结果的平均值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;选择最佳超参数&lt;/strong&gt;：基于交叉验证结果，选择表现最好的超参数设置。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;模型评估&#34;&gt;模型评估&lt;/h3&gt;
&lt;p&gt;在模型评估阶段，交叉验证用于估计模型在独立数据集上的表现。这是通过将数据集分成多个部分，然后在这些部分上重复训练和测试模型来实现的。每一部分都有机会作为测试集，从而使评估结果更加可靠和全面。这个过程可以揭示模型的泛化能力，即模型对未知数据的处理能力。&lt;/p&gt;
&lt;p&gt;使用交叉验证进行模型评估时，通常遵循以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;选择交叉验证策略&lt;/strong&gt;：例如K折交叉验证。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行交叉验证&lt;/strong&gt;：对每一折（或&amp;quot;轮&amp;quot;），训练模型，并在保留的测试折上评估其性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算平均性能指标&lt;/strong&gt;：通常对所有折的性能指标（如准确率、召回率、F1分数等）计算平均值，以得到模型性能的整体估计。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;综合应用&#34;&gt;综合应用&lt;/h3&gt;
&lt;p&gt;在实践中，交叉验证通常先用于超参数调整，确定最佳的超参数设置后，再使用这些超参数在整个训练数据集上训练模型。然后，可以再次使用交叉验证（或保留一部分数据作为最终测试集）来评估这个最终模型的泛化能力。&lt;/p&gt;
&lt;h1 id=&#34;分类问题&#34;&gt;分类问题&lt;/h1&gt;
&lt;h2 id=&#34;准确率-accuracy-精确率-precision-召回率-recall-f1-score-等&#34;&gt;准确率 (Accuracy) 精确率 (Precision) 召回率 (Recall)  F1 score 等&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/93107394&#34;&gt;一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC曲线、AUC曲线&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1vt4y117Zz/?vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站&lt;/a&gt;&lt;br&gt;
（模型）准确率 Accuracy：所有正确预测分类的数据 / 所有数据（总体预测对的）&lt;br&gt;
精确率 Precision：模型预测正确的正样本 / 所有模型预测为正的样本（模型的精确度）&lt;br&gt;
召回率 Recall：预测正确的正样本 / 测试集中所有正样本数（单类预测对的）&lt;br&gt;
三者分子都是预测正确的&lt;br&gt;
用于多分类的时候，将自己看作一类，其余的看作另一类&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;F1分数&lt;/strong&gt;&lt;br&gt;
几何平均：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\sqrt{ab}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.04em;vertical-align:-0.10777999999999999em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord sqrt&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.93222em;&#34;&gt;&lt;span class=&#34;svg-align&#34; style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34; style=&#34;padding-left:0.833em;&#34;&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.89222em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;hide-tail&#34; style=&#34;min-width:0.853em;height:1.08em;&#34;&gt;&lt;svg width=&#39;400em&#39; height=&#39;1.08em&#39; viewBox=&#39;0 0 400000 1080&#39; preserveAspectRatio=&#39;xMinYMin slice&#39;&gt;&lt;path d=&#39;M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z&#39;/&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.10777999999999999em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;算数平均：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\frac{a+b}{2}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.2251079999999999em;vertical-align:-0.345em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8801079999999999em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.345em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;调和平均：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\frac{2ab}{a+b}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.283439em;vertical-align:-0.403331em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8801079999999999em;&#34;&gt;&lt;span style=&#34;top:-2.655em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.403331em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;  &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\frac{2}{\frac{1}{a}+\frac{1}{b}}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.4869279999999998em;vertical-align:-0.64182em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.845108em;&#34;&gt;&lt;span style=&#34;top:-2.59898em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mopen nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8443142857142858em;&#34;&gt;&lt;span style=&#34;top:-2.656em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2255000000000003em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line mtight&#34; style=&#34;border-bottom-width:0.049em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.384em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.344em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mopen nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8443142857142858em;&#34;&gt;&lt;span style=&#34;top:-2.656em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2255000000000003em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line mtight&#34; style=&#34;border-bottom-width:0.049em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.384em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.344em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.64182em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;F1分数使用调和平均，调和平均给予较小的值更多的权重（取倒数）使得精确率和召回率能更好的平衡，否则若使用算数平均，较大的值对整体影响较大，无法起到调和的作用&lt;/p&gt;
&lt;p&gt;ROC 曲线越陡（左上角区域即接近（0,1）点），模型的性能就越好&lt;br&gt;
AUC：ROC 曲线下的面积，越接近 1 效果越好&lt;/p&gt;
&lt;h2 id=&#34;混淆矩阵-confusion-matrix&#34;&gt;混淆矩阵 Confusion Matrix&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1oz4y1R71a/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站入门讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/SartinL/article/details/105844832&#34;&gt;sklearn中混淆矩阵（confusion_matrix函数）的理解与使用&lt;/a&gt;&lt;br&gt;
运行博客二中的代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.metrics import confusion_matrix

y_true = [&amp;quot;cat&amp;quot;, &amp;quot;ant&amp;quot;, &amp;quot;cat&amp;quot;, &amp;quot;cat&amp;quot;, &amp;quot;ant&amp;quot;, &amp;quot;bird&amp;quot;]
y_pred = [&amp;quot;ant&amp;quot;, &amp;quot;ant&amp;quot;, &amp;quot;cat&amp;quot;, &amp;quot;cat&amp;quot;, &amp;quot;ant&amp;quot;, &amp;quot;cat&amp;quot;]
confusion_matrix(y_true, y_pred, labels=[&amp;quot;ant&amp;quot;, &amp;quot;bird&amp;quot;, &amp;quot;cat&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]], dtype=int64)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;labels表示，行，列的标签顺序为[&amp;quot;ant&amp;quot;, &amp;quot;bird&amp;quot;, &amp;quot;cat&amp;quot;]。通过观察对角线（预测正确的次数），第一个数据是ant被预测为ant的次数，为2次，bird被预测为bird的次数为0次，cat被预测为cat的次数为2次.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;debug&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;https://fixexception.com/scikit-learn/at-least-one-label-specified-must-be-in-y-true/&#34;&gt;ValueError: At least one label specified must be in y_true&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;问答&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Q：
1. 基本定义
   - 请解释准确率（Accuracy）的定义及其计算方式。
   - 请定义召回率（Recall）并说明其在何种情况下尤为重要。
   - 描述精确度（Precision）的含义，并提供一个实际应用场景，其中精确度比其他指标更重要。
   - 解释F1得分是如何平衡精确度和召回率的，以及为什么要使用F1得分而不是直接使用精确度或召回率。

2. 计算和应用
   - 给定一个混淆矩阵，如何计算准确率、召回率、精确度和F1得分？
   - 在一个极度不平衡的数据集中，为什么仅使用准确率来评估模型可能会产生误导？
   - 请举例说明在哪种情况下你会优先考虑召回率而不是精确度，反之亦然。

3. 理论和实践
   - 在二分类问题中，如果类别极不平衡，应该使用哪些性能指标？为什么？
   - 请解释为什么F1得分可能不足以全面评估模型的性能。
   - 在多分类问题中，如何计算和解释这些评估指标？
   - 如何提高召回率/精确率？

4. 批判性思维
   - 有哪些情况下准确率高但模型性能实际上并不好？请提供一个实例。
   - 如果你的模型在精确度很高的情况下召回率很低，你会如何调整模型以改善性能？
   - 考虑到业务成本和利益，如何决定在精确度和召回率之间的权衡？
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;A：
1. 基本定义

准确率（Accuracy）的定义及计算方式
准确率是正确预测的数量（真正例和真反例）与总预测数量的比率。它是最直观的性能评估指标，但在数据不平衡的情况下可能会产生误导。

召回率（Recall）的定义及其重要性
召回率是正确预测为正例的数量（真正例）与实际正例总数的比率。召回率在需要捕捉尽可能多的正例（如疾病筛查）时非常重要，因为它关注于遗漏正例的数量。

精确度（Precision）的含义及重要应用场景
精确度是正确预测为正例的数量（真正例）与所有预测为正例的数量的比率。在将误报的成本很高的场景中，精确度尤其重要，例如垃圾邮件检测，你不希望误将重要邮件归类为垃圾邮件。

F1得分的解释
F1得分是精确度和召回率的调和平均值，用于平衡两者。当你需要同时考虑精确度和召回率，且无法确定哪个更重要时，F1得分是一个有用的指标。

2. 计算和应用

给定混淆矩阵的计算
给定一个混淆矩阵，你可以直接应用上述公式来计算准确率、召回率、精确度和F1得分。

不平衡数据集中准确率的误导性
在极度不平衡的数据集中，即使模型仅预测多数类，准确率也可能很高。这会掩盖模型在少数类上表现不佳的事实，因此在这种情况下，准确率不是一个好的性能指标。

优先考虑召回率或精确度的情况
- 在医疗诊断等领域，错过真正的病例（低召回率）可能比误诊（低精确度）更危险，因此可能会优先考虑召回率。
- 在垃圾邮件检测等场景中，误报（低精确度）可能导致重要信息的丢失，因此可能会优先考虑精确度。

3. 理论和实践

类别极不平衡的二分类问题的性能指标
在类别极度不平衡的情况下，应使用召回率、精确度和F1得分而非准确率，因为它们能更好地反映模型在少数类上的性能。

F1得分可能不足以全面评估模型性能的原因
F1得分是精确度和召回率的调和平均，它倾向于同时考虑这两个指标。然而，在某些情况下，这种平衡可能掩盖了模型在这两个方面的极端表现。例如，一个模型可能具有很高的精确度但很低的召回率，或者相反，这在F1得分中可能不会很明显。此外，F1得分不能提供关于模型在不同阈值下表现的信息，这在某些应用中可能非常关键。

多分类问题中的评估指标计算和解释
在多分类问题中，可以分别为每个类计算精确度、召回率和F1得分，然后通过宏平均（对所有类的指标求平均）或微平均（先汇总所有类的TP、FP、FN，然后计算指标）来获得整体性能指标。宏平均对所有类别平等对待，而微平均更多地受到高频类别的影响。

提高召回率/精确率

精确率低（FP较高）和召回率低（FN较高）可能原因：
样本不均衡、特征学习不足、模型不匹配（模型太简单，欠拟合，或太复杂，过拟合）、超参数设置（如学习率过高或过低、正则化不当等）、数据质量或预处理不当
解决方法：
a. 增加正样本，数据重采样
b. 使用加权交叉熵损失，为少数类分配更高的权重
c. 数据标注错误，正样本被标注为负样本

4. 批判性思维

准确率高但模型性能不好的情况
在数据高度不平衡的情况下，即使模型对多数类的预测非常准确，但对少数类几乎总是错误的，准确率也可能会很高。这种情况下，模型实际上对于识别少数类（可能是更感兴趣的类）的能力很差。

精确度高但召回率低的模型调整策略
如果模型的精确度很高但召回率很低，这意味着模型过于保守，只有在非常确定的情况下才会预测正类。调整策略可能包括：
- 降低分类阈值，使模型更容易将实例分类为正类。
- 重新采样或加权以增加少数类的影响，使模型更关注于少数类。
- 在损失函数中引入类权重，提高少数类的错误成本。

在精确度和召回率之间的权衡
权衡精确度和召回率通常涉及业务或应用需求的具体分析。在某些情况下，避免假阳性（高精确度）可能比避免假阴性（高召回率）更重要，反之亦然。考虑成本、风险和可能的后果是决定这种权衡的关键。例如，在金融欺诈检测中，可能更愿意接受较低的精确度以保证较高的召回率，以确保尽可能多的欺诈案例被捕获，即使这意味着更多的正常交易会被错误地标记为欺诈。
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;回归问题&#34;&gt;回归问题&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;均方误差（Mean Squared Error, MSE）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MSE是实际值与预测值之差的平方和的平均值（方差），是衡量预测准确性的常用指标。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;均方根误差（Root Mean Squared Error, RMSE）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RMSE是MSE的平方根（标准差），用于量化预测误差的大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;平均绝对误差（Mean Absolute Error, MAE）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MAE 是实际值与预测值之差的绝对值的平均值，它给所有的误差以相等的权重。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;R平方（R²或决定系数）&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R平方衡量模型解释的变异量占总变异量的比例，值越接近1表示模型越好。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;聚类问题的评分指标&#34;&gt;聚类问题的评分指标&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;轮廓系数（Silhouette Coefficient）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;轮廓系数结合了聚类的凝聚度和分离度，用于评估聚类的质量，其值的范围是[-1, 1]。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;戴维森堡丁指数（Davies-Bouldin Index）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;该指数是一种内部评估方法，通过计算聚类之间的相似度来评估聚类质量，值越小表示聚类效果越好。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Jaccard系数&lt;/strong&gt;&lt;br&gt;
用于分类和聚类问题&lt;br&gt;
计算两个集合 A、B 的相似度，A∩B/A∪B，若交比并越大则代表AB越相似，即Jaccard系数越大相似度越大&lt;br&gt;
聚类分配：数据点根据聚类算法被分配到的聚类（集合A）&lt;br&gt;
真实分组：数据点根据实际情况或先验知识应该被分配到的组（集合B）&lt;br&gt;
系数越接近 1，代表聚类效果越好&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/354289511&#34;&gt;距离相似度计算总结（欧式距离、余弦相似度、杰卡德、互信息等18种）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
">【ML】模型的评估</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-ci-qian-ru/"" data-c="
          &lt;h1 id=&#34;词嵌入word-embedding&#34;&gt;词嵌入（Word Embedding）&lt;/h1&gt;
&lt;p&gt;将词语映射为数值&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/422542949&#34;&gt;从0开始词嵌入（Word embedding）&lt;/a&gt;&lt;br&gt;
one-hot：只编码了词汇，无语义信息&lt;br&gt;
bag of words：只有词的频率信息，无其他语义信息&lt;br&gt;
N-gram：大小为N的滑动窗口，每个片段称为gram，但会有零概率问题&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/187486026#:~:text=%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E9%9B%B6%E6%A6%82%E7%8E%87%E9%97%AE%E9%A2%98%E5%91%A2%EF%BC%8C%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81%E7%BB%99,%E2%80%9C%E6%9C%AA%E5%87%BA%E7%8E%B0%E7%9A%84n-gram%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E4%B8%80%E4%B8%AA%E9%9D%9E%E9%9B%B6%E4%BC%B0%E8%AE%A1%E5%80%BC%EF%BC%8C%E7%9B%B8%E5%BA%94%E5%BE%97%E9%9C%80%E8%A6%81%E9%99%8D%E4%BD%8E%E5%B7%B2%E5%87%BA%E7%8E%B0n-gram%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%EF%BC%8C%E4%B8%94%E7%BB%8F%E6%95%B0%E6%8D%AE%E5%B9%B3%E6%BB%91%E5%90%8E%E4%B8%80%E5%AE%9A%E4%BF%9D%E8%AF%81%E6%A6%82%E7%8E%87%E5%92%8C%E4%B8%BA1%E2%80%9D%20%E3%80%82&#34;&gt;n-gram语言模型原理到实践&lt;/a&gt;&lt;br&gt;
bag of words 和 N-gram 都是基于词频统计的模型，而一些高词频的词不一定有用，比如 &amp;quot;我&amp;quot;、&amp;quot;你&amp;quot; 等，称为停用词（stop words）在构建词汇表的时候可以抛弃这些词&lt;br&gt;
TF-IDF：统计词频来估计词汇的重要程度&lt;/p&gt;
&lt;h1 id=&#34;词袋模型bag-of-wordsbow&#34;&gt;词袋模型（bag of words，BOW）&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/667280452&#34;&gt;传统NLP之Bag of Words（词袋模型）&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;tf-idf&#34;&gt;TF-IDF&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV12u411C7Sq/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;4分钟TF-IDF原理讲解与简单实现！基础看这一篇就够啦&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/31197209&#34;&gt;机器学习：生动理解TF-IDF算法&lt;/a&gt;&lt;br&gt;
用于评估一个词语在特定文档中相对于整个文档集合的重要程度，通过计算每个词语的TF-IDF值，可以确定哪些词语最具代表性或者最能区分当前文档与其他文档。可以自动过滤停用词&lt;/p&gt;
&lt;h1 id=&#34;word2vec&#34;&gt;Word2vec&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27234078&#34;&gt;理解 Word2Vec 之 Skip-Gram 模型&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/m0_63642362/article/details/127991177&#34;&gt;图学习【参考资料1】词向量word2vec&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;简述Word2vec模型&lt;/p&gt;
&lt;h1 id=&#34;glove&#34;&gt;GloVe&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/42073620&#34;&gt;（十五）通俗易懂理解——Glove算法原理&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/50946044&#34;&gt;GloVe算法原理及简单使用&lt;/a&gt;&lt;/p&gt;
">【NLP】词嵌入</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/she-ying-diao-se-si-lu/"" data-c="
          &lt;p&gt;降低纹理可以减少画面杂乱感，比如杂草背景&lt;br&gt;
背光人像可以通过提高清晰度提高人像亮度&lt;br&gt;
调节曝光要保证画面整体看起来和谐。比如白色色阶不能过于割裂&lt;br&gt;
如果遇到颜色过于单一，或者色彩不好平衡的时候，不妨试试黑白调色&lt;/p&gt;
&lt;p&gt;解决不能二次导入LR的问题：&lt;br&gt;
只需更改文件夹名即可，LR就认为你换了个路径&lt;/p&gt;
&lt;p&gt;临时调色文件用完就删&lt;/p&gt;
&lt;p&gt;并不一定是阳光充足就好，阴雨天也能拍出氛围感人像，不同的光线有不同的效果&lt;/p&gt;
&lt;p&gt;调色工具&lt;br&gt;
&lt;a href=&#34;https://www.chinavid.com/color.html&#34;&gt;高级在线配色器&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://photokit.com/colors/eyedropper/?lang=zh&#34;&gt;屏幕取色器&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;色卡生成工具&lt;br&gt;
&lt;a href=&#34;https://photokit.com/colors/palette-generator/?lang=zh&#34;&gt;调色板生成器1&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://colors.dopely.top/image-color-picker/&#34;&gt;调色板生成器2&lt;/a&gt;&lt;/p&gt;
">【摄影】调色思路</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/bpe/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_43902773/article/details/115191790&#34;&gt;基于BPE的汉语tokenization&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;基于bpe的子词压缩&#34;&gt;基于BPE的子词压缩&lt;/h1&gt;
&lt;p&gt;对于英文语料来讲，特别是在预训练模型兴起之前，一种常见的分词方式是通过空格对英文语句直接进行分词。然而这种分词方式可能也会带来一些问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;英文单词由于时态、单复数、大小写等因素，可能具有多个单词变体，比如单词go具有这样的变体： going, gone, goes，单纯基于空格从语料中收集单词，可能会导致词表过大，进而导致模型学习过程中，需要设置较大的词向量矩阵，增加模型参数。&lt;/li&gt;
&lt;li&gt;由于词表难以穷尽所有单词，以及网络中会出现一些新的词，导致某些词无法出现在词表中，即出现集外词（OOV）。&lt;br&gt;
BPE（Byte-Pair Encoding）是缓解这些问题的一种算法，其不再按照完整的单词进行分词，而是将单词划分成了子词（sub-word）的粒度。例如单词showed可以被划分为show和ed， 如此做法，可以有效缩减单词个数，同时通过拆解子词也能够缓解OOV问题。图1展示了一种BPE算法效果的示例，一方面通过右侧的子词组合可以表示左侧任意一个单词，另一方面通过子词的表示大大减小了原本词表的大小。&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1680157576369.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
图1 BPE算法示例&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;12-实现流程&#34;&gt;1.2 实现流程&lt;/h1&gt;
&lt;p&gt;如图2所示，使用BPE算法进行对文本进行分词，首先需要根据英文语料构建BPE的子词词表，根据此词表即可对给定的文本序列进行编码，即分词，获取分词后的文本序列。同时提供根据编码后的结果还原原始语句的方法。&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1680157622297.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
图2 BPE实现流程&lt;/p&gt;
&lt;h1 id=&#34;13-词表构建&#34;&gt;1.3 词表构建&lt;/h1&gt;
&lt;p&gt;词表构建是BPE算法的核心，首先需要准备一批语料，然后从语料中逐步统计词频，构建BPE子词词表。具体来讲，首先需要将训练数据中的每个单词切分成字符作为初始子词，并统计语料中的子词初始化子词词表。接下来，可以按照如下步骤逐步迭代：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;统计每一个连续子词对的出现频率，选择最高频子词对合并成新的子词，并将该子词对加入词表中；&lt;/li&gt;
&lt;li&gt;根据最高频子词对，将语料中的这两个相邻子词进行合并；&lt;/li&gt;
&lt;li&gt;如果组成最高频子词对的子词在原始语料中不再存在，则在词表中进行删除；&lt;/li&gt;
&lt;li&gt;重复第1-3步直到达到设定的子词词表大小或迭代次数；&lt;br&gt;
下面通过一个例子说明如何构造子词词典，假设通过统计获得了如下预处理好的语料库，其中每个单词中的字符通过空格进行分割为子词，同时单词后使用&lt;/w&gt;作为单词结尾符号：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;train_data = {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n i n g &amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a n g u a g e &amp;lt;/w&amp;gt;&#39;: 3,&#39;p r o c e s s i n g &amp;lt;/w&amp;gt;&#39;:7}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;利用以上训练数据，初始化子词词表为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;bpe_vocab = {&#39;a&#39;, &#39;e&#39;, &#39;p&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;o&#39;, &#39;s&#39;, &#39;l&#39;, &#39;r&#39;, &#39;u&#39;, &#39;d&#39;, &#39;n&#39;, &#39;i&#39;, &#39;t&#39;, &#39;c&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接下来，便可以逐步统计最高频的相邻子词对，并对训练数据进行子词合并。&lt;/p&gt;
&lt;p&gt;第1次迭代： 最高频连续子词对&amp;quot;n&amp;quot;和&amp;quot;g&amp;quot;出现了7+3+7=17次，合并成&amp;quot;ng&amp;quot;加入词表。&amp;quot;n&amp;quot;和&amp;quot;g&amp;quot;在语料库中依旧存在，因此不需要在词表中删除，语料库和词表在本次迭代之后的结果为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;train_data = {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n i ng &amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3,&#39;p r o c e s s i ng &amp;lt;/w&amp;gt;&#39;:7}
bpe_vocab = {&#39;a&#39;, &#39;e&#39;, &#39;p&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;o&#39;, &#39;s&#39;, &#39;l&#39;, &#39;r&#39;, &#39;u&#39;, &#39;d&#39;, &#39;n&#39;, &#39;i&#39;, &#39;t&#39;, &#39;c&#39;, &#39;ng&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第2次迭代： 最高频连续子词对&amp;quot;i&amp;quot;和&amp;quot;ng&amp;quot;出现了7+7=14次，合并成&amp;quot;ing&amp;quot;加入词表。子词&amp;quot;i&amp;quot;在语料库中不再存在，因此在词表中进行删除，语料库和词表在本次迭代之后的结果为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;train_data = {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n ing &amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3,&#39;p r o c e s s ing &amp;lt;/w&amp;gt;&#39;:7}
bpe_vocab = {&#39;a&#39;, &#39;e&#39;, &#39;p&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;o&#39;, &#39;s&#39;, &#39;l&#39;, &#39;r&#39;, &#39;u&#39;, &#39;d&#39;, &#39;n&#39;, &#39;t&#39;, &#39;c&#39;, &#39;ng&#39;, &#39;ing&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第3次迭代： 最高频连续子词对&amp;quot;ing&amp;quot;和&amp;quot;&lt;/w&gt;&amp;quot;出现了7+7=14次，合并成&amp;quot;ing&lt;/w&gt;&amp;quot;加入词表。&amp;quot;ing&amp;quot;在语料库中不再存在，因此在词表中进行删除，语料库和词表在本次迭代之后的结果为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;train_data = {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n ing&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3,&#39;p r o c e s s ing&amp;lt;/w&amp;gt;&#39;:7}
bpe_vocab = {&#39;a&#39;, &#39;e&#39;, &#39;p&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;o&#39;, &#39;s&#39;, &#39;l&#39;, &#39;r&#39;, &#39;u&#39;, &#39;d&#39;, &#39;n&#39;, &#39;t&#39;, &#39;c&#39;, &#39;ng&#39;,&#39;ing&amp;lt;/w&amp;gt;&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重复以上迭代过程，直到子词词表规模达到预先设定的大小或下一个最高频的子词对出现频率为1。&lt;/p&gt;
&lt;p&gt;首先，定义函数get_subwords，用以统计子词以及对应的词频，并获取初始化后的子词词表bpe_vocab。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re
import collections

def get_subwords(data):
    &amp;quot;&amp;quot;&amp;quot;
    统计子词以及对应的词频
    &amp;quot;&amp;quot;&amp;quot;
    subwords = collections.defaultdict(int)
    for word, freq in data.items():
        for subword in word.split():
            subwords[subword] += freq

    return subwords

train_data = {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n i n g &amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a n g u a g e &amp;lt;/w&amp;gt;&#39;: 3,&#39;p r o c e s s i n g &amp;lt;/w&amp;gt;&#39;:7}
subwords = get_subwords(train_data)
# 获取初始化的子词词表
bpe_vocab = set(subwords.keys())
print(&amp;quot;词表：&amp;quot;, bpe_vocab)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;词表： {&#39;d&#39;, &#39;s&#39;, &#39;a&#39;, &#39;u&#39;, &#39;o&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;i&#39;, &#39;g&#39;, &#39;c&#39;, &#39;r&#39;, &#39;l&#39;, &#39;t&#39;, &#39;n&#39;, &#39;p&#39;, &#39;e&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接下来，在构造词表过程中，需要统计相邻子词对的词频，以便获取最高频的词对，代码实现如下。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_pair_with_frequency(data):
    &amp;quot;&amp;quot;&amp;quot;
    获取子词对以及子词集合
    &amp;quot;&amp;quot;&amp;quot;
    pairs = collections.defaultdict(int)
    for word, freq in data.items():
        sub_words = word.split()
        for i in range(len(sub_words)-1):
            pair = (sub_words[i],sub_words[i+1])
            pairs[pair] += freq
    return pairs

pairs = get_pair_with_frequency(train_data)
print(&amp;quot;子词词对：&amp;quot;, pairs)
best_pair = max(pairs, key=pairs.get)
print(&amp;quot;当前最高频的子词对: &amp;quot;, best_pair)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;子词词对： defaultdict(&amp;lt;class &#39;int&#39;&amp;gt;, {(&#39;d&#39;, &#39;e&#39;): 5, (&#39;e&#39;, &#39;e&#39;): 5, (&#39;e&#39;, &#39;p&#39;): 5, (&#39;p&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 5, (&#39;l&#39;, &#39;e&#39;): 7, (&#39;e&#39;, &#39;a&#39;): 7, (&#39;a&#39;, &#39;r&#39;): 7, (&#39;r&#39;, &#39;n&#39;): 7, (&#39;n&#39;, &#39;i&#39;): 7, (&#39;i&#39;, &#39;n&#39;): 14, (&#39;n&#39;, &#39;g&#39;): 17, (&#39;g&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 14, (&#39;n&#39;, &#39;a&#39;): 6, (&#39;a&#39;, &#39;t&#39;): 6, (&#39;t&#39;, &#39;u&#39;): 6, (&#39;u&#39;, &#39;r&#39;): 6, (&#39;r&#39;, &#39;a&#39;): 6, (&#39;a&#39;, &#39;l&#39;): 6, (&#39;l&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 6, (&#39;l&#39;, &#39;a&#39;): 3, (&#39;a&#39;, &#39;n&#39;): 3, (&#39;g&#39;, &#39;u&#39;): 3, (&#39;u&#39;, &#39;a&#39;): 3, (&#39;a&#39;, &#39;g&#39;): 3, (&#39;g&#39;, &#39;e&#39;): 3, (&#39;e&#39;, &#39;&amp;lt;/w&amp;gt;&#39;): 3, (&#39;p&#39;, &#39;r&#39;): 7, (&#39;r&#39;, &#39;o&#39;): 7, (&#39;o&#39;, &#39;c&#39;): 7, (&#39;c&#39;, &#39;e&#39;): 7, (&#39;e&#39;, &#39;s&#39;): 7, (&#39;s&#39;, &#39;s&#39;): 7, (&#39;s&#39;, &#39;i&#39;): 7})
当前最高频的子词对:  (&#39;n&#39;, &#39;g&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接下来，根据获取的最高频子词对，对训练语料中的相应子词进行合并，代码实现如下。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def merge_data_with_pair(pair, data):
    &amp;quot;&amp;quot;&amp;quot;
    将语料中的最高频子词对进行合并
    输入：
        - pair: 最高频子词词对
        - data: 字典形式，统计好的输入语料
    &amp;quot;&amp;quot;&amp;quot;
    result = {}
    bigram = re.escape(&#39; &#39;.join(pair))
    p = re.compile(r&#39;(?&amp;lt;!\S)&#39; + bigram + r&#39;(?!\S)&#39;)
    for word in data:
        merged_word = p.sub(&#39;&#39;.join(pair), word)
        result[merged_word] = data[word]
    return result

train_data = merge_data_with_pair(best_pair, train_data)
print(&amp;quot;语料库: &amp;quot;, train_data)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;语料库:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n i ng &amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s i ng &amp;lt;/w&amp;gt;&#39;: 7}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后，将最高频的子词对加入词表，对于不再存在于语料库中的子词在词表中进行删除。基于上述这流程，下面正式定义构建词表函数build_vocab，代码实现如下。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def build_vocab(train_data, num_merges):
    &amp;quot;&amp;quot;&amp;quot;
    根据训练语料构建词表
    输入：
        - train_data: 字典形式，统计好的输入语料
        - num_merges: 迭代次数
    &amp;quot;&amp;quot;&amp;quot;

    # 初始化词表
    subwords = get_subwords(train_data)
    bpe_vocab = set(subwords.keys())
    print(bpe_vocab, len(bpe_vocab))
    i = 1
    # 逐步生成词表
    for _ in range(num_merges):
        # 根据语料统计相邻子词对的词频
        pairs = get_pair_with_frequency(train_data)
        # 取频率最大的子词对, 如果pairs 为空或子词对的最大频次为1，则停止
        if not pairs:
            break
        best_pair = max(pairs, key=pairs.get)
        if pairs[best_pair] == 1:
            break
        # 合并语料
        train_data = merge_data_with_pair(best_pair, train_data)
        # 将子词加入词表中
        merged_word = &amp;quot;&amp;quot;.join(best_pair)
        bpe_vocab.add(merged_word)
        # 删除子词
        subwords = get_subwords(train_data)
        if best_pair[0] not in subwords:
            bpe_vocab.remove(best_pair[0])
        if best_pair[1] not in subwords:
            bpe_vocab.remove(best_pair[1])

        print(&amp;quot;Iter - {}, 最高频子词对: {}&amp;quot;.format(i, best_pair))
        print(&amp;quot;训练数据: &amp;quot;, train_data)
        print(&amp;quot;词表: {}, {}\n&amp;quot;.format(len(bpe_vocab), bpe_vocab))
        i += 1
    return bpe_vocab

num_merges = 14

train_data = {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n i n g &amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a n g u a g e &amp;lt;/w&amp;gt;&#39;: 3,&#39;p r o c e s s i n g &amp;lt;/w&amp;gt;&#39;:7}

bpe_vocab = build_vocab(train_data, num_merges)
print(&amp;quot;词表: &amp;quot;, bpe_vocab)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;{&#39;d&#39;, &#39;s&#39;, &#39;a&#39;, &#39;u&#39;, &#39;o&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;i&#39;, &#39;g&#39;, &#39;c&#39;, &#39;r&#39;, &#39;l&#39;, &#39;t&#39;, &#39;n&#39;, &#39;p&#39;, &#39;e&#39;} 15
Iter - 1, 最高频子词对: (&#39;n&#39;, &#39;g&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n i ng &amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s i ng &amp;lt;/w&amp;gt;&#39;: 7}
词表: 16, {&#39;d&#39;, &#39;s&#39;, &#39;a&#39;, &#39;u&#39;, &#39;o&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;i&#39;, &#39;g&#39;, &#39;c&#39;, &#39;r&#39;, &#39;ng&#39;, &#39;l&#39;, &#39;t&#39;, &#39;n&#39;, &#39;p&#39;, &#39;e&#39;}

Iter - 2, 最高频子词对: (&#39;i&#39;, &#39;ng&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n ing &amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s ing &amp;lt;/w&amp;gt;&#39;: 7}
词表: 16, {&#39;d&#39;, &#39;ing&#39;, &#39;s&#39;, &#39;a&#39;, &#39;u&#39;, &#39;o&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;c&#39;, &#39;r&#39;, &#39;ng&#39;, &#39;l&#39;, &#39;t&#39;, &#39;n&#39;, &#39;p&#39;, &#39;e&#39;}

Iter - 3, 最高频子词对: (&#39;ing&#39;, &#39;&amp;lt;/w&amp;gt;&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;l e a r n ing&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 16, {&#39;d&#39;, &#39;s&#39;, &#39;a&#39;, &#39;u&#39;, &#39;o&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;c&#39;, &#39;r&#39;, &#39;ng&#39;, &#39;l&#39;, &#39;t&#39;, &#39;n&#39;, &#39;p&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;e&#39;}

Iter - 4, 最高频子词对: (&#39;l&#39;, &#39;e&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;le a r n ing&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 17, {&#39;a&#39;, &#39;u&#39;, &#39;c&#39;, &#39;l&#39;, &#39;n&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;le&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;, &#39;o&#39;}

Iter - 5, 最高频子词对: (&#39;le&#39;, &#39;a&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;lea r n ing&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 17, {&#39;a&#39;, &#39;u&#39;, &#39;c&#39;, &#39;l&#39;, &#39;n&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;lea&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;, &#39;o&#39;}

Iter - 6, 最高频子词对: (&#39;lea&#39;, &#39;r&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;lear n ing&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 17, {&#39;a&#39;, &#39;u&#39;, &#39;c&#39;, &#39;l&#39;, &#39;n&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;lear&#39;, &#39;ng&#39;, &#39;t&#39;, &#39;o&#39;}

Iter - 7, 最高频子词对: (&#39;lear&#39;, &#39;n&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;learn ing&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 17, {&#39;a&#39;, &#39;u&#39;, &#39;c&#39;, &#39;l&#39;, &#39;n&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;learn&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;, &#39;o&#39;}

Iter - 8, 最高频子词对: (&#39;learn&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;learning&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;p r o c e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 17, {&#39;a&#39;, &#39;u&#39;, &#39;c&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;, &#39;o&#39;}

Iter - 9, 最高频子词对: (&#39;p&#39;, &#39;r&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;learning&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;pr o c e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 18, {&#39;a&#39;, &#39;u&#39;, &#39;c&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;pr&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;, &#39;o&#39;}

Iter - 10, 最高频子词对: (&#39;pr&#39;, &#39;o&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;learning&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;pro c e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 17, {&#39;a&#39;, &#39;u&#39;, &#39;c&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;pro&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;}

Iter - 11, 最高频子词对: (&#39;pro&#39;, &#39;c&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;learning&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;proc e s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 16, {&#39;proc&#39;, &#39;a&#39;, &#39;u&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;}

Iter - 12, 最高频子词对: (&#39;proc&#39;, &#39;e&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;learning&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;proce s s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 16, {&#39;a&#39;, &#39;u&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;proce&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;}

Iter - 13, 最高频子词对: (&#39;proce&#39;, &#39;s&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;learning&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;proces s ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 16, {&#39;a&#39;, &#39;u&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;proces&#39;, &#39;r&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;s&#39;, &#39;ng&#39;, &#39;t&#39;}

Iter - 14, 最高频子词对: (&#39;proces&#39;, &#39;s&#39;)
训练数据:  {&#39;d e e p &amp;lt;/w&amp;gt;&#39;: 5, &#39;learning&amp;lt;/w&amp;gt;&#39;: 7, &#39;n a t u r a l &amp;lt;/w&amp;gt;&#39;: 6, &#39;l a ng u a g e &amp;lt;/w&amp;gt;&#39;: 3, &#39;process ing&amp;lt;/w&amp;gt;&#39;: 7}
词表: 15, {&#39;a&#39;, &#39;u&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;process&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;ng&#39;, &#39;t&#39;}

词表:  {&#39;a&#39;, &#39;u&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;process&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;ng&#39;, &#39;t&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;14-语料编码&#34;&gt;1.4 语料编码&lt;/h1&gt;
&lt;p&gt;在获得子词词表之后，便可以根据该词表将文本序列进行编码，即分词。这里可以采用贪心的思想，根据子词词表中的子词长度对子词词表由大到小进行排序，然后对于一个待编码的单词，从前向后依次遍历词表中的子词，如果该子词在单词之后，则将该单词在子词位置进行切分，这样便可以获得最多三个单词子串：子词前的单词子串、子词串、子词后的单词子串，然后按照同样的思路继续遍历剩余的单词子串。如果在子词词表遍历完成之后，依然有一些单词子串没有被切分，则使用&#39;&lt;UNK&gt;&#39;进行替代。&lt;/p&gt;
&lt;p&gt;下面来看一个例子，假设给定子词词表为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[“ning&amp;lt;/w&amp;gt;”, “lear”, “deep&amp;lt;/w&amp;gt;”, “est&amp;lt;/w&amp;gt;”, “the&amp;lt;/w&amp;gt;”, “a&amp;lt;/w&amp;gt;”]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;待分词的文本序列为:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[“the&amp;lt;/w&amp;gt;”, “deep&amp;lt;/w&amp;gt;”, “learning&amp;lt;/w&amp;gt;”]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;则最后分词编码的结果为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[“the&amp;lt;/w&amp;gt;”, “deep&amp;lt;/w&amp;gt;”, &amp;quot;lear&amp;quot;, “ning&amp;lt;/w&amp;gt;”]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接下来，先定义函数tokenize_word用于对单词进行编码。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re

def tokenize_word(word, sorted_vocab, unknown_token=&#39;&amp;lt;unk&amp;gt;&#39;):
    &amp;quot;&amp;quot;&amp;quot;
    输入:
        - word: 待编码的单词
        - sorted_vocab: 排序后的子词词典
        - unknown_token: 不能被切分的子词替代符
    &amp;quot;&amp;quot;&amp;quot;
    # 如果传入的词为空
    if word == &amp;quot;&amp;quot;:
        return []
    # 如果词表为空，则将输入的词替换为&amp;lt;UNK&amp;gt;
    if sorted_vocab == []:
        return [unknown_token] + len(string)

    word_tokens = []
    # 遍历词表拆分单词
    for i in range(len(sorted_vocab)):
        token = sorted_vocab[i]
        # 基于该token定义正则，同时将token里面包含句号的变成[.]
        token_reg = re.escape(token.replace(&#39;.&#39;, &#39;[.]&#39;))
        # 在当前word中进行遍历，找到匹配的token的起始和结束位置
        matched_positions = [(m.start(0), m.end(0)) for m in re.finditer(token_reg, word)]
        # 如果当前token没有匹配到相应串，则跳过
        if  len(matched_positions) == 0:
            continue
        
        # 获取匹配到的子串的起始位置
        end_positions = [matched_position[0] for matched_position in matched_positions]
        start_position = 0

        for end_position in end_positions:
            subword = word[start_position: end_position]
            word_tokens += tokenize_word(subword, sorted_vocab[i+1:], unknown_token)
            word_tokens += [token]
            start_position = end_position + len(token)
        # 匹配剩余的子串
        word_tokens += tokenize_word(word[start_position:], sorted_vocab[i+1:], unknown_token)
        break
    else:
        # 如果word没有被匹配，则映射为&amp;lt;unk&amp;gt;
        word_tokens = [unknown_token] * len(word)
    
    return word_tokens
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;定义函数tokenize用于对语句进行编码。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def tokenize(text, bpe_vocab):
    &amp;quot;&amp;quot;&amp;quot;
    使用BPE对输入语句进行编码
    &amp;quot;&amp;quot;&amp;quot;
    # 对子词词表按照子词长度进行排序
    sorted_vocab = sorted(bpe_vocab, key=lambda subword: len(subword), reverse=True)
    print(&amp;quot;待编码语句: &amp;quot;, text)
    tokens = []
    for word in text.split():
        word = word + &amp;quot;&amp;lt;/w&amp;gt;&amp;quot;
        word_tokens = tokenize_word(word, sorted_vocab, unknown_token=&#39;&amp;lt;unk&amp;gt;&#39;)
        tokens.extend(word_tokens)
    
    return tokens

text = &amp;quot;natural language processing&amp;quot;
tokens = tokenize(text, bpe_vocab)
print(&amp;quot;词表: &amp;quot;, bpe_vocab)
print(&amp;quot;编码结果: &amp;quot;, tokens)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;待编码语句:  natural language processing
词表:  {&#39;a&#39;, &#39;u&#39;, &#39;l&#39;, &#39;n&#39;, &#39;learning&amp;lt;/w&amp;gt;&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;g&#39;, &#39;p&#39;, &#39;e&#39;, &#39;r&#39;, &#39;process&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;, &#39;d&#39;, &#39;ng&#39;, &#39;t&#39;}
编码结果:  [&#39;n&#39;, &#39;a&#39;, &#39;t&#39;, &#39;u&#39;, &#39;r&#39;, &#39;a&#39;, &#39;l&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;l&#39;, &#39;a&#39;, &#39;ng&#39;, &#39;u&#39;, &#39;a&#39;, &#39;g&#39;, &#39;e&#39;, &#39;&amp;lt;/w&amp;gt;&#39;, &#39;process&#39;, &#39;ing&amp;lt;/w&amp;gt;&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;15-语料解码&#34;&gt;1.5 语料解码&lt;/h1&gt;
&lt;p&gt;在将一串语句使用BPE进行编码后，如何还原成原来的语句呢。这种情况下，单词后设置的&amp;lt;\w&amp;gt;便起了作用。即可以一直合并分词后的子词，直到遇见&amp;lt;\w&amp;gt;便可以解码出一个完整单词。下面给出了一个例子。&lt;/p&gt;
&lt;p&gt;假设使用BPE编码后的序列：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[“the&amp;lt;/w&amp;gt;”, “deep&amp;lt;/w&amp;gt;”, “lear”, “ning&amp;lt;/w&amp;gt;”]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;则对应的解码结果为:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;[&amp;quot;the&amp;quot;, &amp;quot;deep&amp;quot;,&amp;quot;learning&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;代码实现如下。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def restore(tokens):

    text = []
    word = []
    for token in tokens:
        if token[-4:] == &amp;quot;&amp;lt;/w&amp;gt;&amp;quot;:
            if token != &amp;quot;&amp;lt;/w&amp;gt;&amp;quot;:
                word.append(token[:-4])
            text.append(&amp;quot;&amp;quot;.join(word))
            word.clear()
        else:
            word.append(token)
    return text

tokens = [&amp;quot;the&amp;lt;/w&amp;gt;&amp;quot;, &amp;quot;deep&amp;lt;/w&amp;gt;&amp;quot;, &amp;quot;lear&amp;quot;, &amp;quot;ning&amp;lt;/w&amp;gt;&amp;quot;]
text = restore(tokens)
print(&amp;quot;还原结果: &amp;quot;, text)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;还原结果:  [&#39;the&#39;, &#39;deep&#39;, &#39;learning&#39;]
&lt;/code&gt;&lt;/pre&gt;
">【NLP】BPE子词分割</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shi-pin-mu-biao-jian-ce/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_40557160/article/details/109536612&#34;&gt;视频目标检测VID论文及代码（更新至2020.12）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/94986199&#34;&gt;写给小白的YOLO介绍&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/breeze_blows/article/details/105323491&#34;&gt;视频目标检测(video object detection)简单综述&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_43702653/article/details/123973629?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167842568816782427467521%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;amp;request_id=167842568816782427467521&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123973629-null-null.142%5Ev73%5Einsert_down4,201%5Ev4%5Eadd_ask,239%5Ev2%5Einsert_chatgpt&amp;amp;utm_term=R-CNN&amp;amp;spm=1018.2226.3001.4187&#34;&gt;R-CNN史上最全讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_40716944/article/details/114822515&#34;&gt;YOLO系列详解：YOLOv1、YOLOv2、YOLOv3、YOLOv4、YOLOv5、YOLOv6、YOLOv7&lt;/a&gt;&lt;/p&gt;
">【CV】视频目标检测</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/nlp-wen-ben-xiang-si-du-fen-xi/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_28031525/article/details/79596376&#34;&gt;浅析文本相似度&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/164502624&#34;&gt;一文读懂Embedding的概念，以及它和深度学习的关系&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/114538417&#34;&gt;深入浅出Word2Vec原理解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;把句子都进行结巴分词&lt;br&gt;
分组输入word2vec，只处理前两个元素，第三个元素是标签&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;余弦相似度&lt;/strong&gt;&lt;br&gt;
计算两个向量的余弦值&lt;br&gt;
余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似&lt;br&gt;
反之，内积为0，则向量垂直，二者没有相似度&lt;/p&gt;
">【NLP】文本相似度分析</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/linux-nei-he-mo-kuai-kai-fa/"" data-c="
          &lt;p&gt;https://zhuanlan.zhihu.com/p/420194002&lt;/p&gt;
&lt;p&gt;Linux 内核模块开发，首先需要下载和Linux系统内核相匹配的内核文件。&lt;br&gt;
&lt;a href=&#34;https://mirror.bjtu.edu.cn/kernel/linux/kernel/&#34;&gt;国内Linux内核下载镜像&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Linux 内核文件编译（这步不需要，走弯路了）&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/378149586&#34;&gt;Linux内核编译很简单，6步编译一个自己的内核&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/hxxjxw/article/details/105899282&#34;&gt;编译安装linux内核&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个博客讲vim和gcc编译c文件&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/m0_47668487/article/details/115289154&#34;&gt;VMware下安装Ubuntu系统并编译运行C语言程序&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_36417014/article/details/98239337&#34;&gt;【linux环境下】【C语言编译】【使用makefile】【详细版】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在内核模块中使用printk()函数输出信息，而不是使用printf()等C语言标准库函数。&lt;/p&gt;
&lt;p&gt;编写内核模块makefile和普通的不一样，需要按照一下格式：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;make 时报的错&lt;/strong&gt;&lt;br&gt;
makefile里要用tab，不能用空格&lt;br&gt;
一个函数在没有参数的情况下没有赋参数void&lt;/p&gt;
&lt;p&gt;查看已经存在的mod：lsmod&lt;br&gt;
删除mod：rmmod modname&lt;br&gt;
将编译好的mod加载进去：sudo insmod hello.ko&lt;br&gt;
查看内核日志，最后为新模块产生的日志：dmesg&lt;br&gt;
看最近的内核日志：dmesg | tail&lt;br&gt;
实时监视内核日志的变化，并输出最新的日志信息：tail -f /var/log/kern.log&lt;br&gt;
删除make产生的所有文件：make clean&lt;/p&gt;
">【Linux】内核模块开发</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/linux-chang-yong-ming-ling-zong-jie/"" data-c="
          &lt;h1 id=&#34;文件操作&#34;&gt;文件操作&lt;/h1&gt;
&lt;p&gt;打开文件：vi 文件名&lt;br&gt;
复制粘贴：Ctrl+shift+C；Ctrl+shift+V（在shell中使用）&lt;br&gt;
创建文件：$ &amp;gt; test.txt&lt;br&gt;
通过文件名获取文件绝对路径：find ~ -name test.txt （其中，&lt;sub&gt;后必须有空格，且&lt;/sub&gt;表示全局查找；若 find . -name test.txt 则是在当前文件夹下查找。）&lt;br&gt;
进入文件路径：cd ~/filename&lt;br&gt;
&lt;a href=&#34;https://www.runoob.com/linux/linux-comm-mkdir.html&#34;&gt;创建文件夹：mkdir -p dirname&lt;/a&gt;&lt;br&gt;
查看当前目录所有文件：ls&lt;br&gt;
pwd：获取当前目录的绝对路径&lt;br&gt;
按文件名删除文件：rm -f 文件名&lt;/p&gt;
&lt;h1 id=&#34;系统&#34;&gt;系统&lt;/h1&gt;
&lt;p&gt;切换到root用户：sudo -s&lt;br&gt;
输出内核版本、主机名、操作系统版本、CPU类型等信息：uname -a&lt;br&gt;
查看已安装的linux-image各版本：dpkg --get-selections | grep linux-image&lt;br&gt;
卸载内核：sudo apt-get remove linux-image-5.4.0-xx-generic&lt;br&gt;
运行该代码将版本后面带有deinstall的彻底卸载干净：sudo dpkg -P linux-image-5.4.0-84-generic&lt;br&gt;
输入 Ctrl+c 终止当前运行&lt;/p&gt;
&lt;h1 id=&#34;内核模块开发&#34;&gt;内核模块开发&lt;/h1&gt;
&lt;p&gt;查看已经存在的mod：lsmod&lt;br&gt;
删除mod：rmmod modname&lt;br&gt;
将编译好的mod加载进去：sudo insmod hello.ko&lt;br&gt;
查看内核日志，最后为新模块产生的日志：dmesg&lt;br&gt;
看最近的内核日志：dmesg | tail&lt;br&gt;
实时监视内核日志的变化，并输出最新的日志信息：tail -f /var/log/kern.log&lt;/p&gt;
">【Linux】常用命令总结</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ccha-que-bu-lou/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/yourfriendyo/article/details/119544221&#34;&gt;C语言详解：结构体&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/m0_52902391/article/details/120614881&#34;&gt;模板类/模板函数 template 的用法(超详细)&lt;/a&gt;&lt;br&gt;
template：模板&lt;/p&gt;
&lt;p&gt;数据类型强制转换：&lt;br&gt;
(int)2.5 = 2  （向下取整）&lt;br&gt;
int m = (a+b)/2 ：此时m强行向下取整&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/ImwaterP/article/details/119140242&#34;&gt;C语言中数组长度的计算方法总结（sizeof与strlen）&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;循环&#34;&gt;循环&lt;/h1&gt;
&lt;p&gt;while (cin &amp;gt;&amp;gt; x){}&lt;br&gt;
cin函数，输入NULL时返回0，输入其他值返回它的地址&lt;/p&gt;
&lt;h1 id=&#34;字符串&#34;&gt;字符串&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.runoob.com/cplusplus/cpp-strings.html&#34;&gt;C++ 字符串&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://c.biancheng.net/view/2236.html&#34;&gt;C++ string详解，C++字符串详解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://c.biancheng.net/view/gbrxtwb.html#:~:text=C%2B%2B%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%8C%87%E9%92%88%EF%BC%88%E6%8C%87%E5%90%91%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8C%87%E9%92%88%EF%BC%89%20%E5%9C%A8%20C%2B%2B,%E7%A8%8B%E5%BA%8F%E4%B8%AD%EF%BC%8C%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8F%AF%E4%BB%A5%E5%AD%98%E5%82%A8%E5%9C%A8%E5%AD%97%E7%AC%A6%E6%95%B0%E7%BB%84%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E7%94%A8%E6%8C%87%E9%92%88%E8%AE%BF%E9%97%AE%E6%95%B0%E7%BB%84%EF%BC%8C%E8%87%AA%E7%84%B6%E4%B9%9F%E5%B0%B1%E5%8F%AF%E4%BB%A5%E7%94%A8%E6%8C%87%E9%92%88%E8%AE%BF%E9%97%AE%E5%AD%97%E7%AC%A6%E4%B8%B2%E3%80%82%20%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%8C%87%E9%92%88%E6%9C%AC%E8%B4%A8%E6%98%AF%E4%B8%80%E4%B8%AA%20char%20%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%8C%87%E9%92%88%EF%BC%8C%E7%84%B6%E5%90%8E%E5%B0%86%E5%AE%83%E6%8C%87%E5%90%91%E4%B8%80%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%BC%80%E5%A4%B4%EF%BC%8C%E5%8D%B3%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%AD%97%E7%AC%A6%E3%80%82&#34;&gt;C++字符串指针（指向字符串的指针）&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;数组&#34;&gt;数组&lt;/h1&gt;
&lt;p&gt;初始化数组的常用方法（常见的初始化为 0）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;int a[5]={0};&lt;/li&gt;
&lt;li&gt;memset(a, 0, sizeof a);&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上两种方法仅适用于将 a 中的值全部初始化为 0&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Supreme7/article/details/115431235&#34;&gt;memset()函数的用法详解&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;函数&#34;&gt;函数&lt;/h1&gt;
&lt;p&gt;若函数返回 void，但又想通过 return 来跳出函数，则直接写 return;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void function(){
    return;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;结构体&#34;&gt;结构体&lt;/h1&gt;
&lt;p&gt;typedef struct xxx {} yyy；yyy为结构体xxx的别名，是一种数据类型，需要实例化。&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/jacksls/article/details/108529761&#34;&gt;定义结构体 typedef struct 的用法总结&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在结构体别名中定义结构体指针&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct DNode{
	ElemType data;
	DNode* prior, * next;
}DNode, * DLinkList;  // * DLinkList 就是指向DNode类型的指针，声明时用DNode和DLinkList都可以
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;指针&#34;&gt;指针&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_39640298/article/details/84900326&#34;&gt;C++指针详解&lt;/a&gt;&lt;br&gt;
&amp;amp;：取地址&lt;br&gt;
*：取地址里面的值&lt;br&gt;
&lt;a href=&#34;https://www.w3cschool.cn/cpp/cpp-passing-arrays-to-functions.html&#34;&gt;向函数传递数组的写法&lt;/a&gt;&lt;br&gt;
用“-&amp;gt;”的情况：&lt;br&gt;
A是一个类 class / struct&lt;br&gt;
p是一个指向A类型的指针，那么用p访问A中的成员变量和函数时，使用p-&amp;gt;x，p-&amp;gt;f(x)来访问。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;向函数传入变量的指针和引用的区别&lt;/strong&gt;&lt;br&gt;
传入指针时，函数参数中是对指针的定义 int* a，传入函数的是变量的地址，&amp;amp;a；&lt;br&gt;
传入引用时，函数参数中是对原变量的引用 int &amp;amp;a，传入函数的是原变量，a。&lt;br&gt;
总之，传入指针是 通过指针，对指针指向的内存地址进行操作；传入变量的引用是直接对原变量进行修改。二者效果一样，但是原理不一样。&lt;br&gt;
只传入 int a 时， 传入的是 a 的拷贝，对 a 本身没有影响。&lt;br&gt;
&lt;code&gt;指针&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct SqList{
	int data[MaxSize];
	int length;
};

void InitList(SqList *list){
	cout&amp;lt;&amp;lt;&amp;quot;type in the length of list:&amp;quot;&amp;lt;&amp;lt;endl;
	cin&amp;gt;&amp;gt;list-&amp;gt;length;
	cout&amp;lt;&amp;lt;&amp;quot;type in the data:&amp;quot;&amp;lt;&amp;lt;endl; 
	for(int i = 0; i&amp;lt;list-&amp;gt;length; i++)
		cin&amp;gt;&amp;gt;list-&amp;gt;data[i];
}
int main(){
	SqList sqlist;
	InitList(&amp;amp;sqlist);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;引用&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct SqList{
	int data[MaxSize];
	int length;
};

void InitList(SqList &amp;amp;list){
	cout&amp;lt;&amp;lt;&amp;quot;type in the length of list:&amp;quot;&amp;lt;&amp;lt;endl;
	cin&amp;gt;&amp;gt;list.length;
	cout&amp;lt;&amp;lt;&amp;quot;type in the data:&amp;quot;&amp;lt;&amp;lt;endl; 
	for(int i = 0; i&amp;lt;list.length; i++)
		cin&amp;gt;&amp;gt;list.data[i];
}
int main(){
	SqList sqlist;
	InitList(sqlist);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面两段代码，如果用指针访问结构体，则需要用-&amp;gt;访问结构体成员；如果用原结构体，则用 . 由此可见，指针和引用的差别。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;向函数中传入指针类型的数据&lt;/strong&gt;&lt;br&gt;
和上面的不同，上面传入的是变量的地址，在函数列表中被定义，成为指针。而本问题描述的是直接将指针类型的数据传入函数。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include&amp;lt;bits/stdc++.h&amp;gt;

typedef struct DNode{
	ElemType data;
	DNode* prior, * next;
}DNode, * DLinkList;  //DLinkList为指向结构体的指针类型
 
//初始化双链表
bool InitDLinkList(DLinkList L) {  //此处和变量的指针一样，也可该写作 DNode* L
	L = (DLinkList)malloc(sizeof(DLinkList));
	if (L == NULL) {
		return false;          
	}
	L-&amp;gt;prior = NULL;
	L-&amp;gt;next = NULL;
	return true;
}

int main() {
	DLinkList L;  //定义指针类型数据L
	InitDLinkList(L);  //由于指针的值即为变量的地址，所以和&amp;amp;+变量名一样，都是将地址传入函数。
	return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;swap的例子&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;指针&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;# include&amp;lt;iostream&amp;gt;
using namespace std;

void MySwap(int* a, int* b){  //在列表中定义两个指针a，b，分别指向传入变量a，b的地址 
	int t = 0;  
	t = *a;  //交换值 
	*a = *b;
	*b = t;
	
	//错误的思路：用指针交换来交换 
	int *t = NULL;  //定义中间指针t，用于指针之间的赋值 
	t = a;
	a = b;
	b = t;
	//以上操作只是让函数内的指针ab分别指向了ba，但没有对对应地址内的值进行任何改变 
}

int main(){
	int a = 1,b = 2;
	MySwap(&amp;amp;a, &amp;amp;b);  //传入变量ab的地址 
	cout&amp;lt;&amp;lt;a&amp;lt;&amp;lt;&amp;quot; &amp;quot;&amp;lt;&amp;lt;b;
}
//向函数传入变量的地址。把函数声明和传入函数的形式整体来看，就是 int* a = &amp;amp;a; 
//也就是指针定义操作 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;引用&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;# include&amp;lt;iostream&amp;gt;
using namespace std;

void MySwap(int　&amp;amp;a, int　&amp;amp;b){  //在列表中定义两个地址引用
	int t = 0;  
	t = a; //直接修改原变量
	a = b;
	b = t;
}

int main(){
	int a = 1,b = 2;
	MySwap(a, b);  //直接传入原始变量ab
	cout&amp;lt;&amp;lt;a&amp;lt;&amp;lt;&amp;quot; &amp;quot;&amp;lt;&amp;lt;b;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;类和对象&#34;&gt;类和对象&lt;/h1&gt;
&lt;p&gt;类中不带返回类型的函数为构造函数。造函数可用于为某些成员变量设置初始值。&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_42565910/article/details/90346236&#34;&gt;c语言malloc函数的用法和意义&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;C++三种常见的实例化方法&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;静态实例化：在程序的全局或静态作用域中定义并初始化一个对象，该对象在程序整个生命周期内只存在一个实例。&lt;/li&gt;
&lt;li&gt;堆实例化：使用 new 运算符在动态存储区域中分配内存并实例化一个对象。这样创建的对象在程序运行期间一直存在，直到使用 delete 运算符显式释放其内存。&lt;/li&gt;
&lt;li&gt;栈实例化：在函数或代码块的作用域中定义并实例化一个对象，该对象的生命周期与所在的函数或代码块相同。对象在离开该作用域时自动销毁。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;静态实例化的例子&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;class MyClass {
public:
    MyClass() : m_x(0) {}
    void setX(int x) { m_x = x; }
    int getX() const { return m_x; }
private:
    int m_x;
};

MyClass globalObject;  // 全局实例

int main() {
    static MyClass staticObject;  // 静态实例
    globalObject.setX(5);
    staticObject.setX(10);
    int globalX = globalObject.getX(); // globalX = 5
    int staticX = staticObject.getX(); // staticX = 10
    // ...
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面的例子中，通过调用 setX 和 getX 来对全局对象 globalObject 和静态对象 staticObject 的成员变量进行访问。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;堆实例化的例子&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;class MyClass {
public:
    MyClass() : m_x(0) {}
    void setX(int x) { m_x = x; }
    int getX() const { return m_x; }
private:
    int m_x;
};

int main() {
    MyClass* heapObject = new MyClass;  // 堆实例
    heapObject-&amp;gt;setX(5);
    int heapX = heapObject-&amp;gt;getX(); // heapX = 5
    // ...
    delete heapObject;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面的例子中，通过调用 setX 和 getX 来对堆对象 heapObject 的成员变量进行访问。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;栈实例化的例子&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;class MyClass {
public:
    MyClass() : m_x(0) {}
    void setX(int x) { m_x = x; }
    int getX() const { return m_x; }
private:
    int m_x;
};

void someFunction() {
    MyClass stackObject;  // 栈实例
    stackObject.setX(5);
    int stackX = stackObject.getX(); // stackX = 5
    // ...
}

int main() {
    someFunction();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面的例子中，通过调用 setX 和 getX 来对栈对象 stackObject 的成员变量进行访问。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;函数模板&lt;/strong&gt;&lt;br&gt;
若想向函数传入不同类型的数据，则还需要另外定义不同的函数。为解决该问题，引入函数模板template。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;iostream&amp;gt;
using namespace std;

template&amp;lt;typename T&amp;gt;  //定义模板数据类型 T
T add(T&amp;amp; a, T&amp;amp; b){  //把T当作一种数据类型来用
	return a+b;
}

int main()
{
	float a = 10.3, b = 20.5;  //如果是int，则直接传入函数即可
	cout&amp;lt;&amp;lt;add(a, b);
	return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上例中，可以直接传入int/float等类型，而不用重新定义函数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;类模板&lt;/strong&gt;&lt;br&gt;
参考如下构建栈的写法，照着写就行，功能也是可以随便定义函数的数据类型&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;# include&amp;lt;iostream&amp;gt;
using namespace std;

const int StackSize = 1024;			//定义栈的最大长度
template&amp;lt;class T&amp;gt;
class SeqStack {					//定义顺序栈的模板类
	public:
		SeqStack() { top = -1; }	//构造函数，初始化空栈
		void Push(T x);				//入栈操作
		T Pop();					//出栈操作
		T GetTop();					//查找栈顶元素
		bool Empty();				//判别栈是否为空
	private:
		T data[StackSize];			//定义数组
		int top;					//栈顶指针
};


template&amp;lt;class T&amp;gt;
void SeqStack&amp;lt;T&amp;gt;::Push(T x) {
	if (top &amp;gt;= StackSize - 1) throw &amp;quot;上溢&amp;quot;;
	data[++top] = x;
}

template&amp;lt;class T&amp;gt;
T SeqStack&amp;lt;T&amp;gt;::Pop() {
	if (Empty()) throw &amp;quot;下溢&amp;quot;;
	return data[top--];
}

template&amp;lt;class T&amp;gt;
T SeqStack&amp;lt;T&amp;gt;::GetTop() {
	if (Empty()) throw &amp;quot;下溢&amp;quot;;
	return data[top];
}

template&amp;lt;class T&amp;gt;
bool SeqStack&amp;lt;T&amp;gt;::Empty() {
	if(top == -1) return true;
	else return false;
}

int main() {
	SeqStack&amp;lt;int&amp;gt; stack;  //声明的时候要加上数据类型
	stack.Push(1);
	stack.Push(2);
	stack.Push(3);
	cout &amp;lt;&amp;lt; stack.GetTop();
	cout&amp;lt;&amp;lt;endl;
	
	cout &amp;lt;&amp;lt; stack.Pop();
}
&lt;/code&gt;&lt;/pre&gt;
">C++查缺补漏</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shu-ju-jie-gou/"" data-c="
          &lt;h1 id=&#34;think-like-a-computer&#34;&gt;Think like A Computer&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.qq.com/mind/DRU9BS3ZzTU13T0pH&#34;&gt;数据结构强化课资料索引 （王道团队官方发布）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_47312141/article/details/108909724&#34;&gt;2021 王道考研 数据结构+习题讲解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_40679299/article/details/107721116&#34;&gt;王道考研数据结构代码总结&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Tm4y1x7pm?p=1&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;24考研计算机王道408数据结构考点精讲含课件（完整版）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411t7yn/?p=1&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;北京邮电大学人工智能学院北邮809数据结构考研真题答案详解网学天地考研&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;🔺做题 tips：&lt;br&gt;
代码题：&lt;br&gt;
写完代码一定读一遍，看看有无语法错误等&lt;br&gt;
复习代码题时，要熟知代码逻辑，以及临界点 / 判断条件，一定要记住条件是什么，灵活应对&lt;br&gt;
做代码题时，先自己写一个例子放在旁边，手动实现一遍，然后结合储存的数据结构，对照着还原代码&lt;/p&gt;
&lt;h1 id=&#34;基本代码题汇总&#34;&gt;基本代码题汇总&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;线性表&lt;/strong&gt;&lt;br&gt;
KMP&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;树&lt;/strong&gt;&lt;br&gt;
二叉树创建递归非递归&lt;br&gt;
二叉树前序中序后序，递归非递归&lt;br&gt;
二叉树层序&lt;br&gt;
二叉树结点总数、深度、叶子结点总数&lt;br&gt;
（哈夫曼树构造、编解码）&lt;br&gt;
算数表达式二叉树&lt;br&gt;
二叉树的复制&lt;br&gt;
二叉树路径显示&lt;br&gt;
交换二叉树所有结点的左右子树&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图&lt;/strong&gt;&lt;br&gt;
DFS、BFS&lt;br&gt;
Prim、克鲁斯卡尔&lt;br&gt;
dijkstra、Floyd&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查找&lt;/strong&gt;&lt;br&gt;
二叉排序树插入、构建、删除&lt;/p&gt;
&lt;p&gt;排序所有&lt;/p&gt;
&lt;h1 id=&#34;肖波-ppt&#34;&gt;肖波 PPT&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;ch1&lt;/strong&gt;&lt;br&gt;
p18 带哨兵的顺序查找，从后往前遍历，遍历到第一个哨兵跳出循环&lt;/p&gt;
&lt;h1 id=&#34;绪论&#34;&gt;绪论&lt;/h1&gt;
&lt;p&gt;数据结构：按照某种逻辑关系组织在一起的数据，按一定储存方式储存在计算机存储器中，并在这些数据上定义了一组运算的集合&lt;br&gt;
数据结构包括：&lt;br&gt;
逻辑结构（集合、线性结构、树结构、图结构）&lt;br&gt;
物理结构、存储结构（顺序存储、链式存储）&lt;br&gt;
对数的操作和运算&lt;/p&gt;
&lt;p&gt;算法：解题方法。从计算机角度看：若干条指令组成的有穷序列&lt;br&gt;
算法特性：&lt;br&gt;
输入、输出、有穷性、可行性、确定性&lt;/p&gt;
&lt;p&gt;好的算法还应具备：&lt;br&gt;
健壮性/鲁棒性、高效性、可读性&lt;/p&gt;
&lt;p&gt;注意，写代码一定要考虑健壮性，考虑到不成立的情况&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;时间复杂度计算&lt;/strong&gt;&lt;br&gt;
本质思想：代码执行趟数之和&lt;br&gt;
计算思路：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;看被迭代的语句的表达式，等差/等比/递增&lt;/li&gt;
&lt;li&gt;用 k 代表一次迭代，用 k 列出等差等比求和表达式/第 k 次变量的值&lt;/li&gt;
&lt;li&gt;k 等于边界条件，比如 n/二分之n 等&lt;/li&gt;
&lt;li&gt;解出用 n 表示 k 的表达式，即为复杂度&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于多层循环，列出每一次外层循环，内层循环的执行次数，直至第 k 次，然后进行计算&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_63866037/article/details/128087397&#34;&gt;详解时间复杂度计算公式(附例题细致讲解过程)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_43300894/article/details/105951576&#34;&gt;空间复杂度的四种计算情况，超级简单好懂&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;真题分析：&lt;/code&gt;&lt;br&gt;
书上画的，课后题填空背会即可&lt;br&gt;
基本复杂度计算，没有偏难怪&lt;/p&gt;
&lt;h1 id=&#34;线性表&#34;&gt;线性表&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;顺序表&lt;/strong&gt;&lt;br&gt;
表长为 n 的顺序表&lt;strong&gt;插入&lt;/strong&gt;时移动元素的个数（可操作范围：1~n+1） p27&lt;br&gt;
在最后一个位置（n+1）：0&lt;br&gt;
在第一个位置（1）：n&lt;br&gt;
在中间第 i 个位置：n-i+1&lt;/p&gt;
&lt;p&gt;平均移动的元素个数：n/2&lt;/p&gt;
&lt;p&gt;表长为 n 的顺序表&lt;strong&gt;删除&lt;/strong&gt;时移动元素的个数（可操作范围：1~n）&lt;br&gt;
最后一个位置（n）：0&lt;br&gt;
第一个位置（1）：n-1&lt;br&gt;
中间第 i 个位置：n-i&lt;/p&gt;
&lt;p&gt;平均移动的元素个数：(n-1)/2&lt;/p&gt;
&lt;p&gt;平均删除、插入长度记忆：可操作范围删除比插入少1，所以分母-1&lt;/p&gt;
&lt;p&gt;查找&lt;br&gt;
从 1 开始到 n，对查找次数求和，共 (n×(1+n))/2&lt;br&gt;
除以总共 n 个元素，得到平均查找长度 (1+n)/2&lt;/p&gt;
&lt;p&gt;分析平均移动次数/平均查找长度时，先求对第 i 个元素操作时的执行次数（可以带几个值验证），然后看操作的范围，是 1~n 还是 1~n+1。然后进行求和，再除以元素个数，得到平均值&lt;/p&gt;
&lt;p&gt;&lt;code&gt;真题分析：&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;插入删除的复杂度分析过程，平均移动次数、概率&lt;/li&gt;
&lt;li&gt;插入删除的逻辑，代码&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;线性表 p17 第三题&lt;br&gt;
第五题和第三题思路一样，就是限定不同。&lt;br&gt;
第四题注意是有序的顺序表&lt;br&gt;
第六题，学会双指针如何移动，在同一个列表上操作。&lt;br&gt;
第七题，在函数外部定义新表，一起传入函数。综合6、7题，学会使用 data[i++] 这种表述控制指针是否在本次循环移动。&lt;br&gt;
第九题：顺序表最快查找算法为二分查找（折半查找）&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_45978890/article/details/116094046&#34;&gt;【二分查找】详细图解&lt;/a&gt;&lt;br&gt;
第十一题，每次循环次数减少的算法复杂度为 O(log2n)，比 O(n) 强，优先考虑。&lt;br&gt;
十二题，学会计数器的使用。有时候计数器并不实际代表某个数值，单纯为了计数用。&lt;/p&gt;
&lt;p&gt;线性表常考操作：&lt;br&gt;
顺序逆转&lt;br&gt;
前后调换&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;链表&lt;/strong&gt;&lt;br&gt;
头插法：注意从列表的尾部遍历到头部，保持有序性&lt;br&gt;
尾插法：比头插法多一个尾指针 rear，一直指向链表尾部&lt;br&gt;
方便插入和删除数据，使用双链表&lt;br&gt;
删除一个单链表中的结点至少需要两个指针&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Bob______/article/details/110581129&#34;&gt;C++实现单链表&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;p51 综合应用题&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;递归步骤：找出重复的步骤，将其归纳到一个函数操作中；找到第一种情况，单独列出来；描述后续步骤，用上面的函数代替期中的几步；注意判断不同情况时，函数输入的不同值。&lt;/li&gt;
&lt;li&gt;解释了递归的本质，递归和栈的关系，先入后出，逆序输出&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV13t411Z7N1/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;数据结构与算法基础--第05周11--3.4栈和递归&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;调用原函数可看做函数进栈；当满足跳出递归条件时，开始输出结果，从最后进栈的函数开始向下执行；输出结果的过程为出栈。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;第四题，用指针代替了传统的寻找最小值的方式，只不过删除一个结点需要两个指针。两个指针共同控制过一个最小值。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;链表常考操作：&lt;br&gt;
用指针找到最大最小值；删除结点；去重；链表归并&lt;/p&gt;
&lt;p&gt;&lt;code&gt;顺序表和链表比较&lt;/code&gt;&lt;br&gt;
表长可以预估、查询（搜索）操作较多 ——使用顺序表&lt;br&gt;
表长难以预估，经常需要增加/删除元素 ——使用链表&lt;br&gt;
插入删除主要发生在表头表尾——使用循环链表&lt;/p&gt;
&lt;p&gt;线性表顺序存储：随机存取；链式存储：顺序存取&lt;/p&gt;
&lt;p&gt;存储密度：结点中数据所占空间 / 结点结构所占储存空间&lt;/p&gt;
&lt;h1 id=&#34;栈和队列&#34;&gt;栈和队列&lt;/h1&gt;
&lt;p&gt;栈的主观感受：后进先出，LIFO；用于暂存一些数据，等待某一符合条件的时刻弹出；&lt;/p&gt;
&lt;p&gt;栈一般都是处理栈顶 / 出栈的元素&lt;/p&gt;
&lt;h1 id=&#34;串&#34;&gt;串&lt;/h1&gt;
&lt;p&gt;KMP算法&lt;br&gt;
子串匹配算法&lt;/p&gt;
&lt;p&gt;next数组：&lt;br&gt;
长度和串的长度一样，从0到n，next[0] 不存数据；每一个位置 i 代表，当第 i 位未匹配成功时，子串指针 j 要重新指向串的位置。&lt;/p&gt;
&lt;p&gt;手动求 next数组：next[1] = 0，next[2] = 1 无脑写&lt;/p&gt;
&lt;p&gt;nextval数组：&lt;br&gt;
nextval[1]无脑写0&lt;/p&gt;
&lt;h1 id=&#34;树&#34;&gt;树&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_40646509/article/details/102828109&#34;&gt;数据结构-满k叉树例题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_43152052/article/details/90111095&#34;&gt;二叉树的前序遍历、中序遍历、后序遍历、层序遍历的时间复杂度和空间复杂度&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;手动求线索二叉树的方法：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;写出遍历序列&lt;/li&gt;
&lt;li&gt;找到不满的结点（带有空指针的）&lt;/li&gt;
&lt;li&gt;在序列中找到其前后结点，分别连接&lt;/li&gt;
&lt;li&gt;如果结点在序列头/尾，且有一侧为空，则指向 NULL&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;树的存储&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;树和二叉树的相互转化：&lt;/strong&gt;&lt;br&gt;
二叉树转化为树：&lt;br&gt;
“左孩子右兄弟”&lt;br&gt;
在结点左侧的为孩子结点，右侧的为兄弟结点，依次展开即可&lt;/p&gt;
&lt;p&gt;树转化为二叉树：&lt;br&gt;
本质是用二叉链表存储树。从根节点出发，把结点的孩子写在左孩子，结点的兄弟写在右孩子&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二叉树和森林的相互转化：&lt;/strong&gt;&lt;br&gt;
森林转化为二叉树：&lt;br&gt;
把每棵树先转化为二叉树，然后用右孩子连接每棵树的根节点&lt;/p&gt;
&lt;p&gt;二叉树转化为森林：&lt;br&gt;
从根节点出发，把所有右孩子拿下来，作为拆分出来的树的根节点；按照二叉树转化为树的方法分别转化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;树和森林的遍历&lt;/strong&gt;&lt;br&gt;
树的先根遍历 &amp;lt;=&amp;gt; 对二叉树的先序遍历&lt;br&gt;
树的后根遍历 &amp;lt;=&amp;gt; 对二叉树的中序遍历&lt;/p&gt;
&lt;p&gt;森林的先序遍历 &amp;lt;=&amp;gt; 对二叉树的先序遍历 &amp;lt;=&amp;gt; 依次对各个树先根遍历&lt;br&gt;
森林的中序遍历 &amp;lt;=&amp;gt; 对二叉树的中序遍历 &amp;lt;=&amp;gt; 依次对各个树后根遍历&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;哈夫曼树&lt;/strong&gt;&lt;br&gt;
哈夫曼树不唯一&lt;br&gt;
哈夫曼树是二叉树，但不是完全二叉树和满二叉树&lt;br&gt;
哈夫曼树的叶子结点是数据结点，非叶子结点都是权值结点&lt;br&gt;
哈夫曼树的总结点数是2n-1（n是叶子节点数）&lt;br&gt;
哈夫曼树只有度为0和2的结点，没有度为1的结点&lt;/p&gt;
&lt;h1 id=&#34;图&#34;&gt;图&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_41831593/article/details/119764750&#34;&gt;《数据结构》-第六章 图(习题)&lt;/a&gt;&lt;br&gt;
无向图边集为圆括号：{(v1,v2),(v3,v4)}&lt;br&gt;
有向图边集为尖括号：{&amp;lt;v1,v2&amp;gt;,&amp;lt;v3,v4&amp;gt;}&lt;/p&gt;
&lt;p&gt;一个无向图有 n 个顶点和 n-1 个边，可以使它连通，即生成树（生成树一定有且仅有 n-1 条边）；&lt;br&gt;
若再加一条边即 n 条边，则必形成环（回路）&lt;/p&gt;
&lt;p&gt;强连通图是有向图，指有向图中任意一对顶点都存在路径&lt;br&gt;
n 个顶点的强连通图，至少有 n 条弧（有向边），即连通之后还得形成环&lt;/p&gt;
&lt;p&gt;n 个顶点的完全无向图，有 n(n-1)/2 条边 ①&lt;br&gt;
n 个顶点的完全有向图，有 n(n-1) 条弧 ②&lt;/p&gt;
&lt;p&gt;①：对于一个顶点，和其它 n-1 个顶点分别有一条边，n 个顶点，则为 n(n-1) 条，又因为每个点的边互相重复，所以除以二；&lt;br&gt;
②：有向图允许两个顶点有两条边，所以为 二倍的 ①&lt;/p&gt;
&lt;p&gt;度 = 入度 + 出度&lt;/p&gt;
&lt;p&gt;无向图全部顶点度的和等于边数的二倍&lt;/p&gt;
&lt;p&gt;连通分量是极大连通子图，包含所有点和边&lt;br&gt;
生成树是极小连通子图，包含所有点和相连的 n-1 条边&lt;/p&gt;
&lt;p&gt;回路起始点和终止点一样，路径所有点都不一样；&lt;br&gt;
简单路径：所有点都不重复；简单回路：除了起始点和终止点其余点都不重复&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;邻接矩阵&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/daocaoren_/article/details/98616668&#34;&gt;数据结构之图(二)——邻接矩阵&lt;/a&gt;&lt;br&gt;
无向图&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;无向图的邻接矩阵是对称的（边数 = 1 的个数 / 2），且主对角线元素全为0（无回路）&lt;/li&gt;
&lt;li&gt;顶点 i 的度 = 第 i 行（列）中 1 的个数。&lt;/li&gt;
&lt;li&gt;完全图的邻接矩阵中，主对角元素为 0，其余全为 1&lt;/li&gt;
&lt;li&gt;带权有向图中 0 和 ∞ 表示的都不是有向边&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有向图&lt;br&gt;
边数 = 1 的个数&lt;br&gt;
第i行的含义：以结点 vi 为尾的弧(出度边)；&lt;br&gt;
第i列的含义：以结点 vi 为头的弧(入度边)；&lt;br&gt;
顶点的出度=第i行元素之和；&lt;br&gt;
顶点的入度=第i列元素之和；&lt;br&gt;
顶点的度=第i行元素之和+第i列元素之和。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;邻接表&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/daocaoren_/article/details/98632474&#34;&gt;数据结构之图(三)——邻接表&lt;/a&gt;&lt;br&gt;
无向图&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;边数 = 边结点的个数 / 2&lt;/li&gt;
&lt;li&gt;邻接表不唯一&lt;/li&gt;
&lt;li&gt;若无向图中有 n 个顶点、e 条边，则其邻接表需要 n 个头结点和 2e 个表结点。适宜存储稀疏图&lt;/li&gt;
&lt;li&gt;无向图中顶点 vi 的度等于第 i 个单链表中的结点数&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​有向图&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;边数 = 边结点的个数&lt;/li&gt;
&lt;li&gt;顶点 vi 的出度为第 i 个单链表中的结点个数&lt;/li&gt;
&lt;li&gt;顶点 vi 的入度为整个单链表中邻接点域值是 i-1 的结点个数&lt;/li&gt;
&lt;li&gt;找出度易，找入度难&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;邻接矩阵多用于稠密图；而邻接表多用于稀疏图&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1hV411t7SC/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;数据结构|十字链表|简单粗暴零失误画出十字链表&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先画出邻接表（邻接表表示尾指向头）&lt;/li&gt;
&lt;li&gt;再分割出弧结点的指针域&lt;/li&gt;
&lt;li&gt;最后自己指向自己&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Ae41137Jd/?vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;邻接多重表进阶版画法 三步秒杀 数据结构&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DFS&lt;/strong&gt;&lt;br&gt;
结合北邮书 180 页，c 代码学习&lt;br&gt;
🔺基本思想：沿着一个节点一直走到不能走为止，再出栈找到可以继续走的地方，重复上述&lt;br&gt;
🔺掌握：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在图上直观描述&lt;/li&gt;
&lt;li&gt;使用栈描述的递归方式&lt;/li&gt;
&lt;li&gt;使用邻接表的代码实现（顶点节点、弧结点、边和弧的构成、实现逻辑）&lt;/li&gt;
&lt;li&gt;使用邻接矩阵的代码实现&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;🔺注意：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;进栈即输出节点值，输出节点值即进栈；即第一层递归时就输出结点值&lt;/li&gt;
&lt;li&gt;使用邻接表表示图时，用一个邻接数组 adjlist 代表图&lt;/li&gt;
&lt;li&gt;只有在输出的时候用到结点名称，其余时间都用从 0 开始的下标表示结点，便于输入数组&lt;/li&gt;
&lt;li&gt;无论是顶点节点还是弧结点，都只有指向弧结点的指针&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;🔺代码实现的 tips：&lt;br&gt;
· 邻接表&lt;br&gt;
先深刻理解邻接表的结构：&lt;a href=&#34;https://blog.csdn.net/daocaoren_/article/details/98632474&#34;&gt;数据结构之图(三)——邻接表&lt;/a&gt;&lt;br&gt;
点节点的 data 域（北邮代码中叫 vertex）保存节点的名称信息，firstarc / firstedge 指向弧节点类型的数据，指向该节点的第一条弧结点；弧结点保存邻接点的序号，还有指向下一个弧结点的指针&lt;/p&gt;
&lt;p&gt;· 邻接矩阵&lt;br&gt;
从第 i 个节点开始遍历，打印编号对应的节点值，并记录已访问，找到邻接矩阵第 i 行，邻接矩阵的第 i 行表示和第 i 个节点相邻的元素。&lt;br&gt;
遍历到第一个 1 为止，若未访问，则打印节点，递归遍历对应序号的行，直到行结束&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BFS&lt;/strong&gt;&lt;br&gt;
🔺基本思想：访问一个节点的所有未被访问的相邻节点，然后再从相邻节点中拿出一个重复上述&lt;br&gt;
🔺掌握：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在图上直观描述&lt;/li&gt;
&lt;li&gt;使用队列描述&lt;/li&gt;
&lt;li&gt;使用邻接表的代码实现（顶点节点、弧结点、边和弧的构成、实现逻辑）&lt;/li&gt;
&lt;li&gt;使用邻接矩阵的代码实现&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;🔺注意：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一个顶点先处理，单独入队&lt;/li&gt;
&lt;li&gt;入队即输出顶点值&lt;/li&gt;
&lt;li&gt;出队后对该顶点进行操作&lt;/li&gt;
&lt;li&gt;队列空则遍历结束&lt;/li&gt;
&lt;li&gt;queue[++r] / queue[++f] 先自增一位再输入/输出，下标从 1 开始&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;最小生成树&lt;/strong&gt;&lt;br&gt;
🔺生成树的性质&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对于包含 n 个顶点的无向完全图最多包含 n^(n-2) 颗生成树。&lt;/li&gt;
&lt;li&gt;一个 n 个顶点的连通图的所有生成树都包含 n 个顶点和 n-1 条边&lt;/li&gt;
&lt;li&gt;移除生成树中的任意一条边都会导致图的不连通， 生成树的边最少特性&lt;/li&gt;
&lt;li&gt;生成树中不存在环；在生成树中添加一条边会构成环&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;边的权值之和最小的生成树——最小生成树&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Eb41177d1/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;最小生成树(Kruskal(克鲁斯卡尔)和Prim(普里姆))算法动画演示&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prim(普里姆)&lt;/strong&gt;&lt;br&gt;
北邮书 186 页，以邻接矩阵为例&lt;br&gt;
集合 U：已落在生成树上的点，用数组 adjvex[MAXSIZE] 表示&lt;br&gt;
集合 V-U：未落在树上的点，不用表示&lt;br&gt;
lowcost[] 数组：保存 U 到 V-U 最小权值的边&lt;/p&gt;
&lt;p&gt;🔺注意&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;分析此算法时需要将 图（看邻接点）数组 结合着一起看&lt;/li&gt;
&lt;li&gt;lowcost[i]=0 表示该顶点已经选择（和自己的距离为 0）；lowcost[j]=-1 表示从 i 到 j 没有直接连接的边&lt;/li&gt;
&lt;li&gt;adjvex 的本质保存的是生成树中边的信息。理解：结合北邮书 188 页，adjvex 数组的序号和元素值分别代表两个顶点，一个数组位代表两个顶点间的一条边&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;🔺步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;写出三行的列表，第一行是顶点名称，第二行是 adjvex，第三行是 lowcost&lt;/li&gt;
&lt;li&gt;初始化数组， adjvex 行全填 0，lowcost 行全填 -1&lt;/li&gt;
&lt;li&gt;第一次初始化，选定一个节点 i，更新该节点的 lowcost[i]=0，更新该点到其邻接点的 lowcost，非邻接点不用管，还是 -1&lt;/li&gt;
&lt;li&gt;找到 lowcost 中的最小值，将该位置 lowcost 改为 0，代表已被选&lt;/li&gt;
&lt;li&gt;同时将与该点邻接的点的 adjvex 数组值都改为当前节点下标，代表和该点相连的边，并更新其 lowcost 中的权值&lt;/li&gt;
&lt;li&gt;重复步骤 4，若其邻接点满足：（1. 未被选择 2. 到当前节点的权值比已有权值小）则执行步骤 5&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Kruskal(克鲁斯卡尔)&lt;/strong&gt;&lt;br&gt;
很全：&lt;a href=&#34;http://data.biancheng.net/view/41.html&#34;&gt;克鲁斯卡尔算法(Kruskal算法)求最小生成树&lt;/a&gt;&lt;br&gt;
使用边集数组存储边&lt;br&gt;
边集数组的结构：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct VEdge{
    int fromV;  // 起始顶点
    int endV;  // 终止顶点
    int weight;  // 边的权值
}
VEdge EdgeList[MAX_EDGE];
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;🔺步骤&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;准备一个辅助数组，下标代表不同点，用于判断是否产生回路。原理是记录是否在同一集合（有相同标记），初始化为不同标记&lt;/li&gt;
&lt;li&gt;准备一个新的空边集数组储存结果&lt;/li&gt;
&lt;li&gt;对边按权值进行排序（起泡排序等）得到一个排好序的 EdgeList&lt;/li&gt;
&lt;li&gt;遍历 EdgeList，判断其两个顶点标记是否相同。若相同，则会产生回路，不选择此边；若不同，则选择此边，并将顶点标记改成相同的&lt;/li&gt;
&lt;li&gt;当新边集数组中有 n-1 条边时，结束遍历&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;最短路径算法&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;Dijkstra 算法&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1jE411W7tT/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【全网第二清晰】手写迪杰斯特拉-Dijkstra（考试用）&lt;/a&gt;&lt;br&gt;
注意，迪杰斯特拉算法是找一个点到所有其他顶点的最短路径算法，是点和点之间，两点之间的算法&lt;/p&gt;
&lt;p&gt;🔺感性把握：&lt;br&gt;
从起始点开始，每一次寻找离前一个点权值最小的点，连接两点，并在后一个点上标记当前累加的权值。寻找后一个点时，把已经选择的点看作一个集合，找整体到后一个点的权值最小的路径。一次选择是一次执行过程&lt;/p&gt;
&lt;p&gt;🔺准备以下数组：&lt;br&gt;
dist[i]：源点到顶点 i 的距离（单次来看，指前一个点到该点的距离，是累加得到的结果）&lt;br&gt;
path[i]：源点到顶点 i 的路径（单次来看，指前一个点到该点的路径，也就是该点的前一个结点）&lt;br&gt;
s[i]：记录是否找到源点到顶点 i 的最短路径&lt;/p&gt;
&lt;p&gt;最后得到的 dist 数组包含源点到所有点的最短路径&lt;br&gt;
path 数组：设起始点为 u，要找的点为 v，找到 v 对应的 path 值 a，再找到 a 对应的 path 值 b，以此类推，最终找到 u，则 u 到 v 的路径为 u→....b→a→v&lt;/p&gt;
&lt;p&gt;🔺步骤&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;检查距离起点的邻接点，写入 dist 和 path&lt;/li&gt;
&lt;li&gt;选择 dist 最小的点 v，在 s 中标记已选择&lt;/li&gt;
&lt;li&gt;检查 v 的邻接点的权值，若比 dist 中的值小，则写入 dist 和 path（累加）&lt;/li&gt;
&lt;li&gt;重复 2、3，直到全选完&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;代码思路和直观思路有些不一样&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Floyd 算法&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV14R4y1x7GB/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;求最短路径Floyd算法！&lt;/a&gt;&lt;br&gt;
求图中任意两个顶点之间的最短路径，最后得到的 dist 矩阵，第 i 行 j 列表示 从 i 到 j 的最短距离&lt;/p&gt;
&lt;p&gt;辅助数组&lt;br&gt;
dist&lt;br&gt;
path&lt;/p&gt;
&lt;h1 id=&#34;查找&#34;&gt;查找&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;折半查找&lt;/strong&gt;&lt;br&gt;
终止条件：找到匹配元素 或 low&amp;gt;high&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二分查找&lt;/strong&gt;&lt;br&gt;
求具体 ASL 时，需要画出查找树来看，第一层查找一次，第二层查找两次，第 n 层查找 n 次；求和除以待查元素个数。（注意查找树最后一层优先有右子树）&lt;br&gt;
画查找树时，优先选择靠近左侧的结点（因为计算机自动向下取整）&lt;/p&gt;
&lt;p&gt;平均成功 ASL：⌊log2n⌋ + 1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;平衡二叉树&lt;/strong&gt;&lt;br&gt;
高度（深度）为 k 的平衡二叉树的结点数：习题解答 P100&lt;br&gt;
平衡因子 =左子树深度-右子树深度&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;散列表&lt;/strong&gt;&lt;br&gt;
键值(key)的解释：&lt;a href=&#34;https://blog.csdn.net/LIsaWinLee/article/details/123279068&#34;&gt;哈希表的知识讲解&lt;/a&gt;&lt;br&gt;
哈希函数根据键值计算出一个存储地址，从而将键值对应的数据存储在地址中&lt;br&gt;
哈希表中的冲突指的是，不同键值的元素对应于相同的存储地址&lt;/p&gt;
&lt;p&gt;线性探测法：没特殊规定的情况下，对谁取余，表长就是谁；对自己取余等于 0&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1qJ411k7wc/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;平方探测法&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;#排序&lt;br&gt;
&lt;a href=&#34;https://www.cs.usfca.edu/~galles/visualization/Algorithms.html&#34;&gt;算法可视化平台&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;今年题目预测&#34;&gt;今年题目预测&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;选择&lt;/strong&gt;&lt;br&gt;
多维数组，三维数组的存储&lt;br&gt;
朴素模式匹配、KMP&lt;br&gt;
图的概念&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简答&lt;/strong&gt;&lt;br&gt;
线性表语句分析&lt;/p&gt;
&lt;p&gt;稀疏矩阵，三元组表，十字链表&lt;/p&gt;
&lt;p&gt;二叉树遍历、转化森林&lt;br&gt;
手算哈夫曼&lt;br&gt;
构造平衡二叉树&lt;br&gt;
B-树的插入删除&lt;/p&gt;
&lt;p&gt;图十字链表、临界多重表的构造&lt;br&gt;
图着色、关键路径、拓扑排序&lt;br&gt;
手算 BFS\DFS，手算最小生成树，手算dijkstra&lt;/p&gt;
&lt;p&gt;哈希（链地址法）&lt;/p&gt;
&lt;p&gt;一趟排序&lt;br&gt;
手算大根堆&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;程序&lt;/strong&gt;&lt;br&gt;
（KMP）&lt;/p&gt;
&lt;p&gt;二叉树创建递归非递归&lt;br&gt;
二叉树前序（中序）后序，递归非递归&lt;br&gt;
二叉树层序&lt;br&gt;
二叉树结点总数、深度、叶子结点总数&lt;br&gt;
（哈夫曼树构造、编解码）&lt;br&gt;
（算数表达式二叉树）&lt;br&gt;
二叉树的复制&lt;br&gt;
（二叉树路径显示）&lt;br&gt;
交换二叉树所有结点的左右子树&lt;/p&gt;
&lt;p&gt;邻接表（矩阵）DFS&lt;br&gt;
图的最小生成树算法 Prim、克鲁斯卡尔&lt;br&gt;
最短路径 Floyd&lt;/p&gt;
&lt;p&gt;二叉排序树插入、构建、删除&lt;/p&gt;
&lt;p&gt;排序，除堆排序、计数排序、直接插入&lt;/p&gt;
">数据结构</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/dl-shen-du-sheng-cheng-mo-xing/"" data-c="
          &lt;h1 id=&#34;受限玻尔兹曼机rbm&#34;&gt;受限玻尔兹曼机（RBM）&lt;/h1&gt;
&lt;p&gt;DBN（深度置信网络，Deep Belief Networks）和RBM（受限玻尔兹曼机，Restricted Boltzmann Machines）是两种在深度学习早期非常重要的模型，尤其在深度学习兴起之前，它们在无监督特征学习和深度结构理解方面起到了关键作用。下面分别介绍这两种模型：&lt;/p&gt;
&lt;p&gt;RBM是一种能量基模型，用于&lt;code&gt;无监督学习&lt;/code&gt;。它由一个可见层和一个隐藏层组成，层内没有连接，层间的连接是全连接的，但没有方向，即层间的连接是双向的。RBM的目标是学习输入数据的概率分布。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可见层&lt;/strong&gt;：对应于输入数据的每个特征。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐藏层&lt;/strong&gt;：捕获可见层单元之间复杂的交互。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RBM通过对比散度（Contrastive Divergence, CD）算法进行训练，该算法通过一系列的概率采样步骤来近似梯度下降，以最小化模型的重构误差。RBM可以被用来进行特征提取、降维、分类、协同过滤等任务。&lt;/p&gt;
&lt;h1 id=&#34;深度置信网络dbn&#34;&gt;深度置信网络（DBN）&lt;/h1&gt;
&lt;p&gt;DBN是一种由多个RBM层堆叠而成的深度网络结构。在DBN中，每一个RBM层的隐藏层都作为下一个RBM层的可见层。这种堆叠可以帮助网络学习数据在不同层次上的特征表示。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;预训练&lt;/strong&gt;：DBN的训练通常包含两个阶段。第一个阶段是无监督的预训练，每个RBM层依次进行训练，每一层都在学习其输入的特征表示。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微调&lt;/strong&gt;：在预训练完成后，DBN会进行有监督的微调，通常使用反向传播算法来调整所有层的权重，以提高特定任务（如分类）的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DBN在深度学习的早期阶段解决了训练深度神经网络的难题，尤其是在无监督学习和特征学习方面显示出强大的能力。然而，随着ReLU激活函数、Dropout技术和更强大的计算资源的出现，以及更高效的训练算法（如Adam优化器）的开发，更直接和简单的深度网络结构（如深度卷积神经网络）逐渐取代了DBN在许多应用领域中的地位。&lt;/p&gt;
&lt;h1 id=&#34;pixelcnn和pixelrnn&#34;&gt;PixelCNN和PixelRNN&lt;/h1&gt;
&lt;p&gt;PixelCNN和PixelRNN是两种深度学习模型，专门用于生成图像像素序列。它们属于自回归模型的范畴，意味着每个像素的值是基于之前像素值的函数。这两种模型在图像生成领域表现出色，能够产生高质量的、细节丰富的图像。&lt;/p&gt;
&lt;h3 id=&#34;pixelrnn&#34;&gt;PixelRNN&lt;/h3&gt;
&lt;p&gt;PixelRNN由一系列循环神经网络（RNN）层组成，用于对图像像素进行顺序建模。它通过考虑像素之间的空间关系来生成图像，每个像素的值都依赖于先前生成的像素。PixelRNN通过使用RNN的长期依赖性，能够有效地捕获图像中的复杂结构和纹理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;顺序建模&lt;/strong&gt;：PixelRNN将图像生成视为像素序列生成过程，逐行或按某种顺序处理像素，每个像素的生成都依赖于之前的像素。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSTM/GRU单元&lt;/strong&gt;：PixelRNN通常使用LSTM或GRU单元来处理长期依赖问题，这有助于模型捕获图像中的复杂结构。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pixelcnn&#34;&gt;PixelCNN&lt;/h3&gt;
&lt;p&gt;PixelCNN则是基于卷积神经网络（CNN）的变体，它使用掩码卷积层来确保每个像素仅从先前生成的像素获取信息，从而满足自回归模型的条件性要求。PixelCNN通过堆叠多个掩码卷积层来增加感受野，从而能够捕获图像的更高级特征和结构。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;掩码卷积&lt;/strong&gt;：为了确保模型只考虑当前像素之前的像素，PixelCNN在卷积核中使用了特殊的掩码技术。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并行处理&lt;/strong&gt;：与PixelRNN相比，PixelCNN的一个优势是能够更有效地利用现代硬件进行并行处理，因为卷积操作本质上比递归操作更适合并行化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总体来说，PixelCNN和PixelRNN都是在图像生成领域的重要模型，展示了利用自回归性质进行像素级生成的潜力。它们在细节表现和生成图像的连贯性方面都有很好的表现，但PixelCNN通常由于其并行处理能力而更受青睐。&lt;/p&gt;
&lt;h1 id=&#34;变分自编码器vae&#34;&gt;变分自编码器（VAE）&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1f34y1e7EK/?spm_id_from=333.788.recommend_more_video.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【变分自编码器VAE】可视化讲明白&lt;/a&gt;&lt;br&gt;
变分自编码器（Variational Autoencoder, VAE）是一种生成模型，它通过结合深度学习和贝叶斯推断的概念来学习输入数据的潜在表示。VAE不仅可以用于生成新的数据样本，还可以用于数据的降维和特征提取。它由两个主要部分组成：编码器和解码器。&lt;/p&gt;
&lt;h3 id=&#34;编码器&#34;&gt;编码器&lt;/h3&gt;
&lt;p&gt;编码器的作用是将输入数据映射到一个潜在空间（latent space）的表示。在VAE中，这个映射不是直接输出潜在向量，而是输出该向量的参数，通常是潜在空间分布的均值和方差。这意味着每个输入数据点都被编码为潜在空间中的一个分布，而不是一个固定的点，从而增加了表示的灵活性和表达能力。&lt;/p&gt;
&lt;h3 id=&#34;解码器&#34;&gt;解码器&lt;/h3&gt;
&lt;p&gt;解码器的作用是将潜在空间的这些分布转换回数据空间，即从潜在表示中重构输入数据。在生成新的数据样本时，可以从潜在空间的分布中采样一个点，并通过解码器生成与该点对应的数据样本。&lt;/p&gt;
&lt;h3 id=&#34;重构损失与kl散度&#34;&gt;重构损失与KL散度&lt;/h3&gt;
&lt;p&gt;VAE的训练旨在最小化两个关键部分的组合损失：重构损失和KL散度。重构损失确保解码的数据尽可能接近原始数据，而KL散度则强制潜在空间的分布接近先验分布（通常是标准正态分布）。这种方法不仅促进了有效的数据编码，而且确保了潜在空间的连续性和完整性，这对于生成新的、合理的数据样本至关重要。&lt;/p&gt;
&lt;h3 id=&#34;应用&#34;&gt;应用&lt;/h3&gt;
&lt;p&gt;VAE因其灵活性和强大的生成能力而被广泛应用于各种任务中，包括图像生成、风格转换、数据降维以及作为复杂系统的一部分，如推荐系统和强化学习模型。通过对潜在空间的探索和操作，VAE可以揭示数据的内在结构，并生成新的、具有相似特性的数据点。&lt;/p&gt;
&lt;h1 id=&#34;生成对抗网络-gan&#34;&gt;生成对抗网络 GAN&lt;/h1&gt;
&lt;p&gt;生成对抗网络（GAN，Generative Adversarial Networks）是一种深度学习模型，由Ian Goodfellow等人在2014年提出。GAN由两个重要的网络组成，即生成器（Generator）和判别器（Discriminator），这两个网络在模型的训练过程中相互对抗，从而促使模型生成的数据越来越接近真实数据。&lt;/p&gt;
&lt;h3 id=&#34;生成器generator&#34;&gt;生成器（Generator）&lt;/h3&gt;
&lt;p&gt;生成器的目标是生成与真实数据尽可能相似的数据。在训练开始时，生成器接收一个随机噪声向量作为输入，通过一系列的神经网络层将其转化成与真实数据具有相同维度的输出。随着训练的进行，生成器学习如何调整其参数，以生成越来越逼真的数据。&lt;/p&gt;
&lt;h3 id=&#34;判别器discriminator&#34;&gt;判别器（Discriminator）&lt;/h3&gt;
&lt;p&gt;判别器的作用是区分输入数据是来自于真实数据集还是生成器生成的假数据。它也是一个神经网络，接收真实数据或生成器生成的数据作为输入，并输出一个概率值，表示输入数据是真实数据的可能性。&lt;/p&gt;
&lt;h3 id=&#34;对抗训练过程&#34;&gt;对抗训练过程&lt;/h3&gt;
&lt;p&gt;GAN的训练涉及到一个对抗过程，其中生成器试图生成越来越逼真的数据以“欺骗”判别器，而判别器则试图变得越来越擅长于区分真假数据。这个过程可以类比于一个伪造艺术品的伪造者（生成器）和一个试图识别伪造品的艺术品鉴定师（判别器）之间的博弈。&lt;/p&gt;
&lt;p&gt;训练过程通常包含以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;训练判别器&lt;/strong&gt;：固定生成器的参数，提升判别器的性能。这通过将一批真实数据和一批生成器生成的假数据提供给判别器，并优化判别器的参数来最大化其区分真假数据的能力来实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;训练生成器&lt;/strong&gt;：固定判别器的参数，提升生成器的性能。这通过生成一批假数据，然后尝试欺骗判别器（即让判别器将这些假数据误判为真实数据），并优化生成器的参数来减少判别器的准确性来实现。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个过程反复进行，直到生成器生成的数据足够逼真，判别器无法区分真假数据，或达到某种平衡状态为止。&lt;/p&gt;
&lt;h3 id=&#34;应用-2&#34;&gt;应用&lt;/h3&gt;
&lt;p&gt;GAN已经被应用于多种领域，包括但不限于图像生成、图像编辑、风格转换、图像超分辨率、文本到图像的转换等。由于GAN生成的数据质量高，它在艺术创作、游戏开发、模拟数据生成等方面也显示了巨大的潜力。&lt;/p&gt;
&lt;h3 id=&#34;挑战&#34;&gt;挑战&lt;/h3&gt;
&lt;p&gt;尽管GAN强大且应用广泛，但它们的训练过程仍然具有挑战性，包括模式崩溃（mode collapse）、训练不稳定等问题。研究人员已经提出了多种技术和变种来解决这些问题，使GAN的训练过程更加稳定和高效。&lt;/p&gt;
&lt;h1 id=&#34;gan-网络实现&#34;&gt;GAN 网络实现&lt;/h1&gt;
&lt;h2 id=&#34;图像预处理&#34;&gt;图像预处理&lt;/h2&gt;
&lt;p&gt;对文件夹下批量图片进行rename&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import os

# 图片存放的路径
path = r&amp;quot;C:\Users\ZJL\Desktop\1&amp;quot;

# 遍历更改文件名
num = 1
for file in os.listdir(path):
    os.rename(os.path.join(path,file),os.path.join(path,str(num))+&amp;quot;.jpg&amp;quot;)
    num = num + 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;本次项目只有八张图片，我们需要进行数据增强，获取更大的数据集。&lt;/p&gt;
&lt;p&gt;首先，要对图像进行&lt;strong&gt;分辨率的统一&lt;/strong&gt;。分辨率，即为图像中像素点的个数，例如，一个分辨率为 1920x1080 的图像，表示它在水平方向上有 1920 个像素，在垂直方向上有 1080 个像素。&lt;/p&gt;
&lt;p&gt;问：为什么相同分辨率，相同文件类型，但是图片的文件大小不一样？&lt;br&gt;
答：&lt;br&gt;
图像内容的复杂程度：相同分辨率的图像，如果其内容越复杂，文件大小就可能越大。因为图像的复杂程度与其所包含的信息量有关，而信息量越大，文件大小也就越大。&lt;/p&gt;
&lt;p&gt;像素的位深度：像素的位深度指的是每个像素能够表示的颜色的数量。例如，8 位深度的像素可以表示 256 种颜色，而 16 位深度的像素可以表示 65,536 种颜色。相同分辨率的图像，如果其像素的位深度不同，文件大小也可能会不同。&lt;/p&gt;
&lt;p&gt;元数据的不同：图像文件中可能包含一些元数据，例如创建时间、修改时间、拍摄设备等信息，这些元数据的不同也可能会导致文件大小的差异。&lt;/p&gt;
&lt;p&gt;在神经网络中，我们通常需要将输入图像的尺寸规范化为相同的分辨率。&lt;/p&gt;
&lt;p&gt;然后我们进行数据增强&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;训练循环顺序：&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;步骤1&lt;/code&gt;&lt;br&gt;
生成器不动，生成器产生一批假图片，再拿取一批真实图片，喂给判别器，训练判别器。&lt;br&gt;
我们希望判别器对假图片打上标签0，对真图片打上标签1&lt;br&gt;
&lt;code&gt;步骤2&lt;/code&gt;&lt;br&gt;
判别器不动，训练生成器。生成一批假样本，使用判别器对这些假样本进行评估。&lt;br&gt;
更新生成器的参数，使其能够生成被判别器认为是真实的样本。&lt;/p&gt;
&lt;p&gt;重复上述步骤，直到能生成足够逼真的数据&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_44887621/article/details/120535309&#34;&gt;pytorch保存图片 save_image ，读取图片&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;训练GAN网络训练多少次比较合适？&lt;br&gt;
最好使用早停（early stopping） 的方法，即在模型在验证集上的表现开始下降时停止训练。这样可以避免模型出现过拟合的情况。&lt;/p&gt;
&lt;p&gt;另外，也可以使用 &amp;quot;learning rate decay&amp;quot; 的方法来防止模型出现过拟合的情况。这种方法的原理是，在训练过程中，会逐渐降低学习率，以便模型能够更加稳定地收敛到最优解。&lt;/p&gt;
">【DL】深度生成模型</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shu-ju-gui-yi-hua-chu-li/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features&#34;&gt;sklearn&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/57332604&#34;&gt;数据清洗&amp;amp;预处理入门完整指南&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;标准化&#34;&gt;标准化&lt;/h1&gt;
&lt;p&gt;使数据符合高斯分布，每个数据减去平均值，再除以标准差。目的是让所有特征都在相同的尺度上，从而避免因为特征尺度差异过大而对模型训练产生不良影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;非线性变换&lt;/strong&gt;&lt;br&gt;
如对数变换、平方根变换等，旨在处理偏斜的数据，使其分布更接近正态分布，或者是为了使数据的关系更符合模型的假设。例如，如果数据分布严重偏斜，一些模型的性能可能会受到影响，这时候非线性变换可以帮助改善模型的性能。&lt;/p&gt;
&lt;p&gt;因此，即使在进行了标准化之后，如果数据仍然呈现出明显的偏斜或者模型的性能不佳，可能就需要考虑非线性变换。反之，如果数据在标准化之后表现良好，模型性能满足需求，那么可能不需要进行非线性变换。&lt;/p&gt;
&lt;p&gt;实际操作中，是否采用非线性变换通常通过探索性数据分析（EDA）来决定，EDA可以帮助你了解数据的分布情况。此外，模型的表现和交叉验证的结果也是决策的重要依据。在一些情况下，你可能会同时使用标准化和非线性变换，以最大限度地提高数据质量和模型性能。&lt;/p&gt;
&lt;h1 id=&#34;归一化规范化&#34;&gt;归一化（规范化）&lt;/h1&gt;
&lt;p&gt;将将不同范围的数据缩放到一个指定的范围，通常是0到1之间，或者是-1到1之间。这是通过从每个值中减去特征的最小值并除以最大值和最小值之差来实现的。归一化有助于确保所有特征对模型的贡献是相等的，使不同的数据具有相似的分布和取值范围。&lt;/p&gt;
&lt;p&gt;常见的数据归一化方法有以下几种：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最值归一化（Min-Max Normalization）&lt;/strong&gt;&lt;br&gt;
最值归一化是将数据映射到[0,1]范围内，公式如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Xnormalized = \frac{X - Xmin}{Xmax - Xmin}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.69444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.04398em;&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.275662em;vertical-align:-0.403331em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.872331em;&#34;&gt;&lt;span style=&#34;top:-2.655em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.403331em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中，Xmin和Xmax分别是数据集中的最小值和最大值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;均值方差归一化（Standardization）&lt;/strong&gt;&lt;br&gt;
就是标准化&lt;br&gt;
均值方差归一化是将数据转换为均值为0，方差为1的数据，公式如下：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Xnormalized = \frac{X - Xmean}{Xstd}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.69444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.04398em;&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.217331em;vertical-align:-0.345em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.872331em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;d&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.345em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中，Xmean和Xstd分别是数据集的均值和标准差。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小数定标归一化&lt;/strong&gt;&lt;br&gt;
小数定标归一化是将数据的小数点移动到某一位置，使得数据范围在一定程度上缩小。例如，将数据的小数点向左移动2位，可以将数据的范围缩小100倍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对数归一化&lt;/strong&gt;&lt;br&gt;
对数归一化是将数据取对数后进行归一化处理。这种方法通常用于处理数据的取值范围差异很大的情况。&lt;/p&gt;
&lt;p&gt;数据归一化的目的是使得数据的分布更加规律&lt;br&gt;
归一化处理可以使不同的数据具有相似的分布和取值范围，这在许多机器学习算法中是很有用的。例如，在使用梯度下降算法进行模型训练时，如果数据的范围差异很大，模型可能会在局部最小值附近来回震荡，导致收敛速度减慢。归一化处理可以使梯度下降算法更快地收敛，并且可以使模型的泛化能力更强。&lt;/p&gt;
&lt;p&gt;但是，也要注意，如果数据已经具有相似的分布和取值范围，则不需要进行归一化处理。另外，在使用归一化处理后的数据进行模型训练后，在使用模型进行预测时，还需要将输入数据进行相应的反归一化处理，才能得到正确的预测结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用pytorch进行归一化操作&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;normalize = transforms.Normalize((mean,), (std,))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 mean 为均值，std为方差，想进行归一化操作需要先计算出数据的均值和方差。&lt;/p&gt;
&lt;p&gt;例如对MNIST数据集的处理：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 定义图像处理方法
tranform = transforms.Compose([
    transforms.ToTensor(),  # 将图片转换成Tensor
    transforms.Normalize((0.1307,), (0.3081,))  # 进行数据归一化处理
])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 0.1307 和 0.3081 分别是 MNIST 的均值和方差，可以自己计算，也可以网上查&lt;br&gt;
等同于 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;0.1307&lt;/mn&gt;&lt;/mrow&gt;&lt;mn&gt;0.3081&lt;/mn&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;Xnormalized = \frac{X - 0.1307}{ 0.3081}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.69444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.04398em;&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.217331em;vertical-align:-0.345em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.872331em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;mbin mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.345em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，转化为均值为 0，方差为 1 的数据。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;标准化和归一化的区别和联系&lt;/code&gt;&lt;br&gt;
标准化和归一化是数据预处理中两种常用的尺度变换方法，它们都旨在调整特征值的尺度，以便于不同特征之间能够更公平地比较和组合，但它们在方法和用途上存在一些区别：&lt;/p&gt;
&lt;h3 id=&#34;标准化z-score-normalization&#34;&gt;标准化（Z-score normalization）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;目的&lt;/strong&gt;：使数据具有零均值（Mean = 0）和单位方差（Standard Deviation = 1）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算方法&lt;/strong&gt;：从每个特征值中减去特征的平均值，然后除以特征的标准差。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用场景&lt;/strong&gt;：特别适用于那些假设数据为正态分布的算法，如支持向量机（SVM）、线性回归、逻辑回归等。标准化有助于加快一些算法的收敛速度，并提高其性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;归一化min-max-normalization&#34;&gt;归一化（Min-Max normalization）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;目的&lt;/strong&gt;：将数据缩放到一个指定的最小和最大值之间，通常是0和1之间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算方法&lt;/strong&gt;：从每个特征值中减去特征的最小值，然后除以最大值和最小值的差值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用场景&lt;/strong&gt;：特别适用于那些对输入数据的尺度敏感的算法，如神经网络、k-最近邻算法等。归一化有助于防止数据中某些特征在计算中占据主导地位。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;区别和联系&#34;&gt;区别和联系&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;尺度范围&lt;/strong&gt;：标准化后的数据不限于特定范围，而归一化后的数据范围通常是0到1或者-1到1。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对异常值的敏感度&lt;/strong&gt;：归一化由于直接依赖于最小值和最大值，所以对异常值非常敏感。而标准化由于是依据均值和标准差进行的，对异常值的敏感度较低。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：标准化在数据假定为正态分布时特别有效，归一化适用于不假定数据分布的情境，尤其是当算法对数据的尺度非常敏感时。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;离散化&#34;&gt;离散化&lt;/h1&gt;
&lt;p&gt;它涉及将连续特征的值划分为几个区间，并将这些区间转换为离散的值。这种技术有助于处理连续变量，使其更适合某些特定的算法，尤其是那些设计用于处理类别输入的算法。离散化可以简化模型，使其更易于理解和解释，同时有助于处理异常值和提高模型的稳健性。&lt;/p&gt;
&lt;h1 id=&#34;编码分类特征&#34;&gt;编码分类特征&lt;/h1&gt;
&lt;p&gt;将非数值特征转换为数值形式的过程。最常见的方法是独热编码（One-Hot Encoding），它为每个类别创建一个新的二进制特征，表明样本是否属于该类别。&lt;/p&gt;
&lt;h1 id=&#34;缺失值的插补&#34;&gt;缺失值的插补&lt;/h1&gt;
&lt;p&gt;缺失值的插补是处理缺失数据的方法。常见的插补技术包括使用平均值、中位数、众数填充缺失值，或者使用更复杂的方法如 k-NN 或回归。&lt;/p&gt;
&lt;h1 id=&#34;生成多项式特征&#34;&gt;生成多项式特征&lt;/h1&gt;
&lt;p&gt;通过现有特征的非线性组合来创建新特征的过程。例如，如果有两个特征 A 和 B ，可以创建新特征 A^2 B^2 和 AB 。这可以帮助机器学习模型捕捉特征之间的复杂关系。&lt;/p&gt;
&lt;h1 id=&#34;移除低方差特征&#34;&gt;移除低方差特征&lt;/h1&gt;
&lt;p&gt;低方差代表此特征不利于将样本分开，设置一个阈值，低于该阈值会被移除&lt;/p&gt;
">【ML】数据预处理</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/fl-studio/"" data-c="
          &lt;p&gt;Alt+R 调节音量swing&lt;br&gt;
ctrl左键选择所有&lt;br&gt;
Alt+U 切分音&lt;br&gt;
ctrl+L 延长音符&lt;br&gt;
ctrl+Alt+Z 撤回&lt;br&gt;
ctrl+T 添加标签&lt;br&gt;
ctrl+Q 对齐音符&lt;/p&gt;
&lt;p&gt;FPC：打击垫&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://obeato.com/how-to-merge-patterns-in-fl-studio/#:~:text=To%20be%20able%20to%20do%20split%20patterns%20in,project%20and%20select%20the%20split%20by%20channel%20option.&#34;&gt;How To Merge Patterns In FL Studio + Split [Quick Guide]&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.flstudiochina.com/rumen/fl-yltz.html&#34;&gt;如何在FL Studio中对整首歌曲音量进行调整&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;BPM：每分钟节拍数&lt;br&gt;
水果的一个格子里有四拍，一个格子是节拍器的一个循环；BPM越高，一个小结的拍数不变，则同小节的曲子长度越短&lt;/p&gt;
&lt;p&gt;如果遇到爆音、嘈杂音质等问题（原音频没有问题，很清晰）那么是CPU带不动了。重新设置声卡。&lt;br&gt;
点击 选项 - 音频设置 - 设备 更改选项。&lt;br&gt;
&lt;a href=&#34;https://chilloutwithbeats.com/en/flstudio20-bufferlength/&#34;&gt;设备设置问题&lt;/a&gt;&lt;/p&gt;
">FL Studio 水果</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/mind/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://baijiahao.baidu.com/s?id=1678857872552765603&#34;&gt;正念：运用前额叶改变动物脑，从而改变人生&lt;/a&gt;&lt;/p&gt;
">Mind</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/te-zheng-jiang-wei/"" data-c="
          &lt;p&gt;本篇大致是根据提出顺序由浅入深介绍&lt;/p&gt;
&lt;h1 id=&#34;pcaprinciple-component-analysis&#34;&gt;PCA（Principle Component Analysis）&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1E5411E71z/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;用最直观的方式告诉你：什么是主成分分析PCA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;对于高维、大样本，难以直观地看出某个变量变异性的大小，难以提取到最有效的特征 PCA 是一种最常用的特征降维方法，去除掉相似的特征，保留无关性最大的特征，提高数据处理速度。PCA  能够将原始数据转换为一组线性不相关的成分，通常用于数据降维、特征提取和数据可视化等领域。&lt;/p&gt;
&lt;p&gt;将高维数据投影到低维，使数据在低维上分布的方差最大（方差小数据挨得紧，要尽量让数据在低维分散，避免重合）&lt;/p&gt;
&lt;p&gt;缺点：对离群点很敏感，一个离群点会导致轴偏移很大&lt;/p&gt;
&lt;p&gt;PCA 通过正交变换将一组可能相关的变量的观察值转换为一组线性不相关变量的值，这组不相关变量称为主成分。PCA 的算法步骤可以简述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;标准化数据&lt;/strong&gt;：如果各个特征数据的量纲（单位）不同或数值范围相差很大，需要先对数据进行标准化处理。标准化是为了避免数据中某些特征由于其数值范围大而对结果产生过大的影响。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算协方差矩阵&lt;/strong&gt;：协方差矩阵表达了数据特征间的相关性。如果数据已经中心化（即减去了均值），协方差矩阵可以通过数据矩阵与其转置的乘积，除以样本数减一得到。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算协方差矩阵的特征值和特征向量&lt;/strong&gt;：这些特征值和对应的特征向量表征了数据的主成分。特征值越大，对应的特征向量在数据集中的重要性就越高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;选择主成分&lt;/strong&gt;：根据特征值的大小，选择前k个最大的特征值对应的特征向量，这些特征向量被称为主成分。k的选择取决于我们希望保留原始数据多少的信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;形成特征向量矩阵&lt;/strong&gt;：将选定的k个特征向量组合成一个矩阵，其中每一列代表一个特征向量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据转换&lt;/strong&gt;：使用特征向量矩阵来转换原始数据。这通过将原始数据矩阵乘以特征向量矩阵来完成，结果是一个新的数据矩阵，这个矩阵的每一列都是原始数据在对应主成分上的投影。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;拓展&lt;/code&gt;&lt;br&gt;
核 pca&lt;/p&gt;
&lt;h1 id=&#34;奇异值分解singular-value-decompositionsvd&#34;&gt;奇异值分解（Singular Value Decomposition，SVD）&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV16A411T7zX/?spm_id_from=333.788&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【学长小课堂】什么是奇异值分解SVD--SVD如何分解时空矩阵&lt;/a&gt;&lt;br&gt;
SVD 是一种重要的矩阵分解技术，在信号处理、统计学、语义分析等多个领域都有广泛的应用。对于任意一个mxn的矩阵A，都可以进行奇异值分解（参考：&lt;a href=&#34;https://jeromezjl.github.io/post/xian-xing-dai-shu/&#34;&gt;线性代数&lt;/a&gt;奇异值分解）&lt;/p&gt;
&lt;p&gt;在实际应用中，尤其是面对大数据集时，直接计算协方差矩阵并进行特征值分解（PCA的传统方法）可能非常耗时。而SVD提供了一种更有效的方式来找到主成分，特别是当数据维度很高，但我们只需要最主要的几个成分时。通过对原始数据矩阵应用SVD，而不是先计算协方差矩阵，可以更快地获得主成分，尤其是使用截断SVD（一种只计算最大的几个奇异值和对应奇异向量的方法）时。&lt;/p&gt;
&lt;p&gt;SVD 分解中的 V 矩阵（右奇异向量）和 PCA 的协方差矩阵的特征向量相对应&lt;/p&gt;
&lt;h1 id=&#34;流形学习&#34;&gt;流形学习&lt;/h1&gt;
&lt;p&gt;流形学习（Manifold Learning）是一种探索和利用数据内在结构的非线性降维方法，特别关注于数据可能存在于高维空间中的低维流形。流形是一个可以被视为欧几里得空间的子集的数学空间，但在局部上又类似于欧几里得空间。流形学习的基本假设是高维数据实际上是沿着某个低维流形分布的，尽管这个流形嵌入在高维空间中。流形学习的目标是揭示这个低维结构，以便于数据的可视化、降维和进一步分析。&lt;/p&gt;
&lt;p&gt;流形学习的核心思想在于，即使数据在全局上呈现复杂的非线性结构，其局部区域内的数据点却可能通过简单的线性变换相互关联。这种方法试图通过维护数据点在高维空间中的局部邻近关系来找到一个低维表示，从而尽可能保留数据的内在结构和特性。&lt;/p&gt;
&lt;p&gt;流形学习的一些著名算法包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;局部线性嵌入（Locally Linear Embedding, LLE）&lt;/strong&gt;：假定每个数据点及其最近邻居点是线性相关的，通过保持这种局部线性关系来寻找数据的低维嵌入。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;等度量映射（Isomap）&lt;/strong&gt;：通过保持数据点之间的测地线距离（即数据流形上的实际距离，而非高维空间中的欧氏距离）来寻找低维表示。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;t-分布随机邻域嵌入（t-Distributed Stochastic Neighbor Embedding, t-SNE）&lt;/strong&gt;：通过将高维数据点之间的相似性转换为概率分布，然后在低维空间中以尽可能保持这些概率分布的方式来寻找每个数据点的位置。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;流形学习的应用领域非常广泛，包括图像处理、语音识别、生物信息学和金融分析等。这些算法特别适用于那些传统的线性降维方法（如主成分分析PCA）无法揭示数据内在结构的情况。然而，流形学习也面临一些挑战，比如算法的计算成本、选择最佳参数、以及算法的可解释性。&lt;/p&gt;
&lt;h1 id=&#34;度量学习&#34;&gt;度量学习&lt;/h1&gt;
&lt;p&gt;度量学习（Metric Learning）是机器学习中的一个重要领域，旨在通过学习数据点之间距离的最佳度量方式来改进各种任务，如分类、聚类和推荐系统。在传统的机器学习方法中，通常采用固定的度量（如欧氏距离或曼哈顿距离）来计算数据点之间的相似度或距离。然而，这些固定的度量方式可能并不总是能够有效地捕捉到数据的内在结构或关系。度量学习的目标是发现一种能够最佳地反映数据内在关系的度量方式。&lt;/p&gt;
&lt;h3 id=&#34;主要思想&#34;&gt;主要思想&lt;/h3&gt;
&lt;p&gt;度量学习的核心思想是寻找或学习一个距离函数，这个函数能够使得相似或相关的数据点之间的距离缩小，而不相似或不相关的数据点之间的距离增大。通过这种方式，度量学习能够增强模型的泛化能力，提高其在特定任务上的性能。&lt;/p&gt;
&lt;h3 id=&#34;常见方法&#34;&gt;常见方法&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;马氏距离学习（Mahalanobis Distance Learning）&lt;/strong&gt;：马氏距离是度量学习中常用的一种距离度量方式，它通过学习一个正定矩阵来转换数据空间，使得在新空间中，相似数据点的距离更近，不相似数据点的距离更远。著名的算法包括最近邻成分分析（LMNN）等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基于三元组的度量学习（Triplet-Based Metric Learning）&lt;/strong&gt;：这种方法通过考虑数据点三元组（一个锚点、一个正例和一个负例）来学习度量，目标是使得锚点与正例之间的距离小于锚点与负例之间的距离。这种方法在深度学习和图像识别中尤其受欢迎。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;深度度量学习（Deep Metric Learning）&lt;/strong&gt;：利用深度神经网络来学习数据点之间的距离度量。通过端到端的训练，深度网络能够学习到复杂的非线性变换，以发掘数据的内在特征和结构。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;应用领域&#34;&gt;应用领域&lt;/h3&gt;
&lt;p&gt;度量学习在许多领域都有广泛的应用，如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;人脸识别&lt;/strong&gt;：通过学习一个有效的距离度量，以区分不同人的面部图像。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推荐系统&lt;/strong&gt;：通过度量用户和物品之间的相似度来提高推荐的准确性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文本分类和聚类&lt;/strong&gt;：通过学习文本数据的有效度量，改进文本分类和聚类的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;度量学习通过提供一种灵活而有效的方式来学习数据点之间的相对关系，为提高机器学习模型的性能提供了一种强大的工具。然而，度量学习也面临一些挑战，如选择合适的损失函数、防止过拟合、以及处理大规模数据集时的计算效率问题。&lt;/p&gt;
&lt;h1 id=&#34;auto-encoder&#34;&gt;Auto-encoder&lt;/h1&gt;
&lt;p&gt;自动编码器（Autoencoder, AE）是一种无监督的神经网络，它的目标是学习一种表示（编码）用于输入数据的高效表示形式（编码），然后通过这种表示来重构输入数据（解码）。自动编码器由两部分组成：编码器（Encoder）和解码器（Decoder）。&lt;/p&gt;
&lt;h3 id=&#34;编码器&#34;&gt;编码器&lt;/h3&gt;
&lt;p&gt;编码器部分的作用是将输入数据映射到一个隐藏层，这个隐藏层也被称为编码或潜在空间表示（Latent Space Representation）。这个过程实际上是在学习输入数据的一种压缩表示形式，这种表示通常比原始数据的维度要低，从而捕获数据的内在结构和特征。&lt;/p&gt;
&lt;h3 id=&#34;解码器&#34;&gt;解码器&lt;/h3&gt;
&lt;p&gt;解码器部分的作用是将潜在空间的编码映射回原始数据空间，尽量重构原始输入数据。通过比较输入数据和重构数据之间的差异，网络可以在训练过程中调整参数以最小化重构误差。&lt;/p&gt;
&lt;h3 id=&#34;训练&#34;&gt;训练&lt;/h3&gt;
&lt;p&gt;自动编码器的训练目标是最小化输入数据和重构数据之间的差异，这通常通过最小化一个损失函数（如均方误差）来实现。通过这种方式，自动编码器可以学习到数据的有效和压缩的表示。&lt;/p&gt;
&lt;h3 id=&#34;变体&#34;&gt;变体&lt;/h3&gt;
&lt;p&gt;自动编码器有多种变体，每种变体都有其独特的应用和优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;稀疏自动编码器（Sparse Autoencoder）&lt;/strong&gt;：通过引入稀疏性约束于隐藏层，稀疏自动编码器可以学习到更加鲁棒的特征表示。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;去噪自动编码器（Denoising Autoencoder）&lt;/strong&gt;：通过在输入数据中添加噪声，然后训练网络重构原始的未加噪声数据，去噪自动编码器能够学习到数据的稳健特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;变分自动编码器（Variational Autoencoder, VAE）&lt;/strong&gt;：不同于传统自动编码器的确定性编码过程，变分自动编码器将输入数据映射到潜在空间分布的参数上，从而能够进行生成模型的学习。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;应用&#34;&gt;应用&lt;/h3&gt;
&lt;p&gt;自动编码器广泛应用于数据降维、特征学习、生成模型等多个领域。它们特别适合于数据预处理、数据的可视化、以及作为其他复杂模型的一部分来学习有用的特征表示。自动编码器的能力在于它们可以通过学习重构数据来发现数据的内在结构和规律，即使在未标记的数据上也能有效工作。&lt;/p&gt;
">【ML】特征降维与特征学习</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/sql-fu-xi/"" data-c="
          &lt;p&gt;复习策略：&lt;br&gt;
看网络资料的数据库复习&lt;br&gt;
弄懂知识点，然后做一下里面的题&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jeromezjl.github.io/post/sql/&#34;&gt;SQL笔记&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;第三章-sql&#34;&gt;第三章 SQL&lt;/h1&gt;
&lt;p&gt;熟练编写 sql 语句，创建、删除语句也要看，数据类型&lt;/p&gt;
&lt;h1 id=&#34;第四章&#34;&gt;第四章&lt;/h1&gt;
&lt;p&gt;◼ Join Expressions（连接表达式）&lt;br&gt;
◼ Views 视图&lt;br&gt;
◼ Transactions&lt;br&gt;
◼ Integrity Constraints&lt;br&gt;
◼ SQL Data Types and Schemas&lt;br&gt;
◼ Authorization&lt;br&gt;
◼ Security in SQL&lt;/p&gt;
&lt;p&gt;Join 参见 sql 的总结，natural join，inner join 等&lt;/p&gt;
&lt;h1 id=&#34;第五章-高级-sql&#34;&gt;第五章 高级 SQL&lt;/h1&gt;
&lt;p&gt;这章期中没考&lt;/p&gt;
&lt;p&gt;使用程序设计语言访问数据库&lt;br&gt;
通过两种方式从通用编程语言访问 SQL：&lt;br&gt;
动态 SQL：通过函数或方法&lt;br&gt;
嵌入式 SQL：在编译时全部确定&lt;/p&gt;
&lt;p&gt;JDBC 标准定义了 java 和 SQL 的 API&lt;/p&gt;
&lt;h1 id=&#34;第六章-关系代数&#34;&gt;第六章 关系代数&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/quinnnorris/article/details/70739094&#34;&gt;SQL 形式化语言——关系代数&lt;/a&gt;&lt;br&gt;
重点是如何将sql语句转化为关系代数&lt;/p&gt;
&lt;p&gt;选择运算 select operation σ&lt;br&gt;
选择关系instructor中属于物理系的元组：&lt;br&gt;
σ dept_name=“Physics”(instructor)&lt;br&gt;
选择关系 instructor 中 salary&amp;gt;90000 的元组：&lt;br&gt;
σ salary&amp;gt;90000 (instructor)&lt;br&gt;
⋀ (and), ⋁ (or), (not)&lt;/p&gt;
&lt;p&gt;投影运算 project operation  ∏&lt;br&gt;
用于选择表中想要的属性&lt;br&gt;
∏ name, salary (instructor)&lt;br&gt;
找出物理系中所有教师的名字：&lt;br&gt;
∏ name (σ dept_name=“Physic’ (instructor))&lt;/p&gt;
&lt;p&gt;并运算 union operation ∪&lt;br&gt;
找出开设在 2009 年球季或者 2010 年春季学期，或者二者皆开的课程集合&lt;br&gt;
∏course_id (σ semester=“Fall” Λ year=2009 (section)) ∪&lt;br&gt;
∏course_id (σ semester=“Spring” Λ year=2010 (section))&lt;/p&gt;
&lt;p&gt;集合差运算 Set Difference Operation -&lt;br&gt;
找出开设在 2009 年秋季但不开设在 2010 年春季的课程&lt;br&gt;
∏course_id (σ semester=“Fall”Λ year=2009(section))-&lt;br&gt;
∏course_id (σ semester=“Spring”Λ year=2010(section))&lt;/p&gt;
&lt;p&gt;笛卡尔积运算 Cartesian-Product Operation x&lt;br&gt;
∏ name (σ dept_name=“Physic’ (instructor x teaches))&lt;/p&gt;
&lt;p&gt;更名运算 Rename Operation&lt;br&gt;
选出 instructor 中 salary 最高的：&lt;br&gt;
σ instructor.salary &amp;lt; d.salary (instructor ╳ ρ d(instructor))&lt;/p&gt;
&lt;p&gt;select T.salary&lt;br&gt;
from instructor T, instructor S&lt;br&gt;
where T.salary &amp;gt; S.salary&lt;/p&gt;
&lt;h1 id=&#34;第七章-e-r-图&#34;&gt;第七章 E-R 图&lt;/h1&gt;
&lt;p&gt;非ER关系中，两个实体关联，每个实体中可能会有对方实体的主码，从而产生冗余&lt;br&gt;
在ER关系中，如果一个实体的属性是另一个实体的主码，则删除该属性。二者的关联会在联系集里表达。（P183）&lt;/p&gt;
&lt;p&gt;双线表示一对一关系，实体集唯一对应关系集&lt;/p&gt;
&lt;p&gt;大学实体集及属性（P154 输入183）&lt;/p&gt;
&lt;p&gt;大学 E-R 图（P159 输入188）&lt;/p&gt;
&lt;p&gt;E-R 图图形含义（P172 输入 201）&lt;/p&gt;
&lt;p&gt;练习题（P179 输入208）&lt;/p&gt;
&lt;p&gt;弱实体集：如果保留某些属性，则在和别的集合关联时，会造成属性的冗余。所以我们选择删掉该属性。但删掉后，当前剩余的属性就不能保证唯一标识元素。这样的实体集称为弱实体集。弱实体集必须与强实体集关联才有意义。&lt;/p&gt;
&lt;p&gt;E-R 图中，双线表示有且仅有一个相关的对象&lt;br&gt;
箭头：A → B 表明 每个 A 至多有一个 B&lt;/p&gt;
&lt;p&gt;构造关系表时，如果有多个候选键，最好选取数值型（int, float）候选键作为关系表主键，便于提高基于主键的查询速度&lt;br&gt;
—不要选字符串型属性，如varchar、datetime&lt;br&gt;
—e.g. studentname, instructorName&lt;/p&gt;
&lt;p&gt;双菱形表示弱实体集的标识性联系集&lt;/p&gt;
&lt;p&gt;构建 E-R 图步骤&lt;br&gt;
从关系集入手，分别判断其关联的两个实体集的对应关系。看是采用双线、箭头，还是单线。&lt;br&gt;
判断弱实体集：看关联的两个实体集的属性，是否有相同的，如果有，去掉其中一个的属性，将其变为弱实体集，然后将关系变为双菱形。&lt;/p&gt;
&lt;h1 id=&#34;第八章-关系数据库的设计&#34;&gt;第八章 关系数据库的设计&lt;/h1&gt;
&lt;p&gt;◼ Features of Good Relational Design&lt;br&gt;
◼ Atomic Domains and First Normal Form&lt;br&gt;
◼ Decomposition Using Functional Dependencies&lt;br&gt;
◼ Functional Dependency Theory&lt;br&gt;
◼ Algorithms for Functional Dependencies&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;好的关系设计的特点&lt;/strong&gt;&lt;br&gt;
取决于E-R图质量&lt;br&gt;
是否有重复，是否可以很好的表示所有信息&lt;br&gt;
删除和更新问题&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/sky20080101/articles/8445061.html&#34;&gt;原子性和第一范式&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;第十章-数据存储和文件结构&#34;&gt;第十章 数据存储和文件结构&lt;/h1&gt;
&lt;p&gt;◼ File organization (at physical level, §10.5)&lt;br&gt;
◼ Organization of records in files (at logical level, §10.6 ),&lt;br&gt;
i.e. file structures&lt;br&gt;
◼ Data-dictionary Storage (§10.7)&lt;br&gt;
◼ Data Buffer (§10.8)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10.5 文件组织&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;第十一章-索引&#34;&gt;第十一章 索引&lt;/h1&gt;
&lt;p&gt;搜索码：用于在文件中查找记录的属性或属性集&lt;br&gt;
索引&lt;br&gt;
什么是&lt;br&gt;
聚集索引 clustering index ，非聚集索引，稠密索引，稀疏索引，&lt;/p&gt;
&lt;p&gt;每个索引对数据增删改查是否有影响，&lt;/p&gt;
&lt;p&gt;索引创建在搜索码（属性）上面，可提高检索速度&lt;br&gt;
要会说明原因&lt;/p&gt;
&lt;p&gt;在除了查询之外，delete update insert 时如何提高效率，搜索码&lt;br&gt;
索引也有空间、时间开销，增加/删除，所以不一定能对增加删除修改起到提高效率的作用&lt;br&gt;
也可能拖慢速度&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;on which attributes the indices can be further defined to speed up the query? 在哪里添加索引会继续加快查找？&lt;/strong&gt;&lt;br&gt;
1.找语句中频繁使用的元素&lt;br&gt;
2.找where后面的元素&lt;br&gt;
3.找join on后面的元素&lt;br&gt;
例：&lt;br&gt;
select branch_city, sum(amount)&lt;br&gt;
from branch inner join loan on branch_name&lt;br&gt;
where assets&amp;gt;1000&lt;br&gt;
group by branch_city&lt;br&gt;
1.branch_city加索引&lt;br&gt;
2.assets加索引&lt;br&gt;
3.branch_name加索引&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Give a SQL statement to define a composite index on combined search key(branch_name, amount) on the table loan.  创建索引&lt;/strong&gt;&lt;br&gt;
语法：&lt;br&gt;
create index branch_name_amount_index on loan(branch_name, amount);&lt;br&gt;
create index 索引名 on 表名（属性名）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Can this index be efficiently used for the following query, and why? 是否可以提升查询速度？&lt;/strong&gt;&lt;br&gt;
答题角度：看被索引的对象在什么关键词后面。&lt;br&gt;
比如在where后/经常被查询使用&lt;/p&gt;
&lt;h1 id=&#34;第十二章-查询处理&#34;&gt;第十二章 查询处理&lt;/h1&gt;
&lt;p&gt;熟悉关系代数的表示&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/bianyamei/article/details/89491358&#34;&gt;启发式查询树优化实例&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1Fp4y1a7Cs/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站讲解 数据库语法树优化&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;步骤&lt;br&gt;
1、写出关系代数表达式&lt;br&gt;
2、画出查询树&lt;br&gt;
3、选择关系下移&lt;br&gt;
4、投影下移，注意投影要在选择关系之上；每个自然连接前面必须有投影&lt;/p&gt;
&lt;h1 id=&#34;函数依赖&#34;&gt;函数依赖&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/m0_46670811/article/details/109526906&#34;&gt;求属性集闭包(AB+)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/Game_Zmh/article/details/88058069&#34;&gt;求属性集闭包&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;List all the candidate keys of R. 求候选键&lt;/strong&gt;&lt;br&gt;
1.&lt;a href=&#34;https://blog.csdn.net/YYbLQQ/article/details/124508824&#34;&gt;即只出现在F箭头左边的一定是候选码&lt;/a&gt;&lt;br&gt;
上例中，A和C只出现在箭头左边，我们用闭包计算可以得到U，则（AC）是该关系的候选码&lt;br&gt;
注：除了候选键，其余都是非主属性&lt;br&gt;
2.可以推出所有的字母的是候选键&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is the highest normal form of R 关系R的最高范式是什么（判断是第几范式）&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/m0_37345402/article/details/106163096&#34;&gt;如何判断范式（1NF、2NF、3NF、BCNF）&lt;/a&gt;&lt;br&gt;
1.求候选码。候选键可以是连着的几个字母，而主属性是分开的独立字母；除了主属性之外的字母都是非主属性&lt;br&gt;
2.如果F中，存在左部没有候选码的关系，则有非平凡FD，则不是BCNF&lt;br&gt;
3.如果上述关系中，右部都是主属性，则为3NF&lt;br&gt;
4.如果任何主属性都不能推出非主属性，则为2NF&lt;br&gt;
5.否则为1NF&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;lossless-join decomposition 判断无损分解&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_41338249/article/details/112724127&#34;&gt;无损分解讲解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Compute the canonical cover Fc 求最小函数依赖&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.zhihu.com/question/21235096&#34;&gt;知乎讲解&lt;/a&gt;&lt;br&gt;
1.将右部都化为单一字母&lt;br&gt;
2.去掉左边多余属性，具体方法：只需关注非单属性，求左侧的闭包，但不要加上左边推出的字母，比如 DG-&amp;gt;C：判断(DG)+ = DG，不要再把C加上再推了。观察得到的闭包，如果闭包含有右侧推出的字母，则删除；否则保留。DG不含C，则保留。&lt;br&gt;
3.剩余的单个关系，判断是否存在形如 D-&amp;gt;C, C-&amp;gt;A, D-&amp;gt;A 这样的，删除 D-&amp;gt;A 即可&lt;br&gt;
综上可得出最小函数依赖&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Give a lossless-join and dependency-preserving decomposition of R into 3NF&lt;/strong&gt;&lt;br&gt;
在最小函数依赖上进行构建&lt;/p&gt;
&lt;h1 id=&#34;事务&#34;&gt;事务&lt;/h1&gt;
&lt;p&gt;concurrent transactions：并发事务&lt;br&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=U3SHusK80q0&#34;&gt;画优先图 precedence graph 并 判断是否可串行化 serializable：油管清晰讲解&lt;/a&gt;&lt;br&gt;
关注三对关系：R-&amp;gt;W，W-&amp;gt;R，W-&amp;gt;W&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;是否是可恢复调度？ Is S a recoverable schedule, and why?&lt;/strong&gt;&lt;br&gt;
对于可恢复调度，如果一个调度从另外一个调度的结果中读取数据，那么它必须在另外以后调度的commit之后commit。&lt;br&gt;
不是可恢复调度的例子：&lt;br&gt;
T2 读取 student 表中 stuID=10 的元组时，该元组内容已由 T1 修改过，但 T2 提交操作&lt;br&gt;
commit 早于 T1 提交 commit。一旦 T1 在 T2 的 commit 操作之后回滚其 update student 操作，将 stuName 回滚为旧值，则 T2 的 select 操作无法随着回滚，T2 读取的仍然是 stuName 修改后的值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;是否是无级联调度？Is S a cascadeless schedule, and why?&lt;/strong&gt;&lt;br&gt;
如果事务要对某个值执行读操作，则必须等到执行写入该值的事务 commit。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;是否满足二阶段锁？ obey the two-phase locking protocol？&lt;/strong&gt;&lt;br&gt;
在同一个事务中，前半部分全是lock，后面全是unlock，则满足，否则不满足&lt;br&gt;
注意是在同一个事务中，如在T1这一列中看。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;是否满足严格二阶段锁？ Strict two phase locking protocol&lt;/strong&gt;&lt;br&gt;
共享锁（share）：lock_s；排他锁（exclusive）：lock_x&lt;br&gt;
S2PLP 可以在 lock_s上锁之后随时释放它，但只能在 commit 的时候释放 lock_x&lt;br&gt;
严锁在commit的时候同时释放所有锁。其主要区别简单来说，就是：2PL能随时释放锁，S2PL只能在事务结束后释放锁。但注意，随时释放不是指&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;是否满足严格二阶段锁？Rigorous two phase locking protocol&lt;/strong&gt;&lt;br&gt;
R2PLP 只能在 commit 的时候释放所有锁， lock_s 和 lock_x&lt;/p&gt;
">SQL 复习</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/mldl-zhong-chang-jian-de-ying-wen/"" data-c="
          &lt;p&gt;parameters / params：参数&lt;br&gt;
epochs：总训练次数，使用全部数据训练一次是一个epochs&lt;br&gt;
learning rate：学习率&lt;br&gt;
optimize：优化&lt;br&gt;
regularization：正则化&lt;br&gt;
normalize：归一化、标准化&lt;br&gt;
Regularization： 正则化&lt;/p&gt;
">ML/DL 中常见的英文</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ti-du-xia-jiang-gradient-descent/"" data-c="
          &lt;p&gt;本篇关键词：损失函数/代价函数/误差函数、梯度下降、学习率、Momentum（动量）&lt;br&gt;
损失函数也可以理解为代价函数，机器学习中通常指同一种东西&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV18P4y1j7uH/?spm_id_from=333.788.recommend_more_video.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【梯度下降】3D可视化讲解通俗易懂&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1oY411N7Xz/?spm_id_from=333.337.search-card.all.click&#34;&gt;5分钟深度学习-01 梯度下降算法&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1bP4y1p7Gq/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;72 优化算法【动手学深度学习v2】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;梯度下降算法，拿最简单的线性拟合的例子，首先随机取一条直线 y=wx+b 计算每个真实数据点 xi 和预测值 yi 的差值的平方和，对所有点求和，然后求一个平均，其实就是在求样本的 MSE 均方误差。&lt;br&gt;
MSE 越小代表直线对整体点的拟合效果越好，任务就是求 MSE 这个式子的最小值。&lt;br&gt;
进行整理后发现，可以将这个式子变为一个二次函数的形式，最小值即对称轴所在点。&lt;br&gt;
而机器学习中不能一下看出来，所以采取 GD 算法通过逐步迭代找出这个最小值&lt;br&gt;
&lt;strong&gt;权重w = w - 学习率 x 梯度&lt;/strong&gt;&lt;br&gt;
梯度下降步骤：1. 定义损失函数 2. 选择起始点 3. 计算梯度 4. 按照学习率前进&lt;br&gt;
重复3，4，直到找到最低点&lt;/p&gt;
&lt;h2 id=&#34;三种梯度下降&#34;&gt;三种梯度下降&lt;/h2&gt;
&lt;p&gt;梯度下降（Gradient Descent）：使用所有样本进行梯度下降，更新方向正确，但计算成本高&lt;br&gt;
随机梯度下降（Stochastic GD）：每次只使用一个样本进行梯度下降，更新快，可以跳出局部最优解，但方向不稳定，可能永远不会收敛&lt;br&gt;
小批量样本梯度下降（Mini Batch GD）：每次使用小批量样本进行梯度下降，结合GD和SGD的优点，较稳定，且更新迭代较快，能跳出局部最优解&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV13p4y1g7eQ/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;什么是小批量梯度下降，和批量梯度下降、随机梯度下降有什么不同&lt;/a&gt;&lt;br&gt;
能使用 SGD 和 Mini Batch GD 都是因为导数是线性可加的，可以求多次梯度进行迭代&lt;/p&gt;
&lt;p&gt;🔺目前，小批量样本梯度下降即为 ML、DL 中的默认方法。因为现在的项目数据量通常都很大，无法一次输入内存，需要通过设置 batch size 来决定一次参数更新所用的样本数量。&lt;/p&gt;
&lt;p&gt;🔺Adam：是 SGD 的优化版本，目前使用最广泛的优化算法，一般情况下使用 Adam 都没有问题&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/395685065/answer/2535950728&#34;&gt;怎么通俗易懂的理解SGD中Momentum的含义？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_42109740/article/details/105401197&#34;&gt;深度学习各类优化器详解（动量、NAG、adam、Adagrad、adadelta、RMSprop、adaMax、Nadam、AMSGrad）&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Q：模型评估方法和损失函数使用的函数是否相同？
A：在深度学习中，模型评估方法和损失函数使用的函数通常是不同的，
尽管有些情况下可能会相同或者有所重叠。这两者之间的主要区别在于它们的目的和应用场景：

1. 损失函数（Loss Functions）：
   - 目的：损失函数是在模型训练过程中使用的，目的是量化模型预测的好坏。
   损失函数衡量的是模型预测值和实际值之间的不一致程度。
   训练深度学习模型的目标就是通过优化算法（如梯度下降）最小化这个损失函数。
   - 常见例子：均方误差（MSE）用于回归任务，交叉熵损失用于分类任务，
   以及其他更专业的损失函数，如对抗损失、对比损失等，它们适用于特定类型的深度学习任务。

2. 模型评估方法（Evaluation Metrics）：
   - 目的：模型评估方法用于在模型训练完成后评估模型的性能。
   这些评估指标帮助我们理解模型在实际应用中的表现，比如它的准确度、召回率、F1 分数等。
   - 常见例子：对于分类问题，常用的评估指标包括准确率、精确率、召回率和 F1 分数等。
   对于回归问题，常用的评估指标包括均方误差（MSE）、均方根误差（RMSE）和平均绝对误差（MAE）等。

虽然某些函数既可以用作损失函数也可以用作评估指标（例如，均方误差可以用作回归任务的损失函数，
也可以用来评估回归模型的性能），但它们的用途和上下文是不同的。
评估指标通常被选用来直观地反映模型的性能，而不一定是为了指导模型的训练过程。
此外，一些评估指标（如准确率或F1 分数）并不总是可导的，因此不适合直接用作损失函数进行模型优化。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;MSE 和 方差的辨析&lt;/strong&gt;&lt;br&gt;
均方误差（Mean Squared Error, MSE）和方差（Variance）是两个相关的概念，但它们并不相同。&lt;br&gt;
&lt;strong&gt;均方误差（MSE）&lt;/strong&gt; 是一种用于衡量模型预测值与实际值之间差异的指标。它是&lt;code&gt;预测值&lt;/code&gt;与&lt;code&gt;实际值&lt;/code&gt;之差的平方的平均值，公式如下：&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mtext&gt;MSE&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mfrac&gt;&lt;msubsup&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mover accent=&#34;true&#34;&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\text{MSE} = \frac{1}{n}\sum_{i=1}^{n}(Y_i - \hat{Y_i})^2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord text&#34;&gt;&lt;span class=&#34;mord&#34;&gt;MSE&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.190108em;vertical-align:-0.345em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.845108em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.345em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop&#34;&gt;&lt;span class=&#34;mop op-symbol small-op&#34; style=&#34;position:relative;top:-0.0000050000000000050004em;&#34;&gt;∑&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.804292em;&#34;&gt;&lt;span style=&#34;top:-2.40029em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mrel mtight&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2029em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.29971000000000003em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.19677em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord accent&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.9467699999999999em;&#34;&gt;&lt;span style=&#34;top:-3em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.22222em;&#34;&gt;Y&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.25233em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;accent-body&#34; style=&#34;left:-0.25em;&#34;&gt;^&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;
&lt;strong&gt;方差（Variance）&lt;/strong&gt; 是统计学中衡量一组数据分散程度的指标。它是各个&lt;code&gt;数据点&lt;/code&gt;与&lt;code&gt;数据平均值&lt;/code&gt;之差的平方的平均值，公式如下：&lt;br&gt;
&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mtext&gt;Variance&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mfrac&gt;&lt;msubsup&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msubsup&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\text{Variance} = \frac{1}{n}\sum_{i=1}^{n}(X_i - \mu)^2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.68333em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord text&#34;&gt;&lt;span class=&#34;mord&#34;&gt;Variance&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2777777777777778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.190108em;vertical-align:-0.345em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mopen nulldelimiter&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.845108em;&#34;&gt;&lt;span style=&#34;top:-2.6550000000000002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.23em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line&#34; style=&#34;border-bottom-width:0.04em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.394em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.345em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mop&#34;&gt;&lt;span class=&#34;mop op-symbol small-op&#34; style=&#34;position:relative;top:-0.0000050000000000050004em;&#34;&gt;∑&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.804292em;&#34;&gt;&lt;span style=&#34;top:-2.40029em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mrel mtight&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2029em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.29971000000000003em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.31166399999999994em;&#34;&gt;&lt;span style=&#34;top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathdefault mtight&#34;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.064108em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;μ&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8141079999999999em;&#34;&gt;&lt;span style=&#34;top:-3.063em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
`拓展阅读`
[SGD有多种改进的形式(RMSprop,Adadelta等),为什么大多数论文中仍然用SGD?](https://www.zhihu.com/question/42115548/answer/1636798770)
[PyTorch学习之 torch.optim 的6种优化器及优化算法介绍](https://blog.csdn.net/qq_36589234/article/details/89330342)&lt;/code&gt;&lt;/pre&gt;
">【ML】以梯度下降（Gradient Descent）展开的优化器总结</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/kpl-yu-yan/"" data-c="
          &lt;h1 id=&#34;编译过程&#34;&gt;编译过程&lt;/h1&gt;
&lt;p&gt;编译 package Hello 生成 Hello.s&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;kpl Hello
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;编译 Hello.s 生成 Hello.o&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;asm Hello.s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;combine all of the &amp;quot;.o&amp;quot; object files into an executable file&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;lddd System.o Hello.o Runtime.o -o Hello
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;with the &amp;quot;-o&amp;quot; option , the new file will be named &amp;quot;Hello&amp;quot; or will be &amp;quot;a.out&amp;quot;&lt;/p&gt;
&lt;p&gt;To run the package &amp;quot;Hello&amp;quot;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-C&#34;&gt;blitz -g Hello
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&amp;quot;-g&amp;quot; means run it directly&lt;/p&gt;
&lt;p&gt;After execution completes,enter &amp;quot;q&amp;quot; to quit&lt;/p&gt;
&lt;h1 id=&#34;the-header-and-code-files&#34;&gt;The Header and Code Files&lt;/h1&gt;
&lt;p&gt;A program is made of several packages and each package is described by a header file and a code file&lt;/p&gt;
&lt;p&gt;The header file is the specification for the package. It provides the external interface to that package,giving all information other packages will need about what is in the package. In the Hello-World example, the file “Hello.h” specifies the package will contain a function called “main” and tells what parameters this function takes and returns. (The main function takes no parameters and returns no results.)&lt;/p&gt;
&lt;p&gt;The code file contains the implementation details for the package. All executable code appears in the code file. In the Hello-World example, the “Hello.c” file contains the actual code for the main function&lt;/p&gt;
&lt;h1 id=&#34;编译过程-2&#34;&gt;编译过程&lt;/h1&gt;
&lt;p&gt;直接输入 make，在文件夹内会根据 makefile 中的规则编译所有文件&lt;br&gt;
再次输入 blitz -g os 运行所有代码&lt;/p&gt;
&lt;p&gt;https://github.com/ayushishri/OS-Blitz-Labs&lt;/p&gt;
">KPL 语言</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/mnist-shou-xie-shu-zi-shi-bie/"" data-c="
          &lt;p&gt;MNIST：手写数字&lt;br&gt;
50000张训练图片&lt;br&gt;
10000张测试图片&lt;br&gt;
图像大小：28x28&lt;br&gt;
10个类别（0-9）&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1t44y1r7ct/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;23 经典卷积神经网络 LeNet【动手学深度学习v2】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/m0_58092763/article/details/125631991?spm=1001.2101.3001.6650.1&amp;amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-125631991-blog-112980305.t5_landing_title_tags&amp;amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-125631991-blog-112980305.t5_landing_title_tags&amp;amp;utm_relevant_index=2&#34;&gt;手把手实战PyTorch手写数据集MNIST识别项目全流程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/wqy1837154675/article/details/108003698&#34;&gt;pytorch读取MNIST数据集并显示&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;理论&#34;&gt;理论&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;数据读取和预处理&lt;/strong&gt;&lt;br&gt;
CUDA：显卡驱动，有了CUDA显卡才能进行复杂运算&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/wuzhongqiang/article/details/105499476&#34;&gt;数据读取 DataLoader 和 图像预处理 transforms 详解（这篇值得反复阅读）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.jianshu.com/p/22c50ded4cf7&#34;&gt;深度学习 | 三个概念：Epoch, Batch, Iteration&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_43135178/article/details/115133115&#34;&gt;使用 transforms.Compose() 将图像变换方法整合在一起&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_37555071/article/details/107532319&#34;&gt;torchvision.transforms 对有限的图片数据进行各种变换，如缩小或者放大图片的大小、对图片进行水平或者垂直翻转等，这些都是数据增强的方法。&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.pudn.com/news/6355f71da4b7e43a5ea8bc09.html#%E3%80%90%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E3%80%91&#34;&gt;使用sklearn实现对数据集划分，从而进行交叉验证&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可视化工具包&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/zkp_987/article/details/81748098&#34;&gt;以进度条形式可视化迭代器运行的包：tqdm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1K64y1Q7wu?p=3&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;李沐 Softmax 函数&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;对 softmax 回归的感性理解：&lt;br&gt;
线性回归模型多输入，单输出，而 softmax 多输入，多输出。输出结果为输入的向量所属类别，由于类别有多个，所以多输出。输出概率最大的为所属类别。但由于直接输出的概率值 总和不一定为1，且可能有负值，所以对多个输出结果进行 softmax 方法的计算，从而使得输出结果为 总和为1，且均为正值的概率值。&lt;/p&gt;
&lt;h1 id=&#34;实现&#34;&gt;实现&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 导入库
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from sklearn.model_selection._split import KFold
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 定义超参数
BATCH_SIZE = 128  # 每批处理的数据量
DEVICE = torch.device(&amp;quot;cuda&amp;quot; if torch.cuda.is_available() else &amp;quot;cpu&amp;quot;)  # 用CPU还是GPU训练
EPOCHS = 10  # 定义总训练次数
k_split_value = 5  # 定义 5 折交叉验证
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 定义图像处理方法
tranform = transforms.Compose([
    transforms.ToTensor(),  # 将图片转换成Tensor
    transforms.Normalize((0.1307,), (0.3081,))  # 进行数据归一化处理
])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 下载、加载数据集
from torch.utils.data import DataLoader

train_data = datasets.MNIST(root=&amp;quot;./MNIST&amp;quot;,
                            train=True,
                            transform=tranform,
                            download=False)  # 注，如果已经下载了一遍，也需要用该命令设置data的路径

test_data = datasets.MNIST(root=&amp;quot;./MNIST&amp;quot;,
                           train=False,
                           transform=tranform,
                           download=False)

# 将测试集和训练集合并，以便后续对数据集进行分割
dataFold = torch.utils.data.ConcatDataset([train_data, test_data])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 构建网络模型，使用 AlexNet
class AlexNet(nn.Module):
    def __init__(self):
        super(AlexNet, self).__init__()

        # 由于MNIST为28x28， 而最初AlexNet的输入图片是227x227的。所以网络层数和参数需要调节
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # AlexCONV1(3,96, k=11,s=4,p=0)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # AlexPool1(k=3, s=2)
        self.relu1 = nn.ReLU()

        # self.conv2 = nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # AlexCONV2(96, 256,k=5,s=1,p=2)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # AlexPool2(k=3,s=2)
        self.relu2 = nn.ReLU()

        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  # AlexCONV3(256,384,k=3,s=1,p=1)
        # self.conv4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1)
        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)  # AlexCONV4(384, 384, k=3,s=1,p=1)
        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)  # AlexCONV5(384, 256, k=3, s=1,p=1)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # AlexPool3(k=3,s=2)
        self.relu3 = nn.ReLU()

        self.fc6 = nn.Linear(256 * 3 * 3, 1024)  # AlexFC6(256*6*6, 4096)
        self.fc7 = nn.Linear(1024, 512)  # AlexFC6(4096,4096)
        self.fc8 = nn.Linear(512, 10)  # AlexFC6(4096,1000)
        self.dropout = nn.Dropout(p=0.5)

    def forward(self, x):
        x = self.conv1(x)
        x = self.pool1(x)
        x = self.relu1(x)
        x = self.conv2(x)
        x = self.pool2(x)
        x = self.relu2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.pool3(x)
        x = self.relu3(x)
        x = x.view(-1, 256 * 3 * 3)  # Alex: x = x.view(-1, 256*6*6)
        x = self.fc6(x)
        x = self.dropout(x)
        x = F.relu(x)
        x = self.fc7(x)
        x = self.dropout(x)
        x = F.relu(x)
        x = self.fc8(x)
        return x
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 定义优化器
model = AlexNet().to(DEVICE)
optimizer = optim.Adam(model.parameters())  # 使用 Adam 优化器
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 定义训练方法
def train_model(model, device, train_loader, optimizer, epoch):
    model.train()  # PyTorch 提供的训练方法
    for batch_index, (data, label) in enumerate(train_loader):
        # 部署到DEVICE
        data, label = data.to(device), label.to(device)
        # 梯度初始化为0
        optimizer.zero_grad()
        # 训练后的结果
        output = model(data)
        # 计算损失（针对多分类任务交叉熵，二分类用sigmoid）
        loss = F.cross_entropy(output, label)
        # 找到最大概率的下标
        pred = output.argmax(dim=1)
        # 反向传播Backpropagation
        loss.backward()
        # 参数的优化
        optimizer.step()
        if batch_index % 3000 == 0:
            print(&amp;quot;Train Epoch : {} \t Loss : {:.6f}&amp;quot;.format(epoch, loss.item()))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 定义测试方法
def test_model(model, device, test_loader):
    # 模型验证
    model.eval()
    # 统计正确率
    correct = 0.0
    # 测试损失
    test_loss = 0.0
    with torch.no_grad():  # 不计算梯度，不反向传播
        for data, label in test_loader:
            data, label = data.to(device), label.to(device)
            # 测试数据
            output = model(data)
            # 计算测试损失
            test_loss += F.cross_entropy(output, label).item()
            # 找到概率值最大的下标
            pred = output.argmax(dim=1)
            # 累计正确率
            correct += pred.eq(label.view_as(pred)).sum().item()
        test_loss /= len(test_loader.dataset)
        print(&amp;quot;Test —— Average loss : {:.4f}, Accuracy : {:.3f}\n&amp;quot;.format(test_loss,
                                                                          100.0 * correct / len(test_loader.dataset)))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 对数据进行 K 折交叉划分并且调用前面的方法训练模型
def KFold_and_Train(k_split_value):
    counter = 1  # 自定义一个交叉验证计数器
    kf = KFold(n_splits=k_split_value, shuffle=True, random_state=0)  # 定义K折交叉验证的方法
    for train_index, test_index in kf.split(dataFold):  # 使用kf方法将dataFold分成测试集和验证集
        print(f&amp;quot;第{counter}次交叉验证&amp;quot;)
        counter += 1  # 计数器自增1

        # get train, val
        train_fold = torch.utils.data.dataset.Subset(dataFold, train_index)
        test_fold = torch.utils.data.dataset.Subset(dataFold, test_index)

        # package type of DataLoader
        train_loader = torch.utils.data.DataLoader(dataset=train_fold, batch_size=BATCH_SIZE, shuffle=True)
        test_loader = torch.utils.data.DataLoader(dataset=test_fold, batch_size=BATCH_SIZE, shuffle=True)

        # training and test
        for epoch in range(EPOCHS):
            train_model(model, DEVICE, train_loader, optimizer, epoch)
            test_model(model, DEVICE, test_loader)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 调用函数
KFold_and_Train(k_split_value)
&lt;/code&gt;&lt;/pre&gt;
">【CV】MNIST 手写数字识别</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/novelai-shi-yong/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1EV4y1L7dX/?vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;启动：浏览器输入域名：127.0.0.1:6969&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/572865961&#34;&gt;参数教程&lt;/a&gt;&lt;/p&gt;
">Novelai 使用</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ru-he-yong-ying-yu-si-kao/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1TD4y1q7u9/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;b站&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;reading&#34;&gt;Reading&lt;/h1&gt;
&lt;p&gt;阅读帮助建立特定单词的特定语境&lt;/p&gt;
&lt;h1 id=&#34;new-words&#34;&gt;New Words&lt;/h1&gt;
&lt;p&gt;看全英文的单词解释，用英语解释英语，形成英语思维。如果用中文，那么还是在用中文思考。&lt;br&gt;
学习一个单词的所有变形，尽量学习所有意思&lt;br&gt;
在语境中学习&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.vocabulary.com/&#34;&gt;vocabulary 英文单词查询网站&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;#Idioms&lt;br&gt;
在正确的情况下正确使用谚语&lt;/p&gt;
">如何用英语思考？</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/dian-nao-cao-zuo/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1T54y177W2/?vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;一键禁用电脑键盘&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://baijiahao.baidu.com/s?id=1634287239598842140&#34;&gt;用 Excel 打开 CSV 格式文件乱码&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;全半角切换：&lt;br&gt;
电脑设置中启用 shift+空格切换全半角&lt;br&gt;
使用全角模式，在markdown中输入空格，则会显示空格&lt;/p&gt;
">电脑操作</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/liu-ji/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.hjenglish.com/new/p1334552/&#34;&gt;分值分布&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/373774215&#34;&gt;时间安排&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhenti.burningvocabulary.com/login?uid=632280fbaafe55b3c209ddb6&#34;&gt;做题的神仙网站（随时更新，能看单词意思）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;高级词同义替换；使用复杂句式；灵活使用时态、语态&lt;/p&gt;
&lt;h1 id=&#34;六级作文类型&#34;&gt;六级作文类型&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;第一段
1~2 句提出问题，3过渡句

第二段
论点1 论据1
论点2 论据2
论点3 论据3

第三段
重申观点
提出希望
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;观点对立 / 分析利弊&lt;br&gt;
Some people think its bad others think its good&lt;/p&gt;
&lt;p&gt;议论型&lt;/p&gt;
&lt;p&gt;&lt;code&gt;作文模板&lt;/code&gt;&lt;br&gt;
第一段&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;In the contemporary world 当今世界
there is no consensus among colledge students about the choice of career 没有定论
this proverb reveals that 
according to a recent survey conducted by
with the rapid growth of online shopping 
The popularity of smartphones makes the smartphone addiction increasingly commonplace

引起社会广泛关注
this phenomenon has become a worldwide social problem
... has stirred wide social concern

 反应了很多人对于...的看法
the concept of ... is gaining more popularity and striking deeper roots in people&#39;s heart
it reflects a number of people&#39;s concepts about ...
people come to realize that it is of practical value to stick to the famous saying:

引出谚语
As the well-known proverb goes
Though it is the insight summarized by our forefathers, it is correct and applicable in many case today.

解释谚语
The message it conveys is that

过渡句
Among countless reasons which support my view, there are three conspicuous aspects as follow
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第二段&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;First and foremost, there is no doubt that ...
Moreover no one can deny that 
Last but not least, i firmly believe that


&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第三段&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;in conclusion / To sum up / All in all
while stressing... we should not neglect...

joint efforts should be made to promote...
we spare no efforts to do
if we try our upmost to do
the more.. the more...

our future will be both hopeful and rosy
The pursuit of ... should never be ceased 追逐...的步伐从不应该停止

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;高级短语&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;I deem that 我认为
particularly 非常
as it literally shows
the reason why
the overwhelming majority of 绝大多数
be reluctant to 不情愿
of practical value to do 有实际意义做
stick to 
reflect 反映
remarkable
reveal 揭示
tend to 
a high population of 56 percent of people
Thus
its urgent to do
as is universally acknowledged 
be of great significance
increasingly important
people believe that
extend to
the popularity of 
exerts multiple adverse impacts 造成多重不利影响
individual
all-pervasive 无所不在
quit a few peoper would deem that ... 少数人会认为
in contrast
intriguing 有趣
modern citizens
enhance
its obvious that
it&#39;s a high time that
joint efforts from relative authorities, teachers and students are required
Do bear in mind: 一定要记住
attach importance to
reinforce
one should adapt himself to the environment
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;阅读&#34;&gt;阅读&lt;/h1&gt;
&lt;p&gt;找和题干最匹配的句子，句意、同义词替换&lt;br&gt;
读句子抓主谓宾，副词、形容词实在不知道可以先不卡看&lt;br&gt;
对比相似选项，看哪个和原文最匹配，防止误选&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;段落匹配&lt;/strong&gt;&lt;br&gt;
先读题干句子，抓关键词&lt;br&gt;
看首尾句，明确段意&lt;br&gt;
抓句子关键词，带回段落定位&lt;/p&gt;
">六级</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/linux-ubuntu/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/m0_47668487/article/details/115289154&#34;&gt;VMware下安装Ubuntu系统并编译运行C语言程序&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_44301630/article/details/122390018?app_version=5.7.5&amp;amp;code=app_1562916241&amp;amp;csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22122390018%22%2C%22source%22%3A%22unlogin%22%7D&amp;amp;uLinkId=usr1mkqgl919blen&amp;amp;utm_source=app&#34;&gt;WSL2 Ubuntu 安装 /该方法的图形界面安装出错&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1M94y1U7nc/?spm_id_from=333.788.recommend_more_video.-1&amp;amp;vd_source=0c47757b752e4a1eb04429ea32a157dc&#34;&gt;VMware 安装&lt;/a&gt;&lt;br&gt;
该版本安装包：&lt;br&gt;
链接：https://pan.baidu.com/s/14I13g2N6hdeQf6RpL6Y9_g?pwd=xf0c&lt;br&gt;
提取码：xf0c&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/top_worker/article/details/45918399&#34;&gt;Ubuntu 教程&lt;/a&gt;&lt;br&gt;
Tasksel 安装出错&lt;br&gt;
解决：&lt;a href=&#34;https://mlog.club/article/3125331&#34;&gt;系统范围的安装都需要 root 权限，使用 sudo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Davidietop/article/details/88909622&#34;&gt;failed to fetch/配置 DNS 网关&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;进入 ROOT 模式：root -i&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_42175986/article/details/82770878&#34;&gt;文件操作&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_43798960/article/details/106891641&#34;&gt;保存文件并退出&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1w741147G9?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;环境变量讲解1&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1nS4y1o7LG?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;环境变量讲解2&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1pZ4y1N7pr?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;Linux 环境变量&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/K_K_yl/article/details/119756206&#34;&gt;环境变量的配置&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/sydongjx/article/details/44081265&#34;&gt;解决bash:没有那个文件或目录的方法&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Joker00007/article/details/122526177&#34;&gt;Ubuntu报错 写入失败(设备上没有空间)&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;使用vmware配置ubuntu&#34;&gt;使用VMware配置Ubuntu&lt;/h1&gt;
&lt;p&gt;使用VMware安装时，界面显示不全：按住win键 然后按住鼠标左键拖动， 安装完再去设置vmware&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/130984945&#34;&gt;VMware虚拟机网络配置-NAT篇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;共享文件夹加载问题：在虚拟机中刷新文件夹，点向下的箭头，点击重新加载刷新&lt;/p&gt;
">【Linux】Ubuntu配置与安装</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/linux-shell/"" data-c="
          &lt;p&gt;&lt;a href=&#34;http://c.biancheng.net/linux_tutorial/&#34;&gt;Linux 教程1&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.runoob.com/linux/linux-tutorial.html&#34;&gt;Linux 教程2&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.runoob.com/linux/linux-intro.html&#34;&gt;Linux shell 教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_72910567/article/details/132418542#:~:text=Windows%20%E7%B3%BB%E7%BB%9F%E4%B8%8B%EF%BC%9ASSH%20%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%20Linux%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97%201%20Ubuntu%3A%201.,HOST%20IDENTIFICATION%20HAS%20CHANGED%21%20...%205%20%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%201.%E8%AF%B7%E7%A1%AE%E4%BF%9D%E4%BD%A0%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%9A%84%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E7%8A%B6%E5%86%B5%E8%89%AF%E5%A5%BD&#34;&gt;Windows 系统下：SSH 远程连接 Linux 服务器的完整指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bash 是 Shell 的一种&lt;/p&gt;
&lt;p&gt;对于 Windows 而言，其 cmd 和 powershell 都属于 shell 程序，但 cmd 能干的事 powershell 都能干。&lt;a href=&#34;https://zhuanlan.zhihu.com/p/390464588#:~:text=powershell%E5%92%8Ccmd%E5%8C%BA%E5%88%AB%EF%BC%9A1%E3%80%81CMD%E5%86%99%E7%9A%84BAT%E8%84%9A%E6%9C%AC%E6%88%91%E4%BB%AC%E7%9C%8B%E4%BD%9C%E6%98%AF%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B%E7%9A%84%EF%BC%8C%E8%80%8CPowerShell%E5%88%99%E6%98%AF%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%2C%E6%98%AF%E4%B8%80%E7%A7%8D%E7%AB%99%E5%9C%A8%E4%BD%BF%E7%94%A8%E8%80%85%E7%9A%84%E8%A7%92%E5%BA%A6%E8%BF%9B%E8%A1%8C%E8%84%9A%E6%9C%AC%E7%9A%84%E7%BC%96%E5%86%99%EF%BC%9B2%E3%80%81CMD%E5%8F%AA%E8%83%BD%E6%89%A7%E8%A1%8C%E5%9F%BA%E6%9C%AC%E7%9A%84%E4%BB%BB%E5%8A%A1%EF%BC%8CPowerShell%E5%9B%A0%E4%B8%BA%E6%98%AF%E5%9F%BA%E4%BA%8E%E3%80%90.NET%E3%80%91%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E3%80%82,%E6%9C%AC%E6%96%87%E6%93%8D%E4%BD%9C%E7%8E%AF%E5%A2%83%EF%BC%9Awindows7%E7%B3%BB%E7%BB%9F%E3%80%81Dell%20G3%E7%94%B5%E8%84%91%E3%80%82&#34;&gt;参考文章&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/u010300484/article/details/8879176&#34;&gt;bash shell元字符（通配符）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/568129962&#34;&gt;Linux Shell 内部命令与外部命令&lt;/a&gt;&lt;br&gt;
内部命令：常用命令，系统启动时就调入内存，且常驻内存的，由SHELL程序识别并在SHELL程序内部运行。&lt;br&gt;
外部命令：不常用命令，用户需要时才读入内存。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_34380781/article/details/85970198&#34;&gt;Linux程序命令行选项的3种风格：unix、gnu、x toolkit&lt;/a&gt;&lt;/p&gt;
">【Linux】Shell</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shu-ju-jie-gou-di-gui/"" data-c="
          &lt;p&gt;&lt;strong&gt;递归乘法的实现（未考虑负数版）&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def multi(a, b):  # 返回 b 个 a 的和
    if b == 0:
        return 0
    else:
        return multi(a, b-1) + a

print(multi(2,3))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;递归实现斐波那契数列&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def f(n):  # 斐波那契
    if n == 1:
        return 1
    elif n == 2:
        return 1
    else:
        return f(n - 1) + f(n - 2)


print(f(10))
&lt;/code&gt;&lt;/pre&gt;
">【数据结构】递归</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/sql/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.lintcode.com/course/14/learn/?chapterId=79&amp;amp;sectionId=530&#34;&gt;入门学习网站&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本博客练习数据获取网站：&lt;a href=&#34;https://www.db-book.com/&#34;&gt;https://www.db-book.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Kr4y1i7ru/?p=3&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;MySQL 启动&lt;/a&gt;&lt;br&gt;
以管理员启动 cmd，输入 net start mysql80 启动服务，输入 net stop mysql80 关闭服务&lt;br&gt;
在启动服务之后，找到 MySQL 8.0 Command Line Client ，输入密码即可访问数据库&lt;/p&gt;
&lt;p&gt;MySQL IDE —— Workbench&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1PY411b7Y2/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;基础教学&lt;/a&gt;&lt;br&gt;
单条运行快捷键：选中单条语句，CTRL + enter&lt;br&gt;
格式化：选中代码块 CTRL + B&lt;/p&gt;
&lt;p&gt;SQL 不区分大小写，注意句尾一定加分号&lt;/p&gt;
&lt;p&gt;SQL shell 中使用向上箭头复制刚才输入的命令&lt;/p&gt;
&lt;h1 id=&#34;mysql-语法&#34;&gt;MySQL 语法&lt;/h1&gt;
&lt;h1 id=&#34;ddl-data-definition-language&#34;&gt;DDL （Data Definition Language）&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;数据定义语言，用于定义数据库对象&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;查询所有数据库（注意一定分号结尾&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;show databases;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查询当前正在使用的数据库&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select database();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;创建数据库 （中括号中为可选内容&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create database [if not exists] 数据库名 [default charset 字符集] [collate 排序规则];
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除数据库&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;drop database [if exists] 数据库名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用数据库&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;use 数据库名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;数据库中的表操作&lt;/strong&gt;&lt;br&gt;
查询当前数据库中所有的表&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;show tables;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查询表结构&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;desc 表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;创建表&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create table 表名(
    字段1 字段1类型 comment 字段1 注释,
    字段2 字段2类型 comment 字段2 注释,
    ...
    字段n 字段n类型 comment 字段n 注释
) comment 注释;

例子：
create table sheet1(
id int comment &#39;编号&#39;,
name varchar(50) comment &#39;姓名&#39;,
age int comment &#39;年龄&#39;
)comment &#39;用户表&#39;;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查询指定表的建表语句&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;show create table 表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加字段&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 add 字段名 类型(长度) [comment 注释] [约束];  

例子：
alter table sheet1 add nickname varchar(10) comment &#39;昵称&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改数据类型&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 modify 字段名 新数据类型(长度);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改字段名和字段类型&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 change 旧字段名 新字段名 数据类型(长度) [comment 注释] [约束];  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除字段&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 drop 字段名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改表名&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;alter table 表名 rename to 新表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除表&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;drop table [if exists] 表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除表，并重新创建表（等价于清除表内所有数据）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;truncate table 表名;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;dmldata-manipulation-language&#34;&gt;DML（Data Manipulation Language）&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;数据操作与语言，用于增删改&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;向表中插入数据，注意列名和 values 的对应关系&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;insert into 表名 (字段名1, 字段名2, ...) values(值1, 值2, ...);

例：
insert into test (id, name, age, username) values(1, &amp;quot;jerome&amp;quot;, 20, &#39;zjl&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;向表中全部字段插入数据&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;insert into 表名 values(值1, 值2, ...);

例：
insert into test values(1, &amp;quot;jerome&amp;quot;, 20, &#39;zjl&#39;);

Add a new tuple to student with tot_creds set to null

insert into student
values (’3003’, ’Green’, ’Finance’, null);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;批量插入用逗号分隔每一行&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;例：
insert into test values(1, &amp;quot;jerome&amp;quot;, 20, &#39;zjl&#39;), (2, &amp;quot;raymond&amp;quot;, 21, &#39;R&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;加 select&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;Add all instructors to the student relation with tot_creds set to 
0

insert into student
select ID, name, dept_name, 0
from instructor
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改数据（注，若安全模式报错：&lt;a href=&#34;https://www.cnblogs.com/willingtolove/p/12368712.html&#34;&gt;解决方案&lt;/a&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;update 表名 set 字段名1 = 值1, 字段名2 = 值2, ... [where 条件];

例：
update test set name = &#39;Jerome&#39; where id = 1;

修改整列：
update test set age = 30;

Increase salaries of instructors whose salary is over 
$100,000 by 3%, and all others by a 5% 

update instructor
set salary = salary * 1.03
where salary &amp;gt; 100000;
update instructor
set salary = salary * 1.05
where salary &amp;lt;= 100000;

case 版本：
update instructor
set salary = case
                    when salary &amp;lt;= 100000 then salary * 1.05
                    else salary * 1.03
                    end

Recompute and update tot_creds value for all students

update student S 
set tot_cred = (
select sum(credits)
from takes, course
where takes.course_id = course.course_id and 
S.ID= takes.ID.and 
takes.grade &amp;lt;&amp;gt; &#39;F&#39; and
takes.grade is not null);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除数据&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;delete from 表名 [where 条件];

例：
delete from test where gender = male;

Delete all tuples in the instructor relation for those instructors 
associated with a department located in the Watson building.

delete from instructor
where dept name in (select dept name
from department
where building = ’Watson’);

Delete all instructors whose salary is less than the average 
salary of instructors

delete from instructor
where salary &amp;lt; (select avg (salary) 
from instructor);

删除所有数据：
delete from test;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;dqldata-query-language&#34;&gt;DQL（Data Query Language）&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;数据查询语言，用于查询数据库中表的记录&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;DQL 语句的编写顺序&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select 
    字段列表
from
    表名列表
where
    条件列表
group by
    分组字段列表
having
    分组后条件列表
order by
    排序字段列表
limit
    分页参数
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DQL 语句的执行顺序&lt;br&gt;
执行顺序影响了变量别名的使用顺序&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;from
    表名列表
where
    条件列表
group by
    分组字段列表
having
    分组后条件列表
select 
    字段列表
order by
    排序字段列表
limit
    分页参数
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查询多个字段&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select 字段1,字段2, ... from 表名;

查询所有字段
select * from 表名;

例：
select id,name from student;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;设置别名&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select 字段1 as 别名1, 字段2 as 别名2, ... from 表名;

例：
select name as &amp;quot;姓名&amp;quot; from student;

as 可以省略：
select name &amp;quot;姓名&amp;quot; from student;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;去重查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select distinct 字段列表 from 表名;

例：
select distinct dept_name &amp;quot;课程&amp;quot; from student;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;条件查询 where&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select 字段列表 from 表名 where 条件列表;

多种条件的案例：
普通条件
select * from student where name = &#39;Zhang&#39;;
select ID,tot_cred from student where name = &#39;Zhang&#39;;

不等关系
select * from student where tot_cred &amp;lt;= 60;
select * from student where tot_cred != 60;

查询空值
select * from student where tot_cred is null;

查询非空值
select * from student where tot_cred is not null;

区间查找
select * from student where tot_cred &amp;gt; 50 and tot_cred &amp;lt;= 60;
select * from student where tot_cred between 50 and 60;
注：between and 既包含最大也包含最小

多条件查找
select * from student where dept_name = &amp;quot;Physics&amp;quot; and tot_cred &amp;lt;= 60;

使用元组进行比较
select *
from instructor, teaches
where (instructor.ID, dept_name) = (teaches.ID, &#39;Biology&#39;);
等价于
where instructor.ID = teaches.ID, dept_name = &#39;Biology&#39;;

或关系查找
select * from student where dept_name = &amp;quot;Physics&amp;quot; or dept_name = &amp;quot;Music&amp;quot;;
select * from student where dept_name in(&amp;quot;Physics&amp;quot;,&amp;quot;Music&amp;quot;);

模糊查询 like
匹配七个字长的名字，like 后加七个下划线
select * from student where dept_name like &#39;_______&#39;;
匹配最后一位 / 最后几位：查询以 Sci. 结尾的课程名，%代表匹配前面所有字符
select * from student where dept_name like &#39;%Sci.&#39;;
匹配名字中含有 da 的 instructor
select name 
from instructor
where name like &#39;%da%&#39;
使用“\”转义
select *
from sheet
where score like &#39;100 \%&#39; escape &#39;\&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;常见聚合函数。用于对列进行操作&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;count 统计数量
max 最大值
min 最小值
avg 平均值
sum 求和

语法：
select 聚合函数(字段列表) from 表名;
注：所有的 null 值不参与聚合函数计算

例：
select count(*) from student;
select avg(tot_cred) from student;
select max(tot_cred) from student;
select min(tot_cred) from student;
select sum(tot_cred) from student where dept_name = &amp;quot;Comp. Sci.&amp;quot;;

找出在 Spring 2010 semester 教课的 instructor 总数
select count(distinct ID)
from teaches
where semester = &#39;Spring&#39; and year = 2010;
注意，以 ID 为统计对象，并注意去重
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分组查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;语法：
select 字段列表 from 表名 [where 条件] group by 分组字段名 [having 分组后过滤条件];
先满足 where 条件，再满足 having 条件；where 中不能使用聚合函数，having 中可以

例：
按照课程名称统计数量
select dept_name, count(*) 
from student 
group by dept_name;

按照课程名称分组，统计平均得分
select dept_name, avg(tot_cred) 
from student 
group by dept_name;

查询总分小于 60 的学生，按照课程名分组，获取选课人数等于 3 的课程
select dept_name, count(*) 
from student 
where tot_cred &amp;lt; 60 
group by dept_name 
having count(*) = 3;

注：分组查询后返回一般为聚合函数或分组字段。如果查询单个值是没有意义的，只显示第一个值
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;排序查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select 字段列表 from 表名 order by 字段1 排序方式1, 字段2 排序方式2;
先按字段1排，相同再按字段2排序

asc 表示升序，desc 表示降序
select * from student order by tot_cred asc;
select * from student order by tot_cred desc;

先按照总分进行升序排序，若总分相同，再按照学号进行降序排序
select * from student order by tot_cred asc, ID desc;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分页查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select 字段列表 from 表名 limit 起始索引, 查询记录数;
起始索引的计算公式：（当前页码数-1）x 每页记录数
起始索引从 0 开始

例：
查询第一页，每页 6 条记录
select * from student limit 0, 6;
可省略作：
select * from student limit 6;

查询第二页六条记录：
select * from student limit 6, 6;

查询第二页六条记录：
select * from student limit 12, 6;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;注&lt;/code&gt; 执行多个条件的时候，可以把每个条件加括号，看起来更清晰&lt;/p&gt;
&lt;p&gt;嵌套查询&lt;br&gt;
Find courses offered in Fall 2009 but not in Spring 2010&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select distinct course_id
from section
where semester = &#39;Fall&#39; and year= 2009 and 
course_id not in (
select course_id 
from section
where semester = &#39;Spring&#39; and year= 2010
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;多关系表查询&lt;br&gt;
由于要查询的数据在不同关系表中，所以要从多张表中查询数据&lt;br&gt;
&lt;strong&gt;一对多 / 多对一的关系&lt;/strong&gt;&lt;br&gt;
案例：部门 与 员工的关系，一个部门对应多个员工&lt;br&gt;
实现：在多的一方建立外键，指向一的一方的主键&lt;br&gt;
&lt;strong&gt;多对多的关系&lt;/strong&gt;&lt;br&gt;
案例：学生 与 选修课的关系，一个学生对应多个课程，一个课程也可以对应多个学生&lt;br&gt;
实现：建立第三张中间表，至少包含两个外键，分别关联两方的主键&lt;br&gt;
&lt;strong&gt;一对一的关系&lt;/strong&gt;&lt;br&gt;
案例：用户 与 用户详情的关系，将基础字段和详情字段拆分，提高查询效率&lt;br&gt;
实现：在任意一张表加入外键，关联另一方主键&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;例：
查找教艺术的所有教师姓名和课程 ID
select name, course_id
from instructor , teaches
where instructor.ID = teaches.ID and instructor. dept_name =  &#39;Art&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;注&lt;/code&gt;&lt;br&gt;
select name, course_id from instructor , teaches；这条语句将 instructor 和 teaches 表做笛卡尔积，是没有进行主键自动匹配等操作的，即 但看这个表是没有任何意义的。而后面的 where 语句条件限制，从 笛卡尔积得到的结果的一张大表 中 筛选出有意义的行数。&lt;br&gt;
　　from 子句中包括多个关系表时，一定要在 where 子句中加入连接条件！过滤掉无效的笛卡尔积（两个集合连接时每个元素会分别组合，但是只有键相同的组合是有用的）&lt;br&gt;
实际应用中，对频繁执行的SQL查询，其 from 子句中的表的个数不要过多，如不要超过4个！避免耗时费力的多表连接操作。&lt;br&gt;
如果频繁执行的 SQL 查询涉及的查询数据存放在 N≥4 张表中，可以考虑将这N张表中的数据进行合并&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_45404693/article/details/120630581?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166506743816782391878796%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;amp;request_id=166506743816782391878796&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-120630581-null-null.142%5Ev51%5Epc_rank_34_queryrelevant25,201%5Ev3%5Econtrol_2&amp;amp;utm_term=mysql%20join&amp;amp;spm=1018.2226.3001.4187&#34;&gt;MySQL 中 join 的用法&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_44747858/article/details/107720930?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166506743816782391878796%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;amp;request_id=166506743816782391878796&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-6-107720930-null-null.142%5Ev51%5Epc_rank_34_queryrelevant25,201%5Ev3%5Econtrol_2&amp;amp;utm_term=mysql%20join&amp;amp;spm=1018.2226.3001.4187&#34;&gt;MySQL 中 join 的用法，含有 natural join、using 等简化版语句&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以下三种写法都是取二者的笛卡尔积，但在加限定条件时，只有 带有 join 的语句才能用 on 和 using 语法&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select * from teaches, takes;
select * from teaches join takes;
select * from teaches cross join takes;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;natural join 自动匹配两表中键相同的列（注意，natural 一定不要拼错，要不会变成重命名语句）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select *
from instructor natural join teaches

等价于

select *
from instructor join teaches
using(ID)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;利用 natural join 简化语句：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT customer.customer_name
FROM customer
JOIN depositor ON customer.customer_id = depositor.customer_id
JOIN account ON depositor.account_number = account.account_number
JOIN branch ON account.branch_name = branch.branch_name
WHERE customer.city = &#39;Beijing&#39;
  AND branch.city = &#39;Tianjin&#39;
  AND account.balance &amp;gt; 100;

简化为

SELECT customer.customer_name
FROM customer
NATURAL JOIN depositor
NATURAL JOIN account
NATURAL JOIN branch
WHERE customer.city = &#39;Beijing&#39;
  AND branch.city = &#39;Tianjin&#39;
  AND account.balance &amp;gt; 100;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/94659348&#34;&gt;all/any/some/in&lt;/a&gt;&lt;br&gt;
用 A B 两个实数集合举例&lt;br&gt;
all：A &amp;gt; all( B ) ，则 A 中选出的数要比 B 中所有的数都大&lt;br&gt;
some/any：A &amp;gt; some/any( B )，则 A 中选出的数只要有比 B 中的数大的就行，选出的结果往往是原列表除去最小值后的列表&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;Find the names of all instructors whose salary is greater 
than the salary of all instructors in the Biology department.

select name
from instructor
where salary &amp;gt; all (
select salary
from instructor
where dept name = &#39;Biology&#39; 
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://www.runoob.com/sql/sql-exists.html&#34;&gt;EXISTS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.geeksforgeeks.org/sql-except-clause/&#34;&gt;Except&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;unique&lt;/strong&gt;&lt;br&gt;
如果作为参数的子查询结果中无重复元组，则 unique 返回 true&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;with as 的用法&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;Find all departments where the total salary is greater than 
the average of the total salary at all departments

with dept _total (dept_name, value) as
    (select dept_name, sum(salary)
    from instructor
    group by dept_name),
dept_total_avg(value) as
    (select avg(value)
    from dept_total)
select dept_name
from dept_total, dept_total_avg
where dept_total.value &amp;gt; dept_total_avg.value;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;解析：其中，dept _total 和 dept_total_avg 是两个临时创立的表，括号里是表定义的特征，分别对应 as 后面 select 后选出的特征。定义临时表后，在后续 select 语句中就可以直接使用。&lt;/p&gt;
&lt;p&gt;标量子查询（Scalar subquery）：只需要查询单个值&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select dept_name, 
(select count(*) 
from instructor 
where department.dept_name = instructor.dept_name)
as num_instructors
from department;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;解析：括号中 select count 语句只查询了单个值，将其命名为 num_instructors，作为外层 select 的子查询，表示 instructor 的数量&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;综合案例&lt;/strong&gt;&lt;br&gt;
找出工资高于 Comp. Sci. 学院的所有 instructors 的 instructors 名字&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select distinct T.name
from instructor as T, instructor as S
where T.salary &amp;gt; S.salary and S.dept_name = &#39;Comp. Sci.&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分析：利用 T 、S 重命名以区分不同的 instructor，实现了对同一属性的不同值的比较。&lt;/p&gt;
&lt;p&gt;从 2009 年秋季开设的每个课程段中，找出最多的选课人数。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select sec_id , max(countid)
from (
select sec_id, count(ID) countid
from takes
where semester = &amp;quot;Fall&amp;quot; and year = &#39;2009&#39;
group by sec_id
) as countidlist
group by sec_id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;视图 —— view&lt;/strong&gt;&lt;br&gt;
视图关系可以定义为包含查询结果的关系。可以隐藏不需要的信息，可以把信息从多个关系收集到一个单一的试视图中。&lt;/p&gt;
&lt;p&gt;创建视图&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create view com_instructor as(
select *
from instructor
where dept_name = &#39;Comp. Sci.&#39;
);
select *
from com_instructor;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除视图&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;drop view com_instructor;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;http://m.biancheng.net/sql/transaction.html&#34;&gt;&lt;strong&gt;事务——transaction&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
　　将一条/几条语句关联在一起，要么全部执行成功，要么全部执行失败。如果成功，则提交（Commit）如果其中有一条执行失败，则全部回滚（Rollback）（重新执行）防止数据库信息受损。&lt;br&gt;
事务有很多实用的场景。例如对于电商网站，通常将用户订单存储在一张表中，将商品库存情况存储在另一张表中，当有用户下单时，需要执行两条 SQL 语句，一条负责更新订单表，一条负责更新库存表，这两条 SQL 语句必须同时执行成功。如果只有一条语句执行成功，另一条语句执行失败，将导致数据库出错，这种后果是无法接受的。&lt;br&gt;
　　为了避免出现意外，可以将以上两条语句放到一个事务中，其中一条语句执行失败时，数据库将回滚到原来未修改的状态。对于买家来说，数据库回滚会导致下单失败，但这很容易处理，让买家再次下单即可。数据库的正确性永远是最重要的。&lt;br&gt;
　　其实我们平时使用数据库时，就已经在使用事务了，只不过这种事务只包含一条 SQL 语句，并且由数据库引擎自动封装和提交。这意味着，对于任何一条 SQL 语句，要么执行成功，要么执行失败，不能成功一部分，失败一部分。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;完整性约束&lt;/strong&gt;&lt;br&gt;
保证授权用户对数据库做出的改变不会导致数据一致性的破坏，在创建表的时候添加关键字添加约束&lt;br&gt;
常用约束总结：&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1669360961356.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
主键约束 primary key&lt;br&gt;
该项为主键，唯一且非空&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create table student_1(
    id varchar(10) primary key,
    name varchar(15),
    age int(2),
    sex varchar(1)
)
desc student_1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;唯一约束 unique&lt;br&gt;
指该项在表中不能重复&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create table student(
	id int(8),
	name varchar(20) unique,
	school varchar(10),
	age int(2),
	sex varchar(1)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;非空约束 not null&lt;br&gt;
直接写在非空变量的后面即可&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create table instructor(
    ID varchar (5),
    name varchar (20), not null
    dept_name varchar (20)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;默认约束 default&lt;br&gt;
指在没有对某字段插入具体值的时候，使用默认的值&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create table student(
	id int(8),
	name varchar(20),
	age int(2),
	sex varchar(1) default &#39;男&#39;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;外键约束 foreign key&lt;br&gt;
某一表中某字段的值依赖于另一张表中某字段的值&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1669362336311.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
check 子句&lt;br&gt;
可以定义某一字段满足某种限定&lt;br&gt;
用check子句模拟了一个枚举类型，限定了semester必须是四个中的一个&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1669362564221.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
限定了该字段值的范围&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1669362622241.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_43524214/article/details/122850808&#34;&gt;参照完整性约束：当一个表作为另几个表的参照时，对该表的操作会影响参照该表的表&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/molihuakai_118/article/details/85224637&#34;&gt;触发器约束&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;dcldata-control-language&#34;&gt;DCL（Data Control Language）&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;数据控制语言，用于创建数据库用户、控制数据库的访问权限&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;索引&#34;&gt;索引&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/happyheng/article/details/53143345&#34;&gt;SQL索引详解&lt;/a&gt;&lt;br&gt;
　　索引是一种特殊的查询表，可以被数据库搜索引擎用来加速数据的检索。简单说来，索引就是指向表中数据的指针。数据库的索引同书籍后面的索引非常相像。&lt;br&gt;
　　索引分为聚集索引和非聚集索引&lt;br&gt;
&lt;strong&gt;聚集索引 clustering index&lt;/strong&gt;&lt;br&gt;
　　有主键的表，主键即为聚集索引。MySQL 不能手动创建聚集索引，在创建主键的时候自动创建聚集索引。如果没有创建主键，那么默认非空的列为聚集索引，如果没有非空的列那么会自动生成一个隐藏列为聚集索引。&lt;br&gt;
　　聚集索引可以理解为顺序排列，比如一个主键自增的表即为聚集索引，即 id 为1的存在于第一条，id为 2 的存在于第二条... 假使数据库中是使用数组来存放的这张表中的数据，那么如果我需要查找第100条，那么直接第一条数据的地址加上100即为第一百条的地址，一次就能查询出来。&lt;br&gt;
　　因为数据库中的数据只能按照一个顺序进行排列，所以聚集索引一个数据库只能有一个。所以一般在MySQL 中，我们创建的主键即为聚集索引，数据是按照我们的主键顺序进行排列。所以在根据主键进行查询时会非常快。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;非聚集索引 nonclustering index&lt;/strong&gt;&lt;br&gt;
非聚集索引可以简单理解为有序目录，是一种以空间换取时间的方法。举个例子，在一个user表中，有一个id_num，即身份号，此不为主键id，那么这些数据在存储的时候都是无序的，比如&lt;br&gt;
id为1的id_num为100，id为2的id_num为97，id为3的id_num为98，id为4的id_num为99，id为5的id_num为96。。。id为67的id_num为56。。。&lt;br&gt;
那么如果我要查找id_num为56的人，那么只能一条一条的遍历，n条就需要查询n次，时间复杂度为O(n)，这是非常耗费性能的。&lt;/p&gt;
&lt;p&gt;所以，现在就需要为id_num增加非聚集索引，添加了非聚集索引后，会给id_num进行排序（内部使用结构为B+树），并且排序后，我只需要查询此目录(即查询B+树)，很快就知道为id为56的在数据库中的第67条，而不需要在去遍历表中的所有数据。&lt;br&gt;
所以，在非聚集索引中，不重复的数据越多，那么索引的效率越高。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/jeaforea/article/details/61420445&#34;&gt;稠密索引 dense index、稀疏索引 sparse index&lt;/a&gt;&lt;br&gt;
稠密：为每个搜索码都建立索引       稀疏：只为一部分搜索码建立索引&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;索引的选择原则&lt;/strong&gt;&lt;br&gt;
　　非聚集索引在数据库创建、增加、删除、修改的时候都需要作出相应的修改，所以，使用索引也是有一定的原则，即：&lt;/p&gt;
&lt;p&gt;1、较频繁的作为查询条件的字段应该创建索引&lt;br&gt;
2、重复太多的字段不适合单独创建索引，即使频繁作为查询条件&lt;br&gt;
3、不会出现在WHERE子句中的字段不应该创建索引&lt;/p&gt;
&lt;p&gt;以下情况不建议使用索引&lt;br&gt;
　1、小量的数据不用建索引（参考值一万条数据往下为小量数据），如果对小量数据建立索引可能会更慢，因为索引查找是二次查找，直接全表查询即可。&lt;br&gt;
　2、需要频繁进行大批量的更新或者插入操作的表；&lt;br&gt;
　3、如果列中包含大数或者 NULL 值，不宜创建索引；&lt;br&gt;
　4、频繁操作的列不宜创建索引。&lt;br&gt;
　5、不重复的字段越多，那么索引的价值越高，查看不重复的字段占总体的比例可以使用下面的sql语句：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;    SELECT count(DISTINCT(name))/count(*) AS Selectivity FROM index_test;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;比如上面这个sql就是判断index_test表中name字段中不重复的值占整体的比例，这个比例应该在(0,1]之间，这个数值越大，越应该使用索引。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;创建索引&lt;/strong&gt;&lt;br&gt;
创建普通索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE INDEX index_name ON table_name(属性名);
或者
修改表: ALTER TABLE 表名 ADD INDEX 索引名 (列名1，列名2,...);
或者
创建表时指定索引：CREATE TABLE 表名 ( [...], INDEX 索引名 (列名1，列名 2,...) );
eg:
CREATE INDEX name_index ON index_test(name);
此为在index_test表上的name列上创建一个索引name_index。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;创建唯一索引（添加UNIQUE字段）&lt;br&gt;
下面三种模式都可以创建唯一索引：&lt;br&gt;
1、创建索引：CREATE UNIQUE INDEX 索引名 ON 表名(列的列表);&lt;br&gt;
2、在表上增加索引：ALTER TABLE 表名ADD UNIQUE 索引名 (列的列表);&lt;br&gt;
3、创建表时指定索引：CREATE TABLE 表名( [...], UNIQUE 索引名 (列的列表) );&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE UNIQUE INDEX id_num_index ON index_test(idNum);
也可以写成下面的形式：
 ALTER TABLE index_test ADD UNIQUE id_num_index(idNum);
此为在index_test表的idNum列上创建一个唯一索引id_num_index
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除索引&lt;br&gt;
以下两种模式都可以删除索引：&lt;br&gt;
DROP INDEX index_name ON talbe_name&lt;br&gt;
ALTER TABLE table_name DROP INDEX index_name&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;eg:
DROP INDEX name_index ON index_test;
此为删除在index_test表上的name_index索引       
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/149287061&#34;&gt;B+树看这一篇就够了（B+树查找、插入、删除全上）&lt;/a&gt;&lt;/p&gt;
">SQL</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shu-ju-jie-gou-dong-tai-gui-hua/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1xb411e7ww?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/365698607&#34;&gt;知乎好文&lt;/a&gt;&lt;br&gt;
&lt;code&gt;适用题目特点&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计数&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;有多少种方式走到右下角&lt;/li&gt;
&lt;li&gt;有多少种方法选出 k 个数使得和是 Sum&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;求最大最小值&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;从左上角走到右下角路径的最大数字和&lt;/li&gt;
&lt;li&gt;最长上升子序列长度&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;求存在性&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;取石子游戏，先手是否必胜&lt;/li&gt;
&lt;li&gt;能不能选出 k 个数使得和是 Sum&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;最值型解题步骤&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;确定状态&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;最后一步（最优策略中使用的最后一枚硬币 ak）&lt;/li&gt;
&lt;li&gt;化成子问题（最少的硬币拼出前面的面值 27-ak）  {前两步和递归很像}&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;转移方程&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;f(x) = min{f(x-2)+1, f(x-5)+1, f(x-7)+1}&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;初始条件和边界情况&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;f(0) = 0，如果不能拼出Y，f(Y) = +∞&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;计算顺序&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;从小到大计算，f(0)，f(1)，f(2)....&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://leetcode.cn/problems/coin-change/&#34;&gt;leetcode 零钱兑换&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;题目分析：&lt;br&gt;
假设有面值为 2，5，7 的三种硬币无数个，要求用最少的硬币个数凑出 27&lt;br&gt;
&lt;code&gt;步骤&lt;/code&gt;&lt;br&gt;
先假定最优解的最后一个硬币面值为 ak，则之前的硬币总面值为 27-ak&lt;br&gt;
则定义一个函数 f(x) ，表示构成面值 x 最少要  f(x) 个硬币&lt;br&gt;
找到 f(x) 的递归定义， f(x) 是减去最后一枚硬币的面值的最小值&lt;br&gt;
对特殊情况分别讨论&lt;br&gt;
从小到大计算各个递归阶段的值，从而避免了递归中的重复计算&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Solution(object):
    def coinChange(self, coins, amount):
        f = [float(&#39;inf&#39;) for i in range(amount + 1)]  # 开辟从 0 到 amount 大小的数组，初始值设置为正无穷
        f[0] = 0  # 初始化 f[0] = 0 面值为 0 需要 0 个硬币
        # 这个 for 循环求凑出每一个面值最少需要多少硬币 f[1]、f[2]、f[3]...
        for i in range(1, amount + 1):  # i 代表面值，从 f[1] 开始，到 amount+1 共 amount 个数
            for j in coins:  # 遍历硬币的集合
                if i &amp;gt;= j and f[i - j] != float(&#39;inf&#39;):  # 如果 i 的面值比 j 大，且要判断的数有值
                    # f[i] 的值为 构成 i 面值去掉最后一枚 coin 的面值所需的硬币数，加一（最后一枚 取最小值
                    f[i] = min(f[i - j] + 1, f[i])
        if f[amount] == float(&#39;inf&#39;):  # 如果最后没有被更新，则说明无法构成
            f[amount] = -1
        return f[amount]


coins = [2, 5, 7]
amount = 27
s = Solution()
print(s.coinChange(coins, amount))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;例&lt;/code&gt; &lt;strong&gt;动态规划实现斐波那契数列&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def f(n):  # 动态规划斐波那契函数（从 n = 1 开始）
    a = [1 for _ in range(n + 1)]  # 开辟 0 ~ n 的数组
    a[1] = 1  # 初始化第一项，注意，第 0 项不用
    if n &amp;gt;= 2:  # 当 n 大于等于二的时候
        for i in range(3, n + 1):  # 第三项往后满足递推关系
            a[i] = a[i - 2] + a[i - 1]
    return a[-1]  # 返回最后一项的值

# for i in range(1, 11):  # 检查前 10 项
#     print(f(i))
print(f(100))  # 直接出第 100 项的值，用暴力递归不行
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;【优化版本】根据分析实际进行操作的只有三个内存，所以直接用三个变量进行替代&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def f(n):  # 动态规划斐波那契函数（从 n = 1 开始）
    if n == 1 or n == 2:
        return 1
    else:
        a = 1
        b = 1
        for i in range(2, n):
            sum = a + b  # 更新 c 的值
            a = b
            b = sum
    return sum  # 返回最后一项的值
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;例&lt;/code&gt; &lt;a href=&#34;https://leetcode.cn/problems/qing-wa-tiao-tai-jie-wen-ti-lcof/&#34;&gt;&lt;strong&gt;剑指 Offer 10- II. 青蛙跳台阶问题&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;【分析】此问题和斐波那契数列几乎一模一样，根据上面的类比此题即可&lt;/p&gt;
&lt;p&gt;常规动态规划版&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Solution(object):
    def numWays(self, n):  # 跳了 n 个台阶有几种跳法
        a = [1 for _ in range(n + 1)]  # 开辟数组，初始化都为 1，a[0] = 1
        if n == 1:  # 单独判断 n 为 1 的时候，防止数组溢出
            a[1] = 1
        elif n &amp;gt; 1:
            a[1] = 1  # 初始化前两个
            a[2] = 2
            for i in range(3, n + 1):  # 从第三位开始到最后写递推式
                a[i] = a[i - 1] + a[i - 2]
        return a[-1] % 1000000007  # 题目要求取模
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;【优化版本】根据分析实际进行操作的只有三个内存，所以直接用三个变量进行替代&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Solution(object):
    def numWays(self, n):  # 跳了 n 个台阶有几种跳法
        # 单独判断前三个取值
        if n == 0:  
            return 1
        elif n == 1:
            return 1
        elif n == 2:
            return 2
        # 计算一般情况
        a = 1  # 初始化
        b = 2
        for i in range(2, n):  # 执行 n-2 步迭代
            sum = a + b  # 更新 sum 的值
            a = b
            b = sum
        return sum % 1000000007
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;【再优化版】初始化 a，b 在一行；去掉了第三个变量 c ，直接用计算结果替换&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Solution:
    def numWays(self, n):
        a, b = 1, 1
        for _ in range(n):
            a, b = b, a + b  # a = b；b = a+b
        return a % 1000000007
&lt;/code&gt;&lt;/pre&gt;
">【数据结构】动态规划（Dynamic programming，DP）</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/cao-zuo-xi-tong-bi-ji/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_43914604/article/details/104415990&#34;&gt;CSDN 王道笔记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;用户运行程序不需要向操作系统预定时间&lt;br&gt;
系统吞吐量指的是系统在&lt;strong&gt;单位时间&lt;/strong&gt;内可处理的事务的数量，是用于衡量系统性能的重要指标。&lt;br&gt;
批处理的缺点是缺少交互性，交互性指用户可以控制操作系统处理指令&lt;br&gt;
多道程序设计技术是为了提高系统利用率和吞吐量&lt;br&gt;
内核可以执行 CPU 能处理的任何指令，而用户程序只能执行除特权指令之外的指令。所以特权指令只能由内核（操作系统）使用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;中断处理&lt;/strong&gt;&lt;br&gt;
计算机通过硬件中断机制完成从用户态到核心态的转换&lt;/p&gt;
&lt;p&gt;中断（外中断）：指 CPU 执行指令外部的事件。I/O中断、时钟中断&lt;br&gt;
异常（内中断）：指 CPU 执行指令内部的事件。一般都是程序报错，如地址越界、运算溢出、虚拟内存系统的缺页等。&lt;/p&gt;
&lt;p&gt;用户态转换为核心态的情况&lt;br&gt;
1）用户程序要求操作系统的服务，即系统调用&lt;/p&gt;
&lt;p&gt;用户在使用程序时，凡是与资源有关的操作，例如存储分配、I/O传输、文件管理等操作，都必须通过系统调用的方式向操作系统发出请求。&lt;br&gt;
类似于“在内存中取数”、“将运算结果装入内存”、”寄存器清 0“等指令操作，可以用汇编语言实现，所以用户态下也可以使用。&lt;br&gt;
用户程序执行陷入指令（访管指令/trap指令）发起系统调用，CPU由用户态变为核心态。访管指令在用户态使用，所以不可能是特权指令。&lt;br&gt;
这种机制保证了系统的稳定性和安全性，防止用户程序随意更改系统资源&lt;/p&gt;
&lt;p&gt;2）发生一次中断：程序产生错误、用户程序企图执行一条特权指令&lt;/p&gt;
&lt;p&gt;从核心态转用户态&lt;br&gt;
需要使用到中断返回指令，由于使用的时候在核心态，所以中断返回指令是特权指令&lt;/p&gt;
&lt;p&gt;子程序调用只需保存程序断点，即该指令的下一条指令的地址&lt;br&gt;
中断处理不仅要保存断点（PC 的内容），还要保存程序状态字寄存器（PSW）的内容&lt;/p&gt;
&lt;h1 id=&#34;2-进程与线程&#34;&gt;2 进程与线程&lt;/h1&gt;
&lt;p&gt;PCB （Process Control Block）进程控制块&lt;br&gt;
进程实体 / 进程映像 ：由程序段、相关数据段 和 PCB 三部分构成&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;进程&lt;/strong&gt;&lt;br&gt;
进程是资源分配的单位&lt;/p&gt;
&lt;p&gt;I/O 操作对进程的影响&lt;br&gt;
I/O 操作执行时需要中断，此时进程处于阻塞态，进程需要等待 I/O 的执行结果。完成后进程等待事件就绪，变为就绪态。&lt;/p&gt;
&lt;p&gt;程序的封闭性&lt;br&gt;
是指进程执行的结果只取决于进程本身，不受外界影响。进程不管是否断续执行，执行的速度不会影响执行结果。失去封闭性后，不同速度下执行的结果不同。&lt;/p&gt;
&lt;p&gt;进程的撤销&lt;br&gt;
进程可在完成时撤销，或在出现内存错误等时候撤销&lt;br&gt;
进程在时间片结束时是就绪，不是撤销&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;线程&lt;/strong&gt;&lt;br&gt;
将一个进程划分为多个线程，多个线程可以同时并发执行&lt;br&gt;
内核级线程是处理器调度和分派的单位&lt;/p&gt;
&lt;p&gt;线程没有自己的地址空间，它共享其所属进程的空间&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;信号量机制&lt;/strong&gt;&lt;br&gt;
信号量可以表示系统中某种资源的数量，比如打印机有 5 个，则信号量值为 5&lt;/p&gt;
&lt;p&gt;原语是一种特殊程序段，执行时只能一气呵成，不可以被中断。&lt;br&gt;
用一对原语实现对信号量的操作：&lt;br&gt;
wait() 和 signal()，也称为 P、V 操作 （源于荷兰语 proberen 和 verhogen）&lt;/p&gt;
&lt;p&gt;wait()、P 操作：对系统资源进行申请，并减少相应的信号量&lt;br&gt;
signal()、V 操作：对系统资源进行释放，并增加相应信号量&lt;/p&gt;
&lt;p&gt;&lt;code&gt;例：&lt;/code&gt;&lt;br&gt;
系统中有一台打印机&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int source = 1;   // 设置系统中可用打印机资源数量为1，是全局变量
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;wait() 原语的实现；P 操作&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void wait(int source){
    if(source &amp;lt;= 0)  进入等待队列;     //如果系统资源数量不够，则进入等待队列
    source = source - 1;    //如果够用，则资源数量-1，占用一个资源
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;signal() 原语的实现；V 操作&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void signal(int source){
    source = source + 1;    //使用完资源后，释放资源，资源数+1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;进程 P0 ：
wait(source);      //num0：此时 source 为1，可以使用，执行 source = source - 1;  source 的值变为 0。然后假设此时 P1 进程试图访问打印机资源，跳到 num1
使用打印机资源
signal(source);   //num2：此时 P0 结束使用打印机，执行 source = source + 1; 释放资源，转到 num3

进程 P1 ：
wait(source);      //num1： 此时 source 为 0，执行 if 语句，进入等待队列。跳转到 num2
//num3：此时 P0 结束使用打印机，全局变量 source = 1; 执行 source = source - 1; 转到 num4
使用打印机资源
signal(source);    //num4： 使用结束，执行 source = source + 1; 释放资源
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个例子中，source 就是信号量，代表系统中 打印机资源 的数量。用 wait 和 signal 两个原语对 source 的值进行更改，从而控制线程是否可用访问资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;信号量机制实现进程的互斥和同步&lt;/strong&gt;&lt;br&gt;
互斥锁（Mutex）&lt;br&gt;
进程的互斥需要用到互斥锁。互斥锁是信号量机制 source = 1 的特殊情况，同时间只允许一个进程访问资源。所以各个进程之间是互斥的，所以称为进程的互斥。&lt;br&gt;
初始化 mutex = 1，像上面那样，把 wait 和 signal 中的 source 替换为 mutex 即可&lt;/p&gt;
&lt;p&gt;进程的同步&lt;br&gt;
同步指的是多个进程在同一时间段内如何有序的进行。如代码1必须在代码2前执行，我们需要用信号量机制来保证执行的顺序。&lt;br&gt;
具体实现：初始化 source 为 0 ，表示当前系统没有可用资源，在代码1后使用 V(source) 来释放资源，从而使 source 为 1；在代码 2 前面使用 P(source) 操作来申请资源，如果 source 值为 0，则表示代码1还没执行完，则 P 操作会阻塞代码2的进程，将2进程放入等待序列；若 source 值为 1，则表示代码1已经执行完毕，则 P 操作执行，代码2执行。&lt;br&gt;
总结：前进程后跟 V 操作，后进程前跟 P 操作 —— 前 V 后 P&lt;/p&gt;
&lt;p&gt;同步互斥总结：同步 初始化信号量为 0 ；互斥 初始化信号量为 1&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1676115188396.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1676115194872.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;综上：&lt;/code&gt;&lt;br&gt;
P：理解为申请、减少资源；V：理解为释放、增加资源&lt;br&gt;
当要实现互斥时，在两个·进程前后加PV；当要实现同步时，在先执行的进程后加V，后执行的进程前加P；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;生产者消费者问题&lt;/strong&gt;&lt;br&gt;
分析题目中存在的同步和互斥关系，然后使用信号量控制&lt;br&gt;
访问缓冲区是互斥关系，同一时间只能有一个人访问；生产者和消费者互相等待对缓冲区的操作，是同步关系&lt;/p&gt;
&lt;p&gt;“缓冲区有空余，生产者生产，缓冲区非空，消费者消费”&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1676129782959.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
注：为避免死锁，实现互斥的P操作一定要在实现同步的P操作之后&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;避免死锁——银行家算法&lt;/strong&gt;&lt;br&gt;
1.求Need矩阵&lt;br&gt;
用最大需求量矩阵（Max）减去已分配量矩阵（Allocation）&lt;/p&gt;
&lt;p&gt;2.判断系统是否处于安全状态&lt;br&gt;
如果能找到一个安全序列，则处于安全状态。&lt;br&gt;
判断方法：&lt;br&gt;
a.看Need矩阵中不同进程的资源需求量，先找小于系统可用资源的进程。&lt;br&gt;
b.用当前进程的已分配资源+系统可用资源，得到下一步的系统可用资源。&lt;br&gt;
c.重复上述步骤，如果成功得到进程序列，则该序列为安全序列。&lt;/p&gt;
&lt;p&gt;3.判断是否能满足新请求&lt;br&gt;
a.判断新请求序列是否小于系统资源，并是否小于该进程的最大需求，若都成立，则继续。&lt;br&gt;
b.然后用该进程的已分配资源+新请求，系统可用资源-新请求，Need-新请求。&lt;br&gt;
c.重复2.的步骤，如果成功得到安全序列，则可以满足新请求。&lt;/p&gt;
&lt;h1 id=&#34;3-内存管理&#34;&gt;3 内存管理&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Y44y1D7vv/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;&lt;strong&gt;页面置换算法&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
题干形如：&lt;br&gt;
在一个请求分页系统中，采用最近最少使用（LRU）页面置换算法时，假设一个&lt;br&gt;
作业的页面引用串为 1,3,2,1,1,3,5,1,3,2,1,5，当分配给该作业的物理块数分别为 3 和 4&lt;br&gt;
时，计算在访问过程中发生的缺页次数和缺页率。&lt;/p&gt;
&lt;p&gt;页面引用串为页面编号，物理块数为下面的行数。&lt;br&gt;
缺页次数：除了空的列，剩下都是缺页，都算在缺页次数&lt;br&gt;
缺页率：缺页次数/总页数&lt;br&gt;
页面置换次数：发生页面替换的列数&lt;/p&gt;
&lt;p&gt;OPT算法：最佳置换算法&lt;br&gt;
做题时，在下面标出，等到要替换的时候，从该处往后面找，最后看到的该列中的元素，为最近未使用的元素，则用当前元素替换掉该元素。&lt;/p&gt;
&lt;p&gt;LRU算法：最近最久未使用算法&lt;br&gt;
做题时，在下面标出，等到要替换的时候，从该处往前面找，最后看到的该列中的元素，为最近未使用的元素，则用当前元素替换掉该元素。&lt;/p&gt;
&lt;p&gt;FIFO算法：先进先出算法&lt;br&gt;
淘汰最先进入内存的页面。替换在列中存在时间最长的页面。&lt;/p&gt;
&lt;h1 id=&#34;5-io管理&#34;&gt;5 IO管理&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;磁盘&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1c4411w7Tn/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;&lt;strong&gt;磁盘调度算法&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
FIFO 先进先出：给定什么顺序就走什么顺序&lt;br&gt;
SSTF 最短服务时间优先：找与当前磁道号间隔最短的磁道号，用两个磁道号相减再绝对值，注意只看磁道号就行&lt;br&gt;
SCAN 扫描算法（电梯算法）：先向上走到头，找到最大磁道号，再向下走到最小磁道号&lt;br&gt;
C-SCAN 扫描算法：一直向上走，走到最大磁道号之后继续轮回，从最小磁道向上找。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1P54y1D7Jv/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;&lt;strong&gt;磁盘计算&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
存储容量 = 磁头数（盘面数）x 磁道数（柱面数）x 每道扇区数 x 每扇区字节数&lt;br&gt;
访问时间 = 寻道时间（会给） + 读取时间（用转速求）+ 传输时间 + 控制器时间（会给）&lt;/p&gt;
&lt;p&gt;磁盘计算时，1 GB = 1024 MB，1 MB = 1024 KB，1 KB = 1024 B&lt;br&gt;
G M K之间进位为 1024&lt;/p&gt;
&lt;p&gt;&lt;code&gt;例题&lt;/code&gt;&lt;br&gt;
某计算机系统采用 C-SCAN（循环扫描）磁盘调度策略，使用 2KB 的内存空间&lt;br&gt;
记录 16384 个磁盘块的空闲状态。&lt;br&gt;
设某单面磁盘旋转速度为 6000r/min，每个磁道有 100 个扇区，相邻磁道间的平均移动&lt;br&gt;
时间为 1ms。若在某时刻，磁头位于 80 号磁道处，并沿着磁道号增大的方向移动，磁道号&lt;br&gt;
请求队列为 40，90，30，110，对请求队列中的每个磁道需读取 1 个随机分布的扇区，则&lt;br&gt;
读完这 4 个扇区点共需要多少时间？要求给出计算过程。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;首先，计算寻道时间。总共移动的磁道数为 110 - 80 = 30。磁盘道的移动时间为 30 * 1ms = 30ms。

然后，计算读取每个扇区的时间。单面磁盘旋转速度为 6000r/min，1min = 60,000ms，则一转的时间为 60,000ms/6000r = 10ms

每个磁道有 100 个扇区，所以每个扇区的读取时间为 10ms / 100 = 0.1ms。

最后，累加读取每个扇区的时间，共为 4 * 0.1ms = 0.4ms。加上磁道的移动时间，总共需要的时间为 0.4ms + 30ms = 30.4ms。
&lt;/code&gt;&lt;/pre&gt;
">操作系统笔记</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/pytorch-ru-men/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/wxd1233/article/details/118371404&#34;&gt;【PyTorch总结】tqdm的使用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/48982978&#34;&gt;Tensor--张量&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.zhihu.com/question/341328124&#34;&gt;「张量」和「多维数组」有什么区别？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/Lucky_Ape/article/details/113944257&#34;&gt;张量、数组&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/lxytsos/article/details/90639524&#34;&gt;PyTorch模型保存与加载&lt;/a&gt;&lt;/p&gt;
">PyTorch 入门</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/cnn-juan-ji-shen-jing-wang-luo/"" data-c="
          &lt;p&gt;Convolutional Neural Network&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/hotsnow/p/9734375.html&#34;&gt;常见的 CNN&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/47184529&#34;&gt;文档&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/mvtechnology/article/details/9008499&#34;&gt;图像的通道数&lt;/a&gt;&lt;br&gt;
灰度图的通道数为1，彩色图的通道为3&lt;/p&gt;
&lt;p&gt;CNN 基本结构：&lt;br&gt;
输入层&lt;br&gt;
卷积层：对特征进行提取&lt;br&gt;
池化层：对特征进行压缩&lt;br&gt;
全连接层：和传统神经网络一样，用于分类&lt;br&gt;
&lt;code&gt;注&lt;/code&gt; CNN 的层数 = 卷积层数 + 全连接层数&lt;/p&gt;
&lt;p&gt;卷积神经网络和普通神经网络相比，&lt;br&gt;
输入 CNN 的图像为三维图像，即为长、宽、颜色通道数（R、G、B）&lt;br&gt;
CNN 相当于传统神经网络（用于分类）加上了卷积和池化层（对特征的提取和处理）&lt;br&gt;
根据特征进行分类&lt;/p&gt;
&lt;p&gt;卷积核（filter）&lt;br&gt;
包含三个参数，长、宽、通道数。其中长宽相等，通道数和输入通道数相等。&lt;/p&gt;
&lt;p&gt;卷积过程：&lt;br&gt;
划分图像的区域，用卷积核（filter）扫描区域，卷积得到特征矩阵，三个通道同时进行&lt;/p&gt;
&lt;p&gt;卷积核扫描&lt;br&gt;
卷积核与被扫描区域做内积运算，得到一个数值。三个通道相加，再加上 bias 得到最终结果。得到的结果称为特征图（feature map）&lt;/p&gt;
&lt;p&gt;多特征图&lt;br&gt;
使用不同卷积核对图片进行扫描得到不同的特征图，特征更丰富。特征图个数称为深度，作为下一层卷积的通道数。提取特征后，各种特征在原图像的位置就没那么重要了。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_41088475/article/details/105766758&#34;&gt;通道数的确定&lt;/a&gt;&lt;br&gt;
第一层通道数为 RGB 三通道，后面卷积层的通道数 = 前一层特征图的总数 = 前一层卷积核个数&lt;/p&gt;
&lt;p&gt;CNN 常用参数&lt;br&gt;
输入通道数（in_channels）：输入通道数，第一层看输入图片，如果是灰度图则为1，后面的和前一层的 out_channels 一样&lt;br&gt;
输出通道数（out_channels）：代表该层用到的卷积核的个数，也代表得到的、传输给下一层的特征图的个数&lt;br&gt;
滑动窗口步长（stride）：卷积核每次移动走过的距离。一般设置为1&lt;br&gt;
卷积核尺寸：常用的为 3x3 （不能太大，特征提取不明显）&lt;br&gt;
边缘填充（pad/padding）：为了解决区域边缘被扫描的次数较少的问题，在边缘添加一圈 0 ，使得原来的边界不为边界&lt;br&gt;
注：padding = n 意思是在外围加 n 层。若原图 28 x 28，padding = 2，则一条边长度增加 4，尺寸变为 32 x 32&lt;br&gt;
卷积核个数：决定了生成的特征图的数量、下一层的通道数。每个卷积核一定不同&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/428448728&#34;&gt;ReLU 激活函数&lt;/a&gt;：将特征图上所有负数变为0，正数不变&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/77609689&#34;&gt;Dropout：每一层随机丢弃一些神经元防止过拟合&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;池化层：&lt;br&gt;
对卷积得到的特征进行筛选，筛选出重要的特征，防止过拟合&lt;br&gt;
常用池化方法：&lt;br&gt;
Max Pooling：扫描一定区域，选择区域中的最大值（提取最有用的特征）&lt;/p&gt;
&lt;p&gt;网络结构：&lt;br&gt;
卷积（CONV）后面接着 RELU 激活函数，两层该结构，一层池化，重复累加&lt;/p&gt;
&lt;p&gt;从池化层进入全连接层前，需要先把三维的数据转化为一维的向量&lt;/p&gt;
&lt;p&gt;残差神经网络 Resnet&lt;br&gt;
随着 CNN 层数不断增加，效果不一定会越来越好，是为什么呢？因为某一层可能会效果不好，影响了总体的特征提取效果。Resnet 将其中效果不好的层的权重设置为 0 ，只保留对整体效果有益的层数，从而保证了，层数越多，深度越深，学习效果越好。不过提升程度可能很细微，但是总有提升。&lt;/p&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://c.biancheng.net/pillow/&#34;&gt;Pillow（PIL） 库：python 图像处理库&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_34714751/article/details/85610804&#34;&gt;tf 实现 CNN&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;各层输入输出计算&#34;&gt;各层输入输出计算&lt;/h1&gt;
&lt;p&gt;卷积层和池化层计算方法一样，带入公式即可&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 输出图片大小的计算公式为：
inputSize = 28
kernel = 2
stride = 2
padding = 0

outputSize = ((inputSize - kernel + 2 * padding) / stride) + 1
print(outputSize,&#39;\n&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;全连接层计算：&lt;br&gt;
若最后一层输出为 10 x 10 x 20 ，则作为全连接层的输入为 10 x 10 x 20 = 2000&lt;/p&gt;
&lt;h1 id=&#34;批标准化-batch-normalization&#34;&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24810318&#34;&gt;批标准化 (Batch Normalization)&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_44023658/article/details/105844861&#34;&gt;Batch Normalization（BN）超详细解析&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;变体&#34;&gt;变体&lt;/h1&gt;
&lt;p&gt;CNN 是卷积神经网络的总称，按照时间线，给出一些变体&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LeNet-5 (1998年)&lt;/strong&gt;: 由Yann LeCun开发，是早期的卷积神经网络，主要用于手写数字识别。LeNet-5被认为是卷积神经网络的先驱之一。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;AlexNet (2012年)&lt;/strong&gt;: 由Alex Krizhevsky等人开发，这个模型在2012年的ImageNet挑战赛中取得了突破性的成功，标志着深度学习在视觉领域的崛起。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ZFNet (2013年)&lt;/strong&gt;: 也称为Zeiler&amp;amp;Fergus模型，通过修改AlexNet的结构并使用可视化技术来理解卷积层的工作方式，赢得了2013年ImageNet挑战赛。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GoogLeNet (Inception v1) (2014年)&lt;/strong&gt;: 由Google开发，引入了一种称为“Inception”的新架构，它能够显著减少参数的数量而不牺牲性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;VGGNet (2014年)&lt;/strong&gt;: 由牛津大学的Visual Geometry Group开发，这个模型以其简单而均一的架构著称，证明了网络的深度是提高性能的关键因素。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ResNet (2015年)&lt;/strong&gt;: 由微软研究院开发，引入了残差学习的概念，使得训练非常深的网络成为可能。ResNet在2015年的ImageNet挑战赛中取得了胜利。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DenseNet (2017年)&lt;/strong&gt;: 引入了密集连接的概念，每一层都与前面的所有层相连，极大地提高了效率和效果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MobileNet (2017年)&lt;/strong&gt;: 专为移动和嵌入式设备设计，通过使用深度可分离的卷积来减少计算量和模型大小。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;EfficientNet (2019年)&lt;/strong&gt;: 使用复合系数对深度、宽度和分辨率进行缩放，创造出一系列模型，这些模型在效率和准确性之间取得了良好的平衡。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Vision Transformer (ViT) (2020年)&lt;/strong&gt;: 将Transformer架构应用于图像分析，这是从自然语言处理领域借鉴过来的技术，开辟了神经网络处理视觉信息的新途径。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;lenet-5&#34;&gt;LeNet-5&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1t44y1r7ct?p=1&#34;&gt;23 经典卷积神经网络 LeNet【动手学深度学习v2】&lt;/a&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710506415759.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
使用MNIST：28x28，第一层 padding=2，输入网络是 32x32&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输入层（Input Layer）&lt;/strong&gt;：接受的输入图像大小通常是32x32像素。这是因为网络设计时考虑到数字的实际大小和希望网络能够捕捉到重要的特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第一卷积层（C1）&lt;/strong&gt;：这一层使用6个卷积核（或滤波器），每个大小为5x5，步长为1，无填充（padding），输出的特征图（feature map）大小为28x28x6。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第一下采样层（S2）&lt;/strong&gt;：也称为池化层，使用2x2的窗口进行平均池化，步长为2，将特征图的维度降低到14x14x6。这一步骤有助于减少数据的空间尺寸，从而减少计算量和控制过拟合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二卷积层（C3）&lt;/strong&gt;：这一层有16个卷积核，每个大小为5x5，处理上一层的输出，产生10x10x16的特征图。这一层的设计允许网络学习更高级的特征。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二下采样层（S4）&lt;/strong&gt;：同样采用2x2平均池化，步长为2，输出的维度为5x5x16。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;全连接层（F5）&lt;/strong&gt;：这一层有120个节点，它将前一层的输出展平（flatten）并全连接到这120个节点上。这一层开始将学到的特征组合成更高级别的模式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;第二全连接层（F6）&lt;/strong&gt;：这一层有84个节点，进一步处理特征，为最终的分类决策做准备。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输出层（Output Layer）&lt;/strong&gt;：最后是一个具有10个节点的输出层，对应于10个数字类（0到9）。这一层通常使用softmax激活函数，将网络的输出转换为概率分布。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两层卷积两层池化，卷积池化之间使用 Sigmoid 激活，最后使用全连接层映射到 10 个分类&lt;/p&gt;
&lt;h2 id=&#34;alexnet&#34;&gt;AlexNet&lt;/h2&gt;
&lt;p&gt;AlexNet 在2012年的ImageNet大规模视觉识别挑战（ILSVRC）中取得了冠军。&lt;br&gt;
相比 LeNet，AlexNet 增加了以下部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;dropout 层&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用最大池化层&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sigmoid 换成 ReLU&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用了数据增强&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710595577423.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
AlexNet的结构大致可以分为以下几个关键部分：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输入层&lt;/strong&gt;：AlexNet接受的输入图像大小为227x227x3（宽x高x颜色通道），原论文中提到的是224x224x3，但实际实现时通常使用227x227x3，以适应网络中的卷积层。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;卷积层&lt;/strong&gt;：AlexNet 包含5个卷积层，其中一些卷积层后面跟有最大池化层。这些卷积层用于提取图像中的特征。第一层使用96个大小为11x11的卷积核，步长为4；第二层使用256个5x5的卷积核，其余层则逐渐减少卷积核的尺寸并增加卷积核的数量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;激活函数&lt;/strong&gt;：AlexNet中引入了ReLU（Rectified Linear Unit）作为激活函数，以增加非线性特性并加速训练过程。在每个卷积层和全连接层后都应用了ReLU。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;池化层&lt;/strong&gt;：使用了3层最大池化层，降低特征的空间维度，减少计算量，并在一定程度上提供平移不变性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;规范化层&lt;/strong&gt;：AlexNet在某些卷积层之后引入了局部响应规范化（LRN），这有助于提高泛化能力。但在后来的网络设计中，LRN并不常见，因为被发现效果不如Batch Normalization。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;全连接层&lt;/strong&gt;：AlexNet的顶部有三个全连接层，每个层都有4096个神经元，最后一个全连接层输出1000个类别的得分，对应于1000个不同的图像类别。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dropout&lt;/strong&gt;：在全连接层中，AlexNet使用了Dropout技术来防止模型过拟合。Dropout会在训练过程中随机丢弃一部分神经元，减少神经元之间复杂的共适应关系。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输出层&lt;/strong&gt;：使用softmax层作为输出层，将神经网络的输出转换为概率分布，这些概率表示图像属于每个类别的可能性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;AlexNet的成功不仅因为它的网络结构，还因为它使用了多GPU训练和数据增强等技术，显著提高了训练速度和模型的泛化能力。&lt;/p&gt;
&lt;h2 id=&#34;vggnet&#34;&gt;VGGNet&lt;/h2&gt;
&lt;p&gt;最初是由牛津大学的视觉几何组（Visual Geometry Group，即VGG）开发的，用于参加2014年的 ImageNet 挑战赛。VGGNet 的关键特点在于其使用了非常深的网络结构来提高图像识别的准确性。&lt;/p&gt;
&lt;p&gt;VGGNet 有几个版本，其中最著名的 是VGG16 和 VGG19，数字代表网络中的层数。VGG16 包含16层，VGG19 则包含19层。这些层数主要是卷积层和全连接层。&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710596398916.jpeg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
采用统一的小卷积核（3x3），并通过堆叠多个小卷积层来增加网络的深度和容量，比大卷积核效果更好，提取的特征更细致。&lt;/p&gt;
&lt;p&gt;VGG块：图中①就是一个VGG块，包含多层卷积和一个 ReLU 函数&lt;/p&gt;
&lt;p&gt;VGGNet 的架构特点包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;统一的卷积层设计&lt;/strong&gt;：VGGNet使用了3x3的小卷积核和1x1的卷积步长，并且在每个卷积层后面使用了 ReLU 激活函数。这种设计使得网络在保持感受野大小的同时能够更深。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;池化层&lt;/strong&gt;：在连续的卷积层之后，VGGNet 使用最大池化层来逐渐减少特征图的空间尺寸，增加特征的抽象程度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;全连接层&lt;/strong&gt;：在卷积层和池化层之后，VGGNet 包含了三个全连接层，最后一层是用于分类的 softmax 层。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;深度&lt;/strong&gt;：VGGNet 的深度（即层数）是其最显著的特征之一，这使得网络能够学习到更复杂和抽象的特征表示。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;VGGNet由于其简单和高效的架构，在图像识别领域获得了广泛的应用，包括图像分类、面部识别和风格迁移等。尽管它的参数量比较大，导致模型较为庞大且计算密集，但它仍然是深度学习和计算机视觉领域的一个重要基准。&lt;/p&gt;
&lt;h2 id=&#34;resnet&#34;&gt;ResNet&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1cM4y117ob/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;三分钟说明白ResNet ，关于它的设计、原理、推导及优点&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/101332297&#34;&gt;残差神经网络（ResNet）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1bV41177ap/?spm_id_from=333.999.0.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;29 残差网络 ResNet【动手学深度学习v2】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;主要用于解决深度卷积神经网络训练过程中遇到的梯度消失和梯度爆炸问题。ResNet通过引入“残差学习”的概念来实现对更深网络的有效训练。&lt;/p&gt;
&lt;p&gt;残差块（Residual Block）是ResNet的核心，它允许输入直接通过一条“捷径”（skip connection或shortcut connection）连接到输出，从而实现输入与输出之间的&lt;code&gt;直接相加&lt;/code&gt;。&lt;br&gt;
f(x)=x+g(x)&lt;br&gt;
这种设计使得网络可以学习到残差映射，即学习到的是输入与输出之间的差异，而不是直接学习一个完整的映射。这样做的好处是可以&lt;code&gt;减轻网络训练中的梯度消失问题&lt;/code&gt;，使得网络即使在极深的情况下也能有效训练。&lt;/p&gt;
&lt;p&gt;ResNet架构的另一个重要特点是它的模块化设计，使得网络可以很容易地扩展到不同的深度。ResNet的几个变体，如ResNet-50、ResNet-101和ResNet-152，分别包含不同数量的层，适用于不同的任务和性能要求。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;拓展&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;1x1的卷积核有什么用&#34;&gt;1x1的卷积核有什么用？&lt;/h2&gt;
&lt;p&gt;虽然在空间尺寸上看起来似乎不会对特征图的空间结构产生影响，但实际上它在深度学习中有几个非常有用的作用：&lt;/p&gt;
&lt;h3 id=&#34;通道数变换&#34;&gt;通道数变换&lt;/h3&gt;
&lt;p&gt;1x1卷积可以改变特征图的通道数。这对于控制网络的复杂性和参数数量非常有用。例如，可以用它来减少特征图的通道数，从而减少后续层的计算量和参数量（这种操作有时被称为“瓶颈层”），或者增加通道数以提供更丰富的特征表示。&lt;/p&gt;
&lt;h3 id=&#34;增强非线性&#34;&gt;增强非线性&lt;/h3&gt;
&lt;p&gt;尽管1x1卷积本身是线性的，但在1x1卷积层之后添加非线性激活函数（如ReLU）可以引入额外的非线性，使网络能够学习更复杂的函数。&lt;/p&gt;
&lt;h3 id=&#34;跨通道信息整合&#34;&gt;跨通道信息整合&lt;/h3&gt;
&lt;p&gt;1x1卷积可以实现特征图不同通道之间的信息整合。由于1x1卷积核作用于特征图的所有通道，它可以学习将不同通道的信息组合在一起的新方式，这有助于网络捕捉跨通道的特征依赖。&lt;/p&gt;
&lt;h3 id=&#34;计算效率&#34;&gt;计算效率&lt;/h3&gt;
&lt;p&gt;1x1卷积相对于更大卷积核的卷积操作要更加计算高效。它们可以用来设计更深但计算量不那么大的网络架构，特别是在处理具有大量通道的特征图时。&lt;/p&gt;
&lt;h3 id=&#34;网络中的调节阀&#34;&gt;网络中的“调节阀”&lt;/h3&gt;
&lt;p&gt;在一些复杂的网络结构中（如Inception模块），1x1卷积被用作调节阀，以控制不同路径上的参数量和计算复杂度。&lt;/p&gt;
&lt;p&gt;综上所述，1x1卷积是一个非常强大的工具，它提供了一种简单而有效的方式来增加网络的深度和复杂性，同时控制计算和参数的增长，是现代深度学习架构中不可或缺的一个组件。&lt;/p&gt;
">【CV】CNN 卷积神经网络</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/le-li/"" data-c="
          &lt;h1 id=&#34;和弦&#34;&gt;和弦&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/70724252&#34;&gt;主/属和弦&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/93786223#:~:text=%E4%BB%A5%E4%BB%BB%E4%BD%95%E4%B8%80%E4%B8%AA%E9%9F%B3%E4%BD%9C%E4%B8%BA%E6%A0%B9%E9%9F%B3%EF%BC%8C%E5%BE%80%E4%B8%8A%E4%B8%89%E5%BA%A6%E5%8F%A0%E5%8A%A0%E6%9E%84%E6%88%90%E7%9A%84%EF%BC%8C%E5%92%8C%E5%BC%A6%E6%98%AF%E7%94%B1%E4%B8%8D%E5%90%8C%E9%9F%B3%E6%9E%84%E6%88%90%E7%9A%84%EF%BC%8C%E6%9C%80%E5%B0%913%E4%B8%AA%E9%9F%B3%EF%BC%8C%E6%9C%80%E5%A4%9A%E6%98%AF7%E4%B8%AA%E9%9F%B3%E3%80%82,%E6%80%BB%E5%85%B1%E6%9C%895%E7%A7%8D%E5%92%8C%E5%BC%A6%EF%BC%8C%E5%8C%85%E6%8B%AC%E4%B8%89%E5%92%8C%E5%BC%A6%E3%80%81%E4%B8%83%E5%92%8C%E5%BC%A6%E3%80%81%E4%B9%9D%E5%92%8C%E5%BC%A6%E3%80%81%E5%8D%81%E4%B8%80%E5%92%8C%E5%BC%A6%E3%80%81%E5%8D%81%E4%B8%89%E5%92%8C%E5%BC%A6%E3%80%82&#34;&gt;三、七和弦&lt;/a&gt;&lt;/p&gt;
">【音乐】乐理</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/meng-te-qia-luo-suan-fa/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/369099011&#34;&gt;蒙特卡洛方法&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://leetcode.cn/problems/contains-duplicate/comments/111007&#34;&gt;leetcode 题解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;哈希表&lt;/a&gt;&lt;br&gt;
哈希函数 hash function ，hash 的英文含义是弄乱，所以哈希函数又称为散列函数&lt;br&gt;
&lt;a href=&#34;https://leetcode.cn/problems/two-sum/solution/liang-shu-zhi-he-by-leetcode-solution/&#34;&gt;leetcode 两数之和&lt;/a&gt;&lt;br&gt;
哈希表用于以 O(n) 的时间复杂度查找数据，一般用字典可以实现。&lt;/p&gt;
">leetcode 刷题</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/paypal-mian-shi/"" data-c="
          &lt;p&gt;岗位：AI Engineer&lt;br&gt;
一面&lt;br&gt;
根据项目经历问了项目内容，问了专业知识，人工智能算法，数据结构敲代码&lt;/p&gt;
&lt;p&gt;二面&lt;br&gt;
问了项目内容。人工智能的算法，数据结构敲代码&lt;/p&gt;
&lt;p&gt;三面：&lt;br&gt;
问了python的基础知识，让敲代码&lt;/p&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;leetcode 还是要刷，最起码把数据结构中最基本的题看会&lt;/li&gt;
&lt;li&gt;写在简历上的项目一定要熟悉，能复现项目&lt;/li&gt;
&lt;li&gt;人工智能算法一定要熟悉&lt;/li&gt;
&lt;/ol&gt;
">PayPal 面试</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/zhong-guo-dian-xin-yan-jiu-yuan-gong-zuo-ri-zhi/"" data-c="
          &lt;h1 id=&#34;2022712&#34;&gt;2022.7.12&lt;/h1&gt;
&lt;p&gt;-什么是 CV&lt;br&gt;
（Computer Vision）&lt;br&gt;
-什么是 CVPR&lt;br&gt;
IEEE Conference on Computer Vision and Pattern Recognition&lt;br&gt;
IEEE 国际计算机视觉与模式识别会议&lt;br&gt;
该会议是由IEEE举办的一年一度的计算机视觉和模式识别领域的顶级会议&lt;br&gt;
CVPR 的论文数逐年递增&lt;/p&gt;
&lt;p&gt;CVPR 网址：https://cvpr【year】.thecvf.com/&lt;br&gt;
【year】代表会议的年份&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/46426177&#34;&gt;CVPR 入门1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;历年 CVPR 的 workshop URL&lt;br&gt;
https://cvpr2017.thecvf.com/program/workshops&lt;br&gt;
https://cvpr2018.thecvf.com/program/workshops&lt;br&gt;
https://cvpr2019.thecvf.com/program/workshops&lt;br&gt;
https://cvpr2020.thecvf.com/workshops-schedule&lt;br&gt;
https://cvpr2021.thecvf.com/workshops-schedule&lt;br&gt;
https://cvpr2022.thecvf.com/workshop-schedule&lt;/p&gt;
&lt;h1 id=&#34;2022713&#34;&gt;2022.7.13&lt;/h1&gt;
&lt;p&gt;workshop：研讨会，比 conference 难度低一些&lt;br&gt;
DBLP（DataBase systems and Logic Programming）是计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的集成数据库系统。&lt;/p&gt;
&lt;p&gt;其他类似的机构的 workshop&lt;/p&gt;
&lt;p&gt;&lt;code&gt;一些 AI 顶会&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AAAI&lt;/strong&gt;&lt;br&gt;
国际先进人工智能协会（Association for the Advancement of Artificial Intelligence, AAAI）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NeurIPS&lt;/strong&gt;&lt;br&gt;
神经信息处理系统大会(Conference and Workshop on Neural Information Processing Systems) 关于机器学习和计算神经科学的国际会议&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ACL&lt;/strong&gt;&lt;br&gt;
（The Association for Computational Linguistics）计算语言学年会，由计算语言学学会（Association of Computational Linguistics）举办；ACL 是自然语言处理领域水平最高、最权威的国际会议&lt;/p&gt;
&lt;p&gt;**ICML **&lt;br&gt;
International Conference on Machine Learning，即国际机器学习大会。ICML如今已发展为由国际机器学习学会（IMLS）主办的年度机器学习国际顶级会议。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IJCAI&lt;/strong&gt;&lt;br&gt;
国际人工智能联合会议（International Joint Conference on Artificial Intelligence, 简称为IJCAI）是人工智能领域中最主要的学术会议之一&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ICCV&lt;/strong&gt;&lt;br&gt;
全称是 IEEE International Conference on Computer Vision，即国际计算机视觉大会，由IEEE主办，与计算机视觉模式识别会议（CVPR）和欧洲计算机视觉会议（ECCV）并称计算机视觉方向的三大顶级会议&lt;/p&gt;
&lt;h1 id=&#34;2022714&#34;&gt;2022.7.14&lt;/h1&gt;
&lt;p&gt;调研各个顶会网站的项目内容，统计热门技术分类，进行难易程度排序&lt;br&gt;
思路：先统计大标题，对大标题进行上述分析&lt;/p&gt;
&lt;h1 id=&#34;2022718&#34;&gt;2022.7.18&lt;/h1&gt;
&lt;p&gt;标注陌生名词，明显很复杂的/表意模糊的标完先放那，指向性明显的查出意思&lt;/p&gt;
&lt;h1 id=&#34;2022719&#34;&gt;2022.7.19&lt;/h1&gt;
&lt;p&gt;CVPR 关键词调研&lt;br&gt;
多模态学习是多个模态融合学习&lt;br&gt;
细粒度图像分类：&lt;br&gt;
在区分出基本类别的基础上，进行更精细的子类划分，如区分鸟的种类、车的款式、狗的品种等&lt;br&gt;
长视频理解：&lt;a href=&#34;https://zhuanlan.zhihu.com/p/158702087&#34;&gt;识别视频内容&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/127194745&#34;&gt;神经架构搜索 NAS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/248351130&#34;&gt;合成数据&lt;/a&gt;：人工合成数据用于机器学习&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/huxi2b/p/12989317.html#:~:text=4%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9B%BE%E5%83%8F%2F%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%201%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%202%20DeepCoder,--%20%E5%9F%BA%E4%BA%8E%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%203%20%E5%9F%BA%E4%BA%8ECNN%E7%9A%84%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%204%20%E5%9F%BA%E4%BA%8E%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%EF%BC%88GAN%EF%BC%89%E7%9A%84%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95&#34;&gt;图像压缩算法&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/300595016&#34;&gt;情感分析&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_37555071/article/details/108357663&#34;&gt;细粒度视觉&lt;/a&gt; &lt;a href=&#34;https://blog.csdn.net/wills798/article/details/88974715&#34;&gt;参考代码&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;2022720&#34;&gt;2022.7.20&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;王老师给定方向：&lt;/strong&gt;&lt;br&gt;
入门课题1：&lt;br&gt;
细粒度分类&lt;/p&gt;
&lt;p&gt;入门课题2：&lt;br&gt;
常规的检测识别姿态人脸&lt;br&gt;
GAN 生成对抗网络&lt;/p&gt;
&lt;p&gt;入门课题3：&lt;br&gt;
高级应用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;细粒度分类&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/499273744&#34;&gt;细粒度图像分类模型加实战代码&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/algorithmPro/article/details/113488199&#34;&gt;深度学习: 细粒度图像分类&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/m0_37192554/article/details/103733046&#34;&gt;细粒度分类，比赛，和相关模型介绍&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://cloud.tencent.com/developer/article/1931620&#34;&gt;基于Pytorch细粒度分类实战&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;精细化分类&lt;br&gt;
识别出物体的大类别（比如：计算机、手机、水杯等）较易，但如果进一步去判断更为精细化的物体分类名称，则难度极大。最大的挑战在于，同一大类别下 不同 子类别 间的 视觉差异 极小。因此，精细化分类 所需的图像分辨率 较高。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;一般步骤：&lt;/code&gt;&lt;br&gt;
首先找到前景对象(鸟)及其局部区域(头、脚、翅膀等), 之后分别对这些区&lt;br&gt;
域提取特征. 对所得到的特征进行适当的处理之后, 用来完成分类器的训练&lt;br&gt;
和预测&lt;/p&gt;
&lt;p&gt;&lt;code&gt;细粒度图像分类模型分类:&lt;/code&gt;&lt;br&gt;
(1)强监督模型: 需要类别以外的标签进行监督&lt;br&gt;
Part-based R-CNN 区域卷积神经网络&lt;br&gt;
Pose-normalized CNN&lt;br&gt;
Multi-proposal Net MT-CNN&lt;br&gt;
(2)弱监督模型: 不需要类别以外的标签&lt;br&gt;
图像过滤&lt;br&gt;
Multi-Attention MA-CNN&lt;br&gt;
双线性卷积神经网络结构(Bilinear CNN)&lt;/p&gt;
&lt;h1 id=&#34;2022721&#34;&gt;2022.7.21&lt;/h1&gt;
&lt;p&gt;调研细粒度视觉获奖代码&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/moxibingdao/article/details/106700835?spm=1001.2101.3001.6650.6&amp;amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-6-106700835-blog-103733046.pc_relevant_default&amp;amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-6-106700835-blog-103733046.pc_relevant_default&amp;amp;utm_relevant_index=11&#34;&gt;CVPR 2020 细粒度分类挑战赛冠军方案：数据增强+知识蒸馏，效果大幅提升&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/zsx1713366249/article/details/92370490&#34;&gt;2019CVPR细粒度论文笔记《Destruction and Construction Learning for Fine-grained Image Recognition》&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;2022722&#34;&gt;2022.7.22&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;AAAI 关键词调研&lt;/strong&gt;&lt;br&gt;
强化学习：&lt;br&gt;
试错，用错误调整参数。环境会返回给系统一个正确/错误的信号，用于调整参数&lt;/p&gt;
&lt;p&gt;进化神经网络（evolutionary neural networks,ENN）&lt;br&gt;
是基于 进化 计算和神经网络两大智能分支，将二者有机融合在一起产生的一种全新 神经网络模型&lt;/p&gt;
&lt;p&gt;细粒度图像分类：&lt;br&gt;
在区分出基本类别的基础上，进行更精细的子类划分，如区分鸟的种类、车的款式、狗的品种等&lt;/p&gt;
&lt;p&gt;分类置信度：&lt;br&gt;
分类置信度confidence是介于0和1 (或100%)之间的数字，它描述模型认为此预测边界框包含某类别目标的概率&lt;/p&gt;
&lt;p&gt;集成学习 Ensemble Learning：&lt;br&gt;
组合这里的多个弱监督模型以期得到一个更好更全面的强监督模型，集成学习潜在的思想是即便某一个弱分类器得到了错误的预测，其他的弱分类器也可以将错误纠正回来&lt;/p&gt;
&lt;h1 id=&#34;2022725&#34;&gt;2022.7.25&lt;/h1&gt;
&lt;p&gt;ACL 关键词调研 和 NeurlPS 关键词调研&lt;br&gt;
细粒度文本分类&lt;/p&gt;
&lt;p&gt;合成泛化：&lt;br&gt;
在机器学习的背景下，合成泛化（compositional generalization）是指机器学习从一组训练示例学习上下文表示。&lt;/p&gt;
&lt;h1 id=&#34;2022726&#34;&gt;2022.7.26&lt;/h1&gt;
&lt;p&gt;ICML 顶会的关键词调研&lt;/p&gt;
&lt;p&gt;我的选择：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CNN&lt;/li&gt;
&lt;li&gt;强化学习&lt;/li&gt;
&lt;li&gt;NLP 文本情感分析&lt;/li&gt;
&lt;li&gt;细粒度分类&lt;/li&gt;
&lt;li&gt;AI 安全&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2022 - Snack 物种识别论文方法阅读&lt;/p&gt;
&lt;p&gt;第一名使用方法解读：&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/471531558#:~:text=Visual%20Attention,Network%20%28VAN%29%20VAN%E6%9C%89%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%EF%BC%8C%E5%8D%B3%E4%B8%80%E4%B8%AA%E5%9B%9B%E7%BA%A7%E5%BA%8F%E5%88%97%EF%BC%8C%E8%BE%93%E5%87%BA%E7%A9%BA%E9%97%B4%E5%88%86%E8%BE%A8%E7%8E%87%E9%80%90%E6%B8%90%E9%99%8D%E4%BD%8E%EF%BC%8C%E5%88%86%E5%88%AB%E6%98%AFh4%C3%97w4%E3%80%81h8%C3%97w8%E3%80%81h16%C3%97w16%E5%92%8Ch32%C3%97w32%E3%80%82&#34;&gt;VAN (Visual Attention Network) 视觉注意力网络&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/463033740&#34;&gt;CoAtNet 结合卷积和注意力&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/116466239&#34;&gt;label smoothing 标签平滑 1&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/477813062&#34;&gt;label smoothing 标签平滑 2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;第二名使用方法解读：&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/baidu_36913330/article/details/120198840&#34;&gt;Vision Transformer(ViT)&lt;/a&gt;&lt;/p&gt;
">中国电信研究院工作日志</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shu-ju-fen-xi-de-yi-ban-guo-cheng/"" data-c="
          &lt;h1 id=&#34;读取数据&#34;&gt;读取数据&lt;/h1&gt;
&lt;h1 id=&#34;数据预处理&#34;&gt;数据预处理&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/137175585&#34;&gt;缺失值处理1&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/AvenueCyy/article/details/104354132&#34;&gt;缺失值处理2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_42389265/article/details/107013720&#34;&gt;pandas 统计某一列中各个值的出现次数&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/yyhhlancelot/article/details/82256488&#34;&gt;Pandas 关于pandas.DataFrame.fillna 填充Nan失败的问题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;特征工程&lt;br&gt;
可视化考察数据之间的关系，以及数据和结果的关系&lt;br&gt;
如何选择考察的数据？需要通过自己的想象和亲自动手测试&lt;/p&gt;
&lt;h1 id=&#34;归一化&#34;&gt;归一化&lt;/h1&gt;
&lt;h1 id=&#34;划分数据集&#34;&gt;划分数据集&lt;/h1&gt;
&lt;p&gt;交叉验证&lt;/p&gt;
">数据分析的一般过程</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/kaggle-chu-tan/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27424282&#34;&gt;入门好文：分分钟带你杀入Kaggle Top 1%&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.kaggle.com/code/startupsci/titanic-data-science-solutions/notebook&#34;&gt;大神项目&lt;/a&gt;&lt;br&gt;
&lt;code&gt;项目目的：&lt;/code&gt;&lt;br&gt;
以乘客的不同特征作为输入，输出乘客是生存还是死亡&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Sklearn 版本&lt;/code&gt;&lt;/p&gt;
&lt;h1 id=&#34;读取数据&#34;&gt;读取数据&lt;/h1&gt;
&lt;h1 id=&#34;数据预处理&#34;&gt;数据预处理&lt;/h1&gt;
&lt;p&gt;缺失值填充&lt;/p&gt;
&lt;h1 id=&#34;划分数据集&#34;&gt;划分数据集&lt;/h1&gt;
&lt;p&gt;用 train 数据集交叉验证&lt;/p&gt;
">【Kaggle】Titanic - MLP</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/she-ying-ru-men/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/26309412&#34;&gt;曝光三要素&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;曝光三要素的调节：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;中心思想&lt;/code&gt;&lt;br&gt;
快门速度保证画面不模糊的情况下，ISO 尽量低，高 ISO 会降低画质&lt;br&gt;
每次调节从低感光度起调&lt;/p&gt;
&lt;p&gt;&lt;code&gt;if 需要景深&lt;/code&gt;&lt;br&gt;
大光圈优先&lt;/p&gt;
&lt;p&gt;&lt;code&gt;if 需要整体清晰（如集体合照&lt;/code&gt;&lt;br&gt;
小光圈优先，然后调节快门速度确定合适的曝光&lt;/p&gt;
&lt;p&gt;&lt;code&gt;if 运动物体&lt;/code&gt;&lt;br&gt;
优先调节快门，保证画面清晰&lt;br&gt;
调节 ISO 确保画质&lt;br&gt;
最后调节光圈达到正确曝光&lt;/p&gt;
&lt;p&gt;快门速度的单位：秒&lt;/p&gt;
&lt;h1 id=&#34;调色思路&#34;&gt;调色思路&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;人文&lt;/code&gt;&lt;br&gt;
青橙、蓝绿&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cp.originoo.com/login&#34;&gt;锐景创意内容平台&lt;/a&gt;&lt;/p&gt;
">【摄影】摄影入门</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ji-wang-qi-mo-fu-xi/"" data-c="
          &lt;p&gt;本笔记对应教材为《计算机网络自顶向下方法》&lt;/p&gt;
&lt;h1 id=&#34;第一章-概述&#34;&gt;第一章 概述&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;计算机网络协议分层&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;OSI 七层模型&lt;/code&gt;&lt;br&gt;
&lt;strong&gt;应用层&lt;/strong&gt;  指网络操作系统和具体的应用程序，对应WWW服务器、FTP服务器等应用软件&lt;br&gt;
&lt;strong&gt;表示层&lt;/strong&gt;  数据语法的转换、数据的传送等&lt;br&gt;
&lt;strong&gt;会话层&lt;/strong&gt;  建立起两端之间的会话关系，并负责数据的传送&lt;br&gt;
&lt;strong&gt;传输层&lt;/strong&gt;  负责错误的检查与修复，以确保传送的质量，是TCP工作的地方。（报文）&lt;br&gt;
&lt;strong&gt;网络层&lt;/strong&gt;  提供了编址方案,IP协议工作的地方(数据包）&lt;br&gt;
&lt;strong&gt;数据链路层&lt;/strong&gt;  将由物理层传来的未经处理的位数据包装成数据帧&lt;br&gt;
&lt;strong&gt;物理层&lt;/strong&gt;  对应网线、网卡、接口等物理设备(位)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;计算机网络服务模型&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;TCP/IP 五层模型&lt;/code&gt;&lt;br&gt;
&lt;strong&gt;应用层&lt;/strong&gt;  通过应用进程间交互完成特定的互联网应用，定义应用进程之间通信和交互的规则&lt;br&gt;
&lt;strong&gt;传输层&lt;/strong&gt;  进程之间通信的通用数据传输服务&lt;br&gt;
&lt;strong&gt;网络层&lt;/strong&gt;  网络中不同主机提供通信服务&lt;br&gt;
&lt;strong&gt;数据链路层&lt;/strong&gt;  两个相邻网络结点之间传送数据&lt;br&gt;
&lt;strong&gt;物理层&lt;/strong&gt;  如何在传输媒介中传输比特流&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分层优缺点：&lt;/strong&gt; 分层提供了 一种结构化方式来讨论系统组件。模块化使更新系统组件更为容易。分层的一个潜在缺点 是一层可能冗余较低层的功能。第二种潜在的缺点是某层的功能可能需要仅在其他某层才出现的 信息（如时间戳值），这违反了层次分离的目标。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;电路交换和分组交换的优缺点&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;电路交换&lt;/code&gt;&lt;br&gt;
优点：数据直接传送 ，时延小；保证数据有序性；稳定带宽、专用信道、一致的数据速率。&lt;br&gt;
缺点：线路利用率低、不便于进行差错控制；建立物理链路需要时间、资金成本&lt;br&gt;
&lt;code&gt;分组交换&lt;/code&gt;&lt;br&gt;
优点：链接中的故障不会停止数据的传递；带宽利用率高；更简单、有效、成本更低&lt;br&gt;
缺点：通信有延迟；会导致信息丢失；分组需要提供额外信息增加开销&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;计算机网络性能指标&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.jianshu.com/p/599c11874f24&#34;&gt;公式总结&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;传输时延、发送时延、处理时延：&lt;/strong&gt; 均指在发送端将比特流打包成分组的时间。&lt;br&gt;
发送时延 = 数据帧长度 / 发送速率（信道带宽）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;传播时延：&lt;/strong&gt; 从发送端到接收端过程中消耗的时间&lt;br&gt;
传播时延 = 信道长度 / 电磁波传播速度&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;利用率：&lt;/strong&gt;  D：网络当前时延 D0：网络空闲的时延 U：信道利用率&lt;br&gt;
当前信道利用率：D = D0 / （1 - U）  可见，信道利用率越大，时延越大（包多时延大）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时延带宽积：&lt;/strong&gt; 传播时延 x 带宽&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;吞吐量：&lt;/strong&gt; 单位时间内通过某个网络的实际的数据量&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;第二章-应用层&#34;&gt;第二章 应用层&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;P2P 和 C/S 优缺点&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;客户-服务器&lt;/code&gt;&lt;br&gt;
优点：客户、服务器分离，允许网络分布操作；一个服务器可以服务于多个客户端；&lt;br&gt;
缺点：客户机会比较依赖于服务器工作。&lt;br&gt;
&lt;code&gt;P2P&lt;/code&gt;&lt;br&gt;
优点：可扩展性强，传播速度优化；&lt;br&gt;
缺点：用户直连，没有确保安全性，管理困难。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;P2P 和 C/S 模式计算题&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;题目1&lt;/code&gt;&lt;br&gt;
&lt;em&gt;考虑向N个对等方发F=15Gb的一个文件。该服务器具有us=30Mbps的上载速率，每个对等方具有di=1Mbps的下载速率和上载速率u。对于N=10、100和1000并且u=300kps、700kps和2Mbps，对于N和u的每种组合绘制出确定最小分发时间的图表。需要分别针对客户-服务器分发和P2P分发两种情况制作。&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;在计算C-S分发的最小分发时间时，我们使用以下公式：
Dcs=max{NF/us,F/di}  服务器分发前需要先将数据上载，取服务器上载和各链路下载速率的最大值
其中F=15Gb=15*1000Mb
us=30Mbps，dmin=di=1Mbps
注意，300 Kbps=300/1000 Mbps
在计算P2P分发的最小分发时间时，我们使用以下公式：
Dp2p=max{F/us,F/di,NF/(us+∑ui)}
其中F=15Gb=15*1000Mb
us=30Mbps，di=di=1Mbps
注意，300 Kbps=300/1000 Mbps
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;DNS 域名系统&lt;/strong&gt;&lt;br&gt;
DNS 采用 客户/服务器 模型，运行在 UDP 之上，使用 53 号端口。缓存就是对重复的访问，省去一些重复的解析，节省时间。&lt;br&gt;
&lt;code&gt;域名解析过程&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655655184489.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655656720717.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;超文本传输协议 HTTP&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HTTP 使用 TCP 连接进行可靠传输，端口号 80，定义了在浏览器和服务器之间的请求和响应的格式。&lt;/li&gt;
&lt;li&gt;HTTP 本身是无连接的，通信双方交换 HTTP 报文前不需要先建立连接&lt;/li&gt;
&lt;li&gt;HTTP 是无记忆的，每次访问都一样，各自独立&lt;/li&gt;
&lt;li&gt;使用 Cookie 保存用户活动数据库，Cookie 是服务器产生的、储存在用户主机中的文本文件&lt;/li&gt;
&lt;li&gt;HTTP 既可以建立持久连接（只需建立一次 TCP 连接，然后传输 HTML 文件，之后可一直传输文件），也可以建立非持久连接（先建立一个 TCP 连接传输 HTML 文件，之后每次传输数据还都需要重新建立 TCP 连接）&lt;/li&gt;
&lt;li&gt;HTTP 响应报文和请求报文开始行不同&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;输入 URL 后发生的事情：&lt;/code&gt;&lt;br&gt;
DNS 域名系统解析出 URL 对应的 IP 地址&lt;br&gt;
浏览器与该 IP 对应的服务器建立 TCP 连接&lt;br&gt;
浏览器发出 HTTP 请求&lt;br&gt;
服务器通过 HTTP 响应把文件 index.htm 发送给浏览器&lt;br&gt;
释放 TCP 连接&lt;br&gt;
浏览器解释文件 index.htm ，并将 Web 页展示给用户&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二章综合例题&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;例1 —— 协议使用&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655646282813.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655646288287.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;例2 —— HTTP 连接计算&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655647446351.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655647521822.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655647526867.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;em&gt;本题注意：&lt;/em&gt; 无论是持久还是非持久，都需要先建立一个 TCP 连接，然后传送一个 HTML 网页文件，然后再进行后续操作&lt;/p&gt;
&lt;p&gt;&lt;code&gt;例3 —— HTTP 连接计算&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655654243905.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655654248482.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
考虑单个主机：&lt;br&gt;
非持久并行：&lt;br&gt;
(150/150 + 150/150 + 150/150 + 100000/150) +（150/(150/8) + 150/(150/8) + 150/(150/8) + 200000/(150/8) ）=11360&lt;br&gt;
持久并行：&lt;br&gt;
(150/150+ 150/150 + 150/150+ 100000/150) +  (150/(150/8) + 200000/(150/8))=11344&lt;br&gt;
持续连接HTTP相比非持续并没有显著增益&lt;br&gt;
&lt;em&gt;本题注意：&lt;/em&gt; 题干说的包含数据的 100,000b 的分组是 HTML 网页文件，而且仔细审题，后面说仅包含控制的分组为 150b ，说明 100,000b 中已经含有控制比特。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;常见的应用层协议和对应使用的运输层协议&lt;/code&gt;&lt;br&gt;
TCP:HTTP FTP SMTP POP3&lt;br&gt;
UDP:SNMP DHCP NTP TFTP&lt;/p&gt;
&lt;h1 id=&#34;第三章-传输层-运输层&#34;&gt;第三章 传输层 / 运输层&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;可靠性 RDT&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;拥塞控制&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655464901846.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
在恢复部分：Tahoe：还用慢开始算法，从 1 开始；Reno：快恢复算法，从一半开始&lt;/p&gt;
&lt;h1 id=&#34;第四章-网络层&#34;&gt;第四章 网络层&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;网络层的功能&lt;/strong&gt;&lt;br&gt;
路由选择与分组转发、异构网络互联、拥塞控制&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IP 地址 &amp;amp; 子网掩码&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/fzlsss/p/9678954.html&#34;&gt;网络号，主机号，主机地址，网络地址，主机地址，子网号，子网地址 概念辨析&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1eV411J7Hv?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;子网掩码B站&lt;/a&gt;&lt;br&gt;
IP 地址的主机号全为 0 表示网络号，全为 1 表示广播号&lt;br&gt;
IP 地址和子网掩码都是一串 32 位的二进制数，二者一一对应。子网掩码为 1 的位对应 IP 地址中的网络号，为 0 的位对应 IP 地址中的主机号。注意，子网掩码肯定是由连续的 1 和连续的 0 组成的，因为网络号和主机号不能交叉。IP 和 子网掩码相与得到该网络的网络号（标识该网络的地址）&lt;br&gt;
CIDR记法：在 IP 后面加一个斜杠和一个数字，表示网络号位数是多少，如 172.16.0.0/16 表示有 16 位网络号，前 16 位称为网络前缀&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/85960091&#34;&gt;总结&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;子网划分&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1a84y1F72Z/?spm_id_from=333.788.recommend_more_video.-1&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站讲解&lt;/a&gt;&lt;br&gt;
假如某网络只需要 100 台主机，而主机号可以表示 200 台主机。我们不想对该 IP 进行浪费，将主机号再次进行划分，使用主机字节的前几位标记划分子网的网络号，其余位数用于表示主机地址。&lt;br&gt;
&lt;code&gt;例&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655460590774.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655460595483.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;注&lt;/code&gt; 主机号全 0 表示网络号，全为 1 表示广播号，这两个不能算在主机地址中&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;网络地址转换-NAT&lt;/strong&gt;&lt;br&gt;
将局域网（LAN）址转换为公网（WAN）地址，对外隐藏局域网内部 IP 地址，使得整个局域网只需要一个全球的 IP 即可访问因特网&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/mlgjb/p/8087612.html#:~:text=WLAN%EF%BC%8C%E5%85%A8%E7%A7%B0Wireless%20LAN%2C%20%E6%97%A0%E7%BA%BF%E5%B1%80%E5%9F%9F%E7%BD%91%E3%80%82%20%E5%92%8CLAN%E4%B8%8D%E5%90%8C%EF%BC%8CWLAN%E7%9A%84%E6%95%B0%E6%8D%AE%E9%80%9A%E8%BF%87%E7%94%B5%E7%A3%81%E6%B3%A2%E4%BC%A0%E8%BE%93%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E5%B8%B8%E8%AF%B4%E7%9A%84%E7%A9%BA%E6%B0%94%E4%BC%A0%E8%BE%93%E3%80%82%20WLAN,%E5%88%A9%E7%94%A8%E7%94%B5%E7%A3%81%E6%B3%A2%E5%9C%A8%E7%A9%BA%E6%B0%94%E4%B8%AD%E5%8F%91%E9%80%81%E5%92%8C%E6%8E%A5%E5%8F%97%E6%95%B0%E6%8D%AE%EF%BC%8C%E8%80%8C%E6%97%A0%E9%9C%80%E7%BA%BF%E7%BC%86%E4%BB%8B%E8%B4%A8%E3%80%82%20WLAN%20%E4%BD%BF%E7%94%A8%20ISM%20%28Industrial%E3%80%81Scientific%E3%80%81Medical%29%20%E6%97%A0%E7%BA%BF%E7%94%B5%E5%B9%BF%E6%92%AD%E9%A2%91%E6%AE%B5%E9%80%9A%E4%BF%A1%E3%80%82&#34;&gt;词条辨析：LAN、WAN、WLAN、WIFI&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/434689354&#34;&gt;词条辨析：网关和路由&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ARP 协议&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://kaoyan.koolearn.com/20211028/1468028.html&#34;&gt;同一局域网内，将 IP 地址映射为 MAC 地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DHCP 协议&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/Gherbirthday0916/article/details/125154347&#34;&gt;当一台新主机加入网络时，DHCP 给该主机分配 IP 地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ICMP 协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;距离向量路由算法 - RIP 协议&lt;/strong&gt;&lt;br&gt;
在网络中加入新的路由器时，用于对路由器下一条的更新，更新当前路由表。原则上满足到达下一网络的距离尽量短，距离相同时尽量不改动，同一下一跳改动则必改动的原则。&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1BJ41157rM/?spm_id_from=333.788.recommend_more_video.0&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站原理+题目讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1C4411375y?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;B站做题步骤讲解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最长前缀路由选择&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1jk4y127Cu?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;b站讲解&lt;/a&gt;&lt;br&gt;
原理：哪条 IP 的匹配度最高选择哪个&lt;br&gt;
&lt;code&gt;例&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655458936247.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;步骤&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把目的 IP 化为二进制&lt;/li&gt;
&lt;li&gt;求得路由表中每一条 IP 路径的网络号&lt;/li&gt;
&lt;li&gt;逐一与目的 IP 对比，符合度最高的为正确路径&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;例&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655458832077.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655458838336.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655458843286.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;第五章-数据链路层&#34;&gt;第五章 数据链路层&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;DV算法&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;Dijkstra算法&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;画出表格，左边是已经确定的点，右边每个格包含两个数据，第一个是起始点到该点的距离，第二个是该点前一个点是什么&lt;/li&gt;
&lt;li&gt;从第一个点 V1 出发，每次找和当前点相邻点的距离，将最短路径保存在各个点中&lt;/li&gt;
&lt;li&gt;找到该行距离数最小的点，保存在左侧确定点部分&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655617989211.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;strong&gt;LS算法&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;Bellman-Ford算法&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;第六章-链路层和局域网&#34;&gt;第六章 链路层和局域网&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;随机接入协议&lt;/strong&gt;&lt;br&gt;
用户可以根据自己的意愿随机发送信息，可以占用信道全部速率，但有两个或多个用户同时发送信息时，就会产生碰撞，导致双方均发送失败。为解决随机接入发生的碰撞，用户需要按照几种协议反复重传帧，直到无碰撞通过。&lt;br&gt;
&lt;code&gt;纯 ALOHA 协议&lt;/code&gt;&lt;br&gt;
用户可以不进行检测的发数据，若一段时间按内未收到确认，则认为发生了碰撞。发送站点需等待一段时间后再次发送数据，直至发送成功。纯 ALOHA 网络吞吐量低，改进后变为 时隙 ALOHA&lt;br&gt;
&lt;code&gt;时隙 ALOHA 协议&lt;/code&gt;&lt;br&gt;
把所有各站时间同步，划分一段段等长时隙，只能在每个时隙开始才能发送帧&lt;br&gt;
&lt;code&gt;CSMA 协议&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655716220522.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;CSMA/CD 协议&lt;/code&gt;&lt;br&gt;
先听后发，边听边发，一旦碰撞，停止发送。只能检测碰撞，不能避免。用于总线型网络，通过检测电缆中电压变化实现。&lt;br&gt;
&lt;code&gt;CSMA/CA 协议&lt;/code&gt;&lt;br&gt;
发送数据时先广播告知其他节点，让其他节点某段时间内不要发送数据，以免碰撞。用于无线网络，通过检测电磁波能量强弱实现。&lt;br&gt;
&lt;code&gt;总结&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655717426387.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MAC地址， hop-by-hop&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;第七章-无线网络和移动网络&#34;&gt;第七章 无线网络和移动网络&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;无线 vs 有线&lt;/strong&gt;&lt;br&gt;
协议设计&lt;/p&gt;
&lt;p&gt;区别：有线与无线的区别在于数据传输的方式、标准；在没有干扰的前提下，有线与无线传输速度没有区别。&lt;br&gt;
特点：&lt;br&gt;
1、有线：需要设备之间使用网线连接，这样限制了设备之间的距离。&lt;br&gt;
2、无线：通过无线协议实现数据传输或者网络连接，一般室内50m范围内可以全方位传输数据。不过无线容易被电磁波干扰，而且墙壁对信号削弱也比较大。递减的信号强度、来自其他源的干扰、多路径传播&lt;/p&gt;
&lt;h1 id=&#34;第八章-计算机网络中的安全&#34;&gt;第八章 计算机网络中的安全&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;对称加密 vs. 非对称加密&lt;/strong&gt;&lt;br&gt;
对称 和 非对称指的就是 加密 和 解密 用的 秘钥 是不是同一个。对称：同一个，非对称：不同&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV134411r7Kt?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=**3d9ada7d42c971c0c3f04a22270daf33**&#34;&gt;B站讲解&lt;/a&gt;&lt;br&gt;
&lt;code&gt;对称加密&lt;/code&gt;&lt;br&gt;
一把钥匙一把锁头&lt;br&gt;
加密过程：A 用锁头锁住文件后，把钥匙和密码都发给 B&lt;/p&gt;
&lt;p&gt;&lt;code&gt;非对称加密&lt;/code&gt;&lt;br&gt;
把自己的锁头公开，所有人都可以用你的锁来加密，但只有你自己才有钥匙&lt;br&gt;
加密过程：A 把自己的锁头给 B ，B 用 A 的锁头锁住文件后，再发给 A&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.jianshu.com/p/75a5822d0eec&#34;&gt;traceroute：路由器追踪&lt;/a&gt;&lt;/p&gt;
">【计网】期末复习</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/xing-shi-yu-yan-yu-zi-dong-ji-bi-ji/"" data-c="
          &lt;h1 id=&#34;绪论&#34;&gt;绪论&lt;/h1&gt;
&lt;p&gt;∑（西格玛）表示字母表，字母表中的元素称为该字母表的一个字母&lt;/p&gt;
&lt;p&gt;ɛ 为空串，长度为 0，就是什么都没有。0 次幂代表空串&lt;/p&gt;
&lt;p&gt;字母表的n次幂，得到的集合，其中的元素为字母表中字母构成的句子&lt;br&gt;
字母表的闭包（字母表中所有字母的排列组合）&lt;br&gt;
字母表的正闭包（+）加上字母表的零次幂（空串）为字母表的克林闭包（*）&lt;br&gt;
注意，字母表的闭包是把字母表的 n 次幂并在一起，是各个次幂运算结果之和&lt;/p&gt;
&lt;p&gt;字母表 ∑ 上 的语言 L，是 ∑* 的一个子集 （语言 L 是集合，满足集合运算）&lt;br&gt;
L表示字母表 ∑ 上的一个语言（语言 L 就是所有句子的集合，证明语言相等，则证明集合相等），x 表示语言 L 中的一个句子，abcd表示单个字符&lt;br&gt;
其关系为：a ∈ x ∈ L ⊆ ∑*&lt;/p&gt;
&lt;h1 id=&#34;文法&#34;&gt;文法&lt;/h1&gt;
&lt;p&gt;V ：变量，可以被其他串替换，用大写 ABC 表示&lt;br&gt;
T ：终极符，这个语言里边最终的句子，都是由终极符构成的串（必定含有终极符），用小写 abc 表示&lt;br&gt;
P : 产生式，又叫语法规则、定义式，可以理解为一个语言的语法，字母必须要这么组合，才是该语言。A→B 读作 ：A 可以定义为 / 可以为 B 。 产生式可以是终极符和非终极符构成的串，但是不能仅仅是终极符构成的串&lt;br&gt;
S ：开始符，即，所有推导要从该符号开始。从该符号推导出来的才是里面的句子。开始符必须是变量之一，因为只有在变量集合中才能作为产生式的左部&lt;/p&gt;
&lt;p&gt;若产生式最终只含终极符，那么推导结束&lt;/p&gt;
&lt;p&gt;推导：利用产生式推出新表达式，归约和其相反&lt;/p&gt;
&lt;p&gt;G 表示文法  L(G) 表示由文法 G 定义的语言，也就是符合文法 G 的句子集合&lt;br&gt;
G1 G2为两个文法 ，L(G1) = L(G2) 则，G1 G2等价，也就是句子集合相同&lt;/p&gt;
&lt;p&gt;简化文法：只列出该文法的所有产生式，如：S→A|B|AA|BB，A→0，B→1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;乔姆斯基文法体系&lt;/strong&gt;&lt;br&gt;
0型文法：最常规的文法&lt;br&gt;
1型文法（上下文有关文法CSG），只需满足右边比左边长，（左边可以有终极符，可以任意长度）&lt;br&gt;
2型文法（上下文无关文法CFG）：在1型文法（上下文有关文法）前提下，必须满足左边是一个变量（只能有一个变量，长度为1，不能是终极符）&lt;br&gt;
3型文法（正则文法RG）在2型文法的基础上，右侧为终极符串 + 一个串（注意只能有一个变量，可为空串）形如：A→w，A→wB&lt;/p&gt;
&lt;p&gt;对应语言分别是 0，1，2，3型语言，缩写分别为：CSL,CFL,RL&lt;br&gt;
正则语言 RL&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;线性文法&lt;/strong&gt;&lt;br&gt;
线性文法：在正则文法基础上，增加了新产生式形式：终极符串 + 一个串 + 终极符串 （注意，还是只能有一个变量）形如：A→w，A→wBx&lt;/p&gt;
&lt;p&gt;变量代表的串在哪一侧就是哪种线性文法&lt;br&gt;
右线性文法就是正则文法&lt;br&gt;
左线性文法：形如：A→w，A→Bw&lt;br&gt;
同一个语言用左右线性文法都可以构造，故，左线性文法与右线性文法等价&lt;/p&gt;
&lt;p&gt;注：左线性文法 与 右线性文法 混用不是 正则文法&lt;br&gt;
空语句不会改变语言类型&lt;/p&gt;
&lt;h1 id=&#34;有穷状态自动机&#34;&gt;有穷状态自动机&lt;/h1&gt;
&lt;p&gt;有穷状态自动机（finite automata，简称 FA）：识别正则语言，FA是正则语言的识别器&lt;br&gt;
扩展状态转移函数：Q x *∑→ Q ：一个状态读入一个字符串，变成另一个状态，*∑代表字符串&lt;/p&gt;
&lt;p&gt;确定的有穷状态自动机（deterministic finite automata，简称 DFA）一个输入只有一个结果&lt;br&gt;
构造 DFA 步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定义 DFA 状态，每一步都干啥&lt;/li&gt;
&lt;li&gt;定义转移函数，每个状态输入值后到达的新状态&lt;/li&gt;
&lt;li&gt;画图，完成构造&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655293535417.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
对于上面图片最下面这几行，意思是&lt;br&gt;
q0x1 是即时描述的初始状态，x1q0是即时描述的终止状态，对于下面几行都一样，左边通过至少一步变为右边的终止状态，最后一个q是终止状态的符号&lt;/p&gt;
&lt;p&gt;不确定的有穷状态自动机（Nondeterministic finite automata，简称 NFA）&lt;br&gt;
输入一个字符可以转移到多个状态（多个状态是同时进行的）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NFA → DFA&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655294134548.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;注&lt;/code&gt; q3 在 NFA 中为终止状态，在新的 DFA 中含有 q3 的状态也为终止状态。同样 q0 还为起始状态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ɛ-NFA → NFA&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655380631215.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655294724853.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655380638255.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;步骤&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把 ɛ-NFA 表格列出来，准备构造 NFA 的表格。&lt;/li&gt;
&lt;li&gt;画图构造 ɛ-闭包&lt;/li&gt;
&lt;li&gt;当输入一个数时，把该闭包中所有能接收该数的状态的 ɛ-闭包 并集&lt;/li&gt;
&lt;li&gt;q0，q1，q2 还是原来的 q0，q1，q2 。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;构造与 DFA 等价的正则文法 RG&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655295192637.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;注&lt;/code&gt; 当某一状态 qi 是终止状态时（状态转移图表现为两个套在一起的圆），如 q0 →（0） q1，那么产生式不仅需要 q0 → 0q1，还需要 q0 → 0，因为0可能为该语的最后一位。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;构造与正则文法 RG 等价的 DFA&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655379303621.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;注&lt;/code&gt; 需要单独设置一个终止状态 Z 来接受只含终极符的转移。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;左线性文法 → FA （反过来）&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655295333056.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;注&lt;/code&gt; 和正则文法完全相反，可以先按 RG → DFA 构造一遍，然后箭头全部倒置，S 的位置变为 双圆环，Z 的位置变为单元环。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FA → 左线性文法&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655382154334.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;步骤&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根据 FA 先把 RG 构造出来。&lt;/li&gt;
&lt;li&gt;把单独的终极符加上一个终止状态 Z 变成 2Z。&lt;/li&gt;
&lt;li&gt;全体调转，例如 q2 → 2q3 变为  q3 → q2 2&lt;/li&gt;
&lt;li&gt;删除所有起始状态 q0 ，如 q1 → q0 0 变为  q1 → 0&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;注意：&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;起始状态前必须加 S→&lt;/li&gt;
&lt;li&gt;若某一状态 qi 只有指入的箭头没有指出的箭头，则盖状态为陷阱状态，可以删除不考虑。&lt;/li&gt;
&lt;li&gt;当自动机以正闭包（+）呈现时必须以空串ɛ开始，以克林闭包（*）呈现时不用。因为一个自动机必须以空串开始，而正闭包中不含空串。&lt;/li&gt;
&lt;li&gt;当由 RG → FA 时，需要自己设置一个终止状态Z，用于接收A→1 | 1C 这样的产生式；相反的，左线性文法构造FA时，需要自己设置一个开始状态Z，同样，产生式箭头也和RG相反，例如，A→1 | C1 , 意思时，由开始状态Z读入1跳转到状态A，由状态C读入一个1跳转到状态A。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;正则表达式&#34;&gt;正则表达式&lt;/h1&gt;
&lt;p&gt;正则表达式（regular expression，RE）&lt;br&gt;
形式定义：&lt;br&gt;
前三条都是定义基本字符串，Ø 为空集，ɛ 为空字符串，a 为任意字符。&lt;br&gt;
第四条说的是前三条的元素根据第四条的运算可以形成正则表达式。&lt;br&gt;
第一种运算 (r+s) 是集合的并集。&lt;br&gt;
第二种运算 (rs) 是指 r 和 s 串的连接&lt;br&gt;
第三种是克林闭包，(r*) = ( r0+r1+r2+….. )&lt;br&gt;
&lt;code&gt;注&lt;/code&gt; 正则表达式必须加括号&lt;br&gt;
正则表达式RE r ，记作L(r)，也是一种语言，是一个集合，也可直接记作r&lt;/p&gt;
&lt;p&gt;注：Ø的零次幂是 ɛ&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RE → FA&lt;/strong&gt;&lt;br&gt;
记住下面几个基本元素，拼接即可&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655391708163.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正则语言 RL / DFA → RE&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先增加两个状态，一个起始状态 X 一个终止状态 Y ，为了终止状态唯一&lt;/li&gt;
&lt;li&gt;选取一个状态分析（最好是终止状态前一个状态，因为好分析），找出该状态的出度入度，分析是闭包运算，还是并集运算还是连接运算。然后用正则表达式替换&lt;br&gt;
&lt;code&gt;注&lt;/code&gt; 并弧用加号&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655393874197.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;正则语言的性质&#34;&gt;正则语言的性质&lt;/h1&gt;
&lt;p&gt;如果一个语言是正则语言，那么一定满足泵引理，反之不成立。&lt;br&gt;
正则语言的封闭性：经过运算还为正则语言&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DFA 极小化&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;步骤&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构造表格，如果有不可达状态则先删除，左边列是 1~n 下面行是 0~n-1&lt;/li&gt;
&lt;li&gt;所有终点为一组，行列标上 x&lt;/li&gt;
&lt;li&gt;任意找两个其他未标注的点，看两个点到终点的路径，分别看输入一个数，输入两个数，输入三个数后，是否相同，只要存在相同的路径，则两个点为不可区分，不用标注；无论怎么都找不到，则为可区分，标上 x。注意，不能走自环，只能走直路。&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655482140507.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655482151183.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;上下文无关语言&#34;&gt;上下文无关语言&lt;/h1&gt;
&lt;p&gt;上下文无关文法：CFG&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;派生树：&lt;/strong&gt; 一定是上下文无关文法 CFG 的派生树。&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655469230531.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;最左派生：从最左边开始替换，最右、随机同理。&lt;br&gt;
派生树越靠近叶子节点（越在下面），优先级越高。&lt;br&gt;
随机派生有多少种方式，就有多少种派生。计算派生时，找到派生树种所有的变量（ABC），计算所有变量的排列数，即为派生数。但是要注意固有顺序不能变。&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655470345207.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
根据派生树写出原 CFG 直接看图就行。&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655470533945.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CFG 的化简&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;步骤&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;删除无用符号（注意要把不可达状态的整个表达式都删了，比如 S→AB，B 不存在，则 AB 都删）&lt;/li&gt;
&lt;li&gt;删除 ɛ 产生式&lt;/li&gt;
&lt;li&gt;删除单一产生式（形如 A → B）&lt;/li&gt;
&lt;li&gt;再次出现无用符号时，再次删除无用符号&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;例&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655470845354.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;去除 ɛ 产生式的例子&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655471117714.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
任何不含空串的CFG都能转化为 CNF / GNF&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;乔姆斯基范式：&lt;/strong&gt; CNF，形如 A → BC 、 A → a，在化为 CNF 前需先简化&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655472152865.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;strong&gt;格雷巴赫范式：&lt;/strong&gt; GNF，形如 A → a 、 A → aBCDE.... ，在化为 GNF 前需先简化&lt;br&gt;
需要消除左递归（把左递归变为右递归），形如：A → Aβ&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655476112225.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;code&gt;简例&lt;/code&gt;&lt;br&gt;
A → A0 | 1&lt;br&gt;
变为：&lt;br&gt;
A → 1&lt;br&gt;
A → 1B&lt;br&gt;
B → 0B&lt;br&gt;
B → 0&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655476340663.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;下推自动机-pda&#34;&gt;下推自动机 PDA&lt;/h1&gt;
&lt;p&gt;PDA 是 ɛ-NFA 增加了一个栈&lt;br&gt;
PDA 用于识别一个·句子是否满足上下文无关文法（识别上下文无关语言）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PDA 的构成：&lt;/strong&gt;&lt;br&gt;
M = （Q ，∑，Γ，δ，q0，Z0，F）&lt;br&gt;
Q ：状态的集合 {q0 q1 q2}&lt;br&gt;
∑：输入字母表，要识别的句子含有的符号，如{a,b,c} {1,2,3}&lt;br&gt;
Γ：栈符号表，对应 CFG 中的变量 {S,A,B,C}&lt;br&gt;
δ：状态转移函数，有两种格式，在下面给出&lt;br&gt;
q0：起始状态&lt;br&gt;
Z0：开始符号，开始时栈底的元素&lt;br&gt;
F：终止状态集合{q1 q2 q3}，空栈接受时 F 为 Ø&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;状态转移函数 δ 的两种格式&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;常规转移&lt;/code&gt;&lt;br&gt;
δ(q，a，Z)={(p1，γ1)0(p2，γ2)，...，(pm，γm)}&lt;br&gt;
表示状态 q 时，读入句子中的符号 a ，弹出栈顶符号 Z ，转移到新状态 pi ，将 γi 中的符号从右向左压入栈。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例1&lt;/strong&gt;&lt;br&gt;
δ1(q0，1，S)={(q0，SB)}&lt;br&gt;
在状态 q0 时，读入 1 ，弹出栈顶元素 S ，转移到新状态 q0 ，将 SB 串以 B、S 的顺序入栈（B 在 S 的下面）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例2&lt;/strong&gt;&lt;br&gt;
δ1(q0，0，A)={(q0，ε)}&lt;br&gt;
在状态 q0 时，读入 0 ，弹出栈顶元素 A ，转移到新状态 q0 ，将 ε 入栈&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ɛ 转移&lt;/code&gt;&lt;br&gt;
δ(q，ɛ，Z)={(p1，γ1)0(p2，γ2)，...，(pm，γm)}&lt;br&gt;
表示状态 q 时，读入句子中的符号 a ，弹出栈顶符号 Z ，转移到新状态 pi ，将 γi 中的符号从右向左压入栈。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;&lt;br&gt;
δ2(q0，ε，Z)={(q1，ε)}&lt;br&gt;
在状态 q0 时，读入 1 ，弹出栈顶元素 S ，转移到新状态 q0 ，将 SB 串以 B、S 的顺序入栈（B 在 S 的下面）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;构造 PDA&lt;/strong&gt;&lt;br&gt;
CFG → PDA&lt;br&gt;
&lt;code&gt;空栈接受&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;化为 CFG&lt;/li&gt;
&lt;li&gt;CFG → GNF&lt;/li&gt;
&lt;li&gt;写出 GNF 的最左派生，注明 PDA 转移函数要做的动作&lt;/li&gt;
&lt;li&gt;写出 PDA&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655535184644.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655535222307.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655535227819.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;终态接受&lt;/code&gt;&lt;br&gt;
&lt;strong&gt;和空栈接受对比：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;符号的添加：&lt;br&gt;
添加一个开始符号 Z0、一个栈底符号 Z 、一个终止状态 q1&lt;br&gt;
从 Z0 开始，弹出 Z0，把 Z 压入栈底，当栈内只剩 Z 时，跳转到 q1 终止状态&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;转移函数的添加：&lt;br&gt;
原状态转移函数都不变，找到原栈底元素的转移函数，这里是含有 S 的三个转移函数，把 S 改为新定义的栈底符号 Z0，在右边入栈中加上新的栈底元素 Z 。对于右边是 ε 的转移，只改动 Z0，ε 不变。&lt;br&gt;
此外，还需在最后添加遇到 Z 转移到 q1 的转移函数。&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655536498042.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;空栈接受的 PDA → 终态接受的 PDA （二者等价）&lt;/p&gt;
&lt;p&gt;CFG → 空栈接受的 PDA&lt;/p&gt;
&lt;h1 id=&#34;图灵机-tm&#34;&gt;图灵机 TM&lt;/h1&gt;
&lt;p&gt;M=(Q, ∑, Γ, δ,q0 , B, F)&lt;br&gt;
Q ：状态的集合 {q0 q1 q2}&lt;br&gt;
∑：输入字母表，要识别的句子含有的符号，如{a,b,c} {1,2,3}&lt;br&gt;
Γ：带符号表，对应 CFG 中的变量 {S,A,B,C}&lt;br&gt;
δ：状态转移函数，有两种格式，在下面给出&lt;br&gt;
q0：起始状态&lt;br&gt;
B：空白符&lt;br&gt;
F：终止状态集合{q1 q2 q3}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;状态转移函数 δ 的两种格式&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;右移&lt;/code&gt;&lt;br&gt;
δ(q，X)=(p，Y，R)&lt;br&gt;
表示状态 q 时，读入句子中的符号 X ，弹出栈顶符号 Z ，将状态改为 p ，并在 X 所在的带方格中印刷符号 Y，然后将读头右移一格&lt;br&gt;
&lt;code&gt;左移&lt;/code&gt;&lt;br&gt;
δ(q，X)=(p，Y，L)&lt;br&gt;
表示状态 q 时，读入句子中的符号 X ，弹出栈顶符号 Z ，将状态改为 p ，并在 X 所在的带方格中印刷符号 Y，然后将读头左移一格&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图灵机接受的语言&lt;/strong&gt;&lt;br&gt;
若可接受：停机+接受&lt;br&gt;
若不可接受：停机+拒绝 / 永不停机&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655562933815.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655562939698.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1655562944073.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;构造图灵机&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把要识别的句子模拟写在纸带上&lt;/li&gt;
&lt;li&gt;逐渐向右移动，观察能否用替换（标记）等方式识别走过的路&lt;/li&gt;
&lt;li&gt;设置好不同的状态，不同的输入，列出表格&lt;/li&gt;
&lt;/ol&gt;
">《形式语言与自动机》笔记</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/xing-shi-yu-yan-python-shi-xian-e-nfa-greater-dfa/"" data-c="
          &lt;p&gt;&lt;code&gt;参考资料&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;http://www.srcmini.com/7313.html&#34;&gt;自动机从ε NFA到DFA的转换&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Step1&lt;br&gt;
构建ε闭包&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;输入&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# ε-ΝFA -&amp;gt; DFA
import re  # 引入正则表达式模块

# 打开文件
with open(r&#39;.\ΝFA1.txt&#39;, encoding=&#39;utf-8&#39;) as file:  # 第一例
# with open(r&#39;.\ΝFA2.txt&#39;, encoding=&#39;utf-8&#39;) as file:  # 第二例
    lines = file.readlines()  # 按行读取文件
    # for line in lines:  # 展示文件
    #     print(line, end=&#39;&#39;)

# 创建全局字典，为后面函数所用
e_closure = {}  # 创建空状态转移字典（ε闭包）
state_closure = {}  # 创建状态转移字典，用于保存原状态转移函数


# 创建每一个状态的ε闭包
def Closure():  # 定义e闭包函数
    p1 = re.compile(r&amp;quot;[{](.*?)[}]&amp;quot;, re.S)  # 正则表达式匹配大括号中状态

    # ————————————先单独处理第一行，因为带有起始符#————————————
    linelist0 = lines[1].split()  # 将一行解析为列表形式
    # 求第一行的状态转移函数，并保存
    state_closure[linelist0[0][1:3] + &#39;0&#39;] = linelist0[1][1:-1].split()
    state_closure[linelist0[0][1:3] + &#39;1&#39;] = linelist0[2][1:-1].split()

    trdstate = str(re.findall(p1, linelist0[3]))  # third state 用于保存e转移的所有状态
    if trdstate == &amp;quot;[&#39;&#39;]&amp;quot;:  # 如果e转移为空
        e_closure[linelist0[0][1:3]] = [linelist0[0][1:3]]  # 那么e闭包只包含当前状态
    else:
        string1 = [linelist0[0][1:3]]
        for i in trdstate[2:-2].split(&#39;,&#39;):
            string1.append(i)
        for j in range(2, len(lines)):  # 遍历当前行下面每一行的e转移
            linelist01 = lines[j].split()
            trdstate = str(re.findall(p1, linelist01[3]))  # third state 用于保存e转移的所有状态
            if trdstate == &amp;quot;[&#39;&#39;]&amp;quot;:  # 如果e转移为空
                break
            string1.append(trdstate[2:-2])
        e_closure[linelist0[0][1:3]] = string1

    # ————————————遍历中间行————————————
    for i in range(2, len(lines) - 1):
        linelist = lines[i].split()  # 将一行解析为列表形式
        # 求状态转移函数
        state_closure[linelist[0] + &#39;0&#39;] = linelist[1][1:-1].split()
        state_closure[linelist[0] + &#39;1&#39;] = linelist[2][1:-1].split()

        trdstate = str(re.findall(p1, linelist[3]))  # third state 用于保存e转移的所有状态
        if trdstate == &amp;quot;[&#39;&#39;]&amp;quot;:  # 如果e转移为空
            e_closure[linelist[0]] = [linelist[0]]  # 那么e闭包只包含当前状态
        else:
            string1 = [linelist[0], trdstate[2:-2]]
            for j in range(i + 1, len(lines)):  # 遍历当前行下面每一行的e转移
                linelist01 = lines[j].split()
                trdstate = str(re.findall(p1, linelist01[3]))  # third state 用于保存e转移的所有状态
                if trdstate == &amp;quot;[&#39;&#39;]&amp;quot;:  # 如果e转移为空
                    break
                string1.append(trdstate[2:-2])
            e_closure[linelist[0]] = string1

    # ————————————单独处理最后一行，因为带有终止符*————————————
    i = len(lines) - 1
    linelisti = lines[i].split()  # 将一行解析为列表形式
    # 求状态转移函数
    state_closure[linelisti[0][1:3] + &#39;0&#39;] = linelisti[1][1:-1].split()
    state_closure[linelisti[0][1:3] + &#39;1&#39;] = linelisti[2][1:-1].split()

    trdstate = str(re.findall(p1, linelisti[3]))  # third state 用于保存e转移的所有状态
    if trdstate == &amp;quot;[&#39;&#39;]&amp;quot;:  # 如果e转移为空
        e_closure[linelisti[0][1:3]] = [linelisti[0][1:3]]  # 那么e闭包只包含当前状态
    else:
        e_closure[linelisti[0][1:3]] = [linelisti[0][1:3], trdstate[2:-2]]

    return e_closure, state_closure  # 返回元组，0号元素为e闭包，1号元素为状态转移字典


# 构造新状态列表
def New_state_closure():
    q = []  # 创建新状态列表
    # ————————————处理第一个状态————————————
    q.append(e_closure[&#39;q0&#39;])  # 第一个状态设置为q0的ε闭包

    l0 = []  # 创建input为0时的状态列表
    l1 = []  # 创建input为1时的状态列表
    for state in e_closure[&#39;q0&#39;]:  # 遍历第一个新状态的子状态
        for i in state_closure.keys():  # 遍历子状态转移集
            if i == state + &#39;0&#39; and state_closure[i] != []:  # 如果为当前状态，且input = &#39;0&#39;，并排除空集
                l0 += state_closure[i]  # 保存状态
            if i == state + &#39;1&#39; and state_closure[i] != []:
                l1 += state_closure[i]

    # 将新状态分情况保存在新状态列表
    if l0 == [] and l1 != []:
        q.append([])
        q.append(e_closure[l1[0]])
    elif l0 != [] and l1 == []:
        q.append(e_closure[l0[0]])
        q.append([])
    elif l0 == [] and l1 == []:
        q.append([])
        q.append([])
    else:
        q.append(e_closure[l0[0]])  # 保存的为其ε闭包
        q.append(e_closure[l1[0]])

    # ————————————处理其余状态————————————
    n = 1  # 从状态列表q中第一个元素开始遍历
    chongfu = 0  # 重复判定初始为0（不重复）
    while True:
        l0 = []  # 创建input为0时的状态列表
        l1 = []  # 创建input为1时的状态列表
        if n != 1:
            for i in range(1, n):  # 判断前面是否有该状态
                if q[n] == q[i]:
                    chongfu = 1  # 重复
                    break
                else:
                    chongfu = 0  # 不重复
        if q[n] == [] or chongfu:  # 如果该状态为空集或重复
            if len(q) == n + 1:  # 如果列表结束
                return q  # ~~~~~~~~~~~~函数结束，返回新状态列表~~~~~~~~~~~~
            else:  # 则跳到下一状态
                n += 1

        else:  # 继续更新新状态列表
            for state in q[n]:  # 遍历第n个新状态的子状态
                for i in state_closure.keys():  # 遍历子状态转移集
                    if i == state + &#39;0&#39; and state_closure[i] != []:  # 如果为当前状态，且input = &#39;0&#39;，并排除空集
                        l0 += state_closure[i]  # 保存状态
                    if i == state + &#39;1&#39; and state_closure[i] != []:
                        l1 += state_closure[i]

            if l0 == [] and l1 != []:
                q.append([])
                q.append(e_closure[l1[0]])
            elif l0 != [] and l1 == []:
                q.append(e_closure[l0[0]])
                q.append([])
            elif l0 == [] and l1 == []:
                q.append([])
                q.append([])
            else:
                q.append(e_closure[l0[0]])
                q.append(e_closure[l1[0]])
            n += 1

# 格式化输出新状态列表
def Print_New_state(Q):
    # 重命名
    record = []  # 记录列表，用于保存已经重新命名的元素
    n = 1
    i = 1
    while True:
        if (f&#39;q{n}&#39; not in record) and (Q[i] not in record):
            now = Q[i]
            if now == []:
                Q[i] = &#39;&#39;
                i += 1
                if i == len(Q):
                    break
            else:
                for j in range(i, len(Q)):
                    if Q[j] == now:
                        Q[j] = f&#39;q{n}&#39;
                record.append(f&#39;q{n}&#39;)
                n += 1
                i += 1
        else:
            i += 1
            if i == len(Q):
                break
    for i in range(1, len(Q)):  # 加括号
        Q[i] = &#39;{&#39; + Q[i] + &#39;}&#39;

    # 按格式输出
    print(&#39;0 1 epsilon&#39;)
    for i in range(1, len(Q), 2):
        if i == 1:
            print(&#39;#q0 %s %s&#39; % (Q[i], Q[i + 1]))
        elif i == len(Q) - 2:
            print(&#39;*q%s %s %s&#39; % (i - 3, Q[i], Q[i + 1]))
        else:
            print(&#39;q%s %s %s&#39; % (i - 2, Q[i], Q[i + 1]))


if __name__ == &#39;__main__&#39;:
    closures = Closure()
    # print(Closure())  # 展示e闭包和状态转移字典
    Q = New_state_closure()
    # print(Q)  # 展示新状态列表Q
    Print_New_state(Q)

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;经验总结&#34;&gt;经验总结：&lt;/h1&gt;
&lt;p&gt;先把所有要点都明确之后再搞，要不全是bug&lt;br&gt;
先用伪代码在pycharm里写一遍&lt;br&gt;
可以用思维导图解释算法流程&lt;/p&gt;
">【形式语言】python实现 ε-ΝFA -> DFA</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ji-wang-bian-cheng-shi-yan/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://m653uatd6t.feishu.cn/docs/doccn1134QQsBECAj32x7hzIndf&#34;&gt;要求文档&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_37500516/article/details/120149101&#34;&gt;参考博客&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_33690566/article/details/105415681&#34;&gt;可靠传输协议&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;gbn协议&#34;&gt;GBN协议&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1fU4y1h7Sw?spm_id_from=333.337.search-card.all.click&#34;&gt;b站讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://github.com/fung30678/GBN-Simulator&#34;&gt;参考代码&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;rdt-30比特交替协议alternating-bit-protocol&#34;&gt;Rdt 3.0：比特交替协议(alternating-bit protocol)&lt;/h1&gt;
&lt;h1 id=&#34;环境配置&#34;&gt;环境配置&lt;/h1&gt;
&lt;p&gt;本实验采用c语言实现，用 Visual Studio，我想要在一个项目中用多个源文件来调试不同的子文件（多个 main 函数）遇到的问题：&lt;br&gt;
1、不能正确创建源文件&lt;br&gt;
2、不能正确运行源文件&lt;br&gt;
&lt;strong&gt;解决方案：&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_39886612/article/details/117056754&#34;&gt;创建源文件&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_30815237/article/details/87452311&#34;&gt;分别运行各个文件&lt;/a&gt;&lt;br&gt;
同时注意，若创建空项目，是不可以直接运行的。而创建控制台文件可以直接运行，也可以后续添加源文件。&lt;/p&gt;
&lt;h1 id=&#34;调试&#34;&gt;调试&lt;/h1&gt;
&lt;p&gt;使用 vs 调试时不能直接在 shell 中输入参数，需要在运行前设置参数，要在命令参数中设置好各个参数&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/u012750702/article/details/51508214#:~:text=%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%E5%9C%A8VS%E4%B8%AD%E5%90%91%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%B7%BB%E5%8A%A0%E5%8F%82%E6%95%B0%EF%BC%8C%E5%8D%B3%E5%90%91main%28%29%E5%87%BD%E6%95%B0%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%9A%E5%8F%B3%E9%94%AE%E5%8D%95%E5%87%BB%E8%A6%81,%E6%B7%BB%E5%8A%A0%E5%8F%82%E6%95%B0%E7%9A%84%E5%B7%A5%E7%A8%8B%E2%80%93%3E%E5%B1%9E%E6%80%A7%E2%80%93%3E%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7%E2%80%93%3E%E8%B0%83%E8%AF%95%EF%BC%8C%E5%9C%A8%E5%8F%B3%E4%BE%A7%E2%80%9C%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%E2%80%9D%E6%A0%8F%E8%BE%93%E5%85%A5%E8%A6%81%E6%B7%BB%E5%8A%A0%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%8C%E5%90%84%E5%8F%82%E6%95%B0%E9%97%B4%E7%94%A8%E7%A9%BA%E6%A0%BC%E5%88%86%E7%A6%BB&#34;&gt;VS 传参&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;遇到的c语言问题&#34;&gt;遇到的C语言问题&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_36020968/article/details/72805661&#34;&gt;向函数传入结构体&lt;/a&gt;&lt;br&gt;
在函数中定义的变量为局部变量&lt;/p&gt;
">【计网】可靠运输协议编程实验</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ml-ANN-MLP-linear/"" data-c="
          &lt;p&gt;&lt;strong&gt;人工神经网络（ANN）&lt;/strong&gt; 是一个广泛的概念，包括多种网络架构，用于模仿生物神经网络的信息处理方式。&lt;br&gt;
&lt;strong&gt;MLP&lt;/strong&gt; 是由多个全连接层（和激活函数层）组成的特定类型的 ANN，主要用于处理向量化的数据。&lt;br&gt;
&lt;strong&gt;全连接层&lt;/strong&gt; 是构建 MLP 和其他类型的 ANN 的基本单元，负责执行线性变换，并通常与非线性激活函数结合使用以增加网络的表达能力。&lt;/p&gt;
&lt;h1 id=&#34;人工神经网络-ann&#34;&gt;人工神经网络 (ANN)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：人工神经网络（ANN）是一类模仿生物神经网络结构和功能的计算模型，设计用于模拟人脑分析和处理信息的方式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;多样性&lt;/strong&gt;：ANN 包括多种架构，如前馈神经网络（包括 MLP）、卷积神经网络（CNN）、循环神经网络（RNN）等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;：ANN 可以处理各种类型的数据和任务，包括图像识别、语音处理、自然语言理解等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;概念范围&lt;/strong&gt;：MLP 是 ANN 的一种特殊形式，所有的 MLP 都是 ANN，但不是所有的 ANN 都是 MLP。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;全连接层linear-层&#34;&gt;全连接层（Linear 层）&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：全连接层（也称为 Linear 层、线性层）是神经网络中的一种层，其中每个输入节点都与下一层的每个节点全连接。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;线性变换&lt;/strong&gt;：全连接层对输入执行线性变换（加权和加偏置），可选地后接一个非线性激活函数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通用性&lt;/strong&gt;：几乎所有类型的 ANN 都可以包含全连接层，它们在网络中充当信息综合和变换的角色。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用途&lt;/strong&gt;：尽管全连接层非常通用，但它们特别适用于从高层特征中学习全局模式，在 MLP、CNN 和其他 ANN 架构中作为输出层或中间层出现。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;多层感知机-mlp&#34;&gt;多层感知机 (MLP)&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_43704393/article/details/86700712&#34;&gt;感知机与多层感知机&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：多层感知机（MLP）是一种前馈人工神经网络，由一个输入层、一个或多个隐藏层以及一个输出层组成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;全连接&lt;/strong&gt;：MLP 的每一层都完全连接到下一层，意味着每一层的每个神经元都与前一层的所有神经元连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;非线性激活函数&lt;/strong&gt;：MLP 中通常在&lt;strong&gt;每个&lt;/strong&gt;线性层后面跟着一个非线性激活函数，如 ReLU、Sigmoid 或 Tanh，这允许 MLP 捕捉数据中的非线性关系。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输出层&lt;/strong&gt;：输出层的情况比较特殊，是否使用激活函数以及使用哪种激活函数取决于特定的任务：&lt;br&gt;
&lt;code&gt;回归任务&lt;/code&gt;：如果是回归问题，输出层通常不使用激活函数或使用线性激活函数（即不改变输入），以便网络可以输出一系列连续值。&lt;br&gt;
&lt;code&gt;二分类任务&lt;/code&gt;：对于二元分类问题，输出层常使用 Sigmoid 激活函数，将输出压缩到 [0, 1] 范围内，表示概率。&lt;br&gt;
&lt;code&gt;多分类任务&lt;/code&gt;：对于多类分类问题，输出层通常使用 Softmax 激活函数，将输出转换为概率分布。&lt;br&gt;
&lt;code&gt;特定架构和任务&lt;/code&gt;：在某些特定的网络架构或任务中，可能会故意省略某些层的激活函数，以适应特定的需求或实验设计。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;：广泛用于分类、回归、特征学习等任务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当数据量和模型量比较大的时候，MLP会过拟合，而CNN等卷积神经网络可以相对更好的解决此类问题&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_39441762/article/details/80446692?spm=1001.2101.3001.6650.1&amp;amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.pc_relevant_default&amp;amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.pc_relevant_default&amp;amp;utm_relevant_index=2&#34;&gt;神经网络之BP算法(图说神经网络+BP算法理论推导+例子运用+代码)&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;sklearn-相关实现sklearnneural_network&#34;&gt;sklearn 相关实现——sklearn.neural_network&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.weixueyuan.net/a/913.html&#34;&gt;MLPClassifier分类演示&lt;/a&gt;&lt;/p&gt;
">【ML】人工神经网络、MLP、全连接层</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/surfing/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://edurank.org/uni/beijing-university-of-posts-and-telecommunications/rankings/&#34;&gt;来点鸡血&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/20824615&#34;&gt;如何优雅地使用 Stack Overflow？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/415782127&#34;&gt;三步就可以把代码块完美插入到word中&lt;/a&gt;&lt;/p&gt;
">Surfing</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shuo-du-ke-yi-shuo/"" data-c="
          &lt;h1 id=&#34;欢迎来到博客隐藏部分&#34;&gt;欢迎来到博客隐藏部分&lt;/h1&gt;
&lt;p&gt;对自己说的一些话，大多是偶发的一些念头，想记录下来&lt;br&gt;
&lt;a href=&#34;https://jeromezjl.github.io/post/some-words/&#34;&gt;Some Words&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;https://bbs.boniu123.cc/forum.php?mod=viewthread&amp;amp;tid=178940&lt;/p&gt;
&lt;p&gt;https://bbs.pediy.com/thread-202110.htm&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/345269352&#34;&gt;网警是怎么在线下抓住造谣者的？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ssrshare.github.io/2019/04/07/tor/&#34;&gt;洋葱路由&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/71805955&#34;&gt;洋葱路由1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://program-think.blogspot.com/&#34;&gt;编程随想&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://pincong.rocks/article/32003&#34;&gt;简谈网警是怎么找到海外网站发帖之人的&lt;/a&gt;&lt;/p&gt;
">说，都可以说</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/pandas-mei-tian-yi-dian-pandas/"" data-c="
          &lt;h1 id=&#34;读取数据&#34;&gt;读取数据&lt;/h1&gt;
&lt;p&gt;pd.read_csv()&lt;br&gt;
&lt;a href=&#34;https://www.runoob.com/pandas/pandas-dataframe.html&#34;&gt;pandas.DataFrame()：创建数据表格&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;展示数据&#34;&gt;展示数据&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_24754061/article/details/103738513&#34;&gt;Pandas.describe()：展示数据统计信息&lt;/a&gt;&lt;br&gt;
dataframe.head(n)：展示数据前 n 行&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/lost0910/article/details/107746751&#34;&gt;pd.set_option() 取消折叠显示&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;数据处理&#34;&gt;数据处理&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_42067550/article/details/106260512&#34;&gt;Pandas 统计方法总汇&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/W_weiying/article/details/84626260&#34;&gt;pd.drop()：删除指定行列&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_18351157/article/details/113520345&#34;&gt;data.to_csv()：写入/修改 csv 文件&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://huang-tong-xue.blog.csdn.net/article/details/119222439?spm=1001.2101.3001.6650.2&amp;amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.pc_relevant_default&amp;amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.pc_relevant_default&amp;amp;utm_relevant_index=4&#34;&gt;Pandas.set_option()：设置数据集的展示参数&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/393930947&#34;&gt;Pandas map()：修改数据集中行列值&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/jhr112/article/details/115631246&#34;&gt;pandas 数据清洗：drop() del() 等&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/walking_visitor/article/details/85128461&#34;&gt;相关系数 (correlation coefficient) 函数 corr()&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.jianshu.com/p/9dec47bac5b9&#34;&gt;corr() 的三个相关系数：Pearson相关、Spearman相关、Kendall相关&lt;/a&gt;&lt;a href=&#34;https://www.biaodianfu.com/pearson-kendall-spearman.html#Scipy%E7%9A%84pearsonr%E6%96%B9%E6%B3%95&#34;&gt;；另一篇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_24754061/article/details/103738513&#34;&gt;pd.DataFrame.describe()：展示数据的统计信息，总数、均值、四分均值等&lt;/a&gt;&lt;/p&gt;
">【Pandas】每天一点 Pandas</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/python-shui-de-python-xue-de-bu-zha-shi/"" data-c="
          &lt;h1 id=&#34;基础操作&#34;&gt;基础操作&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;多个变量在一行赋值&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a, b = 1, 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_44168690/article/details/104116406&#34;&gt;Python中print的骚操作(倒计时、转圈显示、进度条)&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;数据类型&#34;&gt;数据类型&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_39700394/article/details/111418838&#34;&gt;浮点数格式化输出&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.py.cn/faq/python/14859.html&#34;&gt;无穷大 inf 和 非数字的 NaN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.w3school.com.cn/python/ref_string_index.asp&#34;&gt;字符串 index() 方法&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/xiaomifanhxx/article/details/81537506&#34;&gt;多文件调用&lt;/a&gt;&lt;br&gt;
若要在 A 文件运行整个 B 文件，则在 A 文件中如下写：（同一目录下）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import B
if __name__ == &#39;__main__&#39;:
    B
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;列表常见操作&#34;&gt;列表常见操作&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;获取列表数据的 index&lt;/strong&gt;&lt;br&gt;
list.index(num)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;列表排序&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;不改变原 list&lt;/code&gt;&lt;br&gt;
newlist = sorted(list)&lt;br&gt;
&lt;code&gt;改变原 list&lt;/code&gt;&lt;br&gt;
list.sort()&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;列表切片&lt;/strong&gt;&lt;br&gt;
例：单独对列表前 n 个数据求和&lt;br&gt;
sum(nums[0:n])  # 从 0 到 n - 1&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://c.biancheng.net/view/2209.html&#34;&gt;&lt;strong&gt;删除列表元素的四种方法&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;列表最后一个元素&lt;/strong&gt;&lt;br&gt;
list[-1]&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/GumpYan/p/12334839.html&#34;&gt;&lt;strong&gt;倒叙遍历列表&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_38564268/article/details/91445719&#34;&gt;&lt;strong&gt;倒序输出列表&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;list.pop()&lt;/strong&gt;&lt;br&gt;
pop() 括号中的是元素的 index，返回 pop 的值。若直接pop则返回最后一个元素。&lt;br&gt;
注意，pop是对原列表直接删除的操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;整体替换列表&lt;/strong&gt;&lt;br&gt;
list1[m:] = list2  # 第 m 个元素后面的元素都替换成 list2 中的元素，list1 变成两个列表的合并&lt;br&gt;
&lt;a href=&#34;https://leetcode.cn/problems/merge-sorted-array/solution/he-bing-liang-ge-you-xu-shu-zu-by-leetco-rrb0/&#34;&gt;leetcode 相关题解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;列表合并（六种方法）&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_38739735/article/details/115451727&#34;&gt;前五种&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_31281613/article/details/112889007&#34;&gt;切片法（同整体替换列表）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_40797015/article/details/112171892&#34;&gt;&lt;strong&gt;将输入的数字转换为列表&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qdPython/article/details/120845987&#34;&gt;开辟一定空间的数组&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[enumerate()：将可迭代对象加编号] (https://zhuanlan.zhihu.com/p/92544989)&lt;br&gt;
&lt;a href=&#34;https://leetcode.cn/problems/two-sum/solution/liang-shu-zhi-he-by-leetcode-solution/&#34;&gt;leetcode 相关题解&lt;/a&gt;&lt;br&gt;
这样 for 循环遍历列表可以直接遍历出序号和值，也方便用该列表构造字典 / 哈希表&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;continue 和 break 的区别&lt;/strong&gt;&lt;br&gt;
continue 是结束本次循环（执行到该条语句后面不执行了，进行下一次循环）&lt;br&gt;
break 是跳出整个循环&lt;/p&gt;
&lt;h1 id=&#34;os-操作&#34;&gt;OS 操作&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/108211297&#34;&gt;创建文件夹 —— os.mkdir ; os.makedirs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_51697369/article/details/119864944&#34;&gt;参数解析&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
os.mkdir(r&amp;quot;C:\Users\ZJL\Desktop\test&amp;quot;)  # 执行之后会发现桌面产生文件夹 test

# 两函数区别
# 假设 r&amp;quot;C:\Users\ZJL\Desktop\test 路径已存在
# 现在要创建 r&amp;quot;C:\Users\ZJL\Desktop\test\1\2
# os.makedirs 可以，os.mkdir 不行

os.mkdir(r&amp;quot;C:\Users\ZJL\Desktop\test\1\2&amp;quot;)
os.makedirs(r&amp;quot;C:\Users\ZJL\Desktop\test\1\2&amp;quot;)

# 总结：os.mkdir 只能创建最后一级的目录，os.makedirs 可以全创建
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;迭代器&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;python继承&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;一些包&#34;&gt;一些包&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/tardis/zm/art/78882641?source_id=1005&#34;&gt;numba，让python速度提升百倍&lt;/a&gt;&lt;/p&gt;
">【Python】谁 Python 学的不扎实？</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/android/"" data-c="
          &lt;h1 id=&#34;root&#34;&gt;Root&lt;/h1&gt;
&lt;p&gt;安卓手机最高权限，可以修改系统设置，卸载系统自带软件。有些手机自带 root，有些需要手动获取 root&lt;/p&gt;
&lt;h1 id=&#34;adb&#34;&gt;ADB&lt;/h1&gt;
&lt;p&gt;安卓调试桥梁，连接电脑时会需要ADB&lt;/p&gt;
&lt;h1 id=&#34;安卓神器软件分享&#34;&gt;安卓神器软件分享&lt;/h1&gt;
&lt;p&gt;黑域：省电管控&lt;br&gt;
Tasker：手机自动化&lt;br&gt;
&lt;a href=&#34;https://taskerm.com/?p=218&#34;&gt;Tasker良心博客分享&lt;/a&gt;&lt;/p&gt;
">【Android】</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shu-ju-jie-gou-ke-she-1tou-cha-fa-gou-zao-lian-biao/"" data-c="
          &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Node():  # 定义节点类
    def __init__(self, item):  # 初始化数据
        self.item = item  # 把数据存入节点
        self.next = None  # 默认next节点为None

# 注意，传入的数据形式为列表，可一次性插入多个数据
def creat_head(datalist, linklist):  # 分别传入要插入的数据列表，和非空单链表
    head_node = Node(datalist[0])  # 定义头节点，把datalist的第一个元素赋给头节点
    head_node.next = linklist  # 把该节点连接在链表最开头
    for data in datalist[1:]:  # 遍历剩余数据
        node = Node(data)  # 创建新节点
        node.next = head_node  # 把新节点插在头节点的前面
        head_node = node  # 把新节点命名为头节点，以便重复上述操作
    return head_node  # 返回改链表的首地址，从而可遍历展示该链表

def print_linklist(current_node):  # 打印链表（传入头节点）
    while current_node:  # 当前节点非空时
        print(current_node.item, end = &#39; &#39;)  # 打印链表节点的数据元素
        current_node = current_node.next  # 移动指针，重复循环

# 下面用最朴素的方法创建一个非空单链表
a = Node(1)  # 创建一个独立节点
a.next = Node(2)  # 在a后连接新节点
a.next.next = Node(3)  # 连接新节点
print_linklist(a)  # 展示该链表 （ 1 2 3 ）

print(&#39;\n&#39;)

linklist1 = creat_head([8,7,6], a)  # 头插法把该列表插入a链表
print_linklist(linklist1)  # 展示链表
&lt;/code&gt;&lt;/pre&gt;
">【数据结构】课设1：头插法构造链表</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/seaborn-shu-ju-ke-shi-hua/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/98729226&#34;&gt;pairplot()：展示数据集变量之间的关系&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/cymx66688/p/10536403.html&#34;&gt;sns.countplot()：柱状图显示&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/96040773?from_voters_page=true&#34;&gt;sns.heatmap()：显示变量之间相关系数矩阵&lt;/a&gt;&lt;/p&gt;
">【Seaborn】数据可视化</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ml-he-fang-fa-he-han-shu/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Nb4y1s7pE/?buvid=XY1E7C2150D585E3FEFD8BAC7D8745A2A78B2&amp;amp;from_spmid=search.search-result.0.0&amp;amp;is_story_h5=false&amp;amp;mid=vUjUrmQZhYx7Mi0YPfhKgg%3D%3D&amp;amp;p=1&amp;amp;plat_id=116&amp;amp;share_from=ugc&amp;amp;share_medium=android&amp;amp;share_plat=android&amp;amp;share_session_id=9c86103b-c5e0-40c9-b57e-8a18a731d836&amp;amp;share_source=WEIXIN&amp;amp;share_tag=s_i&amp;amp;spmid=united.player-video-detail.0.0&amp;amp;timestamp=1711013875&amp;amp;unique_k=E3deF0u&amp;amp;up_id=152254793&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;核技巧Kernel Trick详解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;核方法（Kernel methods）是机器学习中的一类算法，它们通过&lt;code&gt;将数据映射到高维空间&lt;/code&gt;来解决非线性问题。核方法的关键思想是通过一个核函数来隐式地完成这种映射，而不需要显式地计算高维空间中的坐标。这种方法可以有效地处理那些&lt;code&gt;在原始特征空间中不容易用线性模型分割的数据&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;比如要计算两个向量在高维度的积，正常方法需要将向量升维，而核函数能直接输出两个向量的点积，省去了计算和储存资源。&lt;/p&gt;
&lt;h3 id=&#34;核函数&#34;&gt;核函数&lt;/h3&gt;
&lt;p&gt;核函数是核方法的核心，它是一个衡量两个输入数据点相似性的函数。常见的核函数包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;线性核（Linear Kernel）&lt;/strong&gt;:  K(x, y) = x^Ty ，等同于没有进行任何映射的原始欧几里得内积。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多项式核（Polynomial Kernel）&lt;/strong&gt;:  K(x, y) = (x^Ty + c)^d，其中 c 是一个常数，d 是多项式的度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;径向基函数核（Radial Basis Function Kernel, RBF 或 Gaussian Kernel）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sigmoid核&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;支持向量机&#34;&gt;支持向量机&lt;/h3&gt;
&lt;p&gt;支持向量机（SVM）是最著名的使用核方法的算法之一。在SVM中，核方法用于将输入数据映射到一个高维特征空间，在这个空间中可以使用超平面将数据分割开来。选择合适的核函数可以让SVM有效处理非线性问题。&lt;/p&gt;
&lt;h3 id=&#34;核方法的优势&#34;&gt;核方法的优势&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;处理非线性问题&lt;/strong&gt;: 通过将数据映射到高维空间，核方法能有效处理原始特征空间中的非线性关系。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算效率&lt;/strong&gt;: 虽然映射到高维空间听起来计算成本很高，但核方法通过计算核函数来避免了直接在高维空间中进行计算，从而保持了较高的效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;: 通过选择不同的核函数，可以灵活地应对各种类型的数据和问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核方法的挑战&#34;&gt;核方法的挑战&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核函数选择&lt;/strong&gt;: 不同的问题可能需要不同的核函数，核函数的选择对算法的性能有重大影响。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;参数调优&lt;/strong&gt;: 核方法通常有几个参数需要调整，如RBF核的宽度参数 (\sigma)，这需要通过交叉验证等方法来完成，增加了模型选择的复杂性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可解释性&lt;/strong&gt;: 将数据映射到高维空间可能会让模型的决策过程变得难以解释。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;🔺除了支持向量机（SVM），核函数在机器学习中还被用于多种其他算法中，包括但不限于：&lt;/p&gt;
&lt;h3 id=&#34;核主成分分析kernel-pca&#34;&gt;核主成分分析（Kernel PCA）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;核主成分分析是一种非线性降维技术，通过将数据映射到高维特征空间来发现数据在高维空间中的主要成分。这种方法利用核技巧来实现高维映射，从而避免直接在高维空间中计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核岭回归kernel-ridge-regression&#34;&gt;核岭回归（Kernel Ridge Regression）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;核岭回归是一种在岭回归（Ridge Regression）基础上发展起来的算法，通过使用核技巧将数据映射到高维空间，从而使模型能够捕获数据的非线性关系。核岭回归在回归分析中广泛应用，尤其适合处理具有复杂关系的数据集。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;高斯过程gaussian-processes&#34;&gt;高斯过程（Gaussian Processes）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;高斯过程是一种用于回归和分类问题的贝叶斯非参数方法。在高斯过程中，核函数用于定义输入空间中点之间的相似度，这对于模型的预测性能至关重要。通过选择合适的核函数，高斯过程可以灵活地建模数据的不确定性和复杂度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核密度估计kernel-density-estimation-kde&#34;&gt;核密度估计（Kernel Density Estimation, KDE）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;核密度估计是一种用于估计随机变量概率密度函数的非参数方法。在KDE中，核函数用于平滑样本点，以估计整个数据分布。这种方法广泛应用于概率密度估计、数据可视化和异常检测等领域。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核相关分析kernel-canonical-correlation-analysis-kernel-cca&#34;&gt;核相关分析（Kernel Canonical Correlation Analysis, Kernel CCA）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;核相关分析是一种用于寻找两组数据之间关系的方法。通过将原始数据映射到高维特征空间，核CCA能够揭示数据集之间的复杂非线性关联。这种方法在多视图学习和跨域学习等领域有着广泛的应用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核方法在图和序列数据上的扩展&#34;&gt;核方法在图和序列数据上的扩展&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;核方法还被扩展到图结构数据和序列数据上，例如图核（Graph Kernels）和序列核（Sequence Kernels），这些方法能够捕捉图结构或序列中的复杂模式和依赖关系。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;核方法由于其灵活性和强大的非线性建模能力，在机器学习的许多领域都有广泛应用。通过适当选择核函数和调整模型参数，核方法可以有效地处理各种类型的数据和复杂的任务。&lt;/p&gt;
">【ML】核方法和核函数</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/sklearn-mei-tian-yi-dian-sklearn/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://scikit-learn.org.cn/&#34;&gt;sklearn中文社区1&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://sklearn.apachecn.org/#/&#34;&gt;sklearn中文社区2&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/algorithmPro/article/details/103045824&#34;&gt;超详细入门&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;案例&#34;&gt;案例&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/admin11111111/article/details/116570878&#34;&gt;鸢尾花svm&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/Together_CZ/article/details/78697664?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1.pc_relevant_aa&amp;amp;spm=1001.2101.3001.4242.2&amp;amp;utm_relevant_index=4&#34;&gt;鸢尾花2&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://cxymm.net/article/qianyunzzz/122885761&#34;&gt;乳腺癌svm，from UCI&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;数据集&#34;&gt;数据集&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://archive.ics.uci.edu/&#34;&gt;UCI数据集&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_40583722/article/details/121800784&#34;&gt;UCI使用教程（注意看文章里面的链接）&lt;/a&gt;&lt;br&gt;
数据集页面后缀为 .data .csv 的为数据集，剩余的文件均为数据集信息&lt;/p&gt;
&lt;h1 id=&#34;sklearn项目一般步骤&#34;&gt;sklearn项目一般步骤：&lt;/h1&gt;
&lt;p&gt;获取数据&lt;br&gt;
数据预处理&lt;br&gt;
特征工程&lt;br&gt;
建立模型、训练模型、调参&lt;br&gt;
模型评估&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;读入数据：&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/xizi_ghq/article/details/108660671&#34;&gt;datasets 详解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/tcy23456/article/details/106388651/?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.pc_relevant_default&amp;amp;spm=1001.2101.3001.4242.1&amp;amp;utm_relevant_index=3&#34;&gt;数据集文件读取的几种方式&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.jianshu.com/p/29af03788ff6&#34;&gt;数据集文件读取的几种方式2&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.jianshu.com/p/4dfe5ce3bda9&#34;&gt;利用urllib直接网络读入&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/zyj3955/p/15414382.html&#34;&gt;鸢尾花的导入与划分&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;导入的UCI的数据的表头（ names 列表）如何确定？&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;一般都在UCI主页的 Attribute Information 中列出来了，可以直接对应其表头。
个别数据集，比如乳腺癌数据集，3种癌细胞每个有10个特征，需要自行对三种癌细胞进行命名/编号
这就需要对数据集的信息进行分析，观察数据特征，分析其含义，给出适合的 names
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;数据预处理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/program_developer/article/details/78637711?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165123847616782391882623%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;amp;request_id=165123847616782391882623&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-78637711.142%5Ev9%5Epc_search_result_control_group,157%5Ev4%5Econtrol&amp;amp;utm_term=%E5%BD%92%E4%B8%80%E5%8C%96&amp;amp;spm=1018.2226.3001.4187&#34;&gt;&lt;code&gt;归一化&lt;/code&gt;&lt;/a&gt;&lt;br&gt;
注：归一化和标准化不同，标准化是变为正态分布&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特征工程&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.jianshu.com/p/29af03788ff6&#34;&gt;sklearn-pandas 示例&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据集划分&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/Yanjy-OnlyOne/p/11288098.html&#34;&gt;train_test_split()&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据可视化&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;未完成任务&#34;&gt;未完成任务：&lt;/h1&gt;
&lt;p&gt;1 sklearn svm 图 （分类结果可视化&lt;br&gt;
2 实验代码中调参部分函数&lt;/p&gt;
">【ML】每天一点 sklearn</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/keshihua/"" data-c="
          &lt;h1 id=&#34;matplotlib&#34;&gt;matplotlib&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://c.biancheng.net/matplotlib/&#34;&gt;详细教程&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.runoob.com/w3cnote/matplotlib-tutorial.html&#34;&gt;简易教程&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/258106097&#34;&gt;plt.plot()&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/m0_37362454/article/details/81511427&#34;&gt;plt.figure()：设置图像参数&lt;/a&gt;&lt;/p&gt;
">【ML】可视化</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ml-mei-tian-yi-dian-numpy-xiao-ji-qiao/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/38353562#:~:text=Scipy%EF%BC%9A%20%E4%B8%80%E4%B8%AA%E7%94%A8%E4%BA%8E%E6%95%B0%E5%AD%A6%E3%80%81%E7%A7%91%E5%AD%A6%E3%80%81%E5%B7%A5%E7%A8%8B%E9%A2%86%E5%9F%9F%E7%9A%84%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%8C%85%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%A4%84%E7%90%86%E6%8F%92%E5%80%BC%E3%80%81%E7%A7%AF%E5%88%86%E3%80%81%E4%BC%98%E5%8C%96%E3%80%81%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%81%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%95%B0%E5%80%BC%E8%A7%A3%E7%9A%84%E6%B1%82%E8%A7%A3%E3%80%81%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E7%AD%89%E9%97%AE%E9%A2%98%E3%80%82%20Pandas%EF%BC%9A,%E5%9F%BA%E4%BA%8E%20NumPy%20%E7%9A%84%E4%B8%80%E7%A7%8D%E5%B7%A5%E5%85%B7%EF%BC%8C%E8%AF%A5%E5%B7%A5%E5%85%B7%E6%98%AF%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%BB%BB%E5%8A%A1%E8%80%8C%E5%88%9B%E5%BB%BA%E7%9A%84%E3%80%82&#34;&gt;numpy，scipy，pandas这些库的区别是什么？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_39072607/article/details/89321495&#34;&gt;np.zeros：用于生成全 0 的数组&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_41800366/article/details/86589680&#34;&gt;np.arange()：生成序列（等差数列）&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.w3cschool.cn/article/54960412.html&#34;&gt;np.linspace()：当要生成浮点数序列时，用该函数代替arange()，来保证精度&lt;/a&gt;&lt;/p&gt;
">【ML】每天一点 Numpy 小技巧</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shou-ji-zi-dong-hua-cao-zuo-de-yi-xie-tan-suo/"" data-c="
          &lt;p&gt;tasker&lt;br&gt;
自动精灵（操作简单，适合简易任务&lt;br&gt;
Hamibot 需要js&lt;/p&gt;
">手机自动化操作的一些探索</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ml-zhi-chi-xiang-liang-ji-svm/"" data-c="
          &lt;p&gt;支持向量机（support vector machines, SVM）&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV16T4y1y7qj?from=search&amp;amp;seid=9938878737703056911&amp;amp;spm_id_from=333.337.0.0&#34;&gt;b站入门讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1UR4y147AT?p=7&#34;&gt;b站详细讲解&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://mp.weixin.qq.com/s/tj_O8H3S_kdag30jivBy6g&#34;&gt;文档讲解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在数据点间选择一个使两类数据点之间间隔最大的超平面，这个间隔被称为最大间隔。位于最大间隔边界的数据点称为支持向量。&lt;/p&gt;
&lt;p&gt;只有支持向量决定超平面位置，其他数据点不影响。&lt;/p&gt;
&lt;p&gt;支持向量机（SVM）的完整算法流程可以分为以下几个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;选择核函数&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;根据数据的特性选择合适的核函数。如果数据是线性可分的，可以选择线性核；如果数据非线性，可以选择RBF核、多项式核或sigmoid核等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;构建模型&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;初始化SVM模型，设置核函数、惩罚参数C（用于控制误分类和间隔大小之间的权衡）和其他参数（如核函数的参数）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化问题&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;构建一个优化问题，目标是最大化间隔，同时允许一定的误分类（软间隔SVM）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;求解优化问题&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用序列最小优化（SMO）算法、梯度下降法或其他优化技术求解上述优化问题，得到最优的权重向量。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;找到支持向量&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;在训练完成后，识别出支持向量，这些是位于最大间隔边界上的样本点。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;构建决策函数&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用找到的权重向量和偏置项构建决策函数&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;Q&amp;amp;A&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SVM是一种什么类型的机器学习算法？
 SVM是一种监督学习算法，用于分类和回归问题。它是一种基于最大间隔原则的分类器，旨在找到能够最好地分隔数据集的超平面。

SVM的主要目标是什么？
SVM的主要目标是找到一个超平面，使得不同类别的数据点之间的间隔最大化，同时最小化分类错误。

SVM如何处理非线性可分的数据？ 
SVM通过使用核技巧将数据映射到高维特征空间，从而在新的空间中找到一个可以分隔数据的超平面。这种方法允许SVM处理非线性可分的数据。

什么是支持向量？ 
支持向量是指那些影响到超平面位置的训练样本。在SVM中，只有支持向量对模型的决策边界有影响，其他样本点则不影响。

SVM中的核函数是什么作用？ 
核函数在SVM中用于将输入数据映射到高维空间，以便在那里可以找到一个分隔超平面。核函数允许SVM在原始特征空间中执行计算，而不需要显式地计算高维特征空间中的坐标。

常见的SVM核函数有哪些？ 
常见的SVM核函数包括线性核（linear）、多项式核（poly）、径向基函数核（RBF，也称为高斯核）、和sigmoid核。

SVM中的超参数C代表什么？ 
超参数C在SVM中是一个惩罚参数，用于控制误分类的宽容度。C值大意味着分类器会选择一个较小的间隔，以减少训练样本上的错误分类。C值小则意味着分类器会选择一个较大的间隔，允许更多的错误分类。

SVM中的软间隔是什么意思？ 
软间隔是SVM中的一种概念，它允许一些样本不满足硬间隔的要求（即不一定要所有样本都正确分类）。软间隔通过引入一个超参数C来平衡模型的复杂度和训练错误率。

SVM和逻辑回归有什么区别？ 
SVM和逻辑回归都是分类算法，但它们有不同的目标函数和决策边界。SVM尝试最大化数据点之间的间隔，而逻辑回归则直接建模分类概率。SVM的决策边界由支持向量决定，而逻辑回归的决策边界由系数确定。

SVM对于不平衡数据集如何处理？ 
SVM本身不直接处理不平衡数据集。但是，可以通过调整超参数C或使用不同的权重来给不同类别的错误分类以不同的惩罚，从而间接处理不平衡问题。

SVM如何进行多分类任务？ 
SVM通过一对多（one-vs-rest）或一对一（one-vs-one）的策略进行多分类。在一对多策略中，为每个类训练一个分类器，将那个类与其他类分开。在一对一策略中，为每对类训练一个分类器，最终通过投票决定最终的类别。

SVM的训练时间复杂度如何？ 
SVM的训练时间复杂度取决于训练样本的数量和特征维度。对于线性SVM，时间复杂度是O(n^2)到O(n^3)，其中n是样本数量。使用核函数的SVM可能更慢，因为需要计算核函数和解决一个二次规划问题。

如何选择SVM的核函数和超参数？ 
选择核函数和超参数通常涉及交叉验证和网格搜索。交叉验证用于评估不同参数组合的性能，而网格搜索则是在参数空间中系统地尝试不同的参数组合。

SVM在哪些应用场景中表现较好？ 
SVM在中小规模的复杂数据集上表现较好，尤其是在特征维度高和样本数量不是非常巨大的情况下。它也适用于图像识别、文本分类和生物信息学等领域。

SVM有哪些主要的变种？ 
SVM的主要变种包括软间隔SVM、支持向量回归（SVR）、最小二乘SVM（LS-SVM）和多类SVM。每个变种都针对特定类型的问题或性能改进而设计。
&lt;/code&gt;&lt;/pre&gt;
">【ML】支持向量机（SVM）</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/kao-yan-kao-yan-zi-liao/"" data-c="
          &lt;p&gt;&lt;a href=&#34;http://qzbltushu.ysepan.com/&#34;&gt;http://qzbltushu.ysepan.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.cskaoyan.com/forum.php?mod=viewthread&amp;amp;tid=661957&amp;amp;highlight=%C8%CB%B9%A4%D6%C7%C4%DC&#34;&gt;2021上海交通大学人工智能专硕一战上岸经验贴&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.cskaoyan.com/forum.php?mod=viewthread&amp;amp;tid=654181&amp;amp;highlight=%C8%CB%B9%A4%D6%C7%C4%DC&#34;&gt;2019南大人工智能学院经验贴&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.cskaoyan.com/thread-661983-1-1.html&#34;&gt; 2021菜鸡三战最终上岸北大经验贴----最值得一看的经验贴之一&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/536024217&#34;&gt;2022清华深研院人工智能考研经验贴&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/498483239&#34;&gt;2022北大软微上岸客观分析贴！！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/550477200&#34;&gt;人工智能领域导师推荐列表&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bbs.byr.cn/#!article/AimGraduate/1216195&#34;&gt;北大信科考研上岸经验帖&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bbs.byr.cn/#!article/AimGraduate/1212516&#34;&gt;北大软微报录比5:1，点击就送&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;北邮 上交 复旦 浙大&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://csrankings.org/#/fromyear/2012/toyear/2022/index?all&amp;amp;cn&#34;&gt;CSRankings: Computer Science Rankings&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;#北邮&lt;br&gt;
&lt;strong&gt;导师&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://bbs.byr.cn/#!article/AimGraduate/1220097&#34;&gt;【问题】请问有人工智能学院模式识别实验室张洪刚老师的师哥师姐&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://download.csdn.net/download/qq_42543379/85213340&#34;&gt;北京邮电大学809数据结构复习指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://yzb.bupt.edu.cn/content/content.php?p=8_4_69&#34;&gt;2023年人工智能学院硕士专业目录&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://yzb.bupt.edu.cn/content/content.php?p=8_4_69&#34;&gt;人工智能学院2023年研究生招生导师信息&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;上交&#34;&gt;上交&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://yzb.sjtu.edu.cn/info/1022/2464.htm&#34;&gt;上交研究生&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;数学1&#34;&gt;数学1&lt;/h1&gt;
&lt;p&gt;高数 武忠祥&lt;br&gt;
线代 | 概率论 张宇&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;政治&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;https://www.kdocs.cn/l/cqCr6m50zudD&lt;/p&gt;
">【考研】考研资料</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/shi-yong-github-desktop-tong-bu-gridea-cai-keng-ji-lu/"" data-c="
          &lt;p&gt;先放一篇其他大佬的文章，说的已经很详细了&lt;br&gt;
&lt;a href=&#34;https://sonatta.top/post/Ux6xKOeOx/&#34;&gt;https://sonatta.top/post/Ux6xKOeOx/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;踩坑：&lt;/code&gt;&lt;br&gt;
写好博客直接把 output push 上去，导致 url 为本地地址，无法打开&lt;/p&gt;
&lt;p&gt;&lt;code&gt;这里再总结一下&lt;/code&gt;&lt;br&gt;
在 gridea 中写好之后，点击同步，不用管是否同步成功，同步是为了生成正确的 url&lt;br&gt;
等待大约 15 - 20 s之后，文件已经生成成功。&lt;/p&gt;
&lt;p&gt;这时，找到站点源文件的 output 文件夹，打开文件夹&lt;br&gt;
复制里面所有内容，粘贴到从 GitHub 上 Pull 下来的文件夹中。&lt;br&gt;
这时 Github Desktop 中会出现刚才新添加的项目&lt;br&gt;
然后注意一定要填写 summary 名称，否则不能 Push&lt;br&gt;
填写之后，就可以 Push 上去了&lt;/p&gt;
&lt;p&gt;注意有时候用校园网挂梯子不好使，建议连接手机热点&lt;br&gt;
只有点了同步之后 GitHub desktop 上才会出现分支变动&lt;/p&gt;
&lt;p&gt;GitHub desktop 出现同步报错，在 Repository 中找到 Repository setting&lt;br&gt;
在把 GitHub 中博客主页的 GIT URL 复制进去，也就是下面一行&lt;br&gt;
https://github.com/jeromezjl/jeromezjl.github.io.git&lt;br&gt;
再点同步即可&lt;/p&gt;
">【踩坑】使用 Github Desktop 同步 Gridea 踩坑记录</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/github-desktop-guan-li-ben-di-dai-ma/"" data-c="
          &lt;p&gt;首次使用需要用 Git Bash 进行 ssh 密钥配置&lt;br&gt;
&lt;code&gt;ssh密钥配置&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/youzi-xuchongyou/p/15093336.html&#34;&gt;https://www.cnblogs.com/youzi-xuchongyou/p/15093336.html&lt;/a&gt;&lt;br&gt;
&lt;code&gt;总览&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV13W411U7HY?from=search&amp;amp;seid=9646375911820432461&amp;amp;spm_id_from=333.337.0.0&#34;&gt;https://www.bilibili.com/video/BV13W411U7HY?from=search&amp;amp;seid=9646375911820432461&amp;amp;spm_id_from=333.337.0.0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;当需要 push 的文件过大时候报错：&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/69427700/error-rpc-failed-curl-55-send-failure-connection-was-aborted&#34;&gt;https://stackoverflow.com/questions/69427700/error-rpc-failed-curl-55-send-failure-connection-was-aborted&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GitHub教程 仓库的创建、同步、删除&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;https://www.likecs.com/show-204599371.html&#34;&gt;https://www.likecs.com/show-204599371.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;push时报错：&lt;br&gt;
&lt;code&gt;1&lt;/code&gt;&lt;br&gt;
fatal: unable to access &#39;https://github.com/jeromezjl/jeromezjl.github.io.git/&#39;: Failed to connect to github.com port 443 after 21055 ms: Timed out&lt;br&gt;
没挂梯子&lt;/p&gt;
&lt;p&gt;&lt;code&gt;2&lt;/code&gt;&lt;br&gt;
Authentication failed. Some common reasons include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You are not logged in to your account: see File &amp;gt; Options.&lt;/li&gt;
&lt;li&gt;You may need to log out and log back in to refresh your token.&lt;/li&gt;
&lt;li&gt;You do not have permission to access this repository.&lt;/li&gt;
&lt;li&gt;The repository is archived on GitHub. Check the repository settings to confirm you are still permitted to push commits.&lt;/li&gt;
&lt;li&gt;If you use SSH authentication, check that your key is added to the ssh-agent and associated with your account.&lt;/li&gt;
&lt;li&gt;If you use SSH authentication, ensure the host key verification passes for your repository hosting service.&lt;/li&gt;
&lt;li&gt;If you used username / password authentication, you might need to use a Personal Access Token instead of your account password. Check the documentation of your repository hosting service.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;检查是否有权限操作该仓库；检查对应仓库的URL是否适配，使用https还是ssh&lt;/p&gt;
&lt;p&gt;lastest更新：建议重新配置ssh&lt;br&gt;
删除user文件下中 .ssh 文件中所有文件，按照上述步骤重新配置ssh&lt;/p&gt;
&lt;p&gt;配置完之后，如果还是出现，那么点进github原仓库，在Code按钮下拉栏里面，选择SSH，复制信息，&lt;br&gt;
点击github desktop，repository - repository setting - remote 改成刚才复制的数据&lt;/p&gt;
&lt;p&gt;注意同步一定要先点预览，再点同步，然后才能同步&lt;/p&gt;
">Github Desktop 管理本地代码</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/wechat/"" data-c="
          &lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1648906251060.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">Wechat</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ji-wang-socket-bian-cheng-shi-yan/"" data-c="
          &lt;p&gt;&lt;strong&gt;原文档：&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://m653uatd6t.feishu.cn/docs/doccnBhfhSQ8wZ3krkTnQ3GbDHf#KJ735Z&#34;&gt;https://m653uatd6t.feishu.cn/docs/doccnBhfhSQ8wZ3krkTnQ3GbDHf#KJ735Z&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;参考文章：&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/387279376&#34;&gt;https://zhuanlan.zhihu.com/p/387279376&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;服务器端代码：&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import random
from socket import *
# 使用 AF_INET 套接字家族，SOCK_DGRAM 代表面向非连接（UDP）
serverSocket = socket(AF_INET, SOCK_DGRAM)

# 将 socket 绑定在本机 IP 的 10000 端口
serverSocket.bind((&#39;127.0.0.1&#39;, 10000))

while True:
    # 生成一个 [1, 10] 的随机数，包含两端
    rand = random.randint(1, 10)
    # 将收到的 packet 中的数据存入 message，将地址存入 address（客户端地址）
    message, address = serverSocket.recvfrom(1024)
    # 下面是对收到的 message 进行处理
    # 将 bytes 类型的 message 转换为 string 类型
    message_str = message.decode(&#39;utf-8&#39;)
    # 在 30% 的概率下丢弃收到的 packet
    if rand &amp;lt; 4:
        continue
    # 对收到的 message 做简单处理
    ret = &#39;{&#39; + message_str + &#39;}&#39;
    # 做出响应（将处理后的数据通过sendto函数送回客户端），注意还要将 string 编码为 bytes 类型
    serverSocket.sendto(ret.encode(), address)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;客户端代码&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from socket import *
import time

# SOCK_DGRAM 表示使用UDP协议
client = socket(AF_INET, SOCK_DGRAM)
# 设置超时时间为1秒
client.settimeout(1)
# 服务端的ip和端口
server_address = (&#39;152.136.19.235&#39;, 10000)
for i in range(10):
    # 发送ping命令
    client.sendto(b&amp;quot;2020212487&amp;quot;, server_address)
    send_time = time.time()
    try:
        message, adr = client.recvfrom(1024)
        recv_time = time.time()  # 获取
        print(f&amp;quot;[{i}]\t{message.decode()}\tRTT: {(recv_time - send_time) * 1000:.2f}ms&amp;quot;)
    except timeout as e:  # 超时就打印LOST
        print(f&amp;quot;[{i}]\tLOST&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;
">【计网】Socket 编程实验</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/git-shi-yong/"" data-c="
          &lt;p&gt;&lt;strong&gt;使用 Git 上传文件夹到 Github&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/136355306&#34;&gt;https://zhuanlan.zhihu.com/p/136355306&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_45309916/article/details/108273988&#34;&gt;https://blog.csdn.net/weixin_45309916/article/details/108273988&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/dontla/article/details/100017358&#34;&gt;Github 代码上边的Raw、Blame、History是啥意思？&lt;/a&gt;&lt;/p&gt;
">Github 使用</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ml-jue-ce-shu/"" data-c="
          &lt;p&gt;决策树是一种非常通用的机器学习算法，主要用于以下任务：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. 分类
决策树经常用于分类任务。在这类任务中，目标是根据一系列输入特征将实例分配给预定义的类别。
例如，一个决策树可能用于基于病人的临床数据（如年龄、体重、血压等）来判断病人是否患有某种疾病。

2. 回归
决策树也可以用于回归任务，其中输出是一个连续值而非类别标签。回归树的构建与分类树类似，但在每个叶节点上，它们会预测一个连续值而不是类别标签。
例如，决策树可用于根据房屋的特征（如面积、房间数、地段等）预测房屋的市场价格。

3. 数据探索
由于决策树易于理解和解释，它们经常被用于数据探索。通过构建决策树，数据科学家可以了解哪些特征对输出变量有重要影响，以及这些特征是如何组合影响输出的。
这有助于生成有关数据的洞察，可能会指导进一步的分析。

4. 特征选择
在预处理阶段，决策树可以帮助识别最重要的特征，从而减少模型的复杂性和过拟合的风险。
特征重要性是根据特征在构建树时的使用频率和深度来评估的。

5. 多输出任务
决策树还可以扩展到多输出任务，其中一个实例可能有多个标签或多个连续输出。
例如，在环境监测中，一个模型可能需要根据一组传感器读数预测多种污染物的水平。

决策树因其简单、易解释的特性而受到广泛欢迎，尽管它们可能容易过拟合，
但通过技术如剪枝、随机森林和梯度提升树，可以有效地提高它们的泛化能力。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;b站讲解&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1ar4y137GD/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;5分钟学算法 #03 决策树 小明毕业当行长&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1T7411b7DG?from=search&amp;amp;seid=4602675497552466282&amp;amp;spm_id_from=333.337.0.0&#34;&gt;https://www.bilibili.com/video/BV1T7411b7DG?from=search&amp;amp;seid=4602675497552466282&amp;amp;spm_id_from=333.337.0.0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;决策树的使用步骤&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根据属性构建决策树（构建算法）&lt;/li&gt;
&lt;li&gt;在新的数据上决策&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;决策树的构建&#34;&gt;决策树的构建&lt;/h1&gt;
&lt;p&gt;典型决策树算法：ID3、C4.5、CART&lt;br&gt;
ID3用信息增益，C4.5用信息增益率，CART用Gini系数&lt;br&gt;
&lt;img src=&#34;https://jeromezjl.github.io/post-images/1710040898493.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;构建原则：希望第一次分类就尽量分对，即优先选择使数据纯度提升的属性&lt;/p&gt;
&lt;h2 id=&#34;id3&#34;&gt;ID3&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/133846252&#34;&gt;决策树算法--ID3算法&lt;/a&gt;&lt;br&gt;
信息熵：介于0-1之间，反映了数据纯度（和Gini系数一样）样本越纯，信息熵越趋于0，当A，B各占一半时，信息熵达到最大，值为1&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV18D421E7Eq?p=76&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;信息熵公式讲解&lt;/a&gt;&lt;br&gt;
信息增益：表示数据集 D 按照 A 属性划分后，D 的纯度。信息增益值越大，划分后的纯度越大。优先选择信息增益大的属性构建决策树&lt;/p&gt;
&lt;p&gt;但若每个属性只有一个样本，那么信息增益为 0，无法划分，所以使用信息增益率，引出C4.5算法&lt;/p&gt;
&lt;h2 id=&#34;c45算法&#34;&gt;C4.5算法&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/zjsghww/article/details/51638126&#34;&gt;C4.5算法详解（非常仔细）&lt;/a&gt;&lt;br&gt;
信息增益率引入了属性内部信息&lt;br&gt;
&lt;code&gt;算法步骤：&lt;/code&gt;&lt;br&gt;
1）计算总信息熵 Entropy&lt;br&gt;
2）分别计算每个属性信息熵&lt;br&gt;
3）总信息熵 - 属性信息熵 得到信息增益 Gain(A)&lt;br&gt;
4）计算信息增益率 GainRatio(A) = Gain / Ent&lt;br&gt;
5）增益率max的为根节点&lt;/p&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;&lt;br&gt;
总信息熵用结果的概率进行计算&lt;br&gt;
属性信息熵：&lt;br&gt;
∑（ p(属性概率) * ∑ -（ p(该属性内成功概率) log2 p + p(该属性内失败概率)log2 p ））&lt;/p&gt;
&lt;p&gt;&lt;code&gt;习题&lt;/code&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/166393579&#34;&gt;https://zhuanlan.zhihu.com/p/166393579&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;cartclassification-and-regression-tree分类回归树&#34;&gt;CART（classification and regression tree）分类回归树&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/139523931&#34;&gt;决策树算法--CART分类树算法&lt;/a&gt;&lt;br&gt;
基尼系数：反映了数据的纯度（最上面视频有讲解和图像）&lt;br&gt;
假设有两个类别 A，B，单类别占比越多，代表样本越纯&lt;br&gt;
若全是 A / B 则基尼系数为 0，若 A、B 各占一半，则是数据最不纯的情况，Gini系数为 0.5&lt;br&gt;
构建决策树时，优先选择Gini系数小的属性，意味着通过该属性分割后得到的子集在类别分布上更加纯粹，有助于提高决策树的分类性能。&lt;/p&gt;
&lt;h1 id=&#34;决策树的剪枝&#34;&gt;决策树的剪枝&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/u012328159/article/details/79285214&#34;&gt;决策树（decision tree）(二)——剪枝&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;随机森林&#34;&gt;随机森林&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV12s4y1N7Bp/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【机器学习】动画讲解随机森林&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/video/BV1H5411e73F/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33&#34;&gt;【五分钟机器学习】随机森林（RandomForest）：看我以弱搏强&lt;/a&gt;&lt;br&gt;
随机森林是一种流行且强大的机器学习算法，属于&lt;code&gt;集成学习&lt;/code&gt;方法的一种。它由多个决策树构成，通过组合多个决策树的预测结果来提高整体模型的准确性和鲁棒性。随机森林可以用于分类和回归任务，并且因其易于理解、实现简单和表现出色而广受欢迎。&lt;/p&gt;
&lt;h3 id=&#34;工作原理&#34;&gt;工作原理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;自助采样（Bootstrap sampling）&lt;/strong&gt;：从原始训练数据集中进行&lt;code&gt;有放回的&lt;/code&gt;随机采样来创建多个子集，每个子集用来训练一个决策树。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;随机特征选择&lt;/strong&gt;：在决策树的每个分裂过程中，随机森林不会考虑所有可能的特征，而是从全部特征中随机选择一个特征子集，并基于这个子集来选择最佳分裂特征。这一步增加了模型的多样性，有助于提高整体的泛化能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;决策树集成&lt;/strong&gt;：使用多个子集训练多个决策树，每个决策树都尽可能地生长到最大程度，不进行剪枝。最终的预测结果是通过对所有决策树的预测结果进行汇总得到的。对于分类任务，采用&lt;code&gt;投票&lt;/code&gt;机制（多数投票）；对于回归任务，则采用平均值。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;优点&#34;&gt;优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;准确性高&lt;/strong&gt;：集成多个决策树可以减少模型的方差，提高预测准确性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;抗过拟合&lt;/strong&gt;：相比于单个决策树，随机森林通过引入随机性和集成多个模型，能够有效地降低过拟合的风险。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;适用性广&lt;/strong&gt;：随机森林可以处理高维数据，并且不需要对数据进行太多的预处理，如归一化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;重要性评估&lt;/strong&gt;：随机森林能够评估各个特征对模型预测能力的贡献，有助于特征选择。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;缺点&#34;&gt;缺点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模型解释性&lt;/strong&gt;：虽然单个决策树容易理解，但是整个随机森林模型由于包含大量决策树，解释性不如单个决策树。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算和内存开销&lt;/strong&gt;：训练多个决策树需要较多的计算资源和内存，特别是当数据集很大时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;预测速度&lt;/strong&gt;：随机森林在预测时需要汇总所有决策树的预测结果，可能会比单个决策树慢。&lt;/li&gt;
&lt;/ul&gt;
">【ML】决策树和随机森林</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/opencv-qian-ji/"" data-c="
          &lt;h1 id=&#34;matplotlib-显示-opencv-图像失真原因&#34;&gt;matplotlib 显示 opencv 图像失真原因&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Strive_For_Future/article/details/108566534&#34;&gt;https://blog.csdn.net/Strive_For_Future/article/details/108566534&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;br&gt;
opencv 在 anaconda 中文件夹的名称叫 cv2&lt;br&gt;
可在编译器中输入 cv2.path 来查看 cv2 安装地址，从而找到对应的算法文件&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.lsbin.com/7111.html&#34;&gt;如何使用OpenCV截取图片指定区域？&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/fjswcjswzy/article/details/105881899&#34;&gt;cv2.selectROI：框取指定区域&lt;/a&gt;&lt;/p&gt;
">【CV】OpenCV 浅记</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/jupyter-notebook-de-anaconda-pei-zhi/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Inochigohan/article/details/120400990&#34;&gt;Anaconda||（踩坑无数，含泪总结！！！）Anaconda的卸载与安装（tensorflow+Keras+spyder+添加镜像源）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载anaconda之后，用pycharm分配虚拟环境自己摸索一下就会了&lt;br&gt;
但是jupyter一直只有一个虚拟环境，于是上网搜索了一下&lt;br&gt;
jupyter需要手动分配内核，&lt;strong&gt;具体参考：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_44799217/article/details/116056976&#34;&gt;https://blog.csdn.net/weixin_44799217/article/details/116056976&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/81605893&#34;&gt;https://zhuanlan.zhihu.com/p/81605893&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结&lt;/h1&gt;
&lt;p&gt;每次创建虚拟环境的时候，两步配置jupyter内核：&lt;/p&gt;
&lt;p&gt;pip install -i https://pypi.tuna.tsinghua.edu.cn/simple ipykernel # 在该虚拟环境下安装 ipykernel 包&lt;br&gt;
python -m ipykernel install --name 环境名 # 向 jupyter 中添加虚拟内核&lt;/p&gt;
">Jupyter notebook 的 Anaconda 配置</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/cmd/"" data-c="
          &lt;p&gt;&lt;strong&gt;cmd 中 curl 命令的使用&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/zhuzhenwei918/p/6781314.html&#34;&gt;https://www.cnblogs.com/zhuzhenwei918/p/6781314.html&lt;/a&gt;&lt;/p&gt;
">cmd</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/ji-zu-qian-ji/"" data-c="
          &lt;h1 id=&#34;思维导图&#34;&gt;思维导图&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/98226508&#34;&gt;https://zhuanlan.zhihu.com/p/98226508&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/weixin_47423314/article/details/114875087&#34;&gt;https://blog.csdn.net/weixin_47423314/article/details/114875087&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.bilibili.com/read/cv5340324/&#34;&gt;https://www.bilibili.com/read/cv5340324/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;进制转换&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/a9254778/article/details/8513086&#34;&gt;https://blog.csdn.net/a9254778/article/details/8513086&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;机器字长、指令字长、存储字长&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_43627631/article/details/106738058&#34;&gt;https://blog.csdn.net/qq_43627631/article/details/106738058&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ALU&lt;/strong&gt;&lt;br&gt;
算术逻辑单元（Arithmetic&amp;amp;logical Unit）是中央处理器(CPU)的执行单元，是所有中央处理器的核心组成部分，由&amp;quot;And Gate&amp;quot;（与门） 和&amp;quot;Or Gate&amp;quot;（或门）构成的算术逻辑单元，主要功能是进行二位元的算术运算，如加减乘(不包括整数除法)。基本上，在所有现代CPU体系结构中，二进制都以补码的形式来表示。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weibo1230123/article/details/83106141&#34;&gt;CPU中的主要寄存器&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/vavid317/article/details/110946947&#34;&gt;Cache 主存映射&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;第四章-指令系统&#34;&gt;第四章 指令系统&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;操作数：&lt;/strong&gt; 地址码指向的真实数据&lt;/p&gt;
">计组浅记</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/pykeyboard-he-pymouse-zi-dong-hua-cao-zuo/"" data-c="
          &lt;h1 id=&#34;三篇参考文章&#34;&gt;三篇参考文章：&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_51802807/article/details/121179861&#34;&gt;https://blog.csdn.net/weixin_51802807/article/details/121179861&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.cnblogs.com/zjutlitao/p/10188434.html&#34;&gt;https://www.cnblogs.com/zjutlitao/p/10188434.html&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/137133751&#34;&gt;https://zhuanlan.zhihu.com/p/137133751&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;技巧&#34;&gt;技巧：&lt;/h1&gt;
&lt;p&gt;用cmd命令打开网页，这种方法可以省去鼠标操作可能带来的延迟，而且可以运行电脑上任何位置的程序&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/yekui/article/details/83802667&#34;&gt;https://blog.csdn.net/yekui/article/details/83802667&lt;/a&gt;&lt;br&gt;
start 网站 （用该语法打开网站）&lt;br&gt;
下面给出代码演示&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pykeyboard import *
import time   # 连续进行两个动作可能太快而效果不明显，因此加入暂停时间

k = PyKeyboard() #建立键盘对象

k.press_key(k.windows_l_key)  # 按住Win键
k.tap_key(&#39;r&#39;)  # 点击r键
k.release_key(k.windows_l_key)  # 松开Win键
time.sleep(0.2)  # 需等待界面跳转，0.2是极限，0.1就不好用了
k.tap_key(k.enter_key)

time.sleep(0.2)
k.type_string(&#39;start https://www.bilibili.com/?spm_id_from=333.999.b_696e7465726e6174696f6e616c486561646572.1&#39;)
k.tap_key(k.enter_key)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然，用cmd更便于打开本地的文件，只需复制文件地址一步打开，下面给出演示&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pymouse import *    # 模拟鼠标所使用的包
from pykeyboard import *
import pyperclip
import time   # 连续进行两个动作可能太快而效果不明显，因此加入暂停时间

m = PyMouse()   # 鼠标的实例m
k = PyKeyboard() #建立键盘对象
x_dim, y_dim = m.screen_size()


k.press_key(k.windows_l_key)  # 按住win键
k.tap_key(&#39;r&#39;)  # 点击r键
k.release_key(k.windows_l_key)  # 松开win 键
time.sleep(0.5)
k.tap_key(k.enter_key)

pyperclip.copy(r&amp;quot;C:\Users\ZJL\Desktop\软件\Firefox.lnk&amp;quot;)
time.sleep(0.5)
k.press_key(k.control_key)
k.tap_key(&#39;v&#39;)
k.release_key(k.control_key)
k.tap_key(k.enter_key)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里要说明的是，pykeyboard不能输入中文，需要用pyperclip对字符串进行copy，然后模拟键盘CTRL cv&lt;/p&gt;
&lt;h1 id=&#34;另外注意&#34;&gt;另外注意：&lt;/h1&gt;
&lt;p&gt;1）pykeyboard 组合键使用时，需要用小写字母&lt;br&gt;
&lt;strong&gt;例如：&lt;/strong&gt;&lt;br&gt;
模拟 alt+z&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;k.press_key(k.alt_key)  # 按住Alt键
k.tap_key(&#39;z&#39;)  # 点击z键
k.release_key(k.alt_key)  # 松开Alt键
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2）用 m.position() 获取当前鼠标位置坐标&lt;br&gt;
3）需要引入time模块，调整触发时间&lt;/p&gt;
">Pykeyboard 和 Pymouse 自动化操作</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/pa-chong-curl-zhuan-wei-python-pa-chong-dai-ma/"" data-c="
          &lt;p&gt;&lt;a href=&#34;http://tool.yuanrenxue.com/curl&#34;&gt;http://tool.yuanrenxue.com/curl&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.kemaowang.org.cn/n/197417.html&#34;&gt;十大爬虫软件排行（好用的爬虫软件推荐）&lt;/a&gt;&lt;/p&gt;
">【爬虫】curl转为python爬虫代码</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/markdown-yu-fa/"" data-c="
          &lt;h1 id=&#34;官方教程&#34;&gt;官方教程：&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://markdown.com.cn/basic-syntax/paragraphs.html&#34;&gt;https://markdown.com.cn/basic-syntax/paragraphs.html&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;常用&#34;&gt;常用:&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;主标题&lt;/strong&gt;&lt;br&gt;
‘#’ + 字符&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;加粗&lt;/strong&gt;&lt;br&gt;
’** ‘ + 字符+ ’**‘&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;空格&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.csdn.net/qq_34719188/article/details/84205243&#34;&gt;Markdown 语言中空格的几种表示方法&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;添加链接&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://markdown.com.cn/basic-syntax/links.html&#34;&gt;https://markdown.com.cn/basic-syntax/links.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;插入数学公式&lt;/strong&gt;&lt;br&gt;
在 “$$”中间插入公式&lt;br&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/450465546&#34;&gt;Markdown/LaTeX 数学公式和符号表&lt;/a&gt;&lt;/p&gt;
">Markdown 语法</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/leetcode-1323-6-he-9-zu-cheng-de-zui-da-shu-zi/"" data-c="
          &lt;p&gt;给你一个仅由数字 6 和 9 组成的正整数 num。&lt;/p&gt;
&lt;p&gt;你最多只能翻转一位数字，将 6 变成 9，或者把 9 变成 6 。&lt;/p&gt;
&lt;p&gt;请返回你可以得到的最大数字。&lt;/p&gt;
&lt;p&gt;示例 1：&lt;/p&gt;
&lt;p&gt;输入：num = 9669&lt;br&gt;
输出：9969&lt;br&gt;
解释：&lt;br&gt;
改变第一位数字可以得到 6669 。&lt;br&gt;
改变第二位数字可以得到 9969 。&lt;br&gt;
改变第三位数字可以得到 9699 。&lt;br&gt;
改变第四位数字可以得到 9666 。&lt;br&gt;
其中最大的数字是 9969 。&lt;br&gt;
示例 2：&lt;/p&gt;
&lt;p&gt;输入：num = 9996&lt;br&gt;
输出：9999&lt;br&gt;
解释：将最后一位从 6 变到 9，其结果 9999 是最大的数。&lt;br&gt;
示例 3：&lt;/p&gt;
&lt;p&gt;输入：num = 9999&lt;br&gt;
输出：9999&lt;br&gt;
解释：无需改变就已经是最大的数字了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;提示：&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;1 &amp;lt;= num &amp;lt;= 10^4&lt;br&gt;
num 每一位上的数字都是 6 或者 9 。&lt;/p&gt;
&lt;h1 id=&#34;my-solution&#34;&gt;My Solution：&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Solution(object):
    def maximum69Number (self, num):
            list1 = []
            stnum = list(str(num))
            for i in range(len(stnum)):
                stnum = list(str(num))
                stnum[i] = &#39;9&#39;
                list1.append(&#39;&#39;.join(stnum))
            return int(max(list1))
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;python的简单方法&#34;&gt;Python的简单方法：&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def func(num):
    return int(str(num).replace(&#39;6&#39;,&#39;9&#39;,1))
print(func(9669))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;利用replace函数，替换第一个6。根据贪心思想，把最前面的一个6替换为9即可得到最大值&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本题总结：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;int 为不可迭代对象，str可&lt;/li&gt;
&lt;li&gt;join函数的用法&lt;/li&gt;
&lt;li&gt;贪心思想&lt;/li&gt;
&lt;/ol&gt;
">【leetcode】1323. 6 和 9 组成的最大数字</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/lan-qiao-bei-zui-xiao-ju-chi-python/"" data-c="
          &lt;p&gt;&lt;strong&gt;资源限制&lt;/strong&gt;&lt;br&gt;
时间限制：1.0s 内存限制：256.0MB&lt;br&gt;
　　最小距离&lt;br&gt;
　　&lt;br&gt;
&lt;strong&gt;问题描述&lt;/strong&gt;&lt;br&gt;
　　数轴上有n个数字，求最近的两个数，即min(abs(x-y))&lt;br&gt;
　　&lt;br&gt;
&lt;strong&gt;输入格式&lt;/strong&gt;&lt;br&gt;
　　第一行包含一个整数n。&lt;br&gt;
　　接下来一行，表示n整数。&lt;br&gt;
　　&lt;br&gt;
&lt;strong&gt;输出格式&lt;/strong&gt;&lt;br&gt;
　　一个整数表示最小距离&lt;br&gt;
　　&lt;br&gt;
&lt;strong&gt;样例输入&lt;/strong&gt;&lt;br&gt;
6&lt;br&gt;
7 3 4 11 9 17&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;样例输出&lt;/strong&gt;&lt;br&gt;
1&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;样例说明&lt;/strong&gt;&lt;br&gt;
　　取3和4&lt;br&gt;
　　&lt;br&gt;
&lt;strong&gt;数据规模和约定&lt;/strong&gt;&lt;br&gt;
　　n&amp;lt;=100000&lt;br&gt;
　　所有整数&amp;lt;=10^7&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本题要点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;输入格式：a = list(map(int, input().split())) 空格分隔&lt;br&gt;
两次for循环复杂度过大，不能通过，采取先排序，再算min的方法&lt;/p&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;n = int(input())
numlist = list(map(int, input().split()))
numlist.sort()
min = float(&#39;inf&#39;)  # min初始值设为正无穷
for i in range(1, n):
    value = numlist[i] - numlist[i-1]
    if value &amp;lt; min:
        min = value
print(min)
&lt;/code&gt;&lt;/pre&gt;
">【蓝桥杯】最小距离 - Python</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/next-zhu-ti-shi-yong-jiao-cheng/"" data-c="
          &lt;p&gt;&lt;a href=&#34;https://yeming.site/post/1JA_OJlig/&#34;&gt;https://yeming.site/post/1JA_OJlig/&lt;/a&gt;&lt;/p&gt;
">Next主题使用教程</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/the-first-article/"" data-c="
          &lt;p&gt;第一篇文章!&lt;/p&gt;
&lt;p&gt;本站于2022/1/25正式成立&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://jeromezjl.github.io/post-images/1648733500854.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">The First Article</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/about/"" data-c="
          &lt;h1 id=&#34;welcome&#34;&gt;welcome！&lt;/h1&gt;
&lt;h2 id=&#34;jerome-的个人网站-佛系更新&#34;&gt;🏠 Jerome 的个人网站 | 佛系更新&lt;/h2&gt;
&lt;p&gt;20 级 BUPTer | AIer | 摄影师 | 吉他手 | 文玩人&lt;br&gt;
欢迎关注个人社交媒体，欢迎私信！&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://team.byrio.work/&#34;&gt;BYR 系列网站&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://ec.jray.xyz/&#34;&gt;BUPT 空教室查询&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;悄咪咪夹带私货&#34;&gt;悄咪咪夹带私货&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;放两张图片可以作为博客 背景&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;赛博朋克主题&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://img.3dmgame.com/uploads/images/news/20201216/1608109166_366000.jpg&#34;&gt;赛博房间1&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://img.3dmgame.com/uploads/images/news/20200914/1600072653_344511.jpg&#34;&gt;赛博房间2&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://tse1-mm.cn.bing.net/th/id/R-C.0b7b7f15b83e7326de9078d0998d5eac?rik=KDIsnoDnAZ%2b5mw&amp;amp;riu=http%3a%2f%2fwww.obzhi.com%2fwp-content%2fuploads%2f2020%2f09%2fkejigan.jpg&amp;amp;ehk=6nuckhqgEl%2fAyE7ZDxsZnTs1%2bLpurRBJEk6V%2fhbe1cw%3d&amp;amp;risl=&amp;amp;pid=ImgRaw&amp;amp;r=0&#34;&gt;赛博房间3 这个超酷！！&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://tse1-mm.cn.bing.net/th/id/R-C.d64c8f7bf000786740b9be4a0731c8b0?rik=F23wyPNFdcYDzA&amp;amp;riu=http%3a%2f%2fi0.hdslb.com%2fbfs%2farchive%2f42a67c4c29a152ed9496f2f459dd1b4ede9a2659.jpg&amp;amp;ehk=mXdqZreTLQwnvxqIp2jmV7nU9MivTInwzvOWBX8tXjQ%3d&amp;amp;risl=&amp;amp;pid=ImgRaw&amp;amp;r=0&#34;&gt;赛博房间4 这个是我最喜欢壁纸的平替！&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://tse1-mm.cn.bing.net/th/id/R-C.d05131b1eed12bd35ef5ebc1b44a2bd5?rik=Wq3EEaINBRSCpg&amp;amp;riu=http%3a%2f%2fi2.hdslb.com%2fbfs%2farchive%2ff423317e628a2b0d323a72e47c87061709c4da61.jpg&amp;amp;ehk=PzA5T9xku%2feJAab8nvE2oFcsmmZFcRAk%2bf9iQHUKUyg%3d&amp;amp;risl=&amp;amp;pid=ImgRaw&amp;amp;r=0&#34;&gt;赛博房间5 绚烂版&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://tse1-mm.cn.bing.net/th/id/R-C.4f518eb58b5be4c0c51de8d535e0f4c3?rik=SdDpw9hBq6IUrg&amp;amp;riu=http%3a%2f%2fi0.hdslb.com%2fbfs%2farchive%2f84c424a45e06f7e099a7c8fa2a9ba08d9c230c2a.jpg&amp;amp;ehk=L5SoLj6%2b4pysTCpz1QxgD5ywSXOrCwPjcki0oDptfak%3d&amp;amp;risl=&amp;amp;pid=ImgRaw&amp;amp;r=0&#34;&gt;赛博房间6 又是一个喜欢的壁纸&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://tse1-mm.cn.bing.net/th/id/R-C.c4c224c431cdb2cfd70150e8e13955ff?rik=I5xqEwEGkWHq3g&amp;amp;riu=http%3a%2f%2fup.desktx.net%2fpic%2f26%2fb1%2fa1%2f26b1a186df16bfaa83754085a32bbc9b.jpg&amp;amp;ehk=4sIJUj6AIsD%2bRJOc3Vdns0KZrimsuhrg0jXmjYxVThI%3d&amp;amp;risl=&amp;amp;pid=ImgRaw&amp;amp;r=0&#34;&gt;赛博房间7&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://yxbao-img.xiazaibao2.com/patch/image/201911/12/27fa377303.jpg&#34;&gt;国风房间&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://tse1-mm.cn.bing.net/th/id/R-C.8af0a7c2c80b8d3b02f0bd8f0d159331?rik=c8cbKRpcqg7vmA&amp;amp;riu=http%3a%2f%2fup.desktx.net%2fpic_360%2f1d%2f91%2faa%2f1d91aaa58f2afcc5e2b0411c0c3b0ca0.jpg&amp;amp;ehk=W9aEoqN9K6yJWm4rczzIWtFDUF%2fbryueo1g0lEFoHbo%3d&amp;amp;risl=&amp;amp;pid=ImgRaw&amp;amp;r=0&amp;amp;sres=1&amp;amp;sresct=1&#34;&gt;赛博大厅&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://pic3.zhimg.com/v2-2eca64da78d43daca1e085c5a7688b3c_r.jpg&#34;&gt;赛博构图 这张很nice很有感觉！！&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://img.zcool.cn/community/01b96a5e86071da80120a89528e00c.jpg@1280w_1l_2o_100sh.jpg&#34;&gt;赛博city1&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://pic1.zhimg.com/v2-02fef084396c04290fd94fedaba5a8f0_r.jpg&#34;&gt;赛博city2&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://pic3.zhimg.com/v2-be45a8574cec110668120b88a568e9af_1200x500.jpg&#34;&gt;赛博city3&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://pic1.zhimg.com/v2-b0277265665a7c6fca4782a8fcd50fd8_r.jpg&#34;&gt;赛博city4&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://pic4.zhimg.com/v2-60a102c86ce742c5f588687dbbe989d3_r.jpg&#34;&gt;赛博city5 成都太古里&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;其他房间主题&lt;/code&gt; （我好像很喜欢房间？？&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://image.lnstzy.cn/aoaodcom/2020-08/04/20200804022855d8a3bc046d0ecb0189247bd82fb31d45.jpg.h700.jpg&#34;&gt;夏日房间&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://cdn.max-c.com/heybox/dailynews/img/051d4a61594116698e004a4f1c2208ac.jpg?imageMogr2/format/jpg&#34;&gt;电子厨房&lt;/a&gt;&lt;/p&gt;
">关于</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jeromezjl.github.io/post/hello-gridea/"" data-c="
          &lt;p&gt;👏  欢迎使用 &lt;strong&gt;Gridea&lt;/strong&gt; ！&lt;br&gt;
✍️  &lt;strong&gt;Gridea&lt;/strong&gt; 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/getgridea/gridea&#34;&gt;Github&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://gridea.dev/&#34;&gt;Gridea 主页&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://fehey.com/&#34;&gt;示例网站&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;特性&#34;&gt;特性👇&lt;/h2&gt;
&lt;p&gt;📝  你可以使用最酷的 &lt;strong&gt;Markdown&lt;/strong&gt; 语法，进行快速创作&lt;/p&gt;
&lt;p&gt;🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片&lt;/p&gt;
&lt;p&gt;🏷️  你可以对文章进行标签分组&lt;/p&gt;
&lt;p&gt;📋  你可以自定义菜单，甚至可以创建外部链接菜单&lt;/p&gt;
&lt;p&gt;💻  你可以在 &lt;strong&gt;Windows&lt;/strong&gt;，&lt;strong&gt;MacOS&lt;/strong&gt; 或 &lt;strong&gt;Linux&lt;/strong&gt; 设备上使用此客户端&lt;/p&gt;
&lt;p&gt;🌎  你可以使用 &lt;strong&gt;𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌&lt;/strong&gt; 或 &lt;strong&gt;Coding Pages&lt;/strong&gt; 向世界展示，未来将支持更多平台&lt;/p&gt;
&lt;p&gt;💬  你可以进行简单的配置，接入 &lt;a href=&#34;https://github.com/gitalk/gitalk&#34;&gt;Gitalk&lt;/a&gt; 或 &lt;a href=&#34;https://github.com/SukkaW/DisqusJS&#34;&gt;DisqusJS&lt;/a&gt; 评论系统&lt;/p&gt;
&lt;p&gt;🇬🇧  你可以使用&lt;strong&gt;中文简体&lt;/strong&gt;或&lt;strong&gt;英语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力&lt;/p&gt;
&lt;p&gt;🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步&lt;/p&gt;
&lt;p&gt;🌱 当然 &lt;strong&gt;Gridea&lt;/strong&gt; 还很年轻，有很多不足，但请相信，它会不停向前 🏃&lt;/p&gt;
&lt;p&gt;未来，它一定会成为你离不开的伙伴&lt;/p&gt;
&lt;p&gt;尽情发挥你的才华吧！&lt;/p&gt;
&lt;p&gt;😘 Enjoy~&lt;/p&gt;
">Hello Gridea</a>
      </div>
      
    </div>
    <div class="page">
      <div id="page_ul"></div>
    </div>
  </div>
</div>
<script>
  !function () {
    let searchMask = document.querySelector('#search_mask');
    let result = document.querySelector('#result');
    let items = document.querySelectorAll('.item');
    let searchBox = document.querySelector('#search');
    let statCount = document.querySelector('#stat_count');
    let statTimes = document.querySelector('#stat_times');
    let pageUl = document.querySelector('#page_ul');
    let close = document.querySelector('#close');
    
    close.addEventListener('click', function() {
      searchMask.style = 'display: none;'
    })

    let finds = [];
    let contents = [];
    let pageSize = 10;
    items.forEach(item => {
      let a = item.querySelector('a');
      contents.push({
        title: a.innerText,
        details: a.dataset.c,
        link: a.href
      })
      item.remove();
    })

    function insertStr(soure, start, count) {
      let newStr = soure.substr(start, count);
      return soure.slice(0, start) + '<em>' + newStr + '</em>' + soure.slice(start + count);
    }

    pageUl.addEventListener('click', function(event) {
      let target = event.target;
      if (target.__proto__ === HTMLSpanElement.prototype) {
        appendResults(parseInt(target.dataset.i));
      }
    })

    function appendResults(index) {
      let htmlResult = '';
      let start = index || 0;
      let end = Math.min(start + pageSize, finds.length);
      for (let i = start; i < end; i++) {
        const current = finds[i];
        let html = current.title;
        let sum = 0;
        let positions = current.positions;
        positions.forEach(position => {
          html = insertStr(html, position.start + sum, position.count);
          sum += 9;
        })
        htmlResult += `<div class="item"><a class="result-title" href="${current.link}">${html}</a></div>`;
      }
      result.innerHTML = htmlResult;
      pageUl.innerHTML = '';
      let count = finds.length / pageSize;
      let lis = '';
      if (start !== 0) {
        lis += `<span class="fa fa-angle-left" data-i='${start - 1}'></span>`;
      }
      for (let i = 0; i < count; i++) {
        lis += `<span class='${i === start?'current':''}' data-i='${i}'>${i+1}</span>`;     
      }
      if (start+1 < count) {
        lis += `<span class="fa fa-angle-right" data-i='${start+1}'></span>`;  
      }
      pageUl.innerHTML = lis;
    }

    function search(delay) {
      let timer = null
      return function () {
        clearTimeout(timer)
        timer = setTimeout(() => {
          let start = Date.now();
          let segments = searchBox.value.split(' ').filter(c => c != '');
          if (segments.length <= 0) {
            return;
          }
          finds = [];
          let htmlResult = '';
          contents.forEach(content => {
            let title = content.title;
            let positions = [];
            let find = false;
            segments.forEach((segment) => {
              if (content.title.includes(segment)) {
                find = true;
                positions.push({
                  start: content.title.indexOf(segment),
                  count: segment.length
                })
              } else if (content.details.includes(segment)) {
                find = true;
              }
            });
            if (find) {
              finds.push({
                title: content.title,
                link: content.link,
                positions
              });
            }
          })
          appendResults(0);
          statCount.textContent = finds.length;
          statTimes.textContent = Date.now() - start;
        }, delay)
      }
    }
    searchBox.addEventListener('input', search(200));
  }()
</script>

<input hidden id="copy" />
<script>
  !function () {
    let times = document.querySelectorAll('.publish-time');
    for (let i = 0; i < times.length; i++) {
      let date = times[i].dataset.t;
      let time = Math.floor((new Date().getTime() - new Date(date).getTime()) / 1000);
      if (time < 60) {
        str = time + '秒之前';
      } else if (time < 3600) {
        str = Math.floor(time / 60) + '分钟之前';
      } else if (time >= 3600 && time < 86400) {
        str = Math.floor(time / 3600) + '小时之前';
      } else if (time >= 86400 && time < 259200) {
        str = Math.floor(time / 86400) + '天之前';
      } else {
        str = times[i].textContent;
      }
      times[i].textContent = str;
    }
  }();
</script>

<script>
  let language = 'en';
  if (language !== '') {
    let map = new Map();
    if (language === 'en') {
      map.set('search', 'Search');
      map.set('category', 'Categories');
      map.set('article', 'Articles');
      map.set('tag', 'Tags');
      map.set('top', 'Top');
      map.set('publish', 'published');
      map.set('minute', ' minutes');
      map.set('read-more', 'Read More');
      map.set('view', 'View');
      map.set('words', ' words');
      map.set('category-in', 'category in');
      map.set('preview', 'Meta');
      map.set('index', 'Toc');
      map.set('no-archives', "You haven't created yet");
      map.set('archives', " articles in total");
      map.set('cloud-tags', " tags in total");
      map.set('copyright', "Copyright: ");
      map.set('author', "Author: ");
      map.set('link', "Link: ");
      map.set('leave-message', "Leave a message");
      map.set('format', "Links Format");
      map.set('site-name', "Name: ");
      map.set('site-link', "Link: ");
      map.set('site-desc', "Desc: ");
      map.set('stat', " related results, taking ");
      map.set('stat-time', " ms");
      map.set('site-img', "Image: ");
    }

    if (map.size > 0) {
      let lanElems = document.querySelectorAll('.language');
      lanElems.forEach(elem => {
        let lan = elem.dataset.lan, text = map.get(lan);
        if (elem.__proto__ === HTMLInputElement.prototype) {
          elem.placeholder = text
        } else {
          if (elem.dataset.count) {
            text = elem.dataset.count + text;
          }
          elem.textContent = text;
        }
      })
    }
  }

  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })

</script>
<script src="/media/js/motion.js"></script>


  <script
    src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
  <script>
    var scroll = new SmoothScroll('a[href*="#"]', {
      speed: 200
    });
  </script>






</html>