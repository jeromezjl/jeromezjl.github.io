<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://localhost:4000</id>
    <title>Jerome</title>
    <updated>2024-03-27T14:12:45.730Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="http://localhost:4000"/>
    <link rel="self" href="http://localhost:4000/atom.xml"/>
    <subtitle>Jerome&apos;s blog</subtitle>
    <logo>http://localhost:4000/images/avatar.png</logo>
    <icon>http://localhost:4000/favicon.ico</icon>
    <rights>All rights reserved 2024, Jerome</rights>
    <entry>
        <title type="html"><![CDATA[408复试]]></title>
        <id>http://localhost:4000/post/408-fu-shi/</id>
        <link href="http://localhost:4000/post/408-fu-shi/">
        </link>
        <updated>2024-03-27T03:20:45.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/366839763">计算机网络八股文背诵版</a><br>
<a href="https://zhuanlan.zhihu.com/p/373966882">操作系统八股文背诵版</a></p>
<p><a href="https://blog.csdn.net/qq_43468008/article/details/129418769">考研408 王道计算机考研 (初试/复试) 网课笔记总结</a><br>
<a href="https://blog.csdn.net/yinghui_yht/article/details/105443770">计算机考研复试问题汇总（408+计算机前言知识）</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[AIEnglish]]></title>
        <id>http://localhost:4000/post/aienglish/</id>
        <link href="http://localhost:4000/post/aienglish/">
        </link>
        <updated>2024-03-25T04:53:47.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>Artificial General（通用） Intelligence (AGI) represents the hypothetical（假想） ability of an AI system to understand, learn, and apply knowledge across a wide range of tasks at a level of complexity comparable to human intelligence. Unlike narrow AI designed for specific tasks, AGI would possess the versatility and adaptability to perform any intellectual task that a human being can. This includes reasoning, problem-solving, abstract thinking, understanding natural language, and learning from experience. Achieving AGI is considered a monumental milestone in AI research, marking the advent of machines with human-like cognitive abilities.</li>
</ol>
<p>人工通用智能（AGI）代表了一个AI系统的假想能力，即理解、学习并应用知识去完成广泛的任务，这些任务的复杂度与人类智能相当。与为特定任务设计的狭义人工智能不同，AGI将拥有执行人类可以执行的任何智力任务的多功能性和适应性。这包括推理、解决问题、抽象思考、理解自然语言以及从经验中学习。实现AGI被认为是AI研究的一个重要里程碑，标志着具有类似人类认知能力的机器的到来。</p>
<ol start="2">
<li>Supervised learning is a machine learning approach where models are trained on labeled data, meaning each input example is paired with the correct output. The model learns by comparing its predictions to the actual outputs during training, adjusting until it can accurately predict outcomes for unseen data. Unsupervised learning, conversely, involves training models on data without explicit instructions on what to predict. The model identifies patterns and structures within the data autonomously. Supervised learning is typically used for classification and regression tasks, while unsupervised learning is used for clustering, dimensionality reduction, and association rule learning.</li>
</ol>
<p>监督学习是一种机器学习方法，其中模型是在标注数据上训练的，这意味着每个输入实例都与正确的输出配对。模型通过在训练期间将其预测与实际输出进行比较来学习，并调整直到它能够准确预测未见数据的结果。相反，无监督学习涉及在没有关于应预测什么的明确指导的数据上训练模型。模型自主地识别数据中的模式和结构。监督学习通常用于分类和回归任务，而无监督学习用于聚类、降维和关联规则学习。</p>
<ol start="3">
<li>A Multilayer Perception (MLP) is a class of feedforward artificial neural network (ANN) that consists of at least three layers of nodes: an input layer, one or more hidden layers, and an output layer. Each node, except for input nodes, uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its architecture of multiple layers and nonlinear processing enables complex pattern recognition and decision-making, making it foundational to deep learning. Deep learning involves networks with many layers (deep architectures) that can learn hierarchical representations of data, significantly advancing capabilities in AI research and applications.</li>
</ol>
<p>多层感知机（MLP）是一种前馈人工神经网络（ANN），至少包括三层节点：一个输入层、一个或多个隐藏层以及一个输出层。除输入节点外，每个节点都使用非线性激活函数。MLP利用一种称为反向传播的监督学习技术进行训练。它的多层结构和非线性处理使得复杂的模式识别和决策成为可能，是深度学习的基础。深度学习涉及有许多层（深度架构）的网络，这些网络可以学习数据的层次化表示，显著推进了AI研究和应用能力。</p>
<ol start="4">
<li>Backpropagation is a cornerstone algorithm for training neural networks, particularly in deep learning. It operates by propagating the error backward from the output layer to the input layer, allowing the algorithm to adjust the weights of connections in order to minimize the error in predictions. This process involves two key phases: forward pass, where input data is fed through the network to generate output predictions, and backward pass, where the gradient of the loss function is computed with respect to each weight by the chain rule, enabling the network to learn from errors systematically. This iterative adjustment refines the model's accuracy over time.</li>
</ol>
<p>反向传播是训练神经网络，尤其是在深度学习中的基石算法。它通过将错误从输出层反向传播到输入层来运作，允许算法调整连接权重以最小化预测中的错误。这个过程涉及两个关键阶段：前向传播，输入数据通过网络生成输出预测；反向传播，利用链式规则计算损失函数的梯度相对于每个权重，使网络能够系统地从错误中学习。这种迭代调整随着时间提高了模型的准确性。</p>
<ol start="5">
<li>Overfitting is a common problem in machine learning, where a model learns the training data too well, including its noise and outliers, rather than generalizing from the pattern it should learn. This results in high accuracy on training data but poor performance on new, unseen data. Essentially, the model becomes overly complex, capturing spurious correlations that do not exist in real-world data. To combat overfitting, techniques such as cross-validation, regularization, and pruning can be used, along with ensuring a sufficient amount of diverse training data. Overfitting highlights the delicate balance between model complexity and its generalization ability.</li>
</ol>
<p>过拟合是机器学习中的一个常见问题，其中模型过于完美地学习了训练数据，包括其噪音和异常值，而不是从它应该学习的模式中泛化。这导致在训练数据上的高准确度但在新的、未见过的数据上的性能差。本质上，模型变得过于复杂，捕捉到了在现实世界数据中不存在的假相关性。为了对抗过拟合，可以使用交叉验证、正则化和剪枝等技术，同时确保有足够数量的多样化训练数据。过拟合突出了模型复杂度和其泛化能力之间微妙的平衡。</p>
<ol start="6">
<li>A Convolutional Neural Network (CNN) is a class of deep learning algorithm that can take in an input image, assign importance (learnable weights and biases) to various aspects or objects in the image, and differentiate from one another. The preprocessing required in a CNN is much lower compared to other classification algorithms. The architecture of a CNN is analogous to that of the connectivity pattern of neurons in the human brain and was inspired by the organization of the visual cortex. CNNs are primarily used in image recognition, image classification, object detection, and similar tasks, leveraging their ability to learn spatial hierarchies of features.</li>
</ol>
<p>卷积神经网络（CNN）是一种深度学习算法，可以接受输入图像，为图像中的不同方面或对象分配重要性（可学习的权重和偏差），并且彼此区分开来。与其他分类算法相比，CNN所需的预处理要少得多。CNN的架构类似于人脑神经元的连接模式，并且受到视觉皮层组织的启发。CNN主要用于图像识别、图像分类、对象检测以及类似任务，利用它们学习特征的空间层次结构的能力。</p>
<ol start="7">
<li>Deep Reinforcement Learning (DRL) combines deep learning and reinforcement learning principles to create systems that can learn to make decisions. Deep learning processes vast amounts of data through neural networks, enabling feature detection and recognition. Reinforcement learning, on the other hand, is about agents learning to make actions in an environment to achieve a goal, guided by rewards or penalties. DRL utilizes deep neural networks to interpret complex, high-dimensional inputs, allowing the agent to learn optimal actions from its experiences, without explicit programming. This approach has led to significant breakthroughs, such as mastering complex games and improving decision-making in robotics and autonomous vehicles.**</li>
</ol>
<p>深度强化学习（DRL）结合了深度学习和强化学习原理，创造了能够学习做出决策的系统。深度学习通过神经网络处理大量数据，使特征检测和识别成为可能。另一方面，强化学习是关于代理在环境中学习采取行动以实现目标，由奖励或惩罚指导。DRL利用深度神经网络来解释复杂的、高维输入，允许代理从经验中学习最优行动，无需显式编程。这种方法已经在如掌握复杂游戏和改善机器人与自动驾驶车辆的决策制定方面取得了重大突破。</p>
<ol start="8">
<li>In deep learning, activation functions are crucial for neural networks to learn complex patterns. They introduce non-linearity into the network, allowing it to model complicated relationships between inputs and outputs that linear equations cannot. Without activation functions, a neural network, regardless of its depth, would behave like a single-layer perceptron, only capable of solving linear problems. Activation functions, such as Sigmoid, ReLU, and Tanh, help decide whether a neuron should be activated or not, determining the output of neural networks based on input features. This enables deep learning models to tackle non-linear problems, like image recognition and natural language processing, effectively.**</li>
</ol>
<p>在深度学习中，激活函数对于神经网络学习复杂模式至关重要。它们为网络引入非线性，使其能够模拟输入与输出之间的复杂关系，而这是线性方程无法做到的。没有激活函数，无论神经网络的深度如何，都会表现得像一个只能解决线性问题的单层感知机。激活函数，如Sigmoid、ReLU和Tanh，帮助决定一个神经元是否应该被激活，决定了神经网络基于输入特征的输出。这使得深度学习模型能够有效地处理非线性问题，如图像识别和自然语言处理。</p>
<ol start="9">
<li>A generative model in artificial intelligence is an approach used to automatically generate new data instances that resemble a given set of data. Unlike discriminative models, which focus on determining the boundary between different classes, generative models learn the underlying distribution of input data, enabling them to produce new examples that could plausibly come from the original dataset. This ability makes generative models especially valuable in tasks such as image and text generation, data augmentation, and unsupervised learning. Popular examples of generative models include Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), which have been applied in creating realistic images, text-to-image synthesis, and more.</li>
</ol>
<p>在人工智能中，生成模型是一种用于自动生成类似于给定数据集的新数据实例的方法。与专注于确定不同类别之间边界的判别模型不同，生成模型学习输入数据的底层分布，使它们能够生成可能来自原始数据集的新例子。这种能力使得生成模型在图像和文本生成、数据增强和无监督学习等任务中特别有价值。流行的生成模型例子包括生成对抗网络（GANs）和变分自编码器（VAEs），这些已被应用于创造逼真的图像、文本到图像的合成等。</p>
<ol start="10">
<li>Transformer is a groundbreaking architecture in deep learning, introduced for dealing with sequential data, notably in natural language processing (NLP). Unlike its predecessors that relied on recurrence or convolutions, the transformer utilizes attention mechanisms to weigh the significance of different words within the input data. This allows it to capture complex dependencies and relationships within the data more effectively. The architecture comprises an encoder to process the input and a decoder for output generation. Transformers have led to significant advancements in tasks such as machine translation, text summarization, and language understanding, serving as the foundation for models like BERT and GPT.</li>
</ol>
<p>Transformer 是深度学习中的一种开创性架构，专门用于处理顺序数据，特别是在自然语言处理（NLP）中。与依赖于递归或卷积的前身不同，Transformer 利用注意力机制来权衡输入数据中不同单词的重要性。这使它能够更有效地捕捉数据内的复杂依赖关系。该架构包括一个编码器来处理输入和一个解码器来生成输出。Transformer 在机器翻译、文本摘要和语言理解等任务上取得了重大进展，为像BERT和GPT这样的模型提供了基础。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[复试项目]]></title>
        <id>http://localhost:4000/post/fu-shi-xiang-mu/</id>
        <link href="http://localhost:4000/post/fu-shi-xiang-mu/">
        </link>
        <updated>2024-03-23T13:15:13.000Z</updated>
        <content type="html"><![CDATA[<h1 id="gan">GAN</h1>
<p>使用 CIFAR-10 数据集，包含动物和交通工具的图片<br>
生成器和判别器都使用 CNN<br>
生成器：四层卷积，中间用 ReLU，最后用 Tanh<br>
判别器：四层卷积，中间用 ReLU，最后用 Sigmoid<br>
使用交叉熵损失函数<br>
先训练判别器，给判别器真实图片和假图片，分别带有标签，来更新判别器参数<br>
再训练生成器，让生成器生成图片，让判别器判断，更新生成器的参数，使判别器认为生成的是真实图片</p>
<h1 id="cnn-人脸识别">CNN 人脸识别</h1>
<p>首先进行三分类，小组同学三人，每人录制一个全方位的不同角度的面部视频，<br>
使用openCV对视频进行分割，获得3000张左右不同角度、不同光照的人脸图片<br>
CNN：使用alexnet架构，5层卷积，3层最大池化，使用 ReLU 激活，最后 softmax</p>
<h1 id="手写数字">手写数字</h1>
<p>LeNet-5<br>
<img src="http://localhost:4000/post-images/1710506415759.png" alt="" loading="lazy"><br>
使用MNIST：28x28，第一层 padding=2，输入网络是 32x32</p>
<ol>
<li>
<p><strong>输入层（Input Layer）</strong>：接受的输入图像大小通常是32x32像素。这是因为网络设计时考虑到数字的实际大小和希望网络能够捕捉到重要的特征。</p>
</li>
<li>
<p><strong>第一卷积层（C1）</strong>：这一层使用6个卷积核（或滤波器），每个大小为5x5，步长为1，无填充（padding），输出的特征图（feature map）大小为28x28x6。</p>
</li>
<li>
<p><strong>第一下采样层（S2）</strong>：也称为池化层，使用2x2的窗口进行平均池化，步长为2，将特征图的维度降低到14x14x6。这一步骤有助于减少数据的空间尺寸，从而减少计算量和控制过拟合。</p>
</li>
<li>
<p><strong>第二卷积层（C3）</strong>：这一层有16个卷积核，每个大小为5x5，处理上一层的输出，产生10x10x16的特征图。这一层的设计允许网络学习更高级的特征。</p>
</li>
<li>
<p><strong>第二下采样层（S4）</strong>：同样采用2x2平均池化，步长为2，输出的维度为5x5x16。</p>
</li>
<li>
<p><strong>全连接层（F5）</strong>：这一层有120个节点，它将前一层的输出展平（flatten）并全连接到这120个节点上。这一层开始将学到的特征组合成更高级别的模式。</p>
</li>
<li>
<p><strong>第二全连接层（F6）</strong>：这一层有84个节点，进一步处理特征，为最终的分类决策做准备。</p>
</li>
<li>
<p><strong>输出层（Output Layer）</strong>：最后是一个具有10个节点的输出层，对应于10个数字类（0到9）。这一层通常使用softmax激活函数，将网络的输出转换为概率分布。</p>
</li>
</ol>
<p>两层卷积两层池化，卷积池化之间使用 Sigmoid 激活，最后使用全连接层映射到 10 个分类</p>
<h1 id="光度立体法">光度立体法</h1>
<p>对要检测物体在不同方向的光照条件下进行多次拍照。每次改变的只有光源的位置，确保光源的强度和颜色保持一致。<br>
结合不同光照下的像素亮度值，使用最小二乘法计算每个像素点处的表面法向量。用法向量重构三维物体</p>
<h1 id="sift和词袋模型">SIFT和词袋模型</h1>
<p>使用 15-Scene 数据集，包含 15 种不同类型的场景，例如办公室、厨房、卧室、客厅、乡村、海滩等。<br>
共4400张左右，7比3的比例来划分训练集和测试集</p>
<p>原理<br>
SIFT对每张图片生成不同个数的特征描述向量，将这些向量输入kmeans中，聚为300类，即构建了大小为300的视觉词汇表<br>
使用bow对图像编码：<br>
对于每张图像，将其SIFT特征向量与视觉词汇表中的词汇进行比较，找出每个特征向量最接近的视觉词。然后，为每张图像创建一个长度为k的向量（即BoW向量），其中每个元素记录了对应视觉词在该图像中出现的频率。<br>
将图向量输入 svm，一对多将图片分为15类</p>
<h1 id="roberta-问答系统">RoBERTa 问答系统</h1>
<p>SQuAD 数据集是斯坦福大学开发的一个流行的问答数据集，广泛用于自然语言处理中的机器阅读理解研究。SQuAD挑战模型根据给定的段落文本来回答问题。这些段落来自维基百科的文章，问题则是由人工撰写的。SQuAD的目标是推进计算机对自然语言的理解，特别是在问答系统的开发上。</p>
<p>使用transformer中预训练的 RoBERTa</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[八股文]]></title>
        <id>http://localhost:4000/post/ba-gu-wen/</id>
        <link href="http://localhost:4000/post/ba-gu-wen/">
        </link>
        <updated>2024-03-23T11:07:26.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/366839763">计算机网络八股文背诵版</a><br>
<a href="https://zhuanlan.zhihu.com/p/373966882">操作系统八股文背诵版</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【DL】图神经网络]]></title>
        <id>http://localhost:4000/post/dl-tu-shen-jing-wang-luo/</id>
        <link href="http://localhost:4000/post/dl-tu-shen-jing-wang-luo/">
        </link>
        <updated>2024-03-22T09:53:55.000Z</updated>
        <content type="html"><![CDATA[<p>图神经网络（Graph Neural Networks，GNNs）是一类专门处理图结构数据的神经网络。在图结构数据中，数据以图的形式表示，由节点（nodes）和边（edges）组成，非常适合描述物体（或实体）及其间的复杂关系。图神经网络通过直接在图上进行操作，能够有效地捕捉这种结构信息，因此在社交网络分析、推荐系统、蛋白质结构预测、化学分子建模等领域得到了广泛应用。</p>
<h3 id="核心思想">核心思想</h3>
<p>GNN的核心思想是节点表示的更新，这通过聚合来自邻居节点的信息来实现。每个节点的表示都是通过考虑其邻居节点的特征（以及可能的边的特征）进行更新的，这个过程可以迭代进行，直到达到一个稳定状态或者预定的迭代次数。这种信息的聚合方式使得每个节点能够捕捉到其在图中的局部结构信息。</p>
<h3 id="关键组件">关键组件</h3>
<ol>
<li><strong>节点表示</strong>：GNN的起点是节点的特征表示，这可以是节点的初始属性，也可以是节点的嵌入向量。</li>
<li><strong>聚合函数</strong>：用于聚合邻居节点信息的函数，这一步是GNN的核心。不同的GNN变体（如GCN、GAT等）在聚合函数的选择和设计上有所不同。</li>
<li><strong>更新函数</strong>：用于更新节点表示的函数。在每一次迭代中，节点的表示都会根据聚合的邻居信息进行更新。</li>
</ol>
<h3 id="gnn的变体">GNN的变体</h3>
<p>GNN有多种变体，主要包括：</p>
<ul>
<li><strong>图卷积网络（Graph Convolutional Networks, GCNs）</strong>：通过将卷积的概念推广到图上，对节点的特征进行聚合，从而更新节点的状态。</li>
<li><strong>图注意力网络（Graph Attention Networks, GATs）</strong>：引入了注意力机制来动态地确定在聚合邻居节点信息时每个邻居的重要性。</li>
<li><strong>图自编码器（Graph Autoencoders, GAEs）</strong>：用于学习图数据的低维表示，通常用于无监督学习任务。</li>
<li><strong>图生成网络（Graph Generative Networks, GGNs）</strong>：能够生成新的图结构数据，用于药物设计、蛋白质设计等领域。</li>
</ul>
<h3 id="应用">应用</h3>
<p>GNN在多个领域都有广泛应用，例如：</p>
<ul>
<li><strong>社交网络分析</strong>：通过分析社交网络中个体的关系图，进行好友推荐、信息传播分析等。</li>
<li><strong>推荐系统</strong>：利用用户和物品之间的复杂关系进行更精准的推荐。</li>
<li><strong>生物信息学</strong>：在蛋白质结构预测、基因表达数据分析等领域有着重要应用。</li>
<li><strong>化学和材料科学</strong>：用于预测分子的性质、设计新的化合物等。</li>
</ul>
<p>GNN由于能够直接在图结构数据上操作，捕捉复杂的关系和依赖，因此在处理此类数据时比传统的神经网络模型有着明显的优势。随着研究的深入和技术的发展，GNN在更多领域的应用也在不断拓展。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[复试]]></title>
        <id>http://localhost:4000/post/ai-mian-shi/</id>
        <link href="http://localhost:4000/post/ai-mian-shi/">
        </link>
        <updated>2024-03-21T06:09:17.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>
<p>请简要解释分类和回归的区别。<br>
分类输出离散的类别，回归输出连续的值</p>
</li>
<li>
<p>您能列举一些常用的分类算法吗？请简要说明它们的工作原理。<br>
逻辑回归、决策树、随机森林、SVM、KNN、朴素贝叶斯、梯度提升决策树 (Gradient Boosted Decision Trees, GBDT)、CNN等</p>
</li>
<li>
<p>同样地，您能列举一些常用的回归算法吗？请简要说明它们的工作原理。<br>
线性回归、岭回归、SVM、KNN、SGD、贝叶斯、高斯过程</p>
</li>
<li>
<p>既可以用于分类又可以回归的算法？<br>
决策树、随机森林、SVM、KNN、梯度提升决策树 (Gradient Boosted Decision Trees, GBDT)、CNN等</p>
</li>
<li>
<p>在分类问题中，如何评估模型的性能？您能解释准确率、召回率、F1分数等指标吗？</p>
</li>
<li>
<p>在回归问题中，如何评估模型的性能？您能解释均方误差、均方根误差、决定系数等指标吗？</p>
</li>
<li>
<p>过拟合和欠拟合是什么？如何避免这两种情况？</p>
</li>
<li>
<p>在分类或回归任务中，如何处理不平衡数据集？<br>
处理不平衡数据集是机器学习中的一个常见问题，特别是在分类任务中。不平衡数据集指的是数据集中不同类别的样本数量差异很大。这可能会导致模型对多数类别过拟合，而忽略少数类别。以下是一些常用的方法来处理不平衡数据集：</p>
</li>
</ol>
<h3 id="1-重新采样技术">1. <strong>重新采样技术</strong>:</h3>
<ul>
<li><strong>过采样少数类</strong>: 通过复制少数类样本或通过生成类似样本的方法（如SMOTE - 合成少数过采样技术）来增加少数类样本的数量。</li>
<li><strong>欠采样多数类</strong>: 减少多数类样本的数量，以使多数类和少数类的样本数量大致相同。这可能导致信息丢失，应谨慎使用。</li>
</ul>
<h3 id="2-修改损失函数">2. <strong>修改损失函数</strong>:</h3>
<ul>
<li>为不同类别的样本引入不同的权重，使得模型在训练过程中更加关注少数类。这可以通过修改损失函数来实现，使得少数类样本的错误分类的代价更高。</li>
</ul>
<h3 id="3-使用集成方法">3. <strong>使用集成方法</strong>:</h3>
<ul>
<li>使用如随机森林、梯度提升树（GBT）等集成学习方法可以部分缓解不平衡数据带来的问题，因为它们通过构建多个模型并结合它们的预测结果来提高性能。</li>
</ul>
<h3 id="4-选择合适的评估指标">4. <strong>选择合适的评估指标</strong>:</h3>
<ul>
<li>在不平衡数据集上，准确度不再是一个好的性能指标。应该使用混淆矩阵、精确度、召回率、F1分数、ROC-AUC曲线等更复杂的指标来评估模型性能。</li>
</ul>
<h3 id="5-人工合成数据生成">5. <strong>人工合成数据生成</strong>:</h3>
<ul>
<li>使用算法如SMOTE（合成少数过采样技术）或ADASYN（自适应合成采样方法）等来合成新的少数类样本，以解决不平衡问题。</li>
</ul>
<h3 id="6-使用专门针对不平衡数据设计的算法">6. <strong>使用专门针对不平衡数据设计的算法</strong>:</h3>
<ul>
<li>一些算法如代价敏感学习（Cost-sensitive Learning）和异常检测算法在设计时考虑了不平衡数据的特点，可以直接应用于这类问题。</li>
</ul>
<h3 id="7-数据层面的策略">7. <strong>数据层面的策略</strong>:</h3>
<ul>
<li>收集更多数据，尤其是少数类的数据，有助于减少数据不平衡的问题，虽然这在实际中并不总是可行的。</li>
</ul>
<p>选择哪种方法取决于具体问题、数据集的特性以及可用资源。在实践中，经常需要尝试多种方法，并结合问题的具体情况来确定最有效的策略。</p>
<ol start="5">
<li>
<p>请解释特征选择和特征工程的重要性。</p>
</li>
<li>
<p>在机器学习中，如何处理缺失数据和异常值？<br>
请您根据自己的理解和经验回答这些问题，谢谢！</p>
</li>
<li>
<p>人工智能与大数据的区别和联系<br>
AI：通过各种算法和技术实现机器模拟人类智能<br>
大数据：从大量的数据中提取有价值的信息，它包括数据采集、存储、管理和分析的技术，可以用传统机器学习算法进行处理。大量数据也可以被应用于模型的训练，实现AI</p>
</li>
</ol>
<h1 id="数据结构">数据结构</h1>
<h1 id="计网">计网</h1>
<p>五层结构：物理层、数据链路层、网络层、传输层、应用层</p>
<h2 id="物理层">物理层</h2>
<p>电路交换：使用直通的物理线路，传输快，但无法并行<br>
报文交换：端到端中间需要中转时使用，可以并行，适合突发通信<br>
分组交换：将报文分组传输，可以并行，适合突发通信</p>
<p>码间串扰：高频分量在传输过程中衰减，无法正确识别码元<br>
奈氏准则：码元在信道传输要小于一定速率，否则会码间串扰<br>
香农定理：只要传输速率低于信道的容量，理论上就可以做到无误差地传输信息</p>
<h2 id="数据链路层">数据链路层</h2>
<p>数据帧是数据链路层的基本传输单位，帧 = 帧首部 + IP数据报 + 帧尾部<br>
链路层检错编码：奇偶校验码、循环冗余码 CRC<br>
链路层纠错编码：海明码</p>
<p>为什么流量控制？发送较快、接收较慢，造成传输错误；<br>
流量控制方法：停等协议（发一帧就等对方确认信号）、后退N帧协议（只要有没确认的帧就都重传）、选择重传协议（只重传没确认的帧）</p>
<p>介质访问控制：采用一些措施，使得两对结点之间的通信不会互相干扰；<br>
多路复用：将多个信号放在一条物理信道传输，共享信道资源<br>
频分多路复用：分为不同频段<br>
时分多路复用：分为不同时段<br>
波分多路复用：分为不同波长<br>
码分多路复用：分为不同码序</p>
<p>CSMA：“先听再说”发现信道空闲时再发送数据</p>
<p>局域网：某一区域内 由多台计算机互联成的计算机组，使用 广播信道 ；<br>
广域网：覆盖范围广<br>
交换机只能单个网络内交换分组；<br>
路由器可以多个网络之间交换分组；<br>
局域网强调数据传输，广域网强调数据共享；</p>
<h2 id="网络层">网络层</h2>
<p>网络地址转换NAT：将私网IP映射为公网IP<br>
MAC地址（Media Access Control address）：物理地址（硬件地址）<br>
ARP协议：IP到MAC的映射<br>
DHCP：动态主机配置协议：使服务器（路由器、交换机等）自动向客户端分配IP地址和其他网络配置参数。这些参数包括子网掩码、默认网关、DNS服务器地址等<br>
ICMP：差错报告</p>
<p>路由算法：选择最短、最佳路径；监测拥塞；提高安全性</p>
<p>静态路由、动态路由、距离向量路由算法、链路状态路由算法、路径向量路由算法</p>
<h2 id="传输层">传输层</h2>
<p>IP地址 来区分主机，端口号 来区分进程。<br>
将 IP地址 + 端口号 就构成 套接字（socket），用来唯一地标识网络中的一台主机及其上的一个应用进程；</p>
<p>传输协议：<br>
UDP：不需建立连接，不保证可靠性，传输速度快，无流量控制和拥塞控制<br>
TCP：需三次握手建立连接，可靠，传输慢，有流量控制和拥塞控制</p>
<p>三次握手：</p>
<ol>
<li>发送端发送空的请求报文</li>
<li>接收端收到后返回确认报文，允许连接</li>
<li>发送端发送确认报文，并可携带数据</li>
</ol>
<p>释放连接：</p>
<ol>
<li>客户端发送释放报文</li>
<li>服务器发送确认报文，并发送最后的数据</li>
<li>客户端发送确认报文</li>
</ol>
<p>超时重传：长时间未收到确认则重传</p>
<p>采用滑动窗口机制进行流量控制，发送窗口 = Min {接收窗口，拥塞窗口}；</p>
<p>拥塞控制：慢开始、拥塞避免、快重传、快恢复</p>
<h2 id="应用层">应用层</h2>
<p>P2P：每个主机既是客户机也是服务器，可扩展性强</p>
<p>DNS 域名系统：使用 53 号端口，将域名如 baidu.com 解析为 IP 地址<br>
先查询本地域名服务器，若没有再查询更高层的域名服务器</p>
<p>文件传输协议 FTP：使用两个并行的 TCP 链接传输文件<br>
电子邮件 SMTP 协议：也是基于 TCP 的<br>
超文本传输协议 HTTP：定义了浏览器怎样向万维网服务器（www）请求万维网文档，以及万维网服务器怎样将文档传回浏览器<br>
cookie：一些万维网站点希望可以识别用户主机，使用cookie记录用户一段时间内的访问记录。cookie是服务器产生的、储存在用户主机中的文本文件</p>
<h1 id="os">OS</h1>
<p>​操作系统是一组 控制和管理 计算机软硬件资源，合理地 组织 多道程序的运行，方便 用户使用的程序的集合</p>
<p>操作系统的基本特征：并发、共享、虚拟、异步</p>
<p>并发：在同一段时间间隔发生<br>
并行：在同时刻发生</p>
<p>内核态：特权指令<br>
用户态：用户指令</p>
<p>进程是动态的，具有并发性和独立性，存在形式是进程实体（PCB + 程序段 + 数据段）；程序是静态的<br>
三种状态：运行态、就绪态、阻塞态<br>
三种通信方式：共享储存、消息传递（将通信信息放在消息中）、管道通信</p>
<p>进程与线程<br>
进程：资源分配的基本单位；进程内的线程共享进程分配的资源<br>
线程：并发调度的基本单位<br>
同一进程内切换线程不需要切换环境，系统开销小<br>
调度：外存→内存→CPU</p>
<p>​ 一次仅允许一个进程使用的资源称为 临界资源；<br>
​ 对于 临界资源 的访问，必须是 互斥 进行的；每个进程中，访问临界资源的那段代码成为 临界区；<br>
信号量：将系统资源抽象为变量<br>
管程：封装了信号量（系统资源）和相关P/V操作，可以使用管城解决生产者-消费者问题</p>
<p>死锁：两个以上的进程互相等待对方的资源，导致各进程都阻塞。(资源永远不会释放)<br>
解决：银行家算法：先判断是否会死锁，再决定是否分配资源。</p>
<h1 id="计组">计组</h1>
<p>计算机的工作流程<br>
​ 1、把程序和数据装入主存储器（内存）；<br>
​ 2、将源程序转换成可执行文件；<br>
​ 3、从可执行文件的首地址开始逐条执行指令；</p>
<p>主存 - 辅存 结构解决 容量 问题；<br>
缓存 - 主存 结构解决 速度 问题；<br>
​主存和CPU两者的速度存在不匹配问题，故使用 cache缓存 进行解决</p>
<p>CPU ↔ cache ↔ 主存 ↔ 辅存<br>
cache：CPU缓存，集成在 CPU 芯片中的高速存储器<br>
主存：也叫内存，随机存取存储器（RAM）允许数据的快速读写操作，但断电后其中的信息会丢失<br>
辅存：硬盘驱动器、固态驱动器，断电不消失<br>
DRAM：刷新 SRAM：不刷新</p>
<p>RAM：读写<br>
ROM：只读</p>
<p>cache替换算法：随机替换、先进先出、近期使用最少、最近不经常使用</p>
<p>常见寻址算法：直接、间接、寄存器、隐含、基址、变址</p>
<p>CPU组成：运算器 (ALU) + 控制器 (CU) + 寄存器 + 中断系统<br>
CPU功能：指令控制、操作控制、时间控制、数据加工、中断处理</p>
<p>总线：数据总线、地址总线、控制总线</p>
<p>中断请求</p>
<ol>
<li>发出中断信号</li>
<li>响应中断，并设置中断屏蔽，不再响应其他中断请求</li>
<li>保存中断点</li>
<li>识别中断，进入中断服务程序</li>
<li>中断程序结束，恢复CPU</li>
</ol>
<p>DMA：硬件中断</p>
<h1 id="线性代数">线性代数</h1>
<h2 id="矩阵的几何意义">矩阵的几何意义</h2>
<p>表示对矩阵空间中向量的线性变换，定义了一个将输入向量映射到输出向量的规则</p>
<ol>
<li><strong>线性变换矩阵</strong>：
<ul>
<li><strong>二维或三维空间中的变换</strong>：一个 (2 \times 2) 或 (3 \times 3) 矩阵可以表示平面或空间中的线性变换，如旋转、缩放、剪切、反射等。矩阵的列通常表示变换后基向量的方向和长度。</li>
<li><strong>更高维空间</strong>：在更高维的空间中，矩阵表示的线性变换更加复杂，但基本思想是相似的：矩阵定义了一个将输入向量映射到输出向量的规则。</li>
</ul>
</li>
<li><strong>基变换矩阵</strong>：
<ul>
<li><strong>坐标变换</strong>：当我们从一个坐标系统转换到另一个坐标系统时，基向量发生了变化。基变换矩阵描述了如何从旧坐标系统中的向量计算出新坐标系统中的向量。</li>
</ul>
</li>
<li><strong>投影矩阵</strong>：
<ul>
<li><strong>子空间投影</strong>：一个投影矩阵可以将一个向量投影到向量空间的一个子空间上。这在机器学习和数据分析中非常有用，用于降维或特征提取。</li>
</ul>
</li>
<li><strong>逆矩阵</strong>：
<ul>
<li><strong>逆变换</strong>：一个矩阵的逆矩阵表示了该矩阵所定义的线性变换的逆。在几何上，这相当于将原始变换的效果“撤销”。</li>
</ul>
</li>
<li><strong>对称矩阵</strong>：
<ul>
<li><strong>二次型</strong>：一个对称矩阵可以表示一个二次型，它在几何上对应于一个椭圆、双曲线或超椭圆的表面。</li>
</ul>
</li>
<li><strong>正交矩阵</strong>：
<ul>
<li><strong>标准正交基</strong>：正交矩阵的列组成一个标准正交基，这意味着它们是两两正交且长度为1的向量。在几何上，正交矩阵表示旋转或反射，同时保持向量的长度不变。</li>
</ul>
</li>
<li><strong>对角矩阵</strong>：
<ul>
<li><strong>对角化</strong>：对角矩阵表示一个线性变换，该变换在每个基向量上只进行标量乘法。这在几何上意味着每个基向量都被单独拉伸或压缩，而方向不变。</li>
</ul>
</li>
</ol>
<h2 id="n维向量">ｎ维向量</h2>
<p><strong>向量组的定理辨析</strong><br>
梳理思路：从定义 到 方程组 到 方程组的直观理解 到 系数矩阵的秩 的解释</p>
<p>🔺向量组线性相关 ⇔ 至少存在一组非零系数使向量组为 0 ⇔<br>
齐次方程组有非零解 ⇔ 行列式 = 0 ⇔ 未知数数量比方程组多 ⇔<br>
n 维列向量对应 n 个方程组，s 个列向量对应 s 个未知数，s &gt; n  ⇔<br>
系数矩阵为扁长方形则一定相关 ⇔ 有效方程组数量（向量组的秩）小于未知数个数 s（列数）</p>
<p>向量 α 和 β 线性相关，则 β=kα</p>
<p>🔺向量组线性无关 ⇔ 当且仅当 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>k</mi><mn>1</mn></msub><mo>=</mo><msub><mi>k</mi><mn>2</mn></msub><mo>=</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>=</mo><msub><mi>k</mi><mi>s</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">k_1=k_2=...=k_s=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> 向量组 = 0 ⇔<br>
齐次方程组只有零解 ⇔ 若为 nxn 则 行列式 ≠ 0（可逆）⇔ 未知数数量等于方程组<br>
⇔ 向量组的秩（有效方程组数量）等于列数（未知数个数），即列满秩（A 为 m x n 矩阵，则有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mo>≤</mo><mi>r</mi><mo>(</mo><mi>A</mi><mo>)</mo><mo>≤</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo>(</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">0 ≤ r(A) ≤ min(m,n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.78041em;vertical-align:-0.13597em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mopen">(</span><span class="mord mathdefault">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">n</span><span class="mclose">)</span></span></span></span>）⇔ 向量组中至少有一个向量可由其余的向量线性表出</p>
<p>注意，有效方程组只能为扁长形和正方形，不能为竖长，竖长意味着方程组个数大于未知数，则无解</p>
<p><strong>判定向量组线性无关</strong><br>
方程组只有零解 ⇔ 特殊情况：当矩阵为 nxn 时，行列式 ≠ 0 ⇔ 一般情况：矩阵满秩。行向量组线性无关 ⇔ 行满秩；列向量组线性无关 ⇔ 列满秩</p>
<p><strong>相关无关判定</strong><br>
部分组相关 ⇒ 整体组相关<br>
整体组无关 ⇒ 部分组无关</p>
<p>缩短组无关 ⇒ 延伸组无关<br>
延伸组相关 ⇒ 缩短组相关</p>
<p><strong>p68 定理 3.7 理解</strong><br>
相关的多数向量能用少数向量表出（少数向量是基底，多数向量为空间中的很多向量）<br>
无关的少数向量能用多数向量表出（空间中的很多向量通过变换可以求出基底）</p>
<p><strong>向量线性表出相关定理</strong></p>
<ol>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><msub><mi>α</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><msub><mi>α</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>=</mo><msub><mi>x</mi><mi>n</mi></msub><msub><mi>α</mi><mi>n</mi></msub><mo>=</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">x_1α_1+x_2α_2+....=x_nα_n=β</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 有非零解</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>α</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>α</mi><mi>n</mi></msub><mo separator="true">,</mo><mi>β</mi><mo>]</mo></mrow><annotation encoding="application/x-tex">[α_1,α_2,...,α_n,β]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mclose">]</span></span></span></span> 方程组有解，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>(</mo><mi>A</mi><mo>)</mo><mo>=</mo><mi>r</mi><mo>(</mo><mover accent="true"><mi>A</mi><mo stretchy="true">‾</mo></mover><mo>)</mo></mrow><annotation encoding="application/x-tex">r(A)=r(\overline A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.13333em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8833300000000001em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault">A</span></span><span style="top:-3.80333em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li>高维可以表示低维：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>α</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>α</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">α_1,α_2,...,α_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 可由 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>β</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">β_1,β_2,...,β_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表出，则 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>(</mo><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>α</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>α</mi><mi>t</mi></msub><mo>)</mo><mo>≤</mo><mi>r</mi><mo>(</mo><msub><mi>β</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>β</mi><mi>t</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">r(α_1,α_2,...,α_t) ≤ r(β_1,β_2,...,β_t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li>向量组 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>α</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>α</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">α_1,α_2,...α_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 线性相关 向量组中至少有一个向量可由其余的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">m-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>个向量线性表出</li>
<li>若向量组 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>α</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>α</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">α_1,α_2,...α_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 线性无关，而 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi><mo separator="true">,</mo><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>α</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>α</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">β,α_1,α_2,...α_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 线性相关，则 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">β</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 可由 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>α</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>α</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">α_1,α_2,...α_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 线性表出，并且表示法唯一</li>
</ol>
<p><strong>向量空间</strong></p>
<ol>
<li>基底变换：由基 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mi mathvariant="normal">，</mi><msub><mi>α</mi><mn>2</mn></msub><mi mathvariant="normal">，</mi><msub><mi>α</mi><mn>3</mn></msub><mi mathvariant="normal">到</mi><msub><mi>β</mi><mn>1</mn></msub><mi mathvariant="normal">，</mi><msub><mi>β</mi><mn>2</mn></msub><mi mathvariant="normal">，</mi><msub><mi>β</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">α_1，α_2，α_3 到 β_1，β_2，β_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">到</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><br>
对 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">α</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span> 矩阵 列变换，右乘过渡矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi><mo>=</mo><mi>α</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">β=αC</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span></li>
<li>坐标变换<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mo>=</mo><mi>C</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">x=Cy</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 是在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">α</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span> 下的坐标，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> 是在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">β</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 下的坐标（交叉原则）</li>
</ol>
<h2 id="方程组有解">方程组有解</h2>
<p>非齐次有解充要条件：A 的秩等于 A 增广的秩</p>
<h2 id="特征向量">特征向量</h2>
<p>定义：Aα = λα（α 非零）<br>
一个矩阵点乘一个向量就相当于对该向量进行旋转或者拉伸等一系列线性变换，特征向量在经过矩阵 A 的变换后，不改变方向，等价于由特征值 λ 进行缩放。如果特征值大于1，那么特征向量在变换后变长了；如果特征值小于1，特征向量变短了；如果特征值是负数，特征向量的方向会翻转。</p>
<p>特征向量指示了在进行矩阵变换时，矩阵空间中不变的方向。通过研究特征值和特征向量，可以简化一些矩阵的运算，抓住矩阵空间中的不变信息。</p>
<p><strong>奇异值分解（Singular Value Decomposition，SVD）</strong><br>
特征值和特征向量是对方阵而言，对于非方阵（即行数和列数不相等的矩阵），通常不讨论特征向量和特征值，而是讨论奇异值分解（SVD）中的奇异向量和对角矩阵中的奇异值，这可以看作是特征值和特征向量的推广。奇异值分解是任何矩阵都可以进行的分解，它揭示了矩阵与特征值分解类似的某些性质，如数据压缩和结构简化。</p>
<p>特征值和特征向量可以写为：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>=</mo><mi>P</mi><mi>D</mi><msup><mi>P</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">A = PDP^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>  D为特征值矩阵，P为特征向量矩阵<br>
而奇异值分解定义为：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>=</mo><mi>U</mi><mi mathvariant="normal">Σ</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A = U \Sigma V^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord">Σ</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>，U和V是正交矩阵，它们的列向量都是单位向量，且两两正交，U为 mxn，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">V^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>为 nxm；Σ是一个 n×n 的对角矩阵，对角线上的非零元素称为奇异值，按从大到小的顺序排列，其余位置上的元素都是0。</p>
<p>最大的奇异值对应于数据中最主要的成分或特征，而较小的奇异值则对应于次要的成分。矩阵的秩等于其非零奇异值的数量。</p>
<p>在数据分析和信号处理中，可以通过保留最大的奇异值和对应的奇异向量来近似原始数据矩阵，从而实现数据压缩。这种压缩可以去除噪声和不重要的信息，同时保留数据的主要特征；最小二乘问题，SVD可以用来找到最小范数解；可以用于图像去噪、压缩、特征提取；PCA 中使用</p>
<p><strong>矩阵的迹：tr(A)</strong><br>
迹：主对角线元素之和（不管怎么变化，矩阵的迹不会变），等于矩阵的特征值之和。</p>
<h2 id="几种特殊矩阵">几种特殊矩阵</h2>
<p><strong>单位矩阵</strong><br>
对角线都是1，其余都是0</p>
<p><strong>实对称矩阵（对称矩阵）</strong><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>=</mo><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A=A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><br>
n 阶实对称矩阵必可以相似对角化</p>
<p><strong>反对称矩阵</strong><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>=</mo><mo>−</mo><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A=-A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.924661em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><br>
对角线元素一定为 0</p>
<p><strong>逆矩阵</strong><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>P</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>P</mi><mo>=</mo><mi>E</mi></mrow><annotation encoding="application/x-tex">P^{-1}P = E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span></p>
<p><strong>正交矩阵</strong><br>
转置等于其逆的矩阵<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup><mi>A</mi><mo>=</mo><mi>E</mi></mrow><annotation encoding="application/x-tex">A^TA=E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span><br>
矩阵的行向量和列向量都是单位向量，且两两正交。</p>
<p><strong>正定矩阵</strong><br>
对于任意非零向量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>，都有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>T</mi></msup><mi>A</mi><mi>x</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x^TAx&gt;0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.880431em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault">A</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>，则 A 正定<br>
性质：特征值全&gt;0；顺序主子式全&gt;0</p>
<h2 id="矩阵关系">矩阵关系</h2>
<p><strong>判断是否可以相似于对角矩阵</strong><br>
充要条件只需记“n 个特征值对应 n 个线性无关的特征向量”<br>
注意，任何矩阵，不同特征值对应的特征向量线性无关（相同特征值不一定）</p>
<ol>
<li>有 n 个不同的特征值</li>
<li>k 重特征值对应 k 个线性无关的特征向量</li>
<li>实对称矩阵一定可相似对角化。因为实对称不同特征值特征向量必正交，同一特征值的不同特征向量线性无关（但不一定正交），即 n 个特征值对应 n 个线性无关的特征向量</li>
</ol>
<p><strong>矩阵等价 &amp; 向量组等价</strong><br>
矩阵等价：A 经过有限次初等变换可以变成 B ⇔ r(A)=r(B)<br>
向量组等价：两个向量组可以相互线性表出</p>
<p>矩阵等价，其行列向量组都可以不等价；矩阵等价和行列向量组等价无关</p>
<p><strong>矩阵的等价，相似，合同</strong><br>
关系：<br>
（（（相似）合同 ）等价 ）</p>
<p>等价充要条件：存在可逆矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">Q</span></span></span></span> 使得 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>A</mi><mi>Q</mi><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">PAQ=B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">A</span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span><br>
等价性质：r(A)=r(B)<br>
合同充要条件：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>C</mi><mi>T</mi></msup><mi>A</mi><mi>C</mi><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C^TAC=B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span> 可逆<br>
相似充要条件：存在可逆矩阵 P，使 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>P</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>A</mi><mi>P</mi><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">P^{-1}AP = B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span>（AB为方阵）</p>
<h1 id="概率论">概率论</h1>
<h2 id="贝叶斯和全概率">贝叶斯和全概率</h2>
<p>当一个事件可以由几个互不相容的事件导致时，全概率公式用于计算该随机事件发生的总概率<br>
互不相容的事件称为完备事件组，假设互不相容的事件为 Bi，总事件为 A，全概率可以表示为，在 Bi 的条件下 A 发生的概率，乘以 Bi 发生的概率，然后对所有 Bi 求和</p>
<p>贝叶斯公式：<br>
后验概率：总事件发生的条件下，是由单个原因导致的概率<br>
先验概率：与后验相对，没有后验概率就没有先验概率的概念。指的是单独考虑事件 A 发生的概率，而后验概率是，A 已经发生了，但是发现是在某个条件 B 下发生的，求这个概率</p>
<p>贝叶斯公式就是求后验概率的过程，已知总事件发生，但是由多个原因导致的，求是由其中一个原因导致的的概率</p>
<h2 id="分布函数和概率密度">分布函数和概率密度</h2>
<p>分布函数 F(x) 表示的是 x 落在 (-∞，x) 上的概率<br>
分布函数在 [0,1] 之间，趋向于负无穷是 0，趋向正无穷是 1<br>
Fx 是单调不减的函数，右连续</p>
<p>概率密度在负无穷到正无穷的积分为 1，且 f(x) 恒大于零</p>
<p>离散型分布只有分布函数，没有概率密度</p>
<h2 id="常见概率分布">常见概率分布</h2>
<p>0-1 分布（伯努利分布）：投硬币模型，和二项分布的区别是0-1只进行一次实验<br>
二项分布：一件事的结果只有两种取值，进行n次独立重复实验<br>
泊松分布：用于描述在固定时间间隔或空间区域内发生某种事件的次数的概率分布。泊松分布特别适用于事件以恒定的平均速率随机且独立地发生的情况。<br>
几何分布：n 次伯努利试验中，首次成功的概率。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mn>1</mn><mo>−</mo><mi>p</mi><msup><mo>)</mo><mi>k</mi></msup><mi>p</mi></mrow><annotation encoding="application/x-tex">(1-p)^kp</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.099108em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mord mathdefault">p</span></span></span></span><br>
正态分布：下面单独说<br>
均匀分布：随机变量在一个连续的区间内取值，而且在这个区间内的任何一个点取值概率是相等的。<br>
指数分布：适用于描述独立随机事件发生的时间间隔，其中事件以恒定的平均速率发生。例如灯泡使用寿命，具有无记忆性</p>
<h2 id="期望和方差">期望和方差</h2>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mi>X</mi><mo>=</mo><mi>E</mi><mo>(</mo><mi>X</mi><mo>−</mo><mi>E</mi><mi>X</mi><msup><mo>)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">DX = E(X-EX)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mi>X</mi><mo>=</mo><mi>E</mi><msup><mi>X</mi><mn>2</mn></msup><mo>−</mo><mo>(</mo><mi>E</mi><msup><mi>X</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">DX = EX^2-(EX^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><br>
方差反映了数据点与其均值的偏差程度，方差越大，表示数据点之间的差异越大，数据的分散性也就越强。相反，方差越小，表示数据点围绕平均值更加集中，数据的分散性较弱。</p>
<p>协方差反映随机变量XY的相关程度<br>
大于0：正相关；小于0：负相关；等于0：不相关</p>
<p>相关系数：将协方差限制在 -1 到 1 之间，1 表示完全正相关，-1 表示完全负相关，0 表示没有线性相关</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ρ</mi><mo>(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mtext>cov</mtext><mo>(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>)</mo></mrow><mrow><msub><mi>σ</mi><mi>X</mi></msub><msub><mi>σ</mi><mi>Y</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">ρ(X, Y) = \frac{\text{cov}(X, Y)}{\sigma_X \sigma_Y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">ρ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.455305em;vertical-align:-0.44530499999999995em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.22222em;">Y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">cov</span></span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.07847em;">X</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.22222em;">Y</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44530499999999995em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<h2 id="三大分布和假设检验">三大分布和假设检验</h2>
<p><strong>卡方</strong><br>
X服从标准正态，从X1加到Xn的平方和，服从卡方n分布</p>
<p><strong>t-分布</strong><br>
X服从标准正态，Y服从卡方n，X比上根号下n分之Y</p>
<p><strong>F分布</strong><br>
X服从卡方n1，Y服从卡方n2，X比上n1比上Y比n2</p>
<h2 id="假设检验">假设检验</h2>
<p>均用于假设检验</p>
<h2 id="大数定理和中心极限定理">大数定理和中心极限定理</h2>
<p><strong>切比雪夫</strong><br>
切比雪夫不等式给出了随机变量偏离其期望值的概率的一个上界。可以提供一个关于随机变量行为的保守估计。μ是期望，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">σ^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>是方差</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>{</mo><mi mathvariant="normal">∣</mi><mi>X</mi><mo>−</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mo>≥</mo><mi mathvariant="normal">ɛ</mi><mo>}</mo><mo>≤</mo><mfrac><msup><mi>σ</mi><mn>2</mn></msup><msup><mi mathvariant="normal">ɛ</mi><mn>2</mn></msup></mfrac></mrow><annotation encoding="application/x-tex">P\{|X-μ|≥ɛ\}≤\frac{\sigma^2}{ɛ^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">{</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">μ</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ɛ</span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.36292em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01792em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">ɛ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>{</mo><mi mathvariant="normal">∣</mi><mi>X</mi><mo>−</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mo>≤</mo><mi mathvariant="normal">ɛ</mi><mo>}</mo><mo>≥</mo><mn>1</mn><mo>−</mo><mfrac><msup><mi>σ</mi><mn>2</mn></msup><msup><mi mathvariant="normal">ɛ</mi><mn>2</mn></msup></mfrac></mrow><annotation encoding="application/x-tex">P\{|X-μ|≤ɛ\}≥1-\frac{\sigma^2}{ɛ^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">{</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">μ</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ɛ</span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.36292em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01792em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">ɛ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p><strong>大数定律</strong><br>
切比雪夫、辛钦大数定理：<br>
算数平均值（样本均值）依概率收敛于期望</p>
<p>伯努利大数定理：<br>
重复独立的伯努利试验中，试验结果的频率趋近于试验的概率。<br>
也就是说，试验次数趋近于无穷的时候，P(A) 可以拿频率来近似计算</p>
<p><strong>中心极限定理</strong><br>
高斯分布（正态分布）<br>
方差越大，图像越扁平<br>
均值只改变中轴在x轴的位置，均值为0以x=0为轴，均值为1以x=1为轴</p>
<p>大量随机变量的和近似服从正态分布<br>
样本均值为正态分布的均值<br>
样本方差为正态分布的方差<br>
在批量归一化中使用</p>
<h2 id="参数估计">参数估计</h2>
<h3 id="矩估计">矩估计</h3>
<p>一阶原点矩：E(X)<br>
二阶中心矩：D(X)</p>
<h3 id="极大似然">极大似然</h3>
<p>现在发生了的某个事件，似然函数就变成了这个样本的理论概率，而现在的采样结果代表某个事件已经确定发生了，那这个事发生的理论概率应该尽量大 (在这个事件发生的理论概率中最大的那种情况)，才会导致这个事件发生概率最大，所以要用极大似然函数估计。</p>
<p>步骤：</p>
<ol>
<li>样本概率相乘</li>
<li>取对数求导找极值点</li>
<li>极值点处对应的参数值为最大似然估计值</li>
</ol>
<p><strong>无偏性</strong><br>
E(估计值)=真实值</p>
<h1 id="高数">高数</h1>
<p>几何平均：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msqrt><mrow><mi>a</mi><mi>b</mi></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{ab}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.10777999999999999em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.93222em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">a</span><span class="mord mathdefault">b</span></span></span><span style="top:-2.89222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.10777999999999999em;"><span></span></span></span></span></span></span></span></span></p>
<p>算数平均：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>a</mi><mo>+</mo><mi>b</mi></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{a+b}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>调和平均：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mn>2</mn><mi>a</mi><mi>b</mi></mrow><mrow><mi>a</mi><mo>+</mo><mi>b</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{2ab}{a+b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.283439em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">b</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>  <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>2</mn><mrow><mfrac><mn>1</mn><mi>a</mi></mfrac><mo>+</mo><mfrac><mn>1</mn><mi>b</mi></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{\frac{1}{a}+\frac{1}{b}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4869279999999998em;vertical-align:-0.64182em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.59898em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443142857142858em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.64182em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>F1值使用调和平均，调和平均给予较小的值更多的权重（取倒数）使得精确率和召回率能更好的平衡，否则若使用算数平均，较大的值对整体影响较大，无法起到调和的作用</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】Seq2Seq | Beam Search]]></title>
        <id>http://localhost:4000/post/nlp-seq2seq-beamsearch/</id>
        <link href="http://localhost:4000/post/nlp-seq2seq-beamsearch/">
        </link>
        <updated>2024-03-19T12:15:20.000Z</updated>
        <content type="html"><![CDATA[<h1 id="seq2seq">Seq2Seq</h1>
<p><a href="https://www.bilibili.com/video/BV16g411L7FG/?spm_id_from=333.999.0.0&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">62 序列到序列学习（seq2seq）【动手学深度学习v2】</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/194308943">Seq2Seq模型介绍</a><br>
Transformer：Seq2Seq model with attention</p>
<p>encoder-decoder 架构，使用的都是 RNN</p>
<h1 id="beam-search-束搜索">Beam Search 束搜索</h1>
<p>在选择softmax输出时，使用贪心算法（每次选择概率最大值）不一定能达到最优<br>
每次搜索保存k个最好的候选。k=1 是贪心，k=n 是穷举</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【CV】概述]]></title>
        <id>http://localhost:4000/post/cv-gai-shu/</id>
        <link href="http://localhost:4000/post/cv-gai-shu/">
        </link>
        <updated>2024-03-15T11:55:57.000Z</updated>
        <content type="html"><![CDATA[<p>机器视觉算法是计算机视觉领域的关键组成部分，它使计算机能够通过图像和视频数据理解世界。这些算法可以根据它们的功能和用途进行分类。以下是一些常见的分类方式：</p>
<h3 id="1-图像处理算法">1. 图像处理算法</h3>
<ul>
<li><strong>预处理</strong>：包括去噪、对比度增强、颜色空间转换等。</li>
<li><strong>滤波和锐化</strong>：用于改善图像质量或提取特定特征。</li>
<li><strong>边缘检测</strong>：如Sobel、Canny算法，用于检测图像中的边缘。</li>
</ul>
<h3 id="2-特征提取算法">2. 特征提取算法</h3>
<ul>
<li><strong>角点检测</strong>：如Harris角点检测、Shi-Tomasi算法。</li>
<li><strong>兴趣点检测</strong>：如SIFT（尺度不变特征变换）、SURF（加速稳健特征）。</li>
<li><strong>特征描述子</strong>：如ORB（Oriented FAST and Rotated BRIEF）。</li>
</ul>
<h3 id="3-图像分类-image-classification">3. 图像分类 (Image Classification)</h3>
<ul>
<li><strong>任务说明</strong>：将整个图像分配给一个或多个类别。</li>
<li><strong>常用算法</strong>：
<ul>
<li>AlexNet</li>
<li>VGGNet</li>
<li>ResNet</li>
<li>Inception</li>
<li>DenseNet</li>
<li>EfficientNet</li>
<li>转移学习：使用预训练的CNN模型进行微调以适应特定的图像分类任务。</li>
</ul>
</li>
</ul>
<h3 id="4-目标检测与识别-object-detection">4. 目标检测与识别 (Object Detection)</h3>
<ul>
<li><strong>任务说明</strong>：在图像中识别物体的位置，并将每个物体分类。</li>
<li><strong>常用算法</strong>：
<ul>
<li>R-CNN及其变体（Fast R-CNN, Faster R-CNN）</li>
<li>YOLO系列（YOLOv1至YOLOv5）</li>
<li>SSD (Single Shot MultiBox Detector)</li>
<li>RetinaNet</li>
</ul>
</li>
<li><strong>目标识别</strong>：CNN 变体</li>
</ul>
<h3 id="5-图像分割-image-segmentation">5. 图像分割 (Image Segmentation)</h3>
<ul>
<li><strong>任务说明</strong>：将图像分割成多个区域或对象，可以进一步细分为语义分割和实例分割。</li>
<li><strong>常用算法</strong>：
<ul>
<li>FCN (Fully Convolutional Networks)</li>
<li>U-Net</li>
<li>Mask R-CNN（实例分割）</li>
<li>DeepLab系列</li>
<li>PSPNet (Pyramid Scene Parsing Network)</li>
</ul>
</li>
</ul>
<h3 id="6-姿态估计-pose-estimation">6. 姿态估计 (Pose Estimation)</h3>
<ul>
<li><strong>任务说明</strong>：估计图像中人或对象的姿态或关节位置。</li>
<li><strong>常用算法</strong>：
<ul>
<li>OpenPose</li>
<li>AlphaPose</li>
<li>DensePose</li>
<li>PoseNet</li>
</ul>
</li>
</ul>
<h3 id="7-物体跟踪-object-tracking">7. 物体跟踪 (Object Tracking)</h3>
<ul>
<li><strong>任务说明</strong>：在视频序列中跟踪一个或多个对象的运动。</li>
<li><strong>常用算法</strong>：
<ul>
<li>SiamFC (Siamese Fully Convolutional Network)</li>
<li>SORT/Simple Online and Realtime Tracking</li>
</ul>
</li>
</ul>
<h3 id="8-图像生成-image-generation">8. 图像生成 (Image Generation)</h3>
<ul>
<li><strong>任务说明</strong>：从现有的图像或随机噪声生成新图像。</li>
<li><strong>常用算法</strong>：
<ul>
<li>GANs (Generative Adversarial Networks) 及其变体（CGAN, DCGAN, StyleGAN）</li>
<li>VAEs (Variational Autoencoders)</li>
<li>PixelRNN/PixelCNN</li>
</ul>
</li>
</ul>
<h3 id="9-图像恢复-image-restoration">9. 图像恢复 (Image Restoration)</h3>
<ul>
<li><strong>任务说明</strong>：从损坏或降质的图像中恢复出清晰图像。</li>
<li><strong>常用算法</strong>：
<ul>
<li>SRCNN (Super-Resolution Convolutional Neural Network)</li>
<li>VDSR (Very Deep Super-Resolution)</li>
<li>GANs在图像超分辨率方面的应用</li>
<li>Denoising Autoencoders</li>
</ul>
</li>
</ul>
<h3 id="10-3d重建-3d-reconstruction">10. 3D重建 (3D Reconstruction)</h3>
<ul>
<li><strong>任务说明</strong>：从一系列图像中重建出三维场景或对象的结构。</li>
<li><strong>常用算法</strong>：
<ul>
<li>Multi-View Stereo (MVS)</li>
<li>COLMAP</li>
</ul>
</li>
</ul>
<h3 id="11-行为分析-action-analysis">11. 行为分析 (Action Analysis)</h3>
<ul>
<li><strong>任务说明</strong>：分析视频中的人或物体的行为，比如行人的行走路线、人群的动态等。</li>
<li><strong>常用算法</strong>：
<ul>
<li>C3D (Convolutional 3D Networks)</li>
<li>I3D (Inflated 3D ConvNet)</li>
</ul>
</li>
</ul>
<h3 id="12-视觉问答-visual-question-answering">12. 视觉问答 (Visual Question Answering)</h3>
<ul>
<li><strong>任务说明</strong>：根据给定图像和自然语言问题提供答案。</li>
<li><strong>常用算法</strong>：
<ul>
<li>基于注意力机制的模型</li>
<li>LSTM (Long Short-Term Memory) 网络</li>
<li>End-to-End模型</li>
<li>Transformer模型及其在视觉问答中的应用</li>
</ul>
</li>
</ul>
<h3 id="13-优化和机器学习算法">13. 优化和机器学习算法</h3>
<pre><code>- 用于提高识别准确率和效率的算法，如支持向量机（SVM）、随机森林、梯度提升决策树（GBDT）等。
- 
</code></pre>
<p>这些任务和算法展示了机器视觉领域的广泛性和深度，随着研究的进展，还会不断有新</p>
<p>的任务和算法被提出。</p>
<h1 id="数据增强">数据增强</h1>
<p>对图片进行翻转、裁剪、变色（颜色、亮度、饱和度）等操作<br>
<a href="https://www.bilibili.com/video/BV17y4y1g76q/?spm_id_from=333.999.0.0&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">36 数据增广【动手学深度学习v2】</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】文本预处理]]></title>
        <id>http://localhost:4000/post/nlp-wen-ben-yu-chu-li/</id>
        <link href="http://localhost:4000/post/nlp-wen-ben-yu-chu-li/">
        </link>
        <updated>2024-03-15T03:49:11.000Z</updated>
        <content type="html"><![CDATA[<p>数据预处理是自然语言处理（NLP）任务中至关重要的一步，它直接影响到模型训练的效果和最终结果的质量。预处理步骤的目的是将原始文本转换成一种更易于计算机理解和处理的格式。以下是数据预处理中常见的几个步骤：</p>
<ol>
<li>
<p><strong>文本清洗</strong>:<br>
移除无关内容（如HTML标签）、标点符号、数字等，或者将它们转换成有意义的代替文本。</p>
<ul>
<li><strong>去除噪声</strong>：移除文本中的无关信息，如HTML标签、非文本内容（图片链接、JavaScript代码等）、格式符号等。</li>
<li><strong>规范化文本</strong>：将文本统一为标准格式，例如，将所有字母转换为小写（或大写），以减少词汇的变体数量。</li>
<li><strong>去除特殊字符和标点</strong>：根据任务需求，移除或替换文本中的特殊字符和标点符号，有时标点可以保留，因为它可能含有语义信息。</li>
</ul>
</li>
<li>
<p><strong>分词 (Tokenization)</strong>:</p>
<ul>
<li><strong>词级分词</strong>：将句子分割成单词或词汇单元，如短语。这是英文等西方语言中最常见的分词方式。</li>
<li><strong>子词级分词</strong>：将单词进一步分割成更小的单位（如词根、词缀）。这对于处理一些复合词或未见过的词特别有用。</li>
<li><strong>字符级分词</strong>：将文本分割成字符。这种方法对于某些任务或语言（如中文）可能更合适。</li>
</ul>
</li>
<li>
<p><strong>停用词去除</strong>:</p>
<ul>
<li>停用词是指在文本中频繁出现但对于理解文本意义贡献不大的词，如“的”、“是”、“在”等。去除这些词可以帮助减少数据噪声和特征维度。</li>
</ul>
</li>
<li>
<p><strong>词干提取 (Stemming) 和词形还原 (Lemmatization)</strong>:</p>
<ul>
<li><strong>词干提取</strong>：通过去除词缀来将词汇还原到基本形式（可能不是真正的词）。例如，“running”、“runs”词干提取后都变为“run”。</li>
<li><strong>词形还原</strong>：将词汇还原到其词典形式（lemma），考虑了词汇的词性。比如，“better”的词形还原结果是“good”。</li>
</ul>
</li>
<li>
<p><strong>数据增强</strong>:</p>
<ul>
<li>通过词替换、句子重排等方法人为增加训练数据的多样性，有助于改善模型的泛化能力。</li>
</ul>
</li>
<li>
<p><strong>向量化 (Vectorization)</strong>:</p>
<ul>
<li><strong>构建词汇表</strong>：统计词频，小于某个词频的词将不会被加入词汇表</li>
<li><strong>Token 编码</strong>：在构建了词汇表之后，每个唯一的token都会被分配一个唯一的数字ID。向量化的这一阶段涉及将文本中的每个token替换成对应的数字ID。这个过程实际上是一种编码，将文本数据转换为模型可以处理的数值形式。</li>
<li><strong>句子/文本向量化（tokenize）</strong>：完成token的数字编码后，整个句子或文本片段可以表示为一个数字序列。</li>
<li><strong>序列填充 (Padding) 和截断</strong>：对于需要固定长度输入的模型（如很多深度学习模型），需要通过填充（通常用0或特殊标记<code>&lt;PAD&gt;</code> ）或截断来使所有文本序列长度一致。</li>
<li><strong>词袋模型 (Bag of Words, BoW)</strong>：将文本转换为词频向量，但这种方法不考虑词序和上下文。</li>
<li><strong>TF-IDF (Term Frequency-Inverse Document Frequency)</strong>：一种加权的词袋模型，考虑了词在文档集中的稀有程度。</li>
<li><strong>词嵌入 (Word Embeddings)</strong>：将词汇token映射到连续的向量空间中，这些向量捕获了词汇之间的语义关系。常见的词嵌入模型包括Word2Vec、GloVe和BERT等。</li>
</ul>
</li>
</ol>
<p>每个步骤的具体实现和必要性可能会根据具体的任务和语言而有所不同。例如，对于某些任务，保留标点符号可能是有意义的，因为它们可以携带情感或语法信息。而对于一些语言（如中文、日文），分词步骤会比英文复杂得多，可能需要特定的算法和词库。预处理的目的是清洗和转换数据，以提高模型训练的效率和效果。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】概述]]></title>
        <id>http://localhost:4000/post/nlp-gai-shu/</id>
        <link href="http://localhost:4000/post/nlp-gai-shu/">
        </link>
        <updated>2024-03-15T03:19:09.000Z</updated>
        <content type="html"><![CDATA[<h1 id="任务">任务</h1>
<ol>
<li><strong>文本分类（Text Classification）</strong>：将文本数据分类到预定义的类别中。常见的应用包括垃圾邮件检测、情感分析和主题分类。</li>
</ol>
<ul>
<li>朴素贝叶斯（Naive Bayes）</li>
<li>支持向量机（SVM）</li>
<li>随机森林（Random Forest）</li>
<li>卷积神经网络（CNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>Transformer模型（如BERT）</li>
</ul>
<ol start="2">
<li><strong>命名实体识别（Named Entity Recognition, NER）</strong>：识别文本中的命名实体，如人名、地点名、组织名等，并将其分类到预定义的类别。</li>
</ol>
<ul>
<li>条件随机场（CRF）</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）+ CRF</li>
<li>BERT及其变体</li>
</ul>
<ol start="3">
<li><strong>词性标注（Part-of-Speech Tagging, POS Tagging）</strong>：为文本中的每个单词分配一个词性标签，如名词、动词、形容词等。</li>
</ol>
<ul>
<li>隐马尔可夫模型（HMM）</li>
<li>条件随机场（CRF）</li>
<li>循环神经网络（RNN）</li>
<li>Transformer模型（如BERT）</li>
</ul>
<ol start="4">
<li><strong>句法分析（Syntactic Parsing）</strong>：分析句子的语法结构，确定单词之间的依赖关系和句子的语法树结构。</li>
</ol>
<ul>
<li>基于规则的方法</li>
<li>上下文无关文法（CFG）</li>
<li>依存解析（Dependency Parsing）使用神经网络</li>
<li>Transformer模型（如BERT、GPT）</li>
</ul>
<ol start="5">
<li><strong>语义分析（Semantic Analysis）</strong>：理解句子或文本的含义，包括词义消歧和语义角色标注。</li>
</ol>
<ul>
<li>潜在语义分析（LSA）</li>
<li>潜在狄利克雷分配（LDA）</li>
<li>词嵌入方法（如Word2Vec、GloVe）</li>
<li>Transformer模型（如BERT、RoBERTa）</li>
</ul>
<ol start="6">
<li><strong>情感分析（Sentiment Analysis）</strong>：判断文本的情感倾向，如正面、负面或中性。</li>
</ol>
<ul>
<li>朴素贝叶斯（Naive Bayes）</li>
<li>支持向量机（SVM）</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>Transformer模型（如BERT、XLNet）</li>
</ul>
<ol start="7">
<li><strong>文本摘要（Text Summarization）</strong>：生成文本的简短且含义完整的摘要。</li>
</ol>
<ul>
<li>抽取式摘要方法，如TF-IDF</li>
<li>序列到序列模型（Seq2Seq），如LSTM</li>
<li>注意力机制（Attention Mechanism）</li>
<li>预训练语言模型（如GPT-3、BERT）</li>
</ul>
<ol start="8">
<li><strong>机器翻译（Machine Translation）</strong>：将一种语言的文本翻译成另一种语言。</li>
</ol>
<ul>
<li>统计机器翻译（SMT）</li>
<li>序列到序列模型（Seq2Seq）</li>
<li>注意力机制</li>
<li>Transformer架构</li>
</ul>
<ol start="9">
<li><strong>问答系统（Question Answering）</strong>：对自然语言形式的问题给出直接答案。</li>
</ol>
<ul>
<li>信息检索技术</li>
<li>长短期记忆网络（LSTM）</li>
<li>注意力机制</li>
<li>BERT和Transformer模型</li>
</ul>
<ol start="10">
<li><strong>对话系统和聊天机器人（Dialogue Systems and Chatbots）</strong>：构建能够与人类用户进行自然对话的系统。</li>
</ol>
<ul>
<li>序列到序列模型（Seq2Seq）</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>Transformer和GPT系列</li>
</ul>
<ol start="11">
<li><strong>文本生成（Text Generation）</strong>：基于某些输入生成自然语言文本，如新闻文章生成、故事创作等。</li>
</ol>
<ul>
<li>马尔可夫模型</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>GPT系列</li>
</ul>
<ol start="12">
<li><strong>语音识别（Speech Recognition）</strong>：将语音信号转换为文本。</li>
</ol>
<ul>
<li>隐马尔可夫模型（HMM）</li>
<li>深度神经网络（DNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>端到端的深度学习模型</li>
</ul>
<ol start="13">
<li><strong>自然语言理解（Natural Language Understanding, NLU）</strong>：深入理解自然语言的含义和上下文。</li>
</ol>
<ul>
<li>词嵌入（Word Embeddings）</li>
<li>长短期记忆网络（LSTM）</li>
<li>Transformer模型</li>
<li>BERT及其变体</li>
</ul>
<ol start="14">
<li><strong>自然语言生成（Natural Language Generation, NLG）</strong>：从非语言数据生成人类可理解的语言。</li>
</ol>
<ul>
<li>模板方法</li>
<li>序列到序列模型（Seq2Seq）</li>
<li>Transformer模型</li>
<li>GPT系列</li>
</ul>
<ol start="15">
<li><strong>关键词提取（Keyword Extraction）</strong>：从文本中提取最相关的词汇或短语。</li>
</ol>
<ul>
<li>TF-IDF</li>
<li>TextRank</li>
<li>LDA（潜在狄利克雷分配）</li>
<li>BERT Embeddings</li>
</ul>
<ol start="16">
<li><strong>主题建模（Topic Modeling）</strong>：无监督地识别大量文档集中的潜在主题。</li>
</ol>
<ul>
<li>潜在语义分析（LSA）</li>
<li>潜在狄利克雷分配（LDA）</li>
<li>非负矩阵分解（NMF）</li>
</ul>
<p>对于每种任务，选择最合适的算法通常取决于具体的应用场景、可用数据的量和质以及性能要求。随着深度学习技术的发展，基于Transformer的模型如BERT、GPT系列在多个NLP任务中取得了突破性的成果。</p>
<h1 id="算法">算法</h1>
<p>自然语言处理（NLP）领域中有多种算法和技术，这些方法旨在帮助计算机理解、解释和生成人类语言。以下是一些核心的NLP算法和技术：</p>
<ol>
<li>
<p><strong>基于规则的系统</strong>：早期的NLP系统大多依赖于手写的规则来解析和理解文本。这些规则可以基于语法、句法和语义规则来设计。</p>
</li>
<li>
<p><strong>统计方法</strong>：</p>
<ul>
<li><strong>隐马尔可夫模型（HMM）</strong>：用于词性标注和命名实体识别等任务。</li>
<li><strong>条件随机场（CRF）</strong>：用于序列建模，如标注问题和命名实体识别。</li>
</ul>
</li>
<li>
<p><strong>机器学习算法</strong>：随着机器学习的发展，许多传统算法被用于NLP任务，如朴素贝叶斯、决策树、支持向量机（SVM）等。</p>
</li>
<li>
<p><strong>深度学习/神经网络方法</strong>：近年来，深度学习在NLP中取得了重大进展，以下是一些关键的神经网络架构：</p>
<ul>
<li><strong>卷积神经网络（CNNs）</strong>：虽然最初用于图像处理，但也被适用于处理文本数据，如句子分类任务。</li>
<li><strong>循环神经网络（RNNs）</strong>：特别适合处理序列数据，如时间序列或文本。长短期记忆网络（LSTMs）和门控循环单元（GRUs）是RNN的变体，能够解决传统RNNs的梯度消失问题。</li>
<li><strong>注意力机制和Transformer架构</strong>：注意力机制允许模型在处理序列数据时更加灵活地权衡不同部分的重要性，而Transformer架构则彻底改变了NLP领域，成为了多种任务的基础，如BERT、GPT系列、RoBERTa、T5等。</li>
</ul>
</li>
<li>
<p><strong>预训练语言模型</strong>：利用大量无标签文本数据进行预训练，然后在特定任务上进行微调。BERT和GPT系列是这一范式下的两个典型例子。</p>
</li>
<li>
<p><strong>迁移学习和微调</strong>：借助预训练的语言模型，通过在特定任务上的微调，可以显著提高性能。这种方法减少了对大量标记数据的依赖。</p>
</li>
</ol>
<p>这些算法和技术在各种NLP任务中被广泛应用，如文本分类、情感分析、机器翻译、语音识别、问答系统、文本摘要、自然语言生成等。随着研究的不断进展，新的算法和模型也在不断被提出和改进。</p>
<h1 id="nlp-任务的一般过程">NLP 任务的一般过程</h1>
<ol>
<li>
<p><strong>问题定义</strong>:</p>
<ul>
<li>明确任务目标：这可能是文本分类、情感分析、机器翻译、命名实体识别、问答系统等。</li>
<li>确定输入输出：定义任务的输入数据（如文本、句子、段落）和期望的输出（如类别标签、文本响应等）。</li>
</ul>
</li>
<li>
<p><strong>数据收集</strong>:</p>
<ul>
<li>收集足够的数据：根据任务需求，收集标注好的训练数据。对于一些任务，还可能需要收集未标注的数据进行无监督学习或半监督学习。</li>
<li>来源：数据可以来自公共数据集、网络爬虫、社交媒体、公司数据库等。</li>
</ul>
</li>
<li>
<p><strong>数据预处理</strong>:</p>
<ul>
<li>文本清洗：移除无关内容（如HTML标签）、标点符号、数字等，或者将它们转换成有意义的代替文本。</li>
<li>分词：将文本分割成单词、短语或其他有意义的单位。</li>
<li>规范化：包括小写转换、词干提取、词形还原等，旨在将单词规范到基本形式。</li>
<li>去除停用词：移除常见但对于理解文本意义不大的词，如“的”、“是”、“在”等。</li>
<li>向量化：将文本转换为数值形式，常见方法包括词袋模型、TF-IDF、词嵌入等。</li>
</ul>
</li>
<li>
<p><strong>特征工程</strong>:</p>
<ul>
<li>特征提取：根据任务需求，选择或设计文本特征，如n-gram、词频、词嵌入向量等。</li>
<li>降维：对高维特征空间应用降维技术，如PCA、t-SNE，以减少计算复杂度。</li>
</ul>
</li>
<li>
<p><strong>模型选择和训练</strong>:</p>
<ul>
<li>选择模型：根据任务类型选择合适的模型，可能是传统机器学习模型（如SVM、随机森林）或深度学习模型（如CNN、RNN、Transformer）。</li>
<li>训练模型：使用训练数据训练模型，调整超参数以获得最佳性能。</li>
</ul>
</li>
<li>
<p><strong>评估和优化</strong>:</p>
<ul>
<li>使用验证集评估模型性能，采用适当的评估指标（如准确率、召回率、F1分数、BLEU分数等）。</li>
<li>根据评估结果调整模型结构、超参数等，可能包括使用更复杂的模型、增加更多训练数据、应用不同的预处理或特征工程技术。</li>
</ul>
</li>
<li>
<p><strong>部署和监控</strong>:</p>
<ul>
<li>将训练好的模型部署到生产环境，使其能够处理实时数据或新数据。</li>
<li>监控模型性能，定期检查并重新训练模型以适应新数据或变化的数据分布。</li>
</ul>
</li>
<li>
<p><strong>反馈循环</strong>:</p>
<ul>
<li>根据模型在实际应用中的表现，收集反馈，可能需要重新执行前面的步骤，如重新定义问题、收集更多或更高质量的数据、重新训练模型等。</li>
</ul>
</li>
</ol>
<p>这个流程不是一成不变的，具体的步骤和方法可能会根据具体的NLP任务、数据集、业务需求等因素有所不同。</p>
<h1 id="评估指标">评估指标</h1>
<p><a href="https://blog.csdn.net/ph12345687/article/details/130205151">NLP常见任务及评估指标</a></p>
]]></content>
    </entry>
</feed>