<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jeromezjl.github.io</id>
    <title>Jerome</title>
    <updated>2024-03-10T10:20:04.102Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jeromezjl.github.io"/>
    <link rel="self" href="https://jeromezjl.github.io/atom.xml"/>
    <subtitle>Jerome&apos;s blog</subtitle>
    <logo>https://jeromezjl.github.io/images/avatar.png</logo>
    <icon>https://jeromezjl.github.io/favicon.ico</icon>
    <rights>All rights reserved 2024, Jerome</rights>
    <entry>
        <title type="html"><![CDATA[【DL】模型复用]]></title>
        <id>https://jeromezjl.github.io/post/dl-mo-xing-fu-yong/</id>
        <link href="https://jeromezjl.github.io/post/dl-mo-xing-fu-yong/">
        </link>
        <updated>2024-03-10T08:51:41.000Z</updated>
        <content type="html"><![CDATA[<p>模型复用，通常在机器学习和深度学习领域称为迁移学习（Transfer Learning），是一种非常有效的方法，可以将在一个任务上训练好的模型应用到另一个相关但不同的任务上。这种方法特别有用，因为从头开始训练一个复杂模型通常需要大量的计算资源和大量的标记数据，而这两者在很多情况下都是昂贵或难以获得的。</p>
<h1 id="fine-tuning">Fine Tuning</h1>
<h3 id="模型复用的基本思想">模型复用的基本思想</h3>
<p>模型复用的核心思想是，对于不同但相关的任务，模型学习到的特征或知识在一定程度上是通用的。例如，一个在大型图像数据集（如ImageNet）上训练好的卷积神经网络（CNN）学会了识别各种视觉模式和结构，这些模式和结构对于其他视觉识别任务也是有用的。</p>
<h3 id="迁移学习的主要步骤">迁移学习的主要步骤</h3>
<ol>
<li>
<p><strong>预训练模型选择</strong>：选择一个与目标任务相似或相关领域的预训练模型。例如，对于图像识别任务，人们常用在ImageNet数据集上预训练的模型。</p>
</li>
<li>
<p><strong>特征提取</strong>：使用预训练模型的一部分（通常是除最后一层之外的所有层）作为特征提取器。这些层已经学会了从输入数据中提取有用的特征。</p>
</li>
<li>
<p><strong>微调</strong>：根据具体任务，可以对预训练模型的顶层或所有层进行微调。微调是通过在新的目标任务上继续训练模型来完成的，这通常需要较小的学习率，以避免破坏已经学到的特征表示。</p>
</li>
<li>
<p><strong>冻结层</strong>：在微调过程中，可以选择冻结预训练模型的一部分，以保留在原始任务上学到的特征。通常，只有模型的一部分（如顶层）被解冻以进行微调。</p>
</li>
</ol>
<h3 id="模型复用的优点">模型复用的优点</h3>
<ul>
<li><strong>数据需求降低</strong>：迁移学习允许使用较少的标记数据来训练模型，因为模型已经从预训练任务中学习了很多有用的特征。</li>
<li><strong>训练时间缩短</strong>：由于模型不是从零开始训练，因此训练时间通常会大大缩短。</li>
<li><strong>提高性能</strong>：迁移学习可以帮助提高模型在特定任务上的性能，尤其是当原始数据集非常大且多样时。</li>
</ul>
<h3 id="应用场景">应用场景</h3>
<p>迁移学习在许多领域都有应用，包括但不限于图像识别、自然语言处理（NLP）、语音识别和增强现实等。在NLP中，预训练的语言模型如BERT和GPT系列已经成为许多下游任务的基础。</p>
<p>模型复用利用了已有知识，可以加速模型的开发过程，并提高模型在特定任务上的表现，尤其是在数据有限的情况下。</p>
<h1 id="model-ensemble">Model Ensemble</h1>
<p>将多个小模型结合起来解决不同的问题并实现模型复用，通常涉及到模型集成和多任务学习的策略。这些方法允许模型共享知识，并提高整体性能，特别是在数据稀缺或每个单独任务的数据不足以训练一个复杂模型的情况下。</p>
<h3 id="模型集成model-ensemble">模型集成（Model Ensemble）</h3>
<p>模型集成涉及到将多个模型的预测结果结合起来，以提高整体的预测性能。这些模型可以是针对同一个任务的不同模型，也可以是针对不同任务的模型。集成方法包括但不限于：</p>
<ol>
<li><strong>简单平均（Simple Averaging）</strong>：对所有模型的预测结果进行算术平均。</li>
<li><strong>加权平均（Weighted Averaging）</strong>：根据每个模型的性能给予不同的权重，然后进行加权平均。</li>
<li><strong>投票法（Voting）</strong>：对于分类问题，每个模型为每个类别投票，最终决策基于最多投票的类别。</li>
<li><strong>堆叠（Stacking）</strong>：在堆叠方法中，多个模型的预测结果被用作另一个模型（称为元学习器或二级模型）的输入，以进行最终预测。</li>
</ol>
<h3 id="多任务学习multi-task-learning">多任务学习（Multi-task Learning）</h3>
<p>多任务学习是一种同时解决多个相关任务的方法，通过共享底层表示，这种方法可以提高各个任务的学习效率和预测性能。多任务学习的关键在于找到一种方式让模型的不同部分专注于不同的任务：</p>
<ol>
<li>
<p><strong>共享底层</strong>：在这种方法中，模型的底层（例如，神经网络的前几层）被多个任务共享，而顶层被设计为任务特定的层。这允许模型学习到可以跨多个任务通用的特征或表示。</p>
</li>
<li>
<p><strong>软参数共享</strong>：在软参数共享中，不同任务的模型有自己的参数，但是这些参数之间通过某种方式（如正则化）相互约束，以鼓励它们学到相似的表示。</p>
</li>
<li>
<p><strong>任务特定的分支</strong>：在这种结构中，模型从一个共享层分叉出多个分支，每个分支负责不同的任务。这种方法在多模态学习和多任务学习中尤其常见，其中不同的输入类型或不同的任务要求模型有不同的处理分支。</p>
</li>
</ol>
<h3 id="模型复用策略">模型复用策略</h3>
<ol>
<li>
<p><strong>预训练和微调</strong>：可以通过在一个通用任务上预训练模型，然后在特定任务上微调模型的某些层来实现模型复用。这在自然语言处理和图像处理领域尤为常见。</p>
</li>
<li>
<p><strong>特征提取</strong>：利用预训练模型作为特征提取器，提取的特征可以用于不同任务的模型训练中。</p>
</li>
<li>
<p><strong>模型蒸馏（Model Distillation）</strong>：通过模型蒸馏，可以将一个大型模型的知识转移到多个小型模型中。这些小型模型可以针对不同的任务进行优化，同时保持较小的模型大小和更快的推理速度。</p>
</li>
</ol>
<p>将多个小模型结合起来解决不同的问题，需要仔细考虑每个模型的输出如何能为其他任务提供有价值的信息，以及如何在不同模型间高效地共享知识。这通常需要对任务之间</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【ML】分类和回归]]></title>
        <id>https://jeromezjl.github.io/post/fen-lei-he-hui-gui/</id>
        <link href="https://jeromezjl.github.io/post/fen-lei-he-hui-gui/">
        </link>
        <updated>2024-03-10T07:54:20.000Z</updated>
        <content type="html"><![CDATA[<h1 id="分类">分类</h1>
<ul>
<li><strong>目标变量</strong>：分类任务中的目标变量是离散的，也就是说，它将输入数据映射到预定义的类别或标签中。这些类别通常是有限的且不连续的。</li>
<li><strong>应用场景</strong>：邮件是否为垃圾邮件、图像中是否含有特定物体、患者是否患有某种疾病等。</li>
<li><strong>常用算法</strong>：
<ul>
<li>决策树（如CART, ID3, C4.5）</li>
<li>支持向量机（SVM）</li>
<li>逻辑回归</li>
<li>K最近邻（KNN）</li>
<li>随机森林</li>
<li>梯度提升决策树（如XGBoost, LightGBM, CatBoost）</li>
<li>神经网络</li>
</ul>
</li>
</ul>
<h1 id="回归">回归</h1>
<ul>
<li><strong>目标变量</strong>：回归任务中的目标变量是连续的数值。模型的目的是预测出一个具体的数值。</li>
<li><strong>应用场景</strong>：房价预测、股票价格预测、温度预测等。</li>
<li><strong>常用算法</strong>：
<ul>
<li>线性回归</li>
<li>多项式回归</li>
<li>决策树回归</li>
<li>支持向量回归（SVR）</li>
<li>随机森林回归</li>
<li>梯度提升决策树回归（如XGBoost, LightGBM）</li>
<li>神经网络</li>
</ul>
</li>
</ul>
<h1 id="主要区别">主要区别</h1>
<ul>
<li><strong>输出类型</strong>：分类是预测离散标签，而回归是预测连续数值。</li>
<li><strong>评估标准</strong>：分类任务通常使用准确率、精确度、召回率、F1分数等指标进行评估；回归任务则常用均方误差（MSE）、均方根误差（RMSE）、平均绝对误差（MAE）等指标。</li>
<li><strong>决策边界</strong>：分类任务通常涉及到找到决策边界来区分不同的类别；回归任务则是找到一个最佳拟合线或曲面来预测连续值。</li>
</ul>
<h1 id="主要联系">主要联系</h1>
<ul>
<li><strong>监督学习</strong>：无论是分类还是回归，它们都属于监督学习范畴，这意味着它们都使用已标注的训练数据来学习输入和输出之间的映射关系。</li>
<li><strong>模型构建与预测</strong>：分类和回归都涉及到使用训练数据构建模型，并使用这些模型来对新的、未见过的数据进行预测。</li>
<li><strong>损失函数</strong>：两者都通过最小化损失函数来训练模型。虽然使用的具体损失函数可能不同（如分类通常使用交叉熵损失，回归通常使用均方误差损失），但最小化损失函数的基本思想是一致的。</li>
</ul>
<h3 id="从回归到分类的转变">从回归到分类的转变</h3>
<ul>
<li>在某些情况下，可以通过引入阈值将回归问题转化为分类问题。例如，在一个二元分类问题中，模型的输出可以是一个连续的概率值，当这个概率值超过某个阈值时，可以将其视为一个类别，否则视为另一个类别。</li>
</ul>
<h3 id="从分类到回归的转变">从分类到回归的转变</h3>
<ul>
<li>在某些情况下，分类问题也可以转换为回归问题，特别是当类别之间存在天然顺序（有序分类）时。通过预测一个连续的数值并将其映射到最接近的类别，可以处理这类问题。</li>
</ul>
<p>总的来说，虽然分类和回归处理的是不同类型的问题，但它们在许多方面是相似的，使用相似的方法，很多算法和技术可以在这两种任务之间转换和重用。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[复试英语]]></title>
        <id>https://jeromezjl.github.io/post/fu-shi-ying-yu/</id>
        <link href="https://jeromezjl.github.io/post/fu-shi-ying-yu/">
        </link>
        <updated>2024-03-09T06:41:13.000Z</updated>
        <content type="html"><![CDATA[<p>Postgraduate是大学毕业（graduate）后继续深造、但未拿到学位（Master或Doctor）之前的身份，Master是硕士学位</p>
<p>中文：<br>
英文自我介绍</p>
<p>我叫张继隆，我的英文名叫Jerome，我今年21岁了。我来自天津市，我喜欢我的家乡。我本科就读于北京邮电大学，主修人工智能专业</p>
<p>我很喜欢人工智能，大学期间，我系统地学习了专业知识，我的线性代数、概率论、机器学习、深度学习、计算机视觉等课程均达到90分以上。我还参加了许多创新比赛，比如数学竞赛，并取得了奖项。做过很多人工智能相关的项目，提升了我的专业素养和专业能力。<br>
我通过了大学英语四六级考试，其中CET6的成绩在550分以上。我一直是一个勤奋好学，不断提升自己的学生，</p>
<p>我还积极参加各种活动，我喜欢做运动，因为我相信拥有健康的身体可以让我更加积极地学习和工作。同时，我还喜欢音乐和艺术，本科期间是社团的社长，这段经历提升了我的沟通能力，以及对事情的规划能力。对不同领域的探索扩展了我的思维，让我的头脑更加灵活，更能专注于研究工作。</p>
<p>我选择继续在北邮深造的原因，是因为我深爱着北邮的学术氛围。老师们有很好的品德素养和专业能力，在我学习过程中给予了我很大的帮助。同时我们学校在社会上的认可度一直是很高的，我爱北邮。</p>
<p>如果给我一个机会，我会继续努力提高自己。如果我的研究能力在研究生期间得到导师的认可，我将继续攻读博士学位。</p>
<p>最后，我会尽最大努力发掘自己最大的潜力，脚踏实地地做好每件事。这就是我的自我介绍。我真诚地感谢您的聆听</p>
<p>Dear professors, good morning/afternoon! Thank you for giving me this opportunity to attend the interview. I hope I can make a good performance today. Now I will briefly introduce myself.</p>
<p>My name is Zhang Jilong, and my English name is Jerome. I am 21 years old this year. I come from Tianjin, and I love my hometown. I completed my undergraduate studies at Beijing University of Posts and Telecommunications. My major is Artificial Intelligence.</p>
<p>I have a strong passion for artificial intelligence. During my university years, I systematically studied professional knowledge, and my grades in courses such as linear algebra, probability theory, machine learning, deep learning, and computer vision all exceeded 90 points. I also participated in many innovation competitions, such as math competitions, english competitions and won awards. I have worked on many artificial intelligence-related projects, which improved my professional quality and abilities. I passed the College English Test (CET) Levels 4 and 6, with a score of over 550 in CET6. I have always been a diligent and eager student, constantly striving to improve myself.</p>
<p>Additionally, I actively participated in various activities. I enjoy doing sports because I believe having a healthy body allows me to study and work more positively. At the same time, I also love music and art. During my undergraduate studies, I was the president of a club, which enhanced my communication skills and ability to plan events. Exploring different fields expanded my thinking, making my mind more flexible and more focused on research work.</p>
<p>The reason I chose to continue my studies at BUPT is my deep love for the academic atmosphere here. The teachers have good moral character and professional abilities, which have been of great help to me in my studies. At the same time, our school's social recognition has always been very high. I love BUPT.</p>
<p>If given the opportunity, I will continue to work hard to improve myself. If my research abilities are recognized by my advisors during my graduate studies, I will continue to pursue a Ph.D.</p>
<p>In conclusion, I will do my best to uncover my greatest potential and earnestly accomplish everything I undertake. This is my self-introduction. I sincerely thank you for listening.</p>
<p>另外<br>
I will strive to issue some papers on some influencial journals</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【CV】三维重建]]></title>
        <id>https://jeromezjl.github.io/post/cv-san-wei-chong-jian/</id>
        <link href="https://jeromezjl.github.io/post/cv-san-wei-chong-jian/">
        </link>
        <updated>2024-03-07T08:46:57.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://github.com/jeromezjl/PhotometricStereoTutorial">github链接</a></p>
<p>多视角、多光照</p>
<p>多光照：输入多光照图像，输出三维</p>
<p><a href="https://www.bilibili.com/video/BV1Mt4y1a7e6/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">【”UE5夯实基础”每日2更系列】13朗伯漫反射理论</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【CV】人体姿态识别]]></title>
        <id>https://jeromezjl.github.io/post/cv-ren-ti-zi-tai-shi-bie/</id>
        <link href="https://jeromezjl.github.io/post/cv-ren-ti-zi-tai-shi-bie/">
        </link>
        <updated>2024-03-06T02:39:42.000Z</updated>
        <content type="html"><![CDATA[<p>1</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【ML】基础概念]]></title>
        <id>https://jeromezjl.github.io/post/ml-ji-chu-gai-lan/</id>
        <link href="https://jeromezjl.github.io/post/ml-ji-chu-gai-lan/">
        </link>
        <updated>2024-03-05T06:16:47.000Z</updated>
        <content type="html"><![CDATA[<p>有监督：分类、回归<br>
无监督：聚类、密度估计</p>
<p>错误率：error_rate：预测错误/全部<br>
精度：accuracy：1-error_rate</p>
<p>在深度学习中，参数通常是指神经网络中的权重和偏差。<br>
这些参数是通过<code>反向传播</code>算法，根据训练数据中的梯度信息自动调整的，以最小化<code>损失函数</code>。<br>
参数的学习是模型训练的过程，目标是找到最佳的参数配置。</p>
<h1 id="损失函数">损失函数</h1>
<p><a href="https://zhuanlan.zhihu.com/p/261059231">损失函数（Loss Function）</a><br>
计算预测值f(x)与真实值Y的差异程度<br>
绝对值损失 Mean Absolute Error (MAE)：L1 Loss<br>
均方损失：L2 Loss<br>
Huber Loss</p>
<p><strong>正则化</strong><br>
在损失函数中添加一个正则项，使模型学习到更加稀疏的权重分布，防止过拟合<br>
<a href="https://blog.csdn.net/weixin_41960890/article/details/104891561">一篇文章完全搞懂正则化（Regularization）</a></p>
<h1 id="向前传播和反向传播">向前传播和反向传播</h1>
<p>损失函数链式法则对参数求梯度来更新参数值<br>
<a href="https://www.bilibili.com/video/BV1yG411x7Cc/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">5分钟深度学习-反向传播算法</a><br>
<a href="https://zhuanlan.zhihu.com/p/447113449">【深度学习篇】：前向传播（forward）和反向传播（backward）</a><br>
<a href="https://jeromezjl.github.io/post/ti-du-xia-jiang-gradient-descent/">【ML】以梯度下降（Gradient Descent）展开的优化器总结</a><br>
<strong>激活函数</strong><br>
增加神经网络的非线性表达能力，使之能更好的拟合非线性模型<br>
<a href="https://www.bilibili.com/video/BV1qB4y1e7GJ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">5分钟深度学习-激活函数</a><br>
<a href="https://zhuanlan.zhihu.com/p/364620596">深度学习笔记：如何理解激活函数？（附常用激活函数）</a><br>
特点：连续可导（梯度下降）；取值范围是全体实数，将全体实数映射到特定的范围；只需增加非线性的因素，而不需改变对输入的响应状态，所以是单增的，随输入增大而增大<br>
梯度消失（梯度弥散）：sigmoid趋近无穷时，梯度趋近于0，若某次输入过大，梯度几乎为0，导致参数几乎不更新，导致整个网络学习能力下降<br>
sigmoid：非零均值函数→同时更新正负→神经网络不易收敛；饱和函数→梯度消失，使用tanh函数可以<br>
梯度爆炸：使用ReLU函数时，由于函数无上界，如果输出过大，会导致梯度累积，超出上限</p>
<h1 id="分类和回归">分类和回归</h1>
<p>本质都是对输入值进行预测的问题，分类输出离散的、对预测类别的置信度，回归输出连续的预测值<br>
<a href="https://blog.csdn.net/shuiyixin/article/details/88816416">【机器学习小常识】“分类” 与 “回归”的概念及区别详解</a><br>
<a href="https://www.bilibili.com/video/BV1m4421F7Fg/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">详解逻辑回归、softmax回归和神经网络，三种模型的关联和区别</a></p>
<h1 id="训练集-验证集-测试集">训练集、验证集、测试集</h1>
<p>三者必须无交集<br>
<a href="https://blog.csdn.net/qlkaicx/article/details/134767111#:~:text=%E5%8F%82%E6%95%B0%20%E6%98%AF%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%8F%AF%E8%A2%AB%E5%AD%A6%E4%B9%A0%E5%92%8C%E8%B0%83%E6%95%B4%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%8C%E9%80%9A%E8%BF%87%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%AD%A6%E4%B9%A0%E5%92%8C%E4%BC%98%E5%8C%96%EF%BC%9B,%E8%80%8C%20%E8%B6%85%E5%8F%82%E6%95%B0%20%E5%88%99%E6%98%AF%E6%89%8B%E5%8A%A8%E8%AE%BE%E7%BD%AE%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%8C%E7%94%A8%E4%BA%8E%E6%8E%A7%E5%88%B6%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%8C%E4%B8%BA%E5%92%8C%E6%80%A7%E8%83%BD%EF%BC%8C%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E9%80%89%E6%8B%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%AF%B9%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E6%9C%89%E9%87%8D%E8%A6%81%E5%BD%B1%E5%93%8D%E3%80%82">还搞不懂什么是参数，超参数吗？三分钟快速了解参数与超参数的概念和区别！！！</a><br>
<a href="https://blog.csdn.net/qq_41895003/article/details/104811371">训练集、测试集、验证集之间的区别及理解</a><br>
训练集：通过训练自动更新参数<br>
验证集：手动更新超参数<br>
测试集：测试生成的模型的泛化能力</p>
<p>k折交叉验证：将数据集分成k份，每次拿出其中的一份作为验证集，剩下k-1份作为训练集<br>
通过平均误差判断超参数好坏</p>
<p><code>Q&amp;A</code></p>
<pre><code>Q：如果loss很低，是不是就不用设置验证集了
A：在深度学习训练中，即使训练损失（loss）很低，也不意味着可以忽略验证集的设置。这里有几个原因解释为什么验证集依然很重要：

1. 过拟合（Overfitting）：一个很低的训练损失可能意味着模型在训练集上表现得很好，但这也可能是过拟合的一个迹象。过拟合发生时，模型学习到了训练数据中的噪声和细节，而不是底层模式，这会导致模型在未见过的数据上表现不佳。验证集可以帮助检测过拟合情况，因为它提供了模型在非训练数据上的性能评估。

2. 模型选择（Model Selection）：在开发深度学习模型时，我们通常会尝试多种不同的架构、超参数设置等。验证集用于评估这些不同设置的性能，帮助我们选择最佳模型。

3. 调参（Hyperparameter Tuning）：除了选择模型外，我们还需要调整模型的超参数（如学习率、批量大小等）。验证集对于这一过程至关重要，因为它可以帮助我们了解不同超参数设置对模型性能的影响。

4. 泛化能力（Generalization Ability）：最终，我们关心的是模型在实际应用中的表现，即在新的、未见过的数据上的表现。验证集提供了一个近似的泛化能力评估，帮助我们估计模型在现实世界数据上的表现。

因此，即使训练损失很低，也不应该忽视验证集的设置。验证集是深度学习训练过程中不可或缺的一部分，对于确保模型的泛化能力和避免过拟合至关重要。在模型训练的最后阶段，还应该使用独立的测试集对模型进行最终评估，以进一步验证模型的泛化能力。
</code></pre>
<pre><code>Q：验证集在所有任务中都是必须的吗？
A：虽然验证集在许多深度学习和机器学习任务中非常重要，但是否“必须”使用验证集取决于具体的任务、数据的可用性以及目标。在大多数情况下，使用验证集是一种最佳实践，但也有一些情况或任务可能不那么依赖于验证集：

1. 数据量极其有限：在某些情况下，如果可用的数据非常有限，可能无法划分出单独的验证集。在这种情况下，可能会采用交叉验证的方法，这种方法将数据集分为多个小分组，然后依次将其中一个分组作为验证集，其他分组作为训练集，从而有效利用有限的数据。

2. 在线学习或持续学习：对于一些在线学习任务，模型会持续地接收数据并不断更新。在这种情况下，模型可能不会有一个固定的验证集，而是不断地用新数据评估和调整。

3. 使用预训练模型进行微调：当使用预训练模型并对其进行微调以适应特定任务时，如果任务非常接近原始预训练任务，且数据集较小，可能会直接在训练数据上进行微调而不单独设置验证集。然而，这种情况下仍然推荐使用验证集来监控过拟合和模型性能。

4. 简单任务或明确的成功标准：在一些简单的任务或当成功标准非常明确且容易评估时（如明确的数学问题），可能不需要单独的验证集来调整模型参数。

即便在这些特殊情况下，最终还是需要一个独立的测试集来评估模型的性能，确保模型能够在未见过的数据上良好工作。综上所述，虽然在某些特定场景下可以不使用验证集，但在大多数情况下，为了保证模型的泛化能力和避免过拟合，使用验证集都是一种非常重要的实践。
</code></pre>
<p><strong>超参数调整</strong><br>
利用验证集调整超参数的一些策略</p>
<ol>
<li>在每个epoch后或几个epoch后使用验证集验证模型的loss，确保模型权重可以被保存在本地，手动调整超参数后继续训练</li>
<li>使用早停技术：在每个epoch结束时评估模型在验证集上的性能，并在性能不再提升时停止训练</li>
<li>使用自动化超参数优化（Hyperparameter Optimization, HPO）</li>
<li>设置模型检查点（Model Checkpointing）</li>
</ol>
<h1 id="过拟合">过拟合</h1>
<p>过拟合：认为只有和训练数据一样的才是<br>
欠拟合：认为树也是叶子<br>
<a href="https://zhuanlan.zhihu.com/p/158869433">机器学习模型的容量，过拟合与欠拟合</a><br>
dropout：前向传播的时候，让某个神经元的激活值以一定的概率 p 停止工作，这样可以使模型泛化性更强，防止过拟合</p>
<h1 id="算法分类">算法分类</h1>
<p>机器学习算法通常根据学习方式和应用场景被分类为几大类：</p>
<ol>
<li>
<p><strong>监督学习（Supervised Learning）</strong>:</p>
<ul>
<li>在这种类型的学习中，算法从标记的训练数据中学习，每个训练样本都有一个与之对应的标签或输出。</li>
<li>常见的算法包括线性回归、逻辑回归、支持向量机（SVM）、决策树、随机森林、神经网络等。</li>
</ul>
</li>
<li>
<p><strong>无监督学习（Unsupervised Learning）</strong>:</p>
<ul>
<li>在无监督学习中，算法试图从未标记的数据中找出模式。因为没有指导，所以这种类型的学习试图通过数据本身的结构来理解数据。</li>
<li>典型的算法包括聚类算法（如K-means、层次聚类）、降维算法（如主成分分析PCA、t-SNE）、关联规则学习算法（如Apriori、Eclat）等。</li>
</ul>
</li>
<li>
<p><strong>半监督学习（Semi-Supervised Learning）</strong>:</p>
<ul>
<li>这种学习方式介于监督学习和无监督学习之间。它使用少量的标记数据和大量的未标记数据进行训练。通过这种方式，算法可以提高其性能和准确性。</li>
<li>半监督学习方法通常包括自训练、多视图学习、图基方法等。</li>
</ul>
</li>
<li>
<p><strong>强化学习（Reinforcement Learning）</strong>:</p>
<ul>
<li>在强化学习中，算法（通常称为智能体）通过与环境交互来学习如何达到目标。智能体从环境中获得奖励或惩罚，并使用这些反馈来指导其未来的行为。</li>
<li>常见的强化学习算法包括Q-learning、SARSA、深度Q网络（DQN）、策略梯度方法等。</li>
</ul>
</li>
<li>
<p><strong>自监督学习（Self-Supervised Learning）</strong>:</p>
<ul>
<li>这是一种特殊类型的无监督学习，其中数据的一部分被用作监督信号。在自监督学习中，模型试图从数据的未标记部分预测数据的标记部分，从而在没有显式标签的情况下学习数据的表示。</li>
<li>应用示例包括预训练的语言模型、图像特征学习等。</li>
</ul>
</li>
<li>
<p><strong>迁移学习（Transfer Learning）</strong>:</p>
<ul>
<li>这种学习方法涉及将从一个任务中学到的知识应用到另一个不同但相关的任务上。这是通过重用预训练模型的一部分并对其进行微调来实现的，以适应新任务。</li>
<li>这在深度学习中尤其常见，例如使用预训练的卷积神经网络（CNN）进行图像分类任务。<br>
<a href="https://jeromezjl.github.io/post/dl-mo-xing-fu-yong">【DL】模型复用</a></li>
</ul>
</li>
<li>
<p><strong>生成式对抗网络（GANs）</strong>:</p>
<ul>
<li>GANs是一种框架，用于通过两个网络（一个生成器和一个鉴别器）之间的对抗过程来训练生成模型。生成器生成新的数据实例，而鉴别器评估它们是来自于真实数据集还是生成器产生的。</li>
<li>GANs广泛用于图像生成、图像转换、增强现实等领域。</li>
</ul>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【Linux】深度学习配置]]></title>
        <id>https://jeromezjl.github.io/post/linux-shen-du-xue-xi-pei-zhi/</id>
        <link href="https://jeromezjl.github.io/post/linux-shen-du-xue-xi-pei-zhi/">
        </link>
        <updated>2024-02-29T06:00:15.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_45484237/article/details/123514175">实现Linux服务器配置深度学习环境并跑代码完整步骤</a></p>
<p>使用nvidia-smi完全查看显卡型号<br>
nvidia-smi --format=csv --query-gpu=index,name,driver_version,memory.total,memory.used,memory.free<br>
或使用<br>
pip install gpustat<br>
gpustat<br>
来查看</p>
<p><a href="https://zhuanlan.zhihu.com/p/102449309">Linux下Anaconda环境安装/创建/激活/退出/删除/管理</a><br>
<a href="https://blog.csdn.net/Aorg1/article/details/134800426">conda环境下安装nvcc -V</a></p>
<p><a href="https://blog.csdn.net/m0_50181189/article/details/122440985">【详细】Ubuntu18.04安装更新显卡驱动、安装CUDA及cuDNN、CUDA版本切换</a></p>
<p>退出 python：&gt;&gt;&gt; quit（）</p>
<p><a href="https://blog.csdn.net/weixin_59047731/article/details/135634418">pyCharm专业版破解激活（超详细）</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/486360176">一文读懂 PyTorch 显存管理机制</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[毕设]]></title>
        <id>https://jeromezjl.github.io/post/bi-she/</id>
        <link href="https://jeromezjl.github.io/post/bi-she/">
        </link>
        <updated>2024-02-28T14:16:52.000Z</updated>
        <content type="html"><![CDATA[<p>Linux运行python文件<br>
python3 script.py</p>
<p><strong>Hugging Face</strong><br>
&quot;NLP 界的 GitHub&quot;<br>
<a href="https://www.bilibili.com/video/BV1YU4y1g753/?spm_id_from=333.999.0.0&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">Hugging Face 系列视频（一）：Hugging Face 及 Transformer/Datasets/Tokenizers库</a><br>
<a href="https://blog.csdn.net/a1920993165/article/details/128082968">Huggingface的介绍，使用（CSDN最强Huggingface入门手册）</a></p>
<p><strong>Fine tuning 微调</strong><br>
将模型迁移学习，影响因素：新数据集的大小、新数据和原数据集的相似程度<br>
<a href="https://zhuanlan.zhihu.com/p/35890660">CNN入门讲解：什么是微调（Fine Tune）？</a><br>
<a href="https://blog.csdn.net/weixin_42137700/article/details/82107208">什么是fine-tuning？</a><br>
<a href="https://zhuanlan.zhihu.com/p/620618701">预训练大语言模型的三种微调技术总结：fine-tuning、parameter-efficient fine-tuning和prompt-tuning的介绍和对比</a></p>
<p><strong>使用 COCO 数据集进行预训练的 VIT-GPT2 模型</strong><br>
COCO：起源于微软的、大型的、丰富的物体检测数据集<br>
<a href="https://blog.csdn.net/qq_41185868/article/details/82939959">Dataset之COCO数据集：COCO数据集的简介、下载、使用方法之详细攻略</a><br>
<a href="https://huggingface.co/nlpconnect/vit-gpt2-image-captioning">vit-gpt2-image-captioning</a></p>
<p><strong>CLIP</strong><br>
<a href="https://zhuanlan.zhihu.com/p/521151393">详解CLIP (一) | 打通文本-图像预训练实现ImageNet的zero-shot分类，比肩全监督训练的ResNet50/101</a><br>
<a href="https://blog.csdn.net/lsb2002/article/details/132275132">openai多模态大模型：clip详解及实战</a><br>
<a href="https://zhuanlan.zhihu.com/p/493489688">神器CLIP：连接文本和图像，打造可迁移的视觉模型</a></p>
<p>VIT<br>
embedding：通过矩阵乘法，将token升降维，从而让计算机理解。将一个东西映射为向量</p>
<p>linear层：1. 将每个patch变成一维  2. 使一维向量的维度和 transformer 输入维度相符</p>
<p>位置编码和embedding相加</p>
<p>是一个特征提取器<br>
先将图像分割为不同的patch<br>
然后将每个patch拉成一个向量，加入位置信息</p>
<p>transformer必须在大量数据</p>
<p><a href="https://blog.csdn.net/weixin_44966641/article/details/118733341">Vision Transformer（ViT）PyTorch代码全解析（附图解）</a><br>
<a href="https://juejin.cn/post/7238148905095839804">用🤗 Transformers微调ViT图像分类</a></p>
<p>deepfashion<br>
图片：750x1101，共44096个</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【考研】英语单词和词组]]></title>
        <id>https://jeromezjl.github.io/post/kao-yan-ying-yu-dan-ci-he-ci-zu/</id>
        <link href="https://jeromezjl.github.io/post/kao-yan-ying-yu-dan-ci-he-ci-zu/">
        </link>
        <updated>2023-11-29T13:50:01.000Z</updated>
        <content type="html"><![CDATA[<p><strong>时间安排</strong><br>
下午 14：00~17：00 考试，三个小时<br>
小作文：15min<br>
大作文：35min<br>
阅读：70min（17分钟一篇）<br>
新题型：20min<br>
翻译：20min<br>
完形填空：20min</p>
<h1 id="单词">单词</h1>
<p>measurement 测量<br>
lean 倾斜、倚靠、精瘦<br>
likewise 同样的<br>
absently 心不在焉地<br>
concede admit acknowledge confess allow grant 让步、承认<br>
sitter 摆姿势让人画像的人<br>
miserably 痛苦地<br>
stiff、stiffly 僵硬的<br>
notoriously 臭名昭著、众所周知<br>
copper 铜<br>
limbs 肢体、四肢<br>
grin 露齿笑<br>
contemplate 考虑、沉思 too...to contemplate 太...去考虑（无法想象）<br>
notion 概念、观念 the notion is that 意思是说/人们认为<br>
compell 强迫<br>
privilege 给特权<br>
intensify 强化<br>
crisp 脆的<br>
crust 皮，外壳<br>
mandate 授权</p>
<h1 id="词组">词组</h1>
<p>over a six-year period 在六年的时间里<br>
be superior to 优于<br>
be resistant to 不受损害的<br>
increase the level 提高水平<br>
government grant 政府拨款<br>
take for granted 认为...理所应当<br>
justify doing sth. 证明做...（是正确的）<br>
judge by/from 从...判定<br>
starved of 缺乏、挨饿<br>
at high temperature 在高温下<br>
come across 遇到、给人留下印象</p>
<h1 id="长难句">长难句</h1>
<p>its campaign risks coming across as being pushy.<br>
risk 是宾语，有...的风险<br>
coming across as being pushy 给人留下咄咄逼人的印象（遇到被认为咄咄逼人）come across 有给人留下印象的意思<br>
译为，它的活动有可能给人留下咄咄逼人的印象</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【考研】英语作文]]></title>
        <id>https://jeromezjl.github.io/post/kao-yan-ying-yu-zuo-wen/</id>
        <link href="https://jeromezjl.github.io/post/kao-yan-ying-yu-zuo-wen/">
        </link>
        <updated>2023-10-11T13:47:29.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://jeromezjl.github.io/post/liu-ji/">六级整理的作文</a></p>
<p><a href="https://www.zhihu.com/question/380341976">考研英语一的各题型，怎么分配时间合理？</a></p>
<p>小作文<br>
大作文</p>
<h1 id="小作文">小作文</h1>
<p><strong>常考题目有四种</strong><br>
私人书信、公务书信、通知和告示（去年考的）、会议纪要</p>
<p><strong>审题三要素</strong></p>
<ol>
<li>故事背景：打散+改写背景信息</li>
<li>体裁（letter/email+notice）+ 内容要求</li>
<li>正式（I am / It is）/非正式（I'm / It's） + 格式<br>
都写正式肯定没错</li>
</ol>
<p><strong>小作文三段式简易思路</strong><br>
小作文：说事说明白就行，不要求句型很复杂<br>
段首1-2句<br>
a. 写给熟人：首句寒暄，二句目的；<br>
b. 写给陌生人或机构：自我介绍和目的</p>
<p>中间 4-6 句<br>
按题目要求写相应内容，并辅以感谢、强调、对比、建议、说明等功能表达完成写作</p>
<p>段尾 1 句<br>
再次致歉、感谢、期待、展望等</p>
<p>正文缩进四个字符</p>
<p><strong>书信</strong><br>
dear 称呼<br>
Yours sincerely</p>
<p><strong>告示</strong><br>
标题</p>
<p>the purpose of sth. / sth. aims(targets) to 目的是<br>
use their best endeavors to do 尽最大努力做<br>
attach emphasis to sth. 认为...很重要<br>
utmost emphasis should be attached to...<br>
contribute to / induce 是导致...的原因<br>
complete one's work 完成工作<br>
joint efforts 共同努力<br>
I am deeply obliged for your hard work 我十分感谢您的努力</p>
<h1 id="可用单词">可用单词</h1>
<p>character 角色<br>
plight 困境<br>
vigorous 有活力的<br>
tremendous 巨大的<br>
eminent 优秀的<br>
eminently = exceedingly = Immensely 非常<br>
advantageous 有利的，有好处的<br>
miraculous 奇迹般的<br>
gorgeous 美丽的<br>
pervasive = universal 普遍的<br>
enhance = promote = strengthen = optimize 加强、优化、促进<br>
deal with = resolve sth. = tackle sth. = cope with 解决，应对，处理<br>
cultivate = foster 培养<br>
fulfill 完成<br>
contamination 污染<br>
obligation 责任<br>
accelerate 加速<br>
adequate 充足<br>
rational 合理的<br>
feasible 可行的<br>
considerable 相当多的<br>
critical / essential / be extremely vital to us 至关重要的<br>
severe、critical 严重的<br>
terrible / harmful<br>
defect 缺点<br>
eliminate 消除<br>
therefore = hence 因此<br>
demonstrate / illustrate “说明，表明”，用在图表作文中替代show，reveal等单词<br>
depict / portray “描述，描绘”，在漫画作文中替代describe<br>
punctuality 准时 / punctually 准时地<br>
prestigious 有声望的<br>
hospitality 热情好客 / hospitable 热情好客的<br>
imperative 迫切的<br>
magnificent = splendid 壮丽的<br>
innumerable 无数的<br>
deleterious 有害的<br>
pursue 追求<br>
primary 首要的<br>
academic 学术的<br>
indispensable 不可或缺的<br>
severely 严重地</p>
<h1 id="可用词组">可用词组</h1>
<p>I'm writing to request that 我写信恳求（t不双写）<br>
I have several request<br>
表达喜欢{<br>
students who share a love for English 共同热爱<br>
be keen on sth.<br>
have a profound affection  有深厚的感情/浓厚的兴趣<br>
be passionate about<br>
have a peculiar interest in 对...有特殊的兴趣<br>
}<br>
the Internet has become an increasingly important tool for students<br>
Not only do professors require us to... but ... (前后连接复杂句，do 起强调作用)<br>
much of the communication between...  communication 不可数<br>
I cordially invite you to join us 我诚挚地邀请您来参加我们的活动<br>
on behalf of<br>
we are hoping that you will be available for a lecture on January 4th.<br>
there will be 45 minutes allocated for you<br>
in their spare time<br>
sth be in great request 非常需要 sth<br>
compensate for / compensate sb. for sth. 弥补、补偿<br>
urge sb to do 敦促某人做<br>
guarantee sb. sth. 向某人保证某事<br>
remains to do 仍需做某事<br>
be inspired  by 受到启发、鼓舞<br>
A be conducive to B / do sth A有利于B/做某事<br>
be detrimental to 不利于，对...有害<br>
manifest improvement 明显的进步<br>
a wholesome drink 有益健康的饮料<br>
Prevailing among the general public 在一般人群中盛行<br>
be triggered by 由...引起的<br>
If tedious tasks could be eradicated, the world would be a much better place.<br>
如果可以消灭那些单调乏味的工作，世界将会变得更加美好<br>
We must eradicate the unhealthy tendency of cheating in exams.<br>
我们一定要杜绝考试作弊的歪风邪气<br>
The noise pollution badly jeopardizes the health of the operating workers.<br>
噪声污染严重地危害人们的身体健康（jeopardize：危害）<br>
alleviating psychological pressure 缓解心理压力（alleviate 减轻、缓解）<br>
Some people assert that nothing is impossible.<br>
一些人断言没有什么事是不可能的（assert：断言、声称）<br>
stimulate sb. to do sth. 激励某人做<br>
the merits of sth. 某事的好处<br>
be saturated with 充斥着<br>
strive for = spare no efforts for = endeavor to do 努力做<br>
embark on sth. 开始做 sth.<br>
in contemporary society 在当代社会<br>
a multitude of = a vast amount of 大量<br>
there are numerous ways of doing 有许多做...的方法<br>
the majority of 大多数<br>
an alternative is that… 作为替代的是...<br>
cannot afford to 不应当做<br>
attach importance to sth 强调...<br>
obstacle 阻碍<br>
in such circumstances 在这样的情况下<br>
in contrast = conversely 相反地<br>
employ the policy of sth 采取...政策<br>
It is generally established that 众所周知<br>
enduring classic 经久不衰的经典<br>
the inner world 内心世界<br>
I am referring to that 我指的是<br>
have a fascination with 对...感兴趣<br>
a range of 一系列<br>
be involved in 参加<br>
extracurricular activities 课外活动<br>
interpersonal relations 人际关系<br>
i regret to tell you that 我很遗憾的告诉你<br>
particular details 具体细节<br>
one of the most magnificent tourist destination in China<br>
China boasts of a splendid history 中国有辉煌的历史<br>
In addition 无所谓连接<br>
What's more 最好连着前面 比如 Initially，<br>
Further more 最好用在最后，前面必须连<br>
be ascribed to 归因于<br>
If... ever perished from..., it would be a tragedy of immeasurable proportions 如果... 从... 消失，那将是不可估量的悲剧<br>
indulge in / indulgence in 沉浸在<br>
derive from 源于<br>
mental fitness 心理健康<br>
enjoy striking popularity among / be in vogue 流行<br>
demonstrate a social phenomena of 反映了...的社会现象<br>
briefly speaking 简言之<br>
provoke heated debates 引起激烈讨论<br>
double-edged sword<br>
exert profound influence on 产生深远影响<br>
bridge / narrow the gap between<br>
be adopted to 被采纳用于<br>
repent（doing）后悔做<br>
it is imperative for us to take drastic measures. 当务之急是采取严厉措施<br>
enhance the public awareness 提高公众意识<br>
a combination of ... 的结合<br>
this tendency is rather disturbing 这种倾向很令人担忧<br>
give a helping hand<br>
a minority of<br>
every individual</p>
<p><strong>道歉信</strong><br>
I have recently been diagnosed with a serious cold<br>
If possible, i would like to postpone the interview to another day later in the week<br>
I sincerely apologize for any inconvenience this may cause you (may have caused)<br>
Please excuse me for not being able to inform you of my situation sooner.</p>
<p>as a... , i am severely disappointed to find that the service you have recently provided us is far from satisfactory<br>
i am writing to draw you attention to sth.<br>
take...into serious concideration</p>
<p><strong>感谢信</strong><br>
comforting<br>
Benevolence = kind deed<br>
I am writing this letter to express my heartfelt gratitude to you for the meticulous care you provided during my time in the hospital.<br>
The comforting scenes always remind me of the period you took such good care of me.<br>
If it had not been for your timely assistance in giving me first aid, I fear that the consequences might have been very serious<br>
What impressed me the most was<br>
Your appearance has uplifted me/cheered me up<br>
I would like to extend my thanks once again<br>
Your kind deeds are like pearls that will forever be treasured in my mind.</p>
<p><strong>求职、申请</strong><br>
I am writing to apply for the job of doing / your recently advertised position for a teacher<br>
I would like to apply for admission to...<br>
I hold the belief that I am well qualified for this position for several reasons.<br>
Enclosed with this note is my resume, which details my previous academic qualifications and relevant work experiences.<br>
the experiences make me a perfect candidate<br>
cheerful personality<br>
If you could grant me an interview, i would appreciate it.<br>
at your earliest convenience</p>
<p><strong>活动</strong><br>
To enhance the ability and enrich after-class activities<br>
which is to be held on...<br>
Those who have a fascination with ... are welcome to participate in this activity<br>
If the would-be candidates have any questions, please do not hesitate to contact us<br>
this club serves as a platform to demonstrate your marvelous abilities<br>
are eminently beneficial in multiple regards 在多方面都很有益处<br>
improve your level of proficiency 提高你的熟练程度<br>
A good command of English will enable you to get an edge over your peers<br>
好的英语水平让你比同龄人更胜一筹</p>
<p><strong>纪要</strong><br>
during the latest meeting，the following issues were addressed.<br>
If you find any errors or omissions, please contact me</p>
<p><strong>询问信</strong><br>
I am writing to seek your assistance to help...<br>
I hope you can kindly furnish me with specific details regarding the above-mentioned questions.<br>
I wonder if it would be convenient for you to do...</p>
<h1 id="大作文">大作文</h1>
<p>第一段：不用提出论点，只描述即可<br>
总体描述画面<br>
挖掘细节</p>
<p>第二段<br>
主题句，点题，引出下文<br>
论证+论据{<br>
背景、事实（现象）、反方观点、原因、结果<br>
因果、分类、举例<br>
}<br>
总结扣题</p>
<p>第三段<br>
结论<br>
两点建议/评论<br>
展望</p>
<h1 id="大作文积累">大作文积累</h1>
<p><strong>第一段</strong><br>
As is vividly depicted in the caricature<br>
The caricature depicts ....<br>
the caption indicates that... 文字说明...<br>
diagram 图表<br>
excerpt 选段<br>
the author assumes that</p>
<p><strong>第二段</strong><br>
the caricature is to illustrate that<br>
what the drawing intends to convey is that<br>
I cling to the idea that 我坚持... 的观点<br>
from my perspective<br>
it is of vital significance to be<br>
Take an example to illustrate....</p>
<p><strong>第三段</strong><br>
To sum up<br>
Only by doing so can we<br>
we should always be ready to</p>
<p>Love is a pearl  which will never perish from my heart</p>
]]></content>
    </entry>
</feed>