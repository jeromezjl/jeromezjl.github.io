<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jeromezjl.github.io</id>
    <title>Jerome</title>
    <updated>2023-06-05T13:05:22.162Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jeromezjl.github.io"/>
    <link rel="self" href="https://jeromezjl.github.io/atom.xml"/>
    <subtitle>Jerome&apos;s blog</subtitle>
    <logo>https://jeromezjl.github.io/images/avatar.png</logo>
    <icon>https://jeromezjl.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Jerome</rights>
    <entry>
        <title type="html"><![CDATA[【音乐】即兴练习思路]]></title>
        <id>https://jeromezjl.github.io/post/lian-qin/</id>
        <link href="https://jeromezjl.github.io/post/lian-qin/">
        </link>
        <updated>2023-06-03T14:06:36.000Z</updated>
        <content type="html"><![CDATA[<p>B站琴友原文链接：<br>
<a href="https://t.bilibili.com/798087679282511889?share_from=dynamic&amp;share_medium=android&amp;share_plat=android&amp;share_source=WEIXIN&amp;share_tag=s_i&amp;timestamp=1685638014&amp;unique_k=JbGgziL">自学乐器真的有硬伤，那就是乐理真的感觉很难学......</a></p>
<p>你先尝试扒二十首歌，我说的扒不是你能跟着弹下来那么简单，你得知道你弹的什么，这一句旋律是什么，是套在哪个和弦里的。当你扒够100首歌的时候，你这些问题就都不是问题了</p>
<p>即兴呢其实就是要在前面的各种乐理基础上，加上你积累出的各种句子以及演奏技巧，跟着感觉弹出来的。<br>
所以现在问题就明了了，你的即兴苦恼源于没有这些基础和积累。最好找一个老师带着你</p>
<p>1、基础乐理—熟悉指板+即兴—和声学+即兴—配器法—实战编曲—混音、母带<br>
2、多听曲子，多学曲子，多扒曲子，海纳百川<br>
3、保持热爱</p>
<p>先在一个调里把指板吃透了就行 主要还是要掌握大小调已经各种调式音阶的相对音程 一味地练别人的solo一点用都没有（除非你会乐理知道人家在弹什么）</p>
<p>小调里的三五七和弦都会按吗 这个也比较基础</p>
<p>制定计划逼着自己去学，特别是乐理和编曲，乐理得实际应用才记得住，编曲得大量编才能熟练，制定计划每天练多少、课看多少、资料找多少。</p>
<p>学乐理就是少走弯路，但要是自己玩靠耳朵慢慢积累也不是不行，只是弹出来的东西可能就有点固定走不出自己听的最多的五声音阶，我原来学琴的时候老师不怎么讲乐理只有后来自己自学一点点基本属于文盲了[喜极而泣]，但是耳朵还不错 弹久了指板熟了基本听到什么想到什么能弹出来自己玩玩还挺乐。<br>
当年学的时候坑比老师很多，以至于我跟的最久的不怎么讲乐理的老师我还觉得教的很好了[喜极而泣]，多年之后重新学乐理挺头疼的，现在教学环境比原来好了如果是新入门钱包足有条件还是找个好老师少走弯路，但是自学好资源也多了 找不到好老师的话，自学也挺好 ，看自己能不能坚持吧<br>
然后多跟同好交流，即使没有老师和爱好者互相交流帮助也挺大的。</p>
<p>b站找lick library的视频，精通指板。我全自学的音乐，都半职业水平了</p>
<p>是的，乐理就是十二平均律和各种排列组合，不难，难的是持续的兴趣，精力投入，坐住板凳</p>
<p>别练什么视唱练耳，扒歌这些东西，你现在最要紧的是赶紧用你学的五声音阶即兴起来，跟着伴奏弹几个音比你练什么吉他曲子都有效果，把他玩起来才是你学会即兴的最重要的一步，指板不是说练几个乐句，重复练爬几百上千遍音阶可以记住的，只有你即兴的多了，你才能想弹什么音就立马弹出来，找老师是最没有性价比的，浪费时间浪费金钱，你先试着跟着你喜欢的歌弹点旋律吧。这是我的经验之谈，我就是这样从只会弹唱到可以即兴的，不说很厉害，但是已经可以在各种流行歌曲里随意即兴了。</p>
<p>可以试试steve vai写的《吉他巫师 史蒂夫范的独门演奏心法》正版有点小贵，经济不允许可以某宝上买复印版四十几，比较通俗易懂不过是繁体，台湾出版的</p>
<p>买本人民音乐出版社的《吉他指板手册》，看不懂不翻页看完之后最基础的乐理就没啥问题了。但是想学更多的就得买别的教材了，到时候你就根据喜好自己找吧。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【DL】RNN | Attention | LSTM | Transformer]]></title>
        <id>https://jeromezjl.github.io/post/dl-rnn-or-attention-or-lstm-or-transformer/</id>
        <link href="https://jeromezjl.github.io/post/dl-rnn-or-attention-or-lstm-or-transformer/">
        </link>
        <updated>2023-06-01T06:35:52.000Z</updated>
        <content type="html"><![CDATA[<h1 id="rnn">RNN</h1>
<p><a href="https://zhuanlan.zhihu.com/p/30844905">一文搞懂RNN（循环神经网络）基础篇</a></p>
<p><a href="https://blog.csdn.net/bestrivern/article/details/90723524">RNN详解(Recurrent Neural Network)</a></p>
<p><a href="https://blog.csdn.net/weixin_45727931/article/details/114369073">Pytorch循环神经网络（RNN）快速入门与实战</a></p>
<h1 id="attention">Attention</h1>
<p><a href="https://www.bilibili.com/video/BV1q3411U7Hi/?spm_id_from=333.788.recommend_more_video.5&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">Attention、Transformer公式推导和矩阵变化</a></p>
<h1 id="lstm">LSTM</h1>
<p><a href="https://www.bilibili.com/video/BV1fp4y1t7Xb/?p=3&amp;spm_id_from=pageDriver&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">RNN &amp; LSTM (时间序列模型）</a></p>
<h1 id="transformer">Transformer</h1>
<p><a href="https://zhuanlan.zhihu.com/p/403433120">【Transformer】10分钟学会Transformer | Pytorch代码讲解 | 代码可运行</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[机器视觉]]></title>
        <id>https://jeromezjl.github.io/post/ji-qi-shi-jue/</id>
        <link href="https://jeromezjl.github.io/post/ji-qi-shi-jue/">
        </link>
        <updated>2023-05-30T09:09:04.000Z</updated>
        <content type="html"><![CDATA[<p><a href="cv-xueba.club">北邮鲁鹏资源</a></p>
<p>分辨率是 1024 x 768 则图像有 1024 x 768 个像素点</p>
<p>二进制图像：每个点用一个bit表示<br>
灰度图：每个点用一个Byte表示，范围 0-255<br>
RGB图像：每个点由R\G\B三个信息表示，三个Byte，范围 0-255</p>
<p><strong>卷积核/滤波核：filter kernel</strong><br>
卷积运算：对应点相乘再相加（对核内数据进行加权，然后赋给中心点）</p>
<p>在利用均值核对图像进行平滑处理的时候，考虑到距离中心点越远的点 对中心值影响越小。所以考虑使用高斯分布设置核内权重。</p>
<p><strong>高斯核</strong><br>
<a href="https://blog.csdn.net/u013066730/article/details/123112159">CSDN 文字讲解</a><br>
<a href="https://www.bilibili.com/video/BV15B4y1D7QJ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">B站高斯分布复习</a><br>
标准差σ越大，高斯分布的图像越扁平。对应高斯核可取值的范围就会增大。若在这同时增大高斯核的大小，则被用于计算的均值的范围变大，则得到的图像就会越模糊。<br>
当使用高斯滤波器进行图像处理时，W代表窗口的大小（也称为卷积核的尺寸），σ代表高斯函数的标准差（方差的平方根）。经验上，有一个常见的规则是W/2=3σ，它表示窗口的一半尺寸大约等于3倍的标准差。<br>
这个经验规则可以用于选择适当的窗口大小和标准差，以确保高斯滤波器在平滑图像的同时保持图像细节。具体而言，较大的窗口尺寸和较大的标准差可以产生更强烈的平滑效果，但可能会导致图像细节的丢失。相反，较小的窗口尺寸和较小的标准差可以保留更多的细节，但平滑效果会较弱。<br>
根据经验，W/2=3σ提供了一种简单的方法来选择窗口大小和标准差的相对关系，以获得平衡的结果。但需要注意的是，这只是一个经验规则，具体的选择还取决于特定的应用和图像处理的需求。在实际应用中，可能需要进行实验和调整以找到最适合的参数。</p>
<p><a href="https://blog.csdn.net/zjh12312311/article/details/109649188">cv2中的滤波，均值，高斯，中值，高通，低通，傅里叶变换</a></p>
<h1 id="canny算法边缘检测">Canny算法——边缘检测</h1>
<p><a href="https://www.bilibili.com/video/BV1nz4y197Qv?p=3&amp;spm_id_from=pageDriver&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">鲁鹏讲解</a><br>
<a href="https://blog.csdn.net/minjiuhong/article/details/89320225">CSDN文字讲解</a></p>
<p><strong>算法原理概述</strong><br>
<img src="https://jeromezjl.github.io/post-images/1685450396261.png" alt="" loading="lazy"></p>
<p><a href="https://blog.csdn.net/m0_51402531/article/details/121066693">OpenCV——Canny边缘检测（cv2.Canny()）</a></p>
<pre><code class="language-python">edges = cv.Canny( image, threshold1, threshold2[, apertureSize[, L2gradient]])
# threshold1为低阈值，threshold2为高阈值
</code></pre>
<h1 id="图像拟合-fitting">图像拟合 fitting</h1>
<p><strong>最小二乘法拟合</strong><br>
假设需要拟合一条线，通过最小二乘法可以求得这条线的方程，从而将像素点拟合成一条平滑的曲线。这样的应用场景很多，比如图像的边缘检测、图像的灰度平滑和曲线的修正等<br>
<a href="https://blog.csdn.net/MoreAction_/article/details/106443383?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163978851616780269814649%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=163978851616780269814649&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-6-106443383.pc_search_result_cache&amp;utm_term=%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95&amp;spm=1018.2226.3001.4187">一文让你彻底搞懂最小二乘法（超详细推导）</a></p>
<p><strong>鲁棒性最小二乘法</strong><br>
<img src="https://jeromezjl.github.io/post-images/1685457722865.png" alt="" loading="lazy"></p>
<p><strong>RANSAC——随机一致性采样</strong><br>
<a href="https://zhuanlan.zhihu.com/p/45532306">文字讲解</a><br>
在使用RANSAC找到内点之后，再利用找到的点，使用最小二乘法找到直线</p>
<p><code>RANSAC的利弊</code><br>
优点<br>
简单、适用于许多不同的问题，经常在实践中效果很好<br>
缺点<br>
有很多参数需要调整，对于较低的初始比率不能很好地工作(要迭代太多次，或者可能完全失败)<br>
在较小的样本数上不能总是得到一个良好的初始化模型</p>
<p><strong>霍夫变换 Hough transform</strong><br>
<a href="https://blog.csdn.net/leonardohaig/article/details/87907462">CSDN 文字讲解</a><br>
<a href="https://www.bilibili.com/video/BV1nz4y197Qv?p=4&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">鲁鹏讲解</a><br>
软投票法：给相邻的也投一票</p>
<p><a href="https://blog.csdn.net/on2way/article/details/47028969">Python下opencv使用笔记（十一）（详解hough变换检测直线与圆）</a></p>
<h1 id="特征提取">特征提取</h1>
<p><a href="https://blog.csdn.net/max_LLL/article/details/119728338">OpenCV中的几种角点检测方法</a></p>
<p><strong>Harris corner detection(角点检测)</strong><br>
<a href="https://www.bilibili.com/video/BV1Wb411b79B/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">B站讲解</a><br>
典型的数学建模过程，将实际问题用数学模型来表示，从而量化，让计算机理解。<br>
适用于：光照情况、位置、旋转、平移等变化ss<br>
不适用于：大小的变化</p>
<p>Blob detection</p>
<p><strong>SIFT(Scale Invariant Feature Transform)尺度不变特征变换</strong><br>
<a href="https://www.bilibili.com/video/BV1Qb411W7cK/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">B站讲解</a><br>
<img src="https://jeromezjl.github.io/post-images/1685946237448.png" alt="" loading="lazy"><br>
高斯金字塔：图像的尺度空间，用于模拟观察者距离物体的远近程度及模糊程度<br>
参数<br>
层数 octave：O = [log2(min(M,N))]-3   M、N：原图片的宽和高<br>
每层的图片数：S = n + 3   n：能找到的特征图数<br>
n的解释：<br>
假如每层用了五个不同的高斯核进行卷积，那么每层得到五个高斯后的图片（S）。<br>
相邻两个做差，得到四张差分后的图片。差分后的图片需要求梯度来找特征点，但是最上和最下两张找不到。所以n为S-3 = 2。也可以理解为，三个差分图为一组，对中间的那张进行计算，所以四张图片能找到上下两个组。</p>
<p><strong>SIFT 和 CNN 在图像检索任务上的比较</strong><br>
SIFT（尺度不变特征转换）和CNN（卷积神经网络）在图像检索任务中具有不同的特点和应用场景。下面是它们之间的一些比较：</p>
<ol>
<li>
<p>特征表示：</p>
<ul>
<li>SIFT：SIFT算法提取的特征是局部特征，主要关注图像中的关键点和它们的描述子。这些特征具有旋转不变性和尺度不变性，适用于处理图像中的局部变化和几何变换。</li>
<li>CNN：卷积神经网络通过多层卷积和池化操作，从整个图像中学习到的特征表示。这些特征是全局的，能够捕捉到图像中的语义信息和高层次的抽象特征。</li>
</ul>
</li>
<li>
<p>训练需求：</p>
<ul>
<li>SIFT：SIFT算法不需要大规模标注的训练数据，因为它是一种手工设计的特征提取算法。</li>
<li>CNN：卷积神经网络需要大规模的标注数据进行训练，以便通过反向传播算法学习到适合任务的特征表示。这需要大量的计算资源和训练时间。</li>
</ul>
</li>
<li>
<p>鲁棒性：</p>
<ul>
<li>SIFT：SIFT算法在旋转、缩放和仿射变换等情况下具有较强的鲁棒性。它对于图像中的局部变化和几何变换能够提取稳定的特征。</li>
<li>CNN：卷积神经网络在大规模训练的情况下可以具有一定的鲁棒性，但对于缩放和旋转等变换相对较敏感。</li>
</ul>
</li>
<li>
<p>性能：</p>
<ul>
<li>SIFT：SIFT算法在传统的图像检索任务中表现良好，并且在计算机视觉领域经过多年的研究和验证。它在小规模图像数据库上具有较高的检索准确性。</li>
<li>CNN：卷积神经网络在大规模图像数据集上进行端到端的训练，能够学习到更复杂的特征表示，并在一些特定的图像检索任务中达到更好的性能。例如，对于基于图像分类的图像检索任务，CNN通常能够获得更好的结果。</li>
</ul>
</li>
</ol>
<p>综上所述，SIFT适用于小规模图像数据库和对局部特征关注较多的场景，而CNN在大规模图像数据集和需要全局语义信息的任务中具有优势。实际应用中，可以根据具体任务的需求和数据的特点选择适合的方法或结合两者的优势进行</p>
<h1 id="alexnet">AlexNet</h1>
<p><a href="https://blog.csdn.net/guzhao9901/article/details/118552085">AlexNet网络结构详解（含各层维度大小计算过程）与PyTorch实现</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/467017218">手撕 CNN 经典网络之 AlexNet（理论篇）</a></p>
<h1 id="resnet">ResNet</h1>
<h1 id="swin">Swin</h1>
<h1 id="vgg">VGG</h1>
<h1 id="纹理">纹理</h1>
<p>常见任务：<br>
·从图像纹理估计表面方向或形状<br>
·根据纹理线索进行分割/分类 分析，表示纹理<br>
·将纹理一致的图像区域分组<br>
·生成新的纹理/图像</p>
<p>用不同方向的卷积核卷积图像，每个核为输出向量的一维，向量中的最大值对应的卷积核方向，就是该纹理的方向。</p>
<h1 id="分割-segmentation">分割  Segmentation</h1>
<p><strong>Mean shift</strong><br>
<a href="https://blog.csdn.net/google19890102/article/details/51030884">简单易学的机器学习算法——Mean Shift聚类算法</a><br>
找局部密度最高的点</p>
<p>Mean shift算法是一种非参数的聚类算法，其主要用于数据聚类和密度估计。以下是Mean shift算法的基本流程：</p>
<ol>
<li>初始化：选择一个初始种子点，作为每个聚类的中心点，并确定一个窗口大小。</li>
<li>密度估计：对于每个种子点，计算在窗口内的数据点的密度估计。可以使用核函数来衡量数据点在窗口内的密度，通常使用高斯核函数。</li>
<li>平移向量计算：计算每个数据点相对于种子点的平移向量。平移向量的计算方式是通过计算数据点在窗口内的质心（mean）和当前种子点的差异。</li>
<li>平移：将种子点沿着平移向量进行平移，更新种子点的位置。</li>
<li>收敛判断：重复步骤3和步骤4，直到种子点收敛于局部最大值（即平移向量接近于零）。这表示种子点已经找到了局部密度最大的聚类中心。</li>
<li>聚类：将收敛的种子点作为聚类的中心点，并将其他数据点分配到最近的聚类中心。</li>
<li>重复步骤1到步骤6，直到所有数据点都被分配到聚类中心。</li>
</ol>
<p>Mean shift算法的核心思想是通过不断迭代调整种子点的位置，使其向高密度区域移动，直到收敛于局部最大值。这样可以找到数据中的聚类中心，并将数据点分配到对应的聚类中心。</p>
<p><strong>归一化图割 Normalized cut</strong><br>
<a href="https://blog.csdn.net/qq_38476684/article/details/80553850">图像处理--归一化切割--(normalized cut)--Python实现</a></p>
<p>以下是Normalization Cut算法的完整详细步骤：</p>
<p>输入：图像（以像素矩阵表示），标准差σ</p>
<ol>
<li>将像素转换为向量：将图像中的每个像素表示为一个向量。对于灰度图像，可以使用像素的灰度值作为向量的元素；对于彩色图像，可以使用像素的颜色通道值作为向量的元素。</li>
<li>计算两两像素的距离：对于每对像素向量，使用选定的距离函数（如欧氏距离或曼哈顿距离）计算它们之间的距离。得到一个距离矩阵，其中每个元素表示两个像素之间的距离。</li>
<li>将距离映射到[0, 1]范围内：将距离映射到[0, 1]的范围内，可以使用公式 d' = (d - min_distance) / (max_distance - min_distance)，其中 d 是原始距离，d' 是映射后的距离，min_distance 和 max_distance 分别是所有像素对之间距离的最小值和最大值。</li>
<li>利用高斯核函数计算相似度：使用高斯核函数将距离转换为相似度。计算每对像素之间的相似度，可以使用公式 similarity = exp(-d'^2 / (2 * σ^2))，其中 d' 是映射后的距离，σ 是标准差。</li>
<li>生成相似度矩阵W（邻接矩阵）：将计算得到的相似度值填充到一个相似度矩阵中。矩阵的每个元素表示两个像素之间的相似度。注意，W是对称的。且对角线为0，因为相同点间距离为0。</li>
<li>构建拉普拉斯矩阵：根据相似度矩阵，构建拉普拉斯矩阵。拉普拉斯矩阵可以有多种形式，例如对称归一化拉普拉斯矩阵或非对称拉普拉斯矩阵。定义对角矩阵D，D的第n行不为0的元素为W第n行数值之和。</li>
<li>对拉普拉斯矩阵进行特征值分解：对构建的拉普拉斯矩阵进行特征值分解，得到特征值和对应的特征向量。(D-W)y = λDy；取第二小的特征值对应的y向量。</li>
<li>利用特征向量进行聚类或分割：根据特征向量的特定特征值，进行聚类或分割操作。可以使用聚类算法（如谱聚类）或基于特征向量的阈值操作来实现。设置门限值，假设为1，低于1的为一类，高于1的为另一类。</li>
<li>输出分割结果：根据聚类或分割的结果，将图像中的像素分为不同的区域或类别。可以根据特征向量的某个阈值或聚类算法的结果将像素分配到不同的分割区域或类别。</li>
<li>可选的后处理：根据需要，可以进行一些后处理步骤来进一步优化分割结果。例如，可以应用边缘平滑技术来消除分割边界上的噪声或不连续性。</li>
<li>输出最终结果：将最终的图像分割结果作为算法的输出，可以是标记每个像素所属区域或类别的图像。</li>
</ol>
<p><strong>Minimum Cut</strong><br>
<a href="https://blog.csdn.net/mmm_jsw/article/details/83787395">图像分割经典算法--《最小割最大流》（Minimum Cut——Max Flow）</a><br>
去除图中权重最小的边</p>
<h1 id="识别-recognition">识别 Recognition</h1>
<p><strong>BOW词袋模型应用于图像识别分类</strong><br>
词袋模型将图片分成小块，从而一定程度上解决了遮挡等问题<br>
一般步骤：</p>
<ul>
<li>
<p>特征提取<br>
类比一下上面文本特征的提取，把文本1这句话切成一个个单词，这个过程就是在提取这个文本的特征，那么在图像中提取特征也类似，就是把图像切成一个个的片（patch），每片当成该图像的特征。常用的特征提取方法有SIFT、LBP、SURF等。</p>
</li>
<li>
<p>生成字典/词袋（codebook）<br>
在上一步特征提取中我们得到了很多的特征点，我们不能把每个点都放进词袋吧，那么就需要想一个招找到这些点中具有代表性的几类点，这一般需要聚类方法来完成的。对全部特征点进行聚类，得到了几个聚类中心，这些聚类中心就是这些点的特征向量。这一步之后就得到了词袋。（不理解的可以类比一下上面文本形成词袋的过程，上面文本形成词袋是把所有单词都放进去了，但是对图像来说特征点太多不可能全部放进去，所以使用聚类把聚类中心就当成词袋中的点）。</p>
</li>
<li>
<p>根据词袋生成特征直方图<br>
对于每张图片都有大量的特征点，那么就把这些点对照着上面得到的词袋统计出来，这样每张图片都会得到一个特征直方图，可以参考一下上面文本直方图。</p>
</li>
</ul>
<p><strong>空间金字塔算法（Spatial Pyramid）</strong><br>
一种用于图像分类和目标识别的传统机器视觉算法，可以有效地处理不同尺度和大小的图像内容。下面是Spatial Pyramid算法的实现过程：</p>
<ol>
<li>
<p>提取特征：首先，对输入图像进行特征提取。常用的特征提取方法包括SIFT（尺度不变特征变换）、HOG（方向梯度直方图）和LBP（局部二值模式）等。这些方法可以提取图像中的局部特征，用于后续的分析和处理。</p>
</li>
<li>
<p>划分金字塔：接下来，将图像划分为不同层级的金字塔结构。每个金字塔层级对应着不同的尺度和大小。通常，金字塔层级的数量和大小是预先定义好的，例如2层、3层或更多。</p>
</li>
<li>
<p>分块统计：对于每个金字塔层级，将图像分割为固定大小的块。这些块可以是正方形或矩形的区域。然后，在每个块内计算特征的统计信息。这可以包括直方图、均值、方差等。通过这种方式，可以捕捉到图像在不同空间位置的局部特征。</p>
</li>
<li>
<p>特征融合：将每个金字塔层级中的特征统计信息进行融合。一种常见的方法是将不同层级的特征串联起来，形成一个综合的特征向量。这样可以保留不同尺度和大小的信息，从而更好地描述图像的内容。</p>
</li>
<li>
<p>分类器训练：使用融合后的特征向量来训练分类器，例如支持向量机（SVM）、随机森林（Random Forest）或神经网络等。分类器可以根据提供的训练数据学习图像类别的模式，并用于对新图像进行分类和识别。</p>
</li>
<li>
<p>图像分类：对于待分类的新图像，首先进行与训练图像相同的特征提取和金字塔分块过程。然后，将提取到的特征输入训练好的分类器中进行预测。分类器会输出图像所属的类别标签。</p>
</li>
</ol>
<p>Spatial Pyramid算法通过在不同层级和块上进行特征统计和融合，可以有效地捕捉到图像的局部和全局信息。这种方法在处理尺度变化和多尺度目标时具有优势，并且对于不同大小的图像也具有较好的鲁棒性。</p>
<p><strong>Boosting（增强学习算法）</strong><br>
一种集成学习方法，旨在通过组合多个弱分类器来构建一个更强大的分类器。Boosting算法通过迭代的方式逐步改进分类器的准确性，将先前分类器的错误样本权重增加，并对分类错误的样本进行重点关注。</p>
<p>以下是Boosting算法的简要实现过程：</p>
<ol>
<li>
<p>初始化权重：对于包含N个训练样本的训练集，初始化每个样本的权重为相等值（1/N）。</p>
</li>
<li>
<p>迭代训练：进行T轮迭代，每一轮迭代中都训练一个弱分类器。</p>
</li>
<li>
<p>弱分类器训练：在每一轮迭代中，根据当前样本权重，使用训练集训练一个弱分类器。弱分类器通常是一个性能较差的分类器，如决策树桩（仅有一层决策树）或者简单的线性分类器。</p>
</li>
<li>
<p>分类器权重：根据弱分类器的错误率（分类错误的样本比例）计算其权重。错误率越低的弱分类器获得的权重越高，能够对分类结果做出更大的贡献。</p>
</li>
<li>
<p>更新样本权重：根据弱分类器的权重调整训练样本的权重。被错误分类的样本权重会增加，而被正确分类的样本权重会减少。这样，下一轮迭代时，错误分类的样本会受到更多关注。</p>
</li>
<li>
<p>结合弱分类器：将每个弱分类器按照其权重进行加权组合，得到最终的强分类器。强分类器通过累加弱分类器的预测结果，以投票或加权平均的方式进行最终分类。</p>
</li>
<li>
<p>重复迭代：重复步骤3至步骤6，直到达到预定的迭代次数T或者满足某个停止条件（如达到预期准确率）。</p>
</li>
</ol>
<p>Boosting算法通过多次迭代，逐步改进分类器的性能，重点关注那些难以分类的样本。它的优点在于能够构建出具有较高准确性的分类器，并且对于噪声和复杂数据集有一定的鲁棒性。著名的Boosting算法包括AdaBoost（自适应Boosting）和Gradient Boosting（梯度提升）。</p>
<p><strong>Viola-Jones算法</strong><br>
一种用于实时目标检测的传统机器视觉算法。它由Paul Viola和Michael Jones于2001年提出，被广泛应用于人脸检测。Viola-Jones算法基于Haar特征和级联分类器的概念，其实现过程如下：</p>
<ol>
<li>
<p>Haar特征：Haar特征是一种基于图像局部区域的特征描述符。它可以用于描述图像中的边缘、线段、角等特征。Haar特征可以通过在图像上滑动不同大小和位置的滑窗，并计算窗口内不同区域的像素和来表示。</p>
</li>
<li>
<p>积分图像：为了加速特征计算，Viola-Jones算法使用积分图像（Integral Image）进行快速计算。积分图像可以在常数时间内计算出任意矩形区域的像素和，使得特征计算的复杂度降低。</p>
</li>
<li>
<p>Adaboost训练：使用Adaboost算法，Viola-Jones算法训练了一个级联分类器。级联分类器由多个弱分类器组成，每个弱分类器都是一个基于Haar特征的简单二分类器。Adaboost算法通过迭代训练，在每一轮迭代中调整样本的权重，使得错误分类的样本得到更多关注。</p>
</li>
<li>
<p>特征选择：在每一轮迭代中，Viola-Jones算法通过选择具有最小错误率的特征来构建弱分类器。这样可以选择最具区分性的特征，以便有效地区分目标和非目标区域。</p>
</li>
<li>
<p>级联结构：为了提高检测速度，Viola-Jones算法采用了级联的结构。级联分类器将所有弱分类器按顺序组织成级联的多个阶段。每个阶段都具有不同的分类器数量和阈值，以逐步过滤出非目标区域，减少检测的计算量。</p>
</li>
<li>
<p>移动窗口检测：在测试阶段，Viola-Jones算法使用移动窗口技术在图像上滑动不同大小的窗口，对每个窗口进行分类器的评估。通过级联结构和快速特征计算，可以高效地排除大多数非目标窗口，并快速识别出目标窗口。</p>
</li>
</ol>
<p>Viola-Jones算法具有高速和高准确性的特点，尤其在人脸检测方面表现出色。它被广泛应用于实时的图像和视频处理应用中，如人脸识别、表情分析和眼部追踪等。然而</p>
<h1 id="三维重建">三维重建</h1>
<p><strong>摄像机模型</strong><br>
通过多张图片重构三维场景。无人驾驶车、地图等。<br>
摄像机几何</p>
<p><strong>相机标定</strong><br>
找到二维和三维点之间的对应关系，用于计算相机的内参数</p>
<h1 id="计算摄影学">计算摄影学</h1>
<p><a href="https://www.zhihu.com/tardis/zm/art/51490200?source_id=1005">计算摄影学及本专栏介绍</a><br>
<a href="https://www.zhihu.com/question/427425910">计算成像(computational photography)方向的就业前景如何？</a><br>
<a href="https://www.bilibili.com/video/BV1VA4y1Z7DG/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">iPhone 13系列解读之二——让我们聊聊计算摄影</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【DL】深度学习的一般步骤]]></title>
        <id>https://jeromezjl.github.io/post/shen-du-xue-xi-de-yi-ban-bu-zou/</id>
        <link href="https://jeromezjl.github.io/post/shen-du-xue-xi-de-yi-ban-bu-zou/">
        </link>
        <updated>2023-05-19T07:05:13.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/66021413">快速搞定 epoch, batch, iteration</a><br>
<a href="https://link.zhihu.com/?target=http%3A//playground.tensorflow.org">深度学习模拟网站，可观察参数变化对训练的影响</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】BiLSTM-CRF算法]]></title>
        <id>https://jeromezjl.github.io/post/nlp-bilstm-crf-suan-fa/</id>
        <link href="https://jeromezjl.github.io/post/nlp-bilstm-crf-suan-fa/">
        </link>
        <updated>2023-05-15T14:27:05.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/u010366748/article/details/113784204">BiLSTM-CRF实现中文命名实体识别（NER）</a></p>
<p><strong>概述</strong><br>
BiLSTM-CRF（Bidirectional Long Short-Term Memory - Conditional Random Field）是一种深度学习算法，常用于序列标注任务，如命名实体识别、词性标注等。BiLSTM-CRF结合了双向长短时记忆网络（BiLSTM）和条件随机场（CRF）两种技术，具有较强的建模能力和预测准确性。</p>
<p>BiLSTM是一种递归神经网络，可以捕捉序列中前后文的依赖关系。它由两个LSTM（Long Short-Term Memory）层组成，分别从左向右和从右向左处理输入序列，然后将它们的输出拼接起来。这样，每个时间步的输出包含了当前时刻及其前后若干时刻的信息，更好地表达了序列的语义。</p>
<p>CRF是一种概率模型，用于对序列标注结果进行建模，考虑标签之间的关联性和约束条件，可以使得标注结果更加合理和连贯。在BiLSTM-CRF中，CRF层接受BiLSTM层的输出作为输入，并且通过联合学习的方式，将BiLSTM层的输出和CRF层的标注结果进行训练，以最大化标注的准确性。</p>
<p>BiLSTM-CRF的训练过程通常采用反向传播算法，以最小化模型对标注数据的损失。在测试阶段，通过在CRF层上使用维特比算法，找到最可能的标注序列，作为模型的预测结果。</p>
<p>总之，BiLSTM-CRF算法在序列标注任务中表现出了良好的性能，能够捕捉序列中的长距离依赖关系和标签之间的约束关系，从而提高了模型的预测准确性。</p>
<p><strong>命名实体</strong><br>
在自然语言处理中，命名实体（Named Entity）是指具有特定语义的实体，如人名、地名、组织机构名、时间、数量、货币等。命名实体识别（Named Entity Recognition，NER）是一种信息抽取技术，用于自动识别文本中的命名实体，并将其分类为预定义的类型。</p>
<p>命名实体识别在信息检索、机器翻译、问答系统、自然语言生成等领域中有着广泛的应用。例如，在搜索引擎中，将用户查询中的命名实体与数据库中的实体进行匹配，可以帮助用户更快地找到所需信息。在机器翻译中，识别源文本中的命名实体可以帮助翻译系统更准确地理解句子的含义，从而提高翻译质量。</p>
<p>命名实体识别通常使用基于规则、基于统计的方法或基于深度学习的方法。其中，基于深度学习的方法，如BiLSTM-CRF等模型，因其在序列标注任务中的优越表现，已经成为了命名实体识别的主流方法。</p>
<p><strong>序列标注任务</strong><br>
序列标注任务是一种自然语言处理任务，旨在将输入序列中的每个元素标注为特定的类别。常见的序列标注任务包括词性标注、命名实体识别、情感分析、语义角色标注等。</p>
<p>在序列标注任务中，输入序列通常是一个由单词或字符组成的序列，每个单词或字符都要被标注为特定的类别。标注的类别可以是预定义的固定类别，例如名词、动词、形容词等，也可以是根据任务需要定义的自定义类别，例如人名、地名、组织机构名等。</p>
<p>序列标注任务通常使用监督学习的方法进行模型训练，例如最大熵模型、条件随机场、递归神经网络等。在最近几年，基于深度学习的方法，如卷积神经网络（CNN）、循环神经网络（RNN）和其变体，如LSTM、GRU等，已经成为序列标注任务中最有效的方法之一，取得了很好的效果。</p>
<p>序列标注任务在自然语言处理中有着广泛的应用，如文本分类、机器翻译、信息抽取、问答系统等。</p>
<p><strong>BIO-三位序列标注法（BIO-3）</strong><br>
BIO-三位序列标注法（BIO-3）是一种常用于序列标注任务的标注方法，特别在命名实体识别（NER）任务中广泛应用。该方法将每个标记分为三个部分：B（Beginning）、I（Inside）、O（Outside）。下面对BIO-3的含义进行解释：</p>
<p>B（Beginning）：表示实体的起始位置。在一个实体的第一个字上标记为B，例如&quot;B-Person&quot;表示一个人名实体的起始位置。</p>
<p>I（Inside）：表示实体的中间位置。在一个实体的非起始字上标记为I，例如&quot;I-Person&quot;表示一个人名实体的中间或结束位置。</p>
<p>O（Outside）：表示不属于任何实体的标记，即普通文本部分。</p>
<p>通过使用BIO-3标记法，我们可以准确地表示实体在文本中的起始和结束位置。这种方法的主要优点是灵活性，因为它可以处理不同长度和类型的实体。</p>
<p>除了BIO-3，还有其他常见的序列标注方法，包括：</p>
<p>IOB（Inside-Outside-Beginning）：与BIO-3类似，但使用I（Inside）和B（Beginning）标记来表示实体的起始和中间位置。</p>
<p>IOB2：与IOB方法类似，但在一段连续的实体标记序列中，每个实体的第一个字都标记为B，而后续的字标记为I。</p>
<p>IOE（Inside-Outside-End）：与BIO-3类似，但使用I（Inside）和E（End）标记来表示实体的中间和结束位置。</p>
<p>IO：只有I（Inside）和O（Outside）两个标记，没有明确的起始标记。</p>
<p>这些标注方法都是为了在序列标注任务中准确表示实体的位置和边界。具体选择哪种标注方法取决于任务的需求和数据集的特点。</p>
<p><a href="https://zhuanlan.zhihu.com/p/367995480"> 测试集、训练集、开发集的区别</a><br>
<a href="https://zhuanlan.zhihu.com/p/148813079">CRF条件随机场的原理、例子、公式推导和应用</a><br>
<a href="https://zhuanlan.zhihu.com/p/44042528">最通俗易懂的BiLSTM-CRF模型中的CRF层介绍</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【ML】KNN | K-means]]></title>
        <id>https://jeromezjl.github.io/post/k-means/</id>
        <link href="https://jeromezjl.github.io/post/k-means/">
        </link>
        <updated>2023-05-10T13:27:56.000Z</updated>
        <content type="html"><![CDATA[<h1 id="knnk-最近邻">KNN（K-最近邻）</h1>
<p><a href="https://www.bilibili.com/video/BV1Ma411F7Y4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">B站讲解</a><br>
<a href="https://blog.csdn.net/codedz/article/details/108862498">KNN算法详解及实现</a><br>
<a href="https://zhuanlan.zhihu.com/p/341572059">史上最全面K近邻算法/KNN算法详解+python实现</a></p>
<p><code>总结：</code></p>
<ol>
<li>有监督学习</li>
<li>用于分类和回归任务</li>
<li>物体类别由旁边最近的K个样本决定</li>
</ol>
<h1 id="k-meansk-均值">K-means（K-均值）</h1>
<p><a href="https://www.bilibili.com/video/BV1mf4y1k7UC/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">B站讲解</a><br>
<a href="https://www.zhihu.com/tardis/zm/art/158776162?source_id=1005">K-means（K-均值）算法的原理、Python实现和应用</a></p>
<p><code>总结：</code></p>
<ol>
<li>无监督学习</li>
<li>用于聚类</li>
<li>K为簇的数量</li>
</ol>
<h1 id="辨析">辨析</h1>
<p>相似点：<br>
K-means和KNN都是基于距离度量的算法。它们使用距离来衡量数据点之间的相似性或距离。<br>
K-means和KNN都使用K值来控制算法的行为。K-means中的K代表聚类的数量，KNN中的K代表邻居的数量。</p>
<p>不同点：<br>
目标：K-means旨在将数据点划分为不同的聚类，使同一聚类内的数据点相似度较高，不同聚类之间的相似度较低。而KNN旨在通过找到最近的K个邻居来进行分类或回归预测。<br>
学习方式：K-means是一种迭代的聚类算法，通过最小化聚类内部的方差来更新聚类中心，直到达到收敛条件。KNN是一种基于实例的学习方法，通过存储和比较训练集中的实例来进行预测。<br>
数据需求：K-means通常要求数据点能够表示为数值向量，且距离度量可定义。KNN对数据的要求较少，可以处理不同类型的特征和度量方法。<br>
算法复杂度：K-means的计算复杂度较低，但对初始聚类中心的选择敏感，可能会收敛到局部最优解。KNN的计算复杂度较高，因为需要计算每个测试样本与所有训练样本之间的距离。</p>
<p>总结而言，K-means和KNN是不同类型的机器学习算法，K-means用于聚类，而KNN用于分类和回归预测。它们在目标、学习方式、数据需求和算法复杂度等方面有显著的区别。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【ML】分类模型的评估]]></title>
        <id>https://jeromezjl.github.io/post/hun-yao-ju-zhen-confusion-matrix/</id>
        <link href="https://jeromezjl.github.io/post/hun-yao-ju-zhen-confusion-matrix/">
        </link>
        <updated>2023-04-25T06:18:29.000Z</updated>
        <content type="html"><![CDATA[<p>#混淆矩阵 Confusion Matrix<br>
<a href="https://www.bilibili.com/video/BV1oz4y1R71a/?spm_id_from=333.337.search-card.all.click&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">B站入门讲解</a><br>
<a href="https://blog.csdn.net/SartinL/article/details/105844832">sklearn中混淆矩阵（confusion_matrix函数）的理解与使用</a><br>
运行博客二中的代码：</p>
<pre><code class="language-python">from sklearn.metrics import confusion_matrix

y_true = [&quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;bird&quot;]
y_pred = [&quot;ant&quot;, &quot;ant&quot;, &quot;cat&quot;, &quot;cat&quot;, &quot;ant&quot;, &quot;cat&quot;]
confusion_matrix(y_true, y_pred, labels=[&quot;ant&quot;, &quot;bird&quot;, &quot;cat&quot;])
</code></pre>
<pre><code class="language-python">array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]], dtype=int64)
</code></pre>
<p>labels表示，行，列的标签顺序为[&quot;ant&quot;, &quot;bird&quot;, &quot;cat&quot;]。通过观察对角线（预测正确的次数），第一个数据是ant被预测为ant的次数，为2次，bird被预测为bird的次数为0次，cat被预测为cat的次数为2次.</p>
<p><code>debug</code><br>
<a href="https://fixexception.com/scikit-learn/at-least-one-label-specified-must-be-in-y-true/">ValueError: At least one label specified must be in y_true</a></p>
<h1 id="准确率-accuracy-精确率-precision-召回率-recall-f1值">准确率 (Accuracy) 精确率 (Precision) 召回率 (Recall)  F1值</h1>
<p><a href="https://www.bilibili.com/video/BV1vt4y117Zz/?vd_source=3d9ada7d42c971c0c3f04a22270daf33">B站</a><br>
（模型）准确率：所有正确预测分类的数据 / 所有数据<br>
精确率：预测正确的正样本 / 所有预测为正的样本<br>
召回率：预测正确的正样本 / 测试集中所有正样本数</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【摄影】调色思路]]></title>
        <id>https://jeromezjl.github.io/post/she-ying-diao-se-si-lu/</id>
        <link href="https://jeromezjl.github.io/post/she-ying-diao-se-si-lu/">
        </link>
        <updated>2023-04-02T13:54:49.000Z</updated>
        <content type="html"><![CDATA[<p>降低纹理可以减少画面杂乱感，比如杂草背景<br>
背光人像可以通过提高清晰度提高人像亮度<br>
调节曝光要保证画面整体看起来和谐。比如白色色阶不能过于割裂<br>
如果遇到颜色过于单一，或者色彩不好平衡的时候，不妨试试黑白调色</p>
<p>调色工具<br>
<a href="https://www.chinavid.com/color.html">高级在线配色器</a><br>
<a href="https://photokit.com/colors/eyedropper/?lang=zh">屏幕取色器</a></p>
<p>色卡生成工具<br>
<a href="https://photokit.com/colors/palette-generator/?lang=zh">调色板生成器1</a><br>
<a href="https://colors.dopely.top/image-color-picker/">调色板生成器2</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】BPE]]></title>
        <id>https://jeromezjl.github.io/post/bpe/</id>
        <link href="https://jeromezjl.github.io/post/bpe/">
        </link>
        <updated>2023-03-30T06:22:31.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_43902773/article/details/115191790">基于BPE的汉语tokenization</a></p>
<h1 id="基于bpe的子词压缩">基于BPE的子词压缩</h1>
<p>对于英文语料来讲，特别是在预训练模型兴起之前，一种常见的分词方式是通过空格对英文语句直接进行分词。然而这种分词方式可能也会带来一些问题。</p>
<ol>
<li>英文单词由于时态、单复数、大小写等因素，可能具有多个单词变体，比如单词go具有这样的变体： going, gone, goes，单纯基于空格从语料中收集单词，可能会导致词表过大，进而导致模型学习过程中，需要设置较大的词向量矩阵，增加模型参数。</li>
<li>由于词表难以穷尽所有单词，以及网络中会出现一些新的词，导致某些词无法出现在词表中，即出现集外词（OOV）。<br>
BPE（Byte-Pair Encoding）是缓解这些问题的一种算法，其不再按照完整的单词进行分词，而是将单词划分成了子词（sub-word）的粒度。例如单词showed可以被划分为show和ed， 如此做法，可以有效缩减单词个数，同时通过拆解子词也能够缓解OOV问题。图1展示了一种BPE算法效果的示例，一方面通过右侧的子词组合可以表示左侧任意一个单词，另一方面通过子词的表示大大减小了原本词表的大小。<br>
<img src="https://jeromezjl.github.io/post-images/1680157576369.png" alt="" loading="lazy"><br>
图1 BPE算法示例</li>
</ol>
<h1 id="12-实现流程">1.2 实现流程</h1>
<p>如图2所示，使用BPE算法进行对文本进行分词，首先需要根据英文语料构建BPE的子词词表，根据此词表即可对给定的文本序列进行编码，即分词，获取分词后的文本序列。同时提供根据编码后的结果还原原始语句的方法。<br>
<img src="https://jeromezjl.github.io/post-images/1680157622297.png" alt="" loading="lazy"><br>
图2 BPE实现流程</p>
<h1 id="13-词表构建">1.3 词表构建</h1>
<p>词表构建是BPE算法的核心，首先需要准备一批语料，然后从语料中逐步统计词频，构建BPE子词词表。具体来讲，首先需要将训练数据中的每个单词切分成字符作为初始子词，并统计语料中的子词初始化子词词表。接下来，可以按照如下步骤逐步迭代：</p>
<ol>
<li>统计每一个连续子词对的出现频率，选择最高频子词对合并成新的子词，并将该子词对加入词表中；</li>
<li>根据最高频子词对，将语料中的这两个相邻子词进行合并；</li>
<li>如果组成最高频子词对的子词在原始语料中不再存在，则在词表中进行删除；</li>
<li>重复第1-3步直到达到设定的子词词表大小或迭代次数；<br>
下面通过一个例子说明如何构造子词词典，假设通过统计获得了如下预处理好的语料库，其中每个单词中的字符通过空格进行分割为子词，同时单词后使用</w>作为单词结尾符号：</li>
</ol>
<pre><code class="language-python">train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n i n g &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a n g u a g e &lt;/w&gt;': 3,'p r o c e s s i n g &lt;/w&gt;':7}
</code></pre>
<p>利用以上训练数据，初始化子词词表为：</p>
<pre><code class="language-python">bpe_vocab = {'a', 'e', 'p', '&lt;/w&gt;', 'g', 'o', 's', 'l', 'r', 'u', 'd', 'n', 'i', 't', 'c'}
</code></pre>
<p>接下来，便可以逐步统计最高频的相邻子词对，并对训练数据进行子词合并。</p>
<p>第1次迭代： 最高频连续子词对&quot;n&quot;和&quot;g&quot;出现了7+3+7=17次，合并成&quot;ng&quot;加入词表。&quot;n&quot;和&quot;g&quot;在语料库中依旧存在，因此不需要在词表中删除，语料库和词表在本次迭代之后的结果为：</p>
<pre><code class="language-python">train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n i ng &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3,'p r o c e s s i ng &lt;/w&gt;':7}
bpe_vocab = {'a', 'e', 'p', '&lt;/w&gt;', 'g', 'o', 's', 'l', 'r', 'u', 'd', 'n', 'i', 't', 'c', 'ng'}
</code></pre>
<p>第2次迭代： 最高频连续子词对&quot;i&quot;和&quot;ng&quot;出现了7+7=14次，合并成&quot;ing&quot;加入词表。子词&quot;i&quot;在语料库中不再存在，因此在词表中进行删除，语料库和词表在本次迭代之后的结果为：</p>
<pre><code class="language-python">train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n ing &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3,'p r o c e s s ing &lt;/w&gt;':7}
bpe_vocab = {'a', 'e', 'p', '&lt;/w&gt;', 'g', 'o', 's', 'l', 'r', 'u', 'd', 'n', 't', 'c', 'ng', 'ing'}
</code></pre>
<p>第3次迭代： 最高频连续子词对&quot;ing&quot;和&quot;</w>&quot;出现了7+7=14次，合并成&quot;ing</w>&quot;加入词表。&quot;ing&quot;在语料库中不再存在，因此在词表中进行删除，语料库和词表在本次迭代之后的结果为：</p>
<pre><code class="language-python">train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3,'p r o c e s s ing&lt;/w&gt;':7}
bpe_vocab = {'a', 'e', 'p', '&lt;/w&gt;', 'g', 'o', 's', 'l', 'r', 'u', 'd', 'n', 't', 'c', 'ng','ing&lt;/w&gt;'}
</code></pre>
<p>重复以上迭代过程，直到子词词表规模达到预先设定的大小或下一个最高频的子词对出现频率为1。</p>
<p>首先，定义函数get_subwords，用以统计子词以及对应的词频，并获取初始化后的子词词表bpe_vocab。</p>
<pre><code class="language-python">import re
import collections

def get_subwords(data):
    &quot;&quot;&quot;
    统计子词以及对应的词频
    &quot;&quot;&quot;
    subwords = collections.defaultdict(int)
    for word, freq in data.items():
        for subword in word.split():
            subwords[subword] += freq

    return subwords

train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n i n g &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a n g u a g e &lt;/w&gt;': 3,'p r o c e s s i n g &lt;/w&gt;':7}
subwords = get_subwords(train_data)
# 获取初始化的子词词表
bpe_vocab = set(subwords.keys())
print(&quot;词表：&quot;, bpe_vocab)
</code></pre>
<pre><code class="language-python">词表： {'d', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'i', 'g', 'c', 'r', 'l', 't', 'n', 'p', 'e'}
</code></pre>
<p>接下来，在构造词表过程中，需要统计相邻子词对的词频，以便获取最高频的词对，代码实现如下。</p>
<pre><code class="language-python">def get_pair_with_frequency(data):
    &quot;&quot;&quot;
    获取子词对以及子词集合
    &quot;&quot;&quot;
    pairs = collections.defaultdict(int)
    for word, freq in data.items():
        sub_words = word.split()
        for i in range(len(sub_words)-1):
            pair = (sub_words[i],sub_words[i+1])
            pairs[pair] += freq
    return pairs

pairs = get_pair_with_frequency(train_data)
print(&quot;子词词对：&quot;, pairs)
best_pair = max(pairs, key=pairs.get)
print(&quot;当前最高频的子词对: &quot;, best_pair)
</code></pre>
<pre><code class="language-python">子词词对： defaultdict(&lt;class 'int'&gt;, {('d', 'e'): 5, ('e', 'e'): 5, ('e', 'p'): 5, ('p', '&lt;/w&gt;'): 5, ('l', 'e'): 7, ('e', 'a'): 7, ('a', 'r'): 7, ('r', 'n'): 7, ('n', 'i'): 7, ('i', 'n'): 14, ('n', 'g'): 17, ('g', '&lt;/w&gt;'): 14, ('n', 'a'): 6, ('a', 't'): 6, ('t', 'u'): 6, ('u', 'r'): 6, ('r', 'a'): 6, ('a', 'l'): 6, ('l', '&lt;/w&gt;'): 6, ('l', 'a'): 3, ('a', 'n'): 3, ('g', 'u'): 3, ('u', 'a'): 3, ('a', 'g'): 3, ('g', 'e'): 3, ('e', '&lt;/w&gt;'): 3, ('p', 'r'): 7, ('r', 'o'): 7, ('o', 'c'): 7, ('c', 'e'): 7, ('e', 's'): 7, ('s', 's'): 7, ('s', 'i'): 7})
当前最高频的子词对:  ('n', 'g')
</code></pre>
<p>接下来，根据获取的最高频子词对，对训练语料中的相应子词进行合并，代码实现如下。</p>
<pre><code class="language-python">def merge_data_with_pair(pair, data):
    &quot;&quot;&quot;
    将语料中的最高频子词对进行合并
    输入：
        - pair: 最高频子词词对
        - data: 字典形式，统计好的输入语料
    &quot;&quot;&quot;
    result = {}
    bigram = re.escape(' '.join(pair))
    p = re.compile(r'(?&lt;!\S)' + bigram + r'(?!\S)')
    for word in data:
        merged_word = p.sub(''.join(pair), word)
        result[merged_word] = data[word]
    return result

train_data = merge_data_with_pair(best_pair, train_data)
print(&quot;语料库: &quot;, train_data)
</code></pre>
<pre><code class="language-python">语料库:  {'d e e p &lt;/w&gt;': 5, 'l e a r n i ng &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s i ng &lt;/w&gt;': 7}
</code></pre>
<p>最后，将最高频的子词对加入词表，对于不再存在于语料库中的子词在词表中进行删除。基于上述这流程，下面正式定义构建词表函数build_vocab，代码实现如下。</p>
<pre><code class="language-python">def build_vocab(train_data, num_merges):
    &quot;&quot;&quot;
    根据训练语料构建词表
    输入：
        - train_data: 字典形式，统计好的输入语料
        - num_merges: 迭代次数
    &quot;&quot;&quot;

    # 初始化词表
    subwords = get_subwords(train_data)
    bpe_vocab = set(subwords.keys())
    print(bpe_vocab, len(bpe_vocab))
    i = 1
    # 逐步生成词表
    for _ in range(num_merges):
        # 根据语料统计相邻子词对的词频
        pairs = get_pair_with_frequency(train_data)
        # 取频率最大的子词对, 如果pairs 为空或子词对的最大频次为1，则停止
        if not pairs:
            break
        best_pair = max(pairs, key=pairs.get)
        if pairs[best_pair] == 1:
            break
        # 合并语料
        train_data = merge_data_with_pair(best_pair, train_data)
        # 将子词加入词表中
        merged_word = &quot;&quot;.join(best_pair)
        bpe_vocab.add(merged_word)
        # 删除子词
        subwords = get_subwords(train_data)
        if best_pair[0] not in subwords:
            bpe_vocab.remove(best_pair[0])
        if best_pair[1] not in subwords:
            bpe_vocab.remove(best_pair[1])

        print(&quot;Iter - {}, 最高频子词对: {}&quot;.format(i, best_pair))
        print(&quot;训练数据: &quot;, train_data)
        print(&quot;词表: {}, {}\n&quot;.format(len(bpe_vocab), bpe_vocab))
        i += 1
    return bpe_vocab

num_merges = 14

train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n i n g &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a n g u a g e &lt;/w&gt;': 3,'p r o c e s s i n g &lt;/w&gt;':7}

bpe_vocab = build_vocab(train_data, num_merges)
print(&quot;词表: &quot;, bpe_vocab)
</code></pre>
<pre><code class="language-python">{'d', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'i', 'g', 'c', 'r', 'l', 't', 'n', 'p', 'e'} 15
Iter - 1, 最高频子词对: ('n', 'g')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'l e a r n i ng &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s i ng &lt;/w&gt;': 7}
词表: 16, {'d', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'i', 'g', 'c', 'r', 'ng', 'l', 't', 'n', 'p', 'e'}

Iter - 2, 最高频子词对: ('i', 'ng')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'l e a r n ing &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing &lt;/w&gt;': 7}
词表: 16, {'d', 'ing', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'g', 'c', 'r', 'ng', 'l', 't', 'n', 'p', 'e'}

Iter - 3, 最高频子词对: ('ing', '&lt;/w&gt;')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'l e a r n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 16, {'d', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'g', 'c', 'r', 'ng', 'l', 't', 'n', 'p', 'ing&lt;/w&gt;', 'e'}

Iter - 4, 最高频子词对: ('l', 'e')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'le a r n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 'le', 's', 'ng', 't', 'o'}

Iter - 5, 最高频子词对: ('le', 'a')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'lea r n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', '&lt;/w&gt;', 'g', 'p', 'e', 'lea', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't', 'o'}

Iter - 6, 最高频子词对: ('lea', 'r')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'lear n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'lear', 'ng', 't', 'o'}

Iter - 7, 最高频子词对: ('lear', 'n')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learn ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', '&lt;/w&gt;', 'g', 'learn', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't', 'o'}

Iter - 8, 最高频子词对: ('learn', 'ing&lt;/w&gt;')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't', 'o'}

Iter - 9, 最高频子词对: ('p', 'r')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'pr o c e s s ing&lt;/w&gt;': 7}
词表: 18, {'a', 'u', 'c', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'pr', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't', 'o'}

Iter - 10, 最高频子词对: ('pr', 'o')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'pro c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'pro', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't'}

Iter - 11, 最高频子词对: ('pro', 'c')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'proc e s s ing&lt;/w&gt;': 7}
词表: 16, {'proc', 'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't'}

Iter - 12, 最高频子词对: ('proc', 'e')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'proce s s ing&lt;/w&gt;': 7}
词表: 16, {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', 'proce', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't'}

Iter - 13, 最高频子词对: ('proce', 's')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'proces s ing&lt;/w&gt;': 7}
词表: 16, {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'proces', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't'}

Iter - 14, 最高频子词对: ('proces', 's')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'process ing&lt;/w&gt;': 7}
词表: 15, {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'process', 'ing&lt;/w&gt;', 'd', 'ng', 't'}

词表:  {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'process', 'ing&lt;/w&gt;', 'd', 'ng', 't'}
</code></pre>
<h1 id="14-语料编码">1.4 语料编码</h1>
<p>在获得子词词表之后，便可以根据该词表将文本序列进行编码，即分词。这里可以采用贪心的思想，根据子词词表中的子词长度对子词词表由大到小进行排序，然后对于一个待编码的单词，从前向后依次遍历词表中的子词，如果该子词在单词之后，则将该单词在子词位置进行切分，这样便可以获得最多三个单词子串：子词前的单词子串、子词串、子词后的单词子串，然后按照同样的思路继续遍历剩余的单词子串。如果在子词词表遍历完成之后，依然有一些单词子串没有被切分，则使用'<UNK>'进行替代。</p>
<p>下面来看一个例子，假设给定子词词表为：</p>
<pre><code class="language-python">[“ning&lt;/w&gt;”, “lear”, “deep&lt;/w&gt;”, “est&lt;/w&gt;”, “the&lt;/w&gt;”, “a&lt;/w&gt;”]
</code></pre>
<p>待分词的文本序列为:</p>
<pre><code class="language-python">[“the&lt;/w&gt;”, “deep&lt;/w&gt;”, “learning&lt;/w&gt;”]
</code></pre>
<p>则最后分词编码的结果为：</p>
<pre><code class="language-python">[“the&lt;/w&gt;”, “deep&lt;/w&gt;”, &quot;lear&quot;, “ning&lt;/w&gt;”]
</code></pre>
<p>接下来，先定义函数tokenize_word用于对单词进行编码。</p>
<pre><code class="language-python">import re

def tokenize_word(word, sorted_vocab, unknown_token='&lt;unk&gt;'):
    &quot;&quot;&quot;
    输入:
        - word: 待编码的单词
        - sorted_vocab: 排序后的子词词典
        - unknown_token: 不能被切分的子词替代符
    &quot;&quot;&quot;
    # 如果传入的词为空
    if word == &quot;&quot;:
        return []
    # 如果词表为空，则将输入的词替换为&lt;UNK&gt;
    if sorted_vocab == []:
        return [unknown_token] + len(string)

    word_tokens = []
    # 遍历词表拆分单词
    for i in range(len(sorted_vocab)):
        token = sorted_vocab[i]
        # 基于该token定义正则，同时将token里面包含句号的变成[.]
        token_reg = re.escape(token.replace('.', '[.]'))
        # 在当前word中进行遍历，找到匹配的token的起始和结束位置
        matched_positions = [(m.start(0), m.end(0)) for m in re.finditer(token_reg, word)]
        # 如果当前token没有匹配到相应串，则跳过
        if  len(matched_positions) == 0:
            continue
        
        # 获取匹配到的子串的起始位置
        end_positions = [matched_position[0] for matched_position in matched_positions]
        start_position = 0

        for end_position in end_positions:
            subword = word[start_position: end_position]
            word_tokens += tokenize_word(subword, sorted_vocab[i+1:], unknown_token)
            word_tokens += [token]
            start_position = end_position + len(token)
        # 匹配剩余的子串
        word_tokens += tokenize_word(word[start_position:], sorted_vocab[i+1:], unknown_token)
        break
    else:
        # 如果word没有被匹配，则映射为&lt;unk&gt;
        word_tokens = [unknown_token] * len(word)
    
    return word_tokens
</code></pre>
<p>定义函数tokenize用于对语句进行编码。</p>
<pre><code class="language-python">def tokenize(text, bpe_vocab):
    &quot;&quot;&quot;
    使用BPE对输入语句进行编码
    &quot;&quot;&quot;
    # 对子词词表按照子词长度进行排序
    sorted_vocab = sorted(bpe_vocab, key=lambda subword: len(subword), reverse=True)
    print(&quot;待编码语句: &quot;, text)
    tokens = []
    for word in text.split():
        word = word + &quot;&lt;/w&gt;&quot;
        word_tokens = tokenize_word(word, sorted_vocab, unknown_token='&lt;unk&gt;')
        tokens.extend(word_tokens)
    
    return tokens

text = &quot;natural language processing&quot;
tokens = tokenize(text, bpe_vocab)
print(&quot;词表: &quot;, bpe_vocab)
print(&quot;编码结果: &quot;, tokens)
</code></pre>
<pre><code class="language-python">待编码语句:  natural language processing
词表:  {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'process', 'ing&lt;/w&gt;', 'd', 'ng', 't'}
编码结果:  ['n', 'a', 't', 'u', 'r', 'a', 'l', '&lt;/w&gt;', 'l', 'a', 'ng', 'u', 'a', 'g', 'e', '&lt;/w&gt;', 'process', 'ing&lt;/w&gt;']
</code></pre>
<h1 id="15-语料解码">1.5 语料解码</h1>
<p>在将一串语句使用BPE进行编码后，如何还原成原来的语句呢。这种情况下，单词后设置的&lt;\w&gt;便起了作用。即可以一直合并分词后的子词，直到遇见&lt;\w&gt;便可以解码出一个完整单词。下面给出了一个例子。</p>
<p>假设使用BPE编码后的序列：</p>
<pre><code class="language-python">[“the&lt;/w&gt;”, “deep&lt;/w&gt;”, “lear”, “ning&lt;/w&gt;”]
</code></pre>
<p>则对应的解码结果为:</p>
<pre><code class="language-python">[&quot;the&quot;, &quot;deep&quot;,&quot;learning&quot;]
</code></pre>
<p>代码实现如下。</p>
<pre><code class="language-python">def restore(tokens):

    text = []
    word = []
    for token in tokens:
        if token[-4:] == &quot;&lt;/w&gt;&quot;:
            if token != &quot;&lt;/w&gt;&quot;:
                word.append(token[:-4])
            text.append(&quot;&quot;.join(word))
            word.clear()
        else:
            word.append(token)
    return text

tokens = [&quot;the&lt;/w&gt;&quot;, &quot;deep&lt;/w&gt;&quot;, &quot;lear&quot;, &quot;ning&lt;/w&gt;&quot;]
text = restore(tokens)
print(&quot;还原结果: &quot;, text)
</code></pre>
<pre><code class="language-python">还原结果:  ['the', 'deep', 'learning']
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【CV】视频目标检测]]></title>
        <id>https://jeromezjl.github.io/post/shi-pin-mu-biao-jian-ce/</id>
        <link href="https://jeromezjl.github.io/post/shi-pin-mu-biao-jian-ce/">
        </link>
        <updated>2023-03-10T05:51:59.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_40557160/article/details/109536612">视频目标检测VID论文及代码（更新至2020.12）</a><br>
<a href="https://zhuanlan.zhihu.com/p/94986199">写给小白的YOLO介绍</a><br>
<a href="https://blog.csdn.net/breeze_blows/article/details/105323491">视频目标检测(video object detection)简单综述</a><br>
<a href="https://blog.csdn.net/weixin_43702653/article/details/123973629?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167842568816782427467521%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=167842568816782427467521&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123973629-null-null.142%5Ev73%5Einsert_down4,201%5Ev4%5Eadd_ask,239%5Ev2%5Einsert_chatgpt&amp;utm_term=R-CNN&amp;spm=1018.2226.3001.4187">R-CNN史上最全讲解</a><br>
<a href="https://blog.csdn.net/qq_40716944/article/details/114822515">YOLO系列详解：YOLOv1、YOLOv2、YOLOv3、YOLOv4、YOLOv5、YOLOv6、YOLOv7</a></p>
]]></content>
    </entry>
</feed>