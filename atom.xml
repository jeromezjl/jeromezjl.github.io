<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jeromezjl.github.io</id>
    <title>Jerome</title>
    <updated>2024-03-25T05:10:21.387Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jeromezjl.github.io"/>
    <link rel="self" href="https://jeromezjl.github.io/atom.xml"/>
    <subtitle>Jerome&apos;s blog</subtitle>
    <logo>https://jeromezjl.github.io/images/avatar.png</logo>
    <icon>https://jeromezjl.github.io/favicon.ico</icon>
    <rights>All rights reserved 2024, Jerome</rights>
    <entry>
        <title type="html"><![CDATA[AIEnglish]]></title>
        <id>https://jeromezjl.github.io/post/aienglish/</id>
        <link href="https://jeromezjl.github.io/post/aienglish/">
        </link>
        <updated>2024-03-25T04:53:47.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>Artificial General（通用） Intelligence (AGI) represents the hypothetical（假想） ability of an AI system to understand, learn, and apply knowledge across a wide range of tasks at a level of complexity comparable to human intelligence. Unlike narrow AI designed for specific tasks, AGI would possess the versatility and adaptability to perform any intellectual task that a human being can. This includes reasoning, problem-solving, abstract thinking, understanding natural language, and learning from experience. Achieving AGI is considered a monumental milestone in AI research, marking the advent of machines with human-like cognitive abilities.</li>
</ol>
<p>人工通用智能（AGI）代表了一个AI系统的假想能力，即理解、学习并应用知识去完成广泛的任务，这些任务的复杂度与人类智能相当。与为特定任务设计的狭义人工智能不同，AGI将拥有执行人类可以执行的任何智力任务的多功能性和适应性。这包括推理、解决问题、抽象思考、理解自然语言以及从经验中学习。实现AGI被认为是AI研究的一个重要里程碑，标志着具有类似人类认知能力的机器的到来。</p>
<ol start="2">
<li>Supervised learning is a machine learning approach where models are trained on labeled data, meaning each input example is paired with the correct output. The model learns by comparing its predictions to the actual outputs during training, adjusting until it can accurately predict outcomes for unseen data. Unsupervised learning, conversely, involves training models on data without explicit instructions on what to predict. The model identifies patterns and structures within the data autonomously. Supervised learning is typically used for classification and regression tasks, while unsupervised learning is used for clustering, dimensionality reduction, and association rule learning.</li>
</ol>
<p>监督学习是一种机器学习方法，其中模型是在标注数据上训练的，这意味着每个输入实例都与正确的输出配对。模型通过在训练期间将其预测与实际输出进行比较来学习，并调整直到它能够准确预测未见数据的结果。相反，无监督学习涉及在没有关于应预测什么的明确指导的数据上训练模型。模型自主地识别数据中的模式和结构。监督学习通常用于分类和回归任务，而无监督学习用于聚类、降维和关联规则学习。</p>
<ol start="3">
<li>A Multilayer Perception (MLP) is a class of feedforward artificial neural network (ANN) that consists of at least three layers of nodes: an input layer, one or more hidden layers, and an output layer. Each node, except for input nodes, uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its architecture of multiple layers and nonlinear processing enables complex pattern recognition and decision-making, making it foundational to deep learning. Deep learning involves networks with many layers (deep architectures) that can learn hierarchical representations of data, significantly advancing capabilities in AI research and applications.</li>
</ol>
<p>多层感知机（MLP）是一种前馈人工神经网络（ANN），至少包括三层节点：一个输入层、一个或多个隐藏层以及一个输出层。除输入节点外，每个节点都使用非线性激活函数。MLP利用一种称为反向传播的监督学习技术进行训练。它的多层结构和非线性处理使得复杂的模式识别和决策成为可能，是深度学习的基础。深度学习涉及有许多层（深度架构）的网络，这些网络可以学习数据的层次化表示，显著推进了AI研究和应用能力。</p>
<ol start="4">
<li>Backpropagation is a cornerstone algorithm for training neural networks, particularly in deep learning. It operates by propagating the error backward from the output layer to the input layer, allowing the algorithm to adjust the weights of connections in order to minimize the error in predictions. This process involves two key phases: forward pass, where input data is fed through the network to generate output predictions, and backward pass, where the gradient of the loss function is computed with respect to each weight by the chain rule, enabling the network to learn from errors systematically. This iterative adjustment refines the model's accuracy over time.</li>
</ol>
<p>反向传播是训练神经网络，尤其是在深度学习中的基石算法。它通过将错误从输出层反向传播到输入层来运作，允许算法调整连接权重以最小化预测中的错误。这个过程涉及两个关键阶段：前向传播，输入数据通过网络生成输出预测；反向传播，利用链式规则计算损失函数的梯度相对于每个权重，使网络能够系统地从错误中学习。这种迭代调整随着时间提高了模型的准确性。</p>
<ol start="5">
<li>Overfitting is a common problem in machine learning, where a model learns the training data too well, including its noise and outliers, rather than generalizing from the pattern it should learn. This results in high accuracy on training data but poor performance on new, unseen data. Essentially, the model becomes overly complex, capturing spurious correlations that do not exist in real-world data. To combat overfitting, techniques such as cross-validation, regularization, and pruning can be used, along with ensuring a sufficient amount of diverse training data. Overfitting highlights the delicate balance between model complexity and its generalization ability.</li>
</ol>
<p>过拟合是机器学习中的一个常见问题，其中模型过于完美地学习了训练数据，包括其噪音和异常值，而不是从它应该学习的模式中泛化。这导致在训练数据上的高准确度但在新的、未见过的数据上的性能差。本质上，模型变得过于复杂，捕捉到了在现实世界数据中不存在的假相关性。为了对抗过拟合，可以使用交叉验证、正则化和剪枝等技术，同时确保有足够数量的多样化训练数据。过拟合突出了模型复杂度和其泛化能力之间微妙的平衡。</p>
<ol start="6">
<li>A Convolutional Neural Network (CNN) is a class of deep learning algorithm that can take in an input image, assign importance (learnable weights and biases) to various aspects or objects in the image, and differentiate from one another. The preprocessing required in a CNN is much lower compared to other classification algorithms. The architecture of a CNN is analogous to that of the connectivity pattern of neurons in the human brain and was inspired by the organization of the visual cortex. CNNs are primarily used in image recognition, image classification, object detection, and similar tasks, leveraging their ability to learn spatial hierarchies of features.</li>
</ol>
<p>卷积神经网络（CNN）是一种深度学习算法，可以接受输入图像，为图像中的不同方面或对象分配重要性（可学习的权重和偏差），并且彼此区分开来。与其他分类算法相比，CNN所需的预处理要少得多。CNN的架构类似于人脑神经元的连接模式，并且受到视觉皮层组织的启发。CNN主要用于图像识别、图像分类、对象检测以及类似任务，利用它们学习特征的空间层次结构的能力。</p>
<ol start="7">
<li>Deep Reinforcement Learning (DRL) combines deep learning and reinforcement learning principles to create systems that can learn to make decisions. Deep learning processes vast amounts of data through neural networks, enabling feature detection and recognition. Reinforcement learning, on the other hand, is about agents learning to make actions in an environment to achieve a goal, guided by rewards or penalties. DRL utilizes deep neural networks to interpret complex, high-dimensional inputs, allowing the agent to learn optimal actions from its experiences, without explicit programming. This approach has led to significant breakthroughs, such as mastering complex games and improving decision-making in robotics and autonomous vehicles.**</li>
</ol>
<p>深度强化学习（DRL）结合了深度学习和强化学习原理，创造了能够学习做出决策的系统。深度学习通过神经网络处理大量数据，使特征检测和识别成为可能。另一方面，强化学习是关于代理在环境中学习采取行动以实现目标，由奖励或惩罚指导。DRL利用深度神经网络来解释复杂的、高维输入，允许代理从经验中学习最优行动，无需显式编程。这种方法已经在如掌握复杂游戏和改善机器人与自动驾驶车辆的决策制定方面取得了重大突破。</p>
<ol start="8">
<li>In deep learning, activation functions are crucial for neural networks to learn complex patterns. They introduce non-linearity into the network, allowing it to model complicated relationships between inputs and outputs that linear equations cannot. Without activation functions, a neural network, regardless of its depth, would behave like a single-layer perceptron, only capable of solving linear problems. Activation functions, such as Sigmoid, ReLU, and Tanh, help decide whether a neuron should be activated or not, determining the output of neural networks based on input features. This enables deep learning models to tackle non-linear problems, like image recognition and natural language processing, effectively.**</li>
</ol>
<p>在深度学习中，激活函数对于神经网络学习复杂模式至关重要。它们为网络引入非线性，使其能够模拟输入与输出之间的复杂关系，而这是线性方程无法做到的。没有激活函数，无论神经网络的深度如何，都会表现得像一个只能解决线性问题的单层感知机。激活函数，如Sigmoid、ReLU和Tanh，帮助决定一个神经元是否应该被激活，决定了神经网络基于输入特征的输出。这使得深度学习模型能够有效地处理非线性问题，如图像识别和自然语言处理。</p>
<ol start="9">
<li>A generative model in artificial intelligence is an approach used to automatically generate new data instances that resemble a given set of data. Unlike discriminative models, which focus on determining the boundary between different classes, generative models learn the underlying distribution of input data, enabling them to produce new examples that could plausibly come from the original dataset. This ability makes generative models especially valuable in tasks such as image and text generation, data augmentation, and unsupervised learning. Popular examples of generative models include Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), which have been applied in creating realistic images, text-to-image synthesis, and more.</li>
</ol>
<p>在人工智能中，生成模型是一种用于自动生成类似于给定数据集的新数据实例的方法。与专注于确定不同类别之间边界的判别模型不同，生成模型学习输入数据的底层分布，使它们能够生成可能来自原始数据集的新例子。这种能力使得生成模型在图像和文本生成、数据增强和无监督学习等任务中特别有价值。流行的生成模型例子包括生成对抗网络（GANs）和变分自编码器（VAEs），这些已被应用于创造逼真的图像、文本到图像的合成等。</p>
<ol start="10">
<li>Transformer is a groundbreaking architecture in deep learning, introduced for dealing with sequential data, notably in natural language processing (NLP). Unlike its predecessors that relied on recurrence or convolutions, the transformer utilizes attention mechanisms to weigh the significance of different words within the input data. This allows it to capture complex dependencies and relationships within the data more effectively. The architecture comprises an encoder to process the input and a decoder for output generation. Transformers have led to significant advancements in tasks such as machine translation, text summarization, and language understanding, serving as the foundation for models like BERT and GPT.</li>
</ol>
<p>Transformer 是深度学习中的一种开创性架构，专门用于处理顺序数据，特别是在自然语言处理（NLP）中。与依赖于递归或卷积的前身不同，Transformer 利用注意力机制来权衡输入数据中不同单词的重要性。这使它能够更有效地捕捉数据内的复杂依赖关系。该架构包括一个编码器来处理输入和一个解码器来生成输出。Transformer 在机器翻译、文本摘要和语言理解等任务上取得了重大进展，为像BERT和GPT这样的模型提供了基础。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[复试项目]]></title>
        <id>https://jeromezjl.github.io/post/fu-shi-xiang-mu/</id>
        <link href="https://jeromezjl.github.io/post/fu-shi-xiang-mu/">
        </link>
        <updated>2024-03-23T13:15:13.000Z</updated>
        <content type="html"><![CDATA[<h1 id="gan">GAN</h1>
<p>使用 CIFAR-10 数据集，包含动物和交通工具的图片<br>
生成器和判别器都使用 CNN<br>
生成器：四层卷积，中间用 ReLU，最后用 Tanh<br>
判别器：四层卷积，中间用 ReLU，最后用 Sigmoid<br>
使用交叉熵损失函数<br>
先训练判别器，给判别器真实图片和假图片，分别带有标签，来更新判别器参数<br>
再训练生成器，让生成器生成图片，让判别器判断，更新生成器的参数，使判别器认为生成的是真实图片</p>
<h1 id="cnn-人脸识别">CNN 人脸识别</h1>
<p>首先进行三分类，小组同学三人，每人录制一个全方位的不同角度的面部视频，<br>
使用openCV对视频进行分割，获得3000张左右不同角度、不同光照的人脸图片<br>
CNN：使用alexnet架构，5层卷积，3层最大池化，使用 ReLU 激活，最后 softmax</p>
<h1 id="手写数字">手写数字</h1>
<p>LeNet-5<br>
<img src="https://jeromezjl.github.io/post-images/1710506415759.png" alt="" loading="lazy"><br>
使用MNIST：28x28，第一层 padding=2，输入网络是 32x32</p>
<ol>
<li>
<p><strong>输入层（Input Layer）</strong>：接受的输入图像大小通常是32x32像素。这是因为网络设计时考虑到数字的实际大小和希望网络能够捕捉到重要的特征。</p>
</li>
<li>
<p><strong>第一卷积层（C1）</strong>：这一层使用6个卷积核（或滤波器），每个大小为5x5，步长为1，无填充（padding），输出的特征图（feature map）大小为28x28x6。</p>
</li>
<li>
<p><strong>第一下采样层（S2）</strong>：也称为池化层，使用2x2的窗口进行平均池化，步长为2，将特征图的维度降低到14x14x6。这一步骤有助于减少数据的空间尺寸，从而减少计算量和控制过拟合。</p>
</li>
<li>
<p><strong>第二卷积层（C3）</strong>：这一层有16个卷积核，每个大小为5x5，处理上一层的输出，产生10x10x16的特征图。这一层的设计允许网络学习更高级的特征。</p>
</li>
<li>
<p><strong>第二下采样层（S4）</strong>：同样采用2x2平均池化，步长为2，输出的维度为5x5x16。</p>
</li>
<li>
<p><strong>全连接层（F5）</strong>：这一层有120个节点，它将前一层的输出展平（flatten）并全连接到这120个节点上。这一层开始将学到的特征组合成更高级别的模式。</p>
</li>
<li>
<p><strong>第二全连接层（F6）</strong>：这一层有84个节点，进一步处理特征，为最终的分类决策做准备。</p>
</li>
<li>
<p><strong>输出层（Output Layer）</strong>：最后是一个具有10个节点的输出层，对应于10个数字类（0到9）。这一层通常使用softmax激活函数，将网络的输出转换为概率分布。</p>
</li>
</ol>
<p>两层卷积两层池化，卷积池化之间使用 Sigmoid 激活，最后使用全连接层映射到 10 个分类</p>
<h1 id="光度立体法">光度立体法</h1>
<p>对要检测物体在不同方向的光照条件下进行多次拍照。每次改变的只有光源的位置，确保光源的强度和颜色保持一致。<br>
结合不同光照下的像素亮度值，使用最小二乘法计算每个像素点处的表面法向量。用法向量重构三维物体</p>
<h1 id="sift和词袋模型">SIFT和词袋模型</h1>
<p>使用 15-Scene 数据集，包含 15 种不同类型的场景，例如办公室、厨房、卧室、客厅、乡村、海滩等。<br>
共4400张左右，7比3的比例来划分训练集和测试集</p>
<p>原理<br>
SIFT对每张图片生成不同个数的特征描述向量，将这些向量输入kmeans中，聚为300类，即构建了大小为300的视觉词汇表<br>
使用bow对图像编码：<br>
对于每张图像，将其SIFT特征向量与视觉词汇表中的词汇进行比较，找出每个特征向量最接近的视觉词。然后，为每张图像创建一个长度为k的向量（即BoW向量），其中每个元素记录了对应视觉词在该图像中出现的频率。<br>
将图向量输入 svm，一对多将图片分为15类</p>
<h1 id="roberta-问答系统">RoBERTa 问答系统</h1>
<p>SQuAD 数据集是斯坦福大学开发的一个流行的问答数据集，广泛用于自然语言处理中的机器阅读理解研究。SQuAD挑战模型根据给定的段落文本来回答问题。这些段落来自维基百科的文章，问题则是由人工撰写的。SQuAD的目标是推进计算机对自然语言的理解，特别是在问答系统的开发上。</p>
<p>使用transformer中预训练的 RoBERTa</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[八股文]]></title>
        <id>https://jeromezjl.github.io/post/ba-gu-wen/</id>
        <link href="https://jeromezjl.github.io/post/ba-gu-wen/">
        </link>
        <updated>2024-03-23T11:07:26.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/366839763">计算机网络八股文背诵版</a><br>
<a href="https://zhuanlan.zhihu.com/p/373966882">操作系统八股文背诵版</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【DL】图神经网络]]></title>
        <id>https://jeromezjl.github.io/post/dl-tu-shen-jing-wang-luo/</id>
        <link href="https://jeromezjl.github.io/post/dl-tu-shen-jing-wang-luo/">
        </link>
        <updated>2024-03-22T09:53:55.000Z</updated>
        <content type="html"><![CDATA[<p>图神经网络（Graph Neural Networks，GNNs）是一类专门处理图结构数据的神经网络。在图结构数据中，数据以图的形式表示，由节点（nodes）和边（edges）组成，非常适合描述物体（或实体）及其间的复杂关系。图神经网络通过直接在图上进行操作，能够有效地捕捉这种结构信息，因此在社交网络分析、推荐系统、蛋白质结构预测、化学分子建模等领域得到了广泛应用。</p>
<h3 id="核心思想">核心思想</h3>
<p>GNN的核心思想是节点表示的更新，这通过聚合来自邻居节点的信息来实现。每个节点的表示都是通过考虑其邻居节点的特征（以及可能的边的特征）进行更新的，这个过程可以迭代进行，直到达到一个稳定状态或者预定的迭代次数。这种信息的聚合方式使得每个节点能够捕捉到其在图中的局部结构信息。</p>
<h3 id="关键组件">关键组件</h3>
<ol>
<li><strong>节点表示</strong>：GNN的起点是节点的特征表示，这可以是节点的初始属性，也可以是节点的嵌入向量。</li>
<li><strong>聚合函数</strong>：用于聚合邻居节点信息的函数，这一步是GNN的核心。不同的GNN变体（如GCN、GAT等）在聚合函数的选择和设计上有所不同。</li>
<li><strong>更新函数</strong>：用于更新节点表示的函数。在每一次迭代中，节点的表示都会根据聚合的邻居信息进行更新。</li>
</ol>
<h3 id="gnn的变体">GNN的变体</h3>
<p>GNN有多种变体，主要包括：</p>
<ul>
<li><strong>图卷积网络（Graph Convolutional Networks, GCNs）</strong>：通过将卷积的概念推广到图上，对节点的特征进行聚合，从而更新节点的状态。</li>
<li><strong>图注意力网络（Graph Attention Networks, GATs）</strong>：引入了注意力机制来动态地确定在聚合邻居节点信息时每个邻居的重要性。</li>
<li><strong>图自编码器（Graph Autoencoders, GAEs）</strong>：用于学习图数据的低维表示，通常用于无监督学习任务。</li>
<li><strong>图生成网络（Graph Generative Networks, GGNs）</strong>：能够生成新的图结构数据，用于药物设计、蛋白质设计等领域。</li>
</ul>
<h3 id="应用">应用</h3>
<p>GNN在多个领域都有广泛应用，例如：</p>
<ul>
<li><strong>社交网络分析</strong>：通过分析社交网络中个体的关系图，进行好友推荐、信息传播分析等。</li>
<li><strong>推荐系统</strong>：利用用户和物品之间的复杂关系进行更精准的推荐。</li>
<li><strong>生物信息学</strong>：在蛋白质结构预测、基因表达数据分析等领域有着重要应用。</li>
<li><strong>化学和材料科学</strong>：用于预测分子的性质、设计新的化合物等。</li>
</ul>
<p>GNN由于能够直接在图结构数据上操作，捕捉复杂的关系和依赖，因此在处理此类数据时比传统的神经网络模型有着明显的优势。随着研究的深入和技术的发展，GNN在更多领域的应用也在不断拓展。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI 面试]]></title>
        <id>https://jeromezjl.github.io/post/ai-mian-shi/</id>
        <link href="https://jeromezjl.github.io/post/ai-mian-shi/">
        </link>
        <updated>2024-03-21T06:09:17.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>
<p>请简要解释分类和回归的区别。<br>
分类输出离散的类别，回归输出连续的值</p>
</li>
<li>
<p>您能列举一些常用的分类算法吗？请简要说明它们的工作原理。<br>
逻辑回归、决策树、随机森林、SVM、KNN、朴素贝叶斯、梯度提升决策树 (Gradient Boosted Decision Trees, GBDT)、CNN等</p>
</li>
<li>
<p>同样地，您能列举一些常用的回归算法吗？请简要说明它们的工作原理。<br>
线性回归、岭回归、SVM、KNN、SGD、贝叶斯、高斯过程</p>
</li>
<li>
<p>既可以用于分类又可以回归的算法？<br>
决策树、随机森林、SVM、KNN、梯度提升决策树 (Gradient Boosted Decision Trees, GBDT)、CNN等</p>
</li>
<li>
<p>在分类问题中，如何评估模型的性能？您能解释准确率、召回率、F1分数等指标吗？</p>
</li>
<li>
<p>在回归问题中，如何评估模型的性能？您能解释均方误差、均方根误差、决定系数等指标吗？</p>
</li>
<li>
<p>过拟合和欠拟合是什么？如何避免这两种情况？</p>
</li>
<li>
<p>在分类或回归任务中，如何处理不平衡数据集？<br>
处理不平衡数据集是机器学习中的一个常见问题，特别是在分类任务中。不平衡数据集指的是数据集中不同类别的样本数量差异很大。这可能会导致模型对多数类别过拟合，而忽略少数类别。以下是一些常用的方法来处理不平衡数据集：</p>
</li>
</ol>
<h3 id="1-重新采样技术">1. <strong>重新采样技术</strong>:</h3>
<ul>
<li><strong>过采样少数类</strong>: 通过复制少数类样本或通过生成类似样本的方法（如SMOTE - 合成少数过采样技术）来增加少数类样本的数量。</li>
<li><strong>欠采样多数类</strong>: 减少多数类样本的数量，以使多数类和少数类的样本数量大致相同。这可能导致信息丢失，应谨慎使用。</li>
</ul>
<h3 id="2-修改损失函数">2. <strong>修改损失函数</strong>:</h3>
<ul>
<li>为不同类别的样本引入不同的权重，使得模型在训练过程中更加关注少数类。这可以通过修改损失函数来实现，使得少数类样本的错误分类的代价更高。</li>
</ul>
<h3 id="3-使用集成方法">3. <strong>使用集成方法</strong>:</h3>
<ul>
<li>使用如随机森林、梯度提升树（GBT）等集成学习方法可以部分缓解不平衡数据带来的问题，因为它们通过构建多个模型并结合它们的预测结果来提高性能。</li>
</ul>
<h3 id="4-选择合适的评估指标">4. <strong>选择合适的评估指标</strong>:</h3>
<ul>
<li>在不平衡数据集上，准确度不再是一个好的性能指标。应该使用混淆矩阵、精确度、召回率、F1分数、ROC-AUC曲线等更复杂的指标来评估模型性能。</li>
</ul>
<h3 id="5-人工合成数据生成">5. <strong>人工合成数据生成</strong>:</h3>
<ul>
<li>使用算法如SMOTE（合成少数过采样技术）或ADASYN（自适应合成采样方法）等来合成新的少数类样本，以解决不平衡问题。</li>
</ul>
<h3 id="6-使用专门针对不平衡数据设计的算法">6. <strong>使用专门针对不平衡数据设计的算法</strong>:</h3>
<ul>
<li>一些算法如代价敏感学习（Cost-sensitive Learning）和异常检测算法在设计时考虑了不平衡数据的特点，可以直接应用于这类问题。</li>
</ul>
<h3 id="7-数据层面的策略">7. <strong>数据层面的策略</strong>:</h3>
<ul>
<li>收集更多数据，尤其是少数类的数据，有助于减少数据不平衡的问题，虽然这在实际中并不总是可行的。</li>
</ul>
<p>选择哪种方法取决于具体问题、数据集的特性以及可用资源。在实践中，经常需要尝试多种方法，并结合问题的具体情况来确定最有效的策略。</p>
<ol start="5">
<li>请解释特征选择和特征工程的重要性。</li>
<li>在机器学习中，如何处理缺失数据和异常值？<br>
请您根据自己的理解和经验回答这些问题，谢谢！</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】Seq2Seq | Beam Search]]></title>
        <id>https://jeromezjl.github.io/post/nlp-seq2seq-beamsearch/</id>
        <link href="https://jeromezjl.github.io/post/nlp-seq2seq-beamsearch/">
        </link>
        <updated>2024-03-19T12:15:20.000Z</updated>
        <content type="html"><![CDATA[<h1 id="seq2seq">Seq2Seq</h1>
<p><a href="https://www.bilibili.com/video/BV16g411L7FG/?spm_id_from=333.999.0.0&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">62 序列到序列学习（seq2seq）【动手学深度学习v2】</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/194308943">Seq2Seq模型介绍</a><br>
Transformer：Seq2Seq model with attention</p>
<p>encoder-decoder 架构，使用的都是 RNN</p>
<h1 id="beam-search-束搜索">Beam Search 束搜索</h1>
<p>在选择softmax输出时，使用贪心算法（每次选择概率最大值）不一定能达到最优<br>
每次搜索保存k个最好的候选。k=1 是贪心，k=n 是穷举</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【CV】概述]]></title>
        <id>https://jeromezjl.github.io/post/cv-gai-shu/</id>
        <link href="https://jeromezjl.github.io/post/cv-gai-shu/">
        </link>
        <updated>2024-03-15T11:55:57.000Z</updated>
        <content type="html"><![CDATA[<p>机器视觉算法是计算机视觉领域的关键组成部分，它使计算机能够通过图像和视频数据理解世界。这些算法可以根据它们的功能和用途进行分类。以下是一些常见的分类方式：</p>
<h3 id="1-图像处理算法">1. 图像处理算法</h3>
<ul>
<li><strong>预处理</strong>：包括去噪、对比度增强、颜色空间转换等。</li>
<li><strong>滤波和锐化</strong>：用于改善图像质量或提取特定特征。</li>
<li><strong>边缘检测</strong>：如Sobel、Canny算法，用于检测图像中的边缘。</li>
</ul>
<h3 id="2-特征提取算法">2. 特征提取算法</h3>
<ul>
<li><strong>角点检测</strong>：如Harris角点检测、Shi-Tomasi算法。</li>
<li><strong>兴趣点检测</strong>：如SIFT（尺度不变特征变换）、SURF（加速稳健特征）。</li>
<li><strong>特征描述子</strong>：如ORB（Oriented FAST and Rotated BRIEF）。</li>
</ul>
<h3 id="3-图像分类-image-classification">3. 图像分类 (Image Classification)</h3>
<ul>
<li><strong>任务说明</strong>：将整个图像分配给一个或多个类别。</li>
<li><strong>常用算法</strong>：
<ul>
<li>AlexNet</li>
<li>VGGNet</li>
<li>ResNet</li>
<li>Inception</li>
<li>DenseNet</li>
<li>EfficientNet</li>
<li>转移学习：使用预训练的CNN模型进行微调以适应特定的图像分类任务。</li>
</ul>
</li>
</ul>
<h3 id="4-目标检测与识别-object-detection">4. 目标检测与识别 (Object Detection)</h3>
<ul>
<li><strong>任务说明</strong>：在图像中识别物体的位置，并将每个物体分类。</li>
<li><strong>常用算法</strong>：
<ul>
<li>R-CNN及其变体（Fast R-CNN, Faster R-CNN）</li>
<li>YOLO系列（YOLOv1至YOLOv5）</li>
<li>SSD (Single Shot MultiBox Detector)</li>
<li>RetinaNet</li>
</ul>
</li>
<li><strong>目标识别</strong>：CNN 变体</li>
</ul>
<h3 id="5-图像分割-image-segmentation">5. 图像分割 (Image Segmentation)</h3>
<ul>
<li><strong>任务说明</strong>：将图像分割成多个区域或对象，可以进一步细分为语义分割和实例分割。</li>
<li><strong>常用算法</strong>：
<ul>
<li>FCN (Fully Convolutional Networks)</li>
<li>U-Net</li>
<li>Mask R-CNN（实例分割）</li>
<li>DeepLab系列</li>
<li>PSPNet (Pyramid Scene Parsing Network)</li>
</ul>
</li>
</ul>
<h3 id="6-姿态估计-pose-estimation">6. 姿态估计 (Pose Estimation)</h3>
<ul>
<li><strong>任务说明</strong>：估计图像中人或对象的姿态或关节位置。</li>
<li><strong>常用算法</strong>：
<ul>
<li>OpenPose</li>
<li>AlphaPose</li>
<li>DensePose</li>
<li>PoseNet</li>
</ul>
</li>
</ul>
<h3 id="7-物体跟踪-object-tracking">7. 物体跟踪 (Object Tracking)</h3>
<ul>
<li><strong>任务说明</strong>：在视频序列中跟踪一个或多个对象的运动。</li>
<li><strong>常用算法</strong>：
<ul>
<li>SiamFC (Siamese Fully Convolutional Network)</li>
<li>SORT/Simple Online and Realtime Tracking</li>
</ul>
</li>
</ul>
<h3 id="8-图像生成-image-generation">8. 图像生成 (Image Generation)</h3>
<ul>
<li><strong>任务说明</strong>：从现有的图像或随机噪声生成新图像。</li>
<li><strong>常用算法</strong>：
<ul>
<li>GANs (Generative Adversarial Networks) 及其变体（CGAN, DCGAN, StyleGAN）</li>
<li>VAEs (Variational Autoencoders)</li>
<li>PixelRNN/PixelCNN</li>
</ul>
</li>
</ul>
<h3 id="9-图像恢复-image-restoration">9. 图像恢复 (Image Restoration)</h3>
<ul>
<li><strong>任务说明</strong>：从损坏或降质的图像中恢复出清晰图像。</li>
<li><strong>常用算法</strong>：
<ul>
<li>SRCNN (Super-Resolution Convolutional Neural Network)</li>
<li>VDSR (Very Deep Super-Resolution)</li>
<li>GANs在图像超分辨率方面的应用</li>
<li>Denoising Autoencoders</li>
</ul>
</li>
</ul>
<h3 id="10-3d重建-3d-reconstruction">10. 3D重建 (3D Reconstruction)</h3>
<ul>
<li><strong>任务说明</strong>：从一系列图像中重建出三维场景或对象的结构。</li>
<li><strong>常用算法</strong>：
<ul>
<li>Multi-View Stereo (MVS)</li>
<li>COLMAP</li>
</ul>
</li>
</ul>
<h3 id="11-行为分析-action-analysis">11. 行为分析 (Action Analysis)</h3>
<ul>
<li><strong>任务说明</strong>：分析视频中的人或物体的行为，比如行人的行走路线、人群的动态等。</li>
<li><strong>常用算法</strong>：
<ul>
<li>C3D (Convolutional 3D Networks)</li>
<li>I3D (Inflated 3D ConvNet)</li>
</ul>
</li>
</ul>
<h3 id="12-视觉问答-visual-question-answering">12. 视觉问答 (Visual Question Answering)</h3>
<ul>
<li><strong>任务说明</strong>：根据给定图像和自然语言问题提供答案。</li>
<li><strong>常用算法</strong>：
<ul>
<li>基于注意力机制的模型</li>
<li>LSTM (Long Short-Term Memory) 网络</li>
<li>End-to-End模型</li>
<li>Transformer模型及其在视觉问答中的应用</li>
</ul>
</li>
</ul>
<h3 id="13-优化和机器学习算法">13. 优化和机器学习算法</h3>
<pre><code>- 用于提高识别准确率和效率的算法，如支持向量机（SVM）、随机森林、梯度提升决策树（GBDT）等。
- 
</code></pre>
<p>这些任务和算法展示了机器视觉领域的广泛性和深度，随着研究的进展，还会不断有新</p>
<p>的任务和算法被提出。</p>
<h1 id="数据增强">数据增强</h1>
<p>对图片进行翻转、裁剪、变色（颜色、亮度、饱和度）等操作<br>
<a href="https://www.bilibili.com/video/BV17y4y1g76q/?spm_id_from=333.999.0.0&amp;vd_source=3d9ada7d42c971c0c3f04a22270daf33">36 数据增广【动手学深度学习v2】</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】文本预处理]]></title>
        <id>https://jeromezjl.github.io/post/nlp-wen-ben-yu-chu-li/</id>
        <link href="https://jeromezjl.github.io/post/nlp-wen-ben-yu-chu-li/">
        </link>
        <updated>2024-03-15T03:49:11.000Z</updated>
        <content type="html"><![CDATA[<p>数据预处理是自然语言处理（NLP）任务中至关重要的一步，它直接影响到模型训练的效果和最终结果的质量。预处理步骤的目的是将原始文本转换成一种更易于计算机理解和处理的格式。以下是数据预处理中常见的几个步骤：</p>
<ol>
<li>
<p><strong>文本清洗</strong>:<br>
移除无关内容（如HTML标签）、标点符号、数字等，或者将它们转换成有意义的代替文本。</p>
<ul>
<li><strong>去除噪声</strong>：移除文本中的无关信息，如HTML标签、非文本内容（图片链接、JavaScript代码等）、格式符号等。</li>
<li><strong>规范化文本</strong>：将文本统一为标准格式，例如，将所有字母转换为小写（或大写），以减少词汇的变体数量。</li>
<li><strong>去除特殊字符和标点</strong>：根据任务需求，移除或替换文本中的特殊字符和标点符号，有时标点可以保留，因为它可能含有语义信息。</li>
</ul>
</li>
<li>
<p><strong>分词 (Tokenization)</strong>:</p>
<ul>
<li><strong>词级分词</strong>：将句子分割成单词或词汇单元，如短语。这是英文等西方语言中最常见的分词方式。</li>
<li><strong>子词级分词</strong>：将单词进一步分割成更小的单位（如词根、词缀）。这对于处理一些复合词或未见过的词特别有用。</li>
<li><strong>字符级分词</strong>：将文本分割成字符。这种方法对于某些任务或语言（如中文）可能更合适。</li>
</ul>
</li>
<li>
<p><strong>停用词去除</strong>:</p>
<ul>
<li>停用词是指在文本中频繁出现但对于理解文本意义贡献不大的词，如“的”、“是”、“在”等。去除这些词可以帮助减少数据噪声和特征维度。</li>
</ul>
</li>
<li>
<p><strong>词干提取 (Stemming) 和词形还原 (Lemmatization)</strong>:</p>
<ul>
<li><strong>词干提取</strong>：通过去除词缀来将词汇还原到基本形式（可能不是真正的词）。例如，“running”、“runs”词干提取后都变为“run”。</li>
<li><strong>词形还原</strong>：将词汇还原到其词典形式（lemma），考虑了词汇的词性。比如，“better”的词形还原结果是“good”。</li>
</ul>
</li>
<li>
<p><strong>数据增强</strong>:</p>
<ul>
<li>通过词替换、句子重排等方法人为增加训练数据的多样性，有助于改善模型的泛化能力。</li>
</ul>
</li>
<li>
<p><strong>向量化 (Vectorization)</strong>:</p>
<ul>
<li><strong>构建词汇表</strong>：统计词频，小于某个词频的词将不会被加入词汇表</li>
<li><strong>Token 编码</strong>：在构建了词汇表之后，每个唯一的token都会被分配一个唯一的数字ID。向量化的这一阶段涉及将文本中的每个token替换成对应的数字ID。这个过程实际上是一种编码，将文本数据转换为模型可以处理的数值形式。</li>
<li><strong>句子/文本向量化（tokenize）</strong>：完成token的数字编码后，整个句子或文本片段可以表示为一个数字序列。</li>
<li><strong>序列填充 (Padding) 和截断</strong>：对于需要固定长度输入的模型（如很多深度学习模型），需要通过填充（通常用0或特殊标记<code>&lt;PAD&gt;</code> ）或截断来使所有文本序列长度一致。</li>
<li><strong>词袋模型 (Bag of Words, BoW)</strong>：将文本转换为词频向量，但这种方法不考虑词序和上下文。</li>
<li><strong>TF-IDF (Term Frequency-Inverse Document Frequency)</strong>：一种加权的词袋模型，考虑了词在文档集中的稀有程度。</li>
<li><strong>词嵌入 (Word Embeddings)</strong>：将词汇token映射到连续的向量空间中，这些向量捕获了词汇之间的语义关系。常见的词嵌入模型包括Word2Vec、GloVe和BERT等。</li>
</ul>
</li>
</ol>
<p>每个步骤的具体实现和必要性可能会根据具体的任务和语言而有所不同。例如，对于某些任务，保留标点符号可能是有意义的，因为它们可以携带情感或语法信息。而对于一些语言（如中文、日文），分词步骤会比英文复杂得多，可能需要特定的算法和词库。预处理的目的是清洗和转换数据，以提高模型训练的效率和效果。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】概述]]></title>
        <id>https://jeromezjl.github.io/post/nlp-gai-shu/</id>
        <link href="https://jeromezjl.github.io/post/nlp-gai-shu/">
        </link>
        <updated>2024-03-15T03:19:09.000Z</updated>
        <content type="html"><![CDATA[<h1 id="任务">任务</h1>
<ol>
<li><strong>文本分类（Text Classification）</strong>：将文本数据分类到预定义的类别中。常见的应用包括垃圾邮件检测、情感分析和主题分类。</li>
</ol>
<ul>
<li>朴素贝叶斯（Naive Bayes）</li>
<li>支持向量机（SVM）</li>
<li>随机森林（Random Forest）</li>
<li>卷积神经网络（CNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>Transformer模型（如BERT）</li>
</ul>
<ol start="2">
<li><strong>命名实体识别（Named Entity Recognition, NER）</strong>：识别文本中的命名实体，如人名、地点名、组织名等，并将其分类到预定义的类别。</li>
</ol>
<ul>
<li>条件随机场（CRF）</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）+ CRF</li>
<li>BERT及其变体</li>
</ul>
<ol start="3">
<li><strong>词性标注（Part-of-Speech Tagging, POS Tagging）</strong>：为文本中的每个单词分配一个词性标签，如名词、动词、形容词等。</li>
</ol>
<ul>
<li>隐马尔可夫模型（HMM）</li>
<li>条件随机场（CRF）</li>
<li>循环神经网络（RNN）</li>
<li>Transformer模型（如BERT）</li>
</ul>
<ol start="4">
<li><strong>句法分析（Syntactic Parsing）</strong>：分析句子的语法结构，确定单词之间的依赖关系和句子的语法树结构。</li>
</ol>
<ul>
<li>基于规则的方法</li>
<li>上下文无关文法（CFG）</li>
<li>依存解析（Dependency Parsing）使用神经网络</li>
<li>Transformer模型（如BERT、GPT）</li>
</ul>
<ol start="5">
<li><strong>语义分析（Semantic Analysis）</strong>：理解句子或文本的含义，包括词义消歧和语义角色标注。</li>
</ol>
<ul>
<li>潜在语义分析（LSA）</li>
<li>潜在狄利克雷分配（LDA）</li>
<li>词嵌入方法（如Word2Vec、GloVe）</li>
<li>Transformer模型（如BERT、RoBERTa）</li>
</ul>
<ol start="6">
<li><strong>情感分析（Sentiment Analysis）</strong>：判断文本的情感倾向，如正面、负面或中性。</li>
</ol>
<ul>
<li>朴素贝叶斯（Naive Bayes）</li>
<li>支持向量机（SVM）</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>Transformer模型（如BERT、XLNet）</li>
</ul>
<ol start="7">
<li><strong>文本摘要（Text Summarization）</strong>：生成文本的简短且含义完整的摘要。</li>
</ol>
<ul>
<li>抽取式摘要方法，如TF-IDF</li>
<li>序列到序列模型（Seq2Seq），如LSTM</li>
<li>注意力机制（Attention Mechanism）</li>
<li>预训练语言模型（如GPT-3、BERT）</li>
</ul>
<ol start="8">
<li><strong>机器翻译（Machine Translation）</strong>：将一种语言的文本翻译成另一种语言。</li>
</ol>
<ul>
<li>统计机器翻译（SMT）</li>
<li>序列到序列模型（Seq2Seq）</li>
<li>注意力机制</li>
<li>Transformer架构</li>
</ul>
<ol start="9">
<li><strong>问答系统（Question Answering）</strong>：对自然语言形式的问题给出直接答案。</li>
</ol>
<ul>
<li>信息检索技术</li>
<li>长短期记忆网络（LSTM）</li>
<li>注意力机制</li>
<li>BERT和Transformer模型</li>
</ul>
<ol start="10">
<li><strong>对话系统和聊天机器人（Dialogue Systems and Chatbots）</strong>：构建能够与人类用户进行自然对话的系统。</li>
</ol>
<ul>
<li>序列到序列模型（Seq2Seq）</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>Transformer和GPT系列</li>
</ul>
<ol start="11">
<li><strong>文本生成（Text Generation）</strong>：基于某些输入生成自然语言文本，如新闻文章生成、故事创作等。</li>
</ol>
<ul>
<li>马尔可夫模型</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>GPT系列</li>
</ul>
<ol start="12">
<li><strong>语音识别（Speech Recognition）</strong>：将语音信号转换为文本。</li>
</ol>
<ul>
<li>隐马尔可夫模型（HMM）</li>
<li>深度神经网络（DNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>端到端的深度学习模型</li>
</ul>
<ol start="13">
<li><strong>自然语言理解（Natural Language Understanding, NLU）</strong>：深入理解自然语言的含义和上下文。</li>
</ol>
<ul>
<li>词嵌入（Word Embeddings）</li>
<li>长短期记忆网络（LSTM）</li>
<li>Transformer模型</li>
<li>BERT及其变体</li>
</ul>
<ol start="14">
<li><strong>自然语言生成（Natural Language Generation, NLG）</strong>：从非语言数据生成人类可理解的语言。</li>
</ol>
<ul>
<li>模板方法</li>
<li>序列到序列模型（Seq2Seq）</li>
<li>Transformer模型</li>
<li>GPT系列</li>
</ul>
<ol start="15">
<li><strong>关键词提取（Keyword Extraction）</strong>：从文本中提取最相关的词汇或短语。</li>
</ol>
<ul>
<li>TF-IDF</li>
<li>TextRank</li>
<li>LDA（潜在狄利克雷分配）</li>
<li>BERT Embeddings</li>
</ul>
<ol start="16">
<li><strong>主题建模（Topic Modeling）</strong>：无监督地识别大量文档集中的潜在主题。</li>
</ol>
<ul>
<li>潜在语义分析（LSA）</li>
<li>潜在狄利克雷分配（LDA）</li>
<li>非负矩阵分解（NMF）</li>
</ul>
<p>对于每种任务，选择最合适的算法通常取决于具体的应用场景、可用数据的量和质以及性能要求。随着深度学习技术的发展，基于Transformer的模型如BERT、GPT系列在多个NLP任务中取得了突破性的成果。</p>
<h1 id="算法">算法</h1>
<p>自然语言处理（NLP）领域中有多种算法和技术，这些方法旨在帮助计算机理解、解释和生成人类语言。以下是一些核心的NLP算法和技术：</p>
<ol>
<li>
<p><strong>基于规则的系统</strong>：早期的NLP系统大多依赖于手写的规则来解析和理解文本。这些规则可以基于语法、句法和语义规则来设计。</p>
</li>
<li>
<p><strong>统计方法</strong>：</p>
<ul>
<li><strong>隐马尔可夫模型（HMM）</strong>：用于词性标注和命名实体识别等任务。</li>
<li><strong>条件随机场（CRF）</strong>：用于序列建模，如标注问题和命名实体识别。</li>
</ul>
</li>
<li>
<p><strong>机器学习算法</strong>：随着机器学习的发展，许多传统算法被用于NLP任务，如朴素贝叶斯、决策树、支持向量机（SVM）等。</p>
</li>
<li>
<p><strong>深度学习/神经网络方法</strong>：近年来，深度学习在NLP中取得了重大进展，以下是一些关键的神经网络架构：</p>
<ul>
<li><strong>卷积神经网络（CNNs）</strong>：虽然最初用于图像处理，但也被适用于处理文本数据，如句子分类任务。</li>
<li><strong>循环神经网络（RNNs）</strong>：特别适合处理序列数据，如时间序列或文本。长短期记忆网络（LSTMs）和门控循环单元（GRUs）是RNN的变体，能够解决传统RNNs的梯度消失问题。</li>
<li><strong>注意力机制和Transformer架构</strong>：注意力机制允许模型在处理序列数据时更加灵活地权衡不同部分的重要性，而Transformer架构则彻底改变了NLP领域，成为了多种任务的基础，如BERT、GPT系列、RoBERTa、T5等。</li>
</ul>
</li>
<li>
<p><strong>预训练语言模型</strong>：利用大量无标签文本数据进行预训练，然后在特定任务上进行微调。BERT和GPT系列是这一范式下的两个典型例子。</p>
</li>
<li>
<p><strong>迁移学习和微调</strong>：借助预训练的语言模型，通过在特定任务上的微调，可以显著提高性能。这种方法减少了对大量标记数据的依赖。</p>
</li>
</ol>
<p>这些算法和技术在各种NLP任务中被广泛应用，如文本分类、情感分析、机器翻译、语音识别、问答系统、文本摘要、自然语言生成等。随着研究的不断进展，新的算法和模型也在不断被提出和改进。</p>
<h1 id="nlp-任务的一般过程">NLP 任务的一般过程</h1>
<ol>
<li>
<p><strong>问题定义</strong>:</p>
<ul>
<li>明确任务目标：这可能是文本分类、情感分析、机器翻译、命名实体识别、问答系统等。</li>
<li>确定输入输出：定义任务的输入数据（如文本、句子、段落）和期望的输出（如类别标签、文本响应等）。</li>
</ul>
</li>
<li>
<p><strong>数据收集</strong>:</p>
<ul>
<li>收集足够的数据：根据任务需求，收集标注好的训练数据。对于一些任务，还可能需要收集未标注的数据进行无监督学习或半监督学习。</li>
<li>来源：数据可以来自公共数据集、网络爬虫、社交媒体、公司数据库等。</li>
</ul>
</li>
<li>
<p><strong>数据预处理</strong>:</p>
<ul>
<li>文本清洗：移除无关内容（如HTML标签）、标点符号、数字等，或者将它们转换成有意义的代替文本。</li>
<li>分词：将文本分割成单词、短语或其他有意义的单位。</li>
<li>规范化：包括小写转换、词干提取、词形还原等，旨在将单词规范到基本形式。</li>
<li>去除停用词：移除常见但对于理解文本意义不大的词，如“的”、“是”、“在”等。</li>
<li>向量化：将文本转换为数值形式，常见方法包括词袋模型、TF-IDF、词嵌入等。</li>
</ul>
</li>
<li>
<p><strong>特征工程</strong>:</p>
<ul>
<li>特征提取：根据任务需求，选择或设计文本特征，如n-gram、词频、词嵌入向量等。</li>
<li>降维：对高维特征空间应用降维技术，如PCA、t-SNE，以减少计算复杂度。</li>
</ul>
</li>
<li>
<p><strong>模型选择和训练</strong>:</p>
<ul>
<li>选择模型：根据任务类型选择合适的模型，可能是传统机器学习模型（如SVM、随机森林）或深度学习模型（如CNN、RNN、Transformer）。</li>
<li>训练模型：使用训练数据训练模型，调整超参数以获得最佳性能。</li>
</ul>
</li>
<li>
<p><strong>评估和优化</strong>:</p>
<ul>
<li>使用验证集评估模型性能，采用适当的评估指标（如准确率、召回率、F1分数、BLEU分数等）。</li>
<li>根据评估结果调整模型结构、超参数等，可能包括使用更复杂的模型、增加更多训练数据、应用不同的预处理或特征工程技术。</li>
</ul>
</li>
<li>
<p><strong>部署和监控</strong>:</p>
<ul>
<li>将训练好的模型部署到生产环境，使其能够处理实时数据或新数据。</li>
<li>监控模型性能，定期检查并重新训练模型以适应新数据或变化的数据分布。</li>
</ul>
</li>
<li>
<p><strong>反馈循环</strong>:</p>
<ul>
<li>根据模型在实际应用中的表现，收集反馈，可能需要重新执行前面的步骤，如重新定义问题、收集更多或更高质量的数据、重新训练模型等。</li>
</ul>
</li>
</ol>
<p>这个流程不是一成不变的，具体的步骤和方法可能会根据具体的NLP任务、数据集、业务需求等因素有所不同。</p>
<h1 id="评估指标">评估指标</h1>
<p><a href="https://blog.csdn.net/ph12345687/article/details/130205151">NLP常见任务及评估指标</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【DL】强化学习]]></title>
        <id>https://jeromezjl.github.io/post/dl-qiang-hua-xue-xi/</id>
        <link href="https://jeromezjl.github.io/post/dl-qiang-hua-xue-xi/">
        </link>
        <updated>2024-03-14T14:40:15.000Z</updated>
        <content type="html"><![CDATA[<p>强化学习是机器学习的一个领域，它主要关注如何使智能体（Agent）在环境（Environment）中学会采取行动（Action）以最大化某种累积奖励（Reward）。强化学习与其他类型的机器学习（如监督学习和无监督学习）的主要区别在于，它不依赖于预先标记的输入/输出对，而是通过智能体与环境的交互来学习。以下是这些概念的详细介绍：</p>
<ol>
<li>
<p><strong>智能体（Agent）</strong>：</p>
<ul>
<li>智能体是强化学习中的决策者，它通过观察环境来学习如何采取行动。智能体的目标是通过这些行动来最大化其长期奖励。它可以是任何能够感知其环境并根据这些观察做出决策的实体，如机器人、软件程序等。</li>
</ul>
</li>
<li>
<p><strong>环境（Environment）</strong>：</p>
<ul>
<li>环境是智能体所处并与之互动的系统或问题域。环境接收智能体的行动并根据这些行动提供状态的反馈和奖励。环境的反馈可以是非常简单的，也可以是极其复杂且动态变化的。</li>
</ul>
</li>
<li>
<p><strong>状态（State）</strong>：</p>
<ul>
<li>状态是对环境在某一时刻的描述。它可以是环境的完整描述，也可以只是环境的一部分。状态为智能体提供了决策的上下文，在给定状态下采取行动可以导致环境状态的变化。</li>
</ul>
</li>
<li>
<p><strong>动作（Action）</strong>：</p>
<ul>
<li>动作是智能体在给定状态下可以采取的决策或步骤。智能体的动作空间可以是离散的（如左转、右转）或连续的（如加速的量）。智能体的行动会影响环境，并导致状态的变化和奖励的给予。</li>
</ul>
</li>
<li>
<p><strong>奖励（Reward）</strong>：</p>
<ul>
<li>奖励是环境对智能体采取特定行动的即时评价。奖励通常是一个标量值，指示智能体的行动对于达成其目标的有用程度。智能体的目标是最大化在整个学习过程中获得的累积奖励。</li>
</ul>
</li>
<li>
<p><strong>策略（Policy）</strong>：</p>
<ul>
<li>策略是从状态到动作的映射，它定义了智能体在给定状态下应该采取什么行动。策略可以是简单的静态规则，也可以是复杂的动态函数，取决于智能体的学习算法和环境的性质。智能体的目标是学习一个最优策略，这个策略能在长期内最大化累积奖励。</li>
</ul>
</li>
</ol>
<p>强化学习的过程过程可以通过多种算法来通常涉及智能体不断地通过与环境互动来尝试不同的策略，评估这些策略带来的奖励，并根据这些奖励来调整其策略，以学习如何最优地行动。这个实现，如Q学习、深度Q网络（DQN）、策略梯度方法等。</p>
<h1 id="常见算法">常见算法</h1>
<h2 id="动态规划">动态规划</h2>
<p>动态规划（Dynamic Programming, DP）在强化学习中扮演着基础而重要的角色，尤其是在处理具有完全已知的环境模型（即状态转移概率和奖励函数已知）的问题时。DP方法依赖于贝尔曼方程，这是一组递归方程，用于描述状态值函数或动作值函数（即Q函数）之间的关系。在强化学习中，动态规划法主要用于两个方面：策略评估（Policy Evaluation）和策略提升（Policy Improvement），这两个步骤循环交替执行以找到最优策略。</p>
<h3 id="策略评估policy-evaluation">策略评估（Policy Evaluation）</h3>
<p>策略评估的目标是计算某策略下的状态值函数，即在遵循特定策略的条件下，从某状态开始所能获得的预期回报。通过迭代地应用贝尔曼期望方程，我们可以评估当前策略的效果：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>V</mi><mi>π</mi></msup><mo>(</mo><mi>s</mi><mo>)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>a</mi><mo>∈</mo><mi>A</mi></mrow></munder><mi>π</mi><mo>(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo>)</mo><munder><mo>∑</mo><mrow><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo separator="true">,</mo><mi>r</mi></mrow></munder><mi>P</mi><mo>(</mo><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo separator="true">,</mo><mi>r</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo><mo>[</mo><mi>r</mi><mo>+</mo><mi>γ</mi><msup><mi>V</mi><mi>π</mi></msup><mo>(</mo><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo>)</mo><mo>]</mo></mrow><annotation encoding="application/x-tex">V^{\pi}(s) = \sum_{a \in A} \pi(a|s) \sum_{s&#x27;, r} P(s&#x27;, r | s, a)[r + \gamma V^{\pi}(s&#x27;)]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.480098em;vertical-align:-1.430093em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8556639999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight">A</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.321706em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8560149999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.430093em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord">∣</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<p>其中，$$  V^{\pi}(s) $$ 是在状态 ( s ) 下遵循策略 ( \pi ) 所得到的价值，( \pi(a|s) ) 是在状态 ( s ) 下采取动作 ( a ) 的概率，( P(s', r | s, a) ) 是从状态 ( s ) 采取动作 ( a ) 转移到状态 ( s' ) 并得到奖励 ( r ) 的概率，( \gamma ) 是折扣因子，用于计算未来奖励的现值。</p>
<h3 id="策略提升policy-improvement">策略提升（Policy Improvement）</h3>
<p>策略提升的目标是生成一个新策略，该策略在每个状态下都可以选择使动作价值最大化的动作。通过这个过程，我们可以从当前策略产生一个更好的策略。策略提升通常使用贝尔曼最优方程：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>Q</mi><mi>π</mi></msup><mo>(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo><mo>=</mo><munder><mo>∑</mo><mrow><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo separator="true">,</mo><mi>r</mi></mrow></munder><mi>P</mi><mo>(</mo><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo separator="true">,</mo><mi>r</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo><mo>[</mo><mi>r</mi><mo>+</mo><mi>γ</mi><msup><mi>V</mi><mi>π</mi></msup><mo>(</mo><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo>)</mo><mo>]</mo></mrow><annotation encoding="application/x-tex">Q^{\pi}(s, a) = \sum_{s&#x27;, r} P(s&#x27;, r | s, a)[r + \gamma V^{\pi}(s&#x27;)]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.480098em;vertical-align:-1.430093em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8560149999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.430093em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord">∣</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<p>然后，新的策略 ( \pi' ) 在每个状态下选择最大化 ( Q^{\pi}(s, a) ) 的动作：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>π</mi><mo mathvariant="normal">′</mo></msup><mo>(</mo><mi>s</mi><mo>)</mo><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mi>max</mi><mo>⁡</mo><mi>a</mi></munder><msup><mi>Q</mi><mi>π</mi></msup><mo>(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\pi&#x27;(s) = \arg\max_a Q^{\pi}(s, a)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.45em;vertical-align:-0.7em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43056em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span></span></span></span></span></p>
<h3 id="策略迭代policy-iteration">策略迭代（Policy Iteration）</h3>
<p>策略迭代结合了策略评估和策略提升，通过迭代这两个步骤直到策略收敛到最优策略。每次迭代包括完全评估当前策略（直到值函数收敛），然后进行策略提升。</p>
<h3 id="值迭代value-iteration">值迭代（Value Iteration）</h3>
<p>值迭代是策略迭代的一种简化形式，它结合了策略评估的一步操作和策略提升。值迭代直接迭代更新每个状态的最大动作价值，直到价值函数收敛：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi><mo>(</mo><mi>s</mi><mo>)</mo><mo>=</mo><munder><mi>max</mi><mo>⁡</mo><mi>a</mi></munder><munder><mo>∑</mo><mrow><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo separator="true">,</mo><mi>r</mi></mrow></munder><mi>P</mi><mo>(</mo><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo separator="true">,</mo><mi>r</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo><mo>[</mo><mi>r</mi><mo>+</mo><mi>γ</mi><mi>V</mi><mo>(</mo><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo>)</mo><mo>]</mo></mrow><annotation encoding="application/x-tex">V(s) = \max_a \sum_{s&#x27;, r} P(s&#x27;, r | s, a)[r + \gamma V(s&#x27;)]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.480098em;vertical-align:-1.430093em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43056em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8560149999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.430093em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord">∣</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<p>动态规划方法在理论上可以得到最优策略，但其应用受限于环境模型的已知性以及状态和动作空间的规模。当状态和动作空间非常大或环境模型未知时，直接应用动态规划变得不可行，这时通常会</p>
<h2 id="马尔可夫">马尔可夫</h2>
<h2 id="蒙特卡洛">蒙特卡洛</h2>
<p>蒙特卡洛方法在强化学习中的应用提供了一种在不完全知道环境模型（即转移概率和奖励函数未知）的情况下学习最优策略的方法。与动态规划不同，蒙特卡洛（MC）方法不需要知道环境的具体动态，而是通过从环境中采样完成的序列（或称为“情节”）来学习。这些方法特别适用于具有高度不确定性或模型未知的环境。MC方法的关键特点是它们依赖于经验平均来估计值函数，这些平均值是从一系列完整情节中获得的。</p>
<h3 id="mc策略评估">MC策略评估</h3>
<p>在策略评估过程中，MC方法通过对从当前策略生成的一系列完整情节的回报进行平均来估计状态的值。每个情节包含一系列的状态、动作和奖励，以及情节的最终结果。通过对同一状态多次访问得到的回报进行平均，MC方法可以估计该状态的值，即该状态的长期回报期望。</p>
<h3 id="mc控制">MC控制</h3>
<p>为了找到最优策略，MC方法采用了一种称为MC控制的方法。MC控制通常涉及两个主要步骤：探索和利用。一个常见的策略是使用ε-贪婪策略，其中智能体大部分时间选择当前最佳动作（利用），但有时也随机选择其他动作（探索），以确保长期学习。</p>
<p>MC控制方法通过不断交替执行策略评估和策略提升来工作。在策略评估阶段，智能体使用其当前策略在环境中执行动作，并记录下来每个情节的结果。接着，使用这些情节的结果来更新值函数。在策略提升阶段，智能体根据估计的值函数更新其策略，通常是通过选择使得估计值函数最大化的动作。</p>
<h3 id="优点与局限">优点与局限</h3>
<p>MC方法的一个主要优点是它们不依赖于环境的先验知识，使其适用于模型未知的情况。此外，MC方法直接从最终回报中学习，而不依赖于其他状态的值估计，这有助于减少累积的估计误差。</p>
<p>然而，MC方法也有其局限性。首先，它们只适用于情节性任务，即那些有明确开始和结束的任务。其次，MC方法可能需要很多情节才能获得可靠的值估计，尤其是在回报信号稀疏或噪声很大的情境中。此外，MC方法只在情节结束时更新值函数和策略，这可能导致学习速度较慢。</p>
<p>总的来说，蒙特卡洛方法在强化学习中提供了一种强大的工具，尤其是在那些模型未知或难以精确建模的情况下。通过适当的策略和技巧（如重要性采样）的改进，可以进一步增强MC方法的应用范围和效率。</p>
<h2 id="时序差分法">时序差分法</h2>
<h3 id="q-learning">Q-Learning</h3>
]]></content>
    </entry>
</feed>