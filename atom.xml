<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jeromezjl.github.io</id>
    <title>Jerome</title>
    <updated>2023-05-22T02:06:33.459Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jeromezjl.github.io"/>
    <link rel="self" href="https://jeromezjl.github.io/atom.xml"/>
    <subtitle>Jerome&apos;s blog</subtitle>
    <logo>https://jeromezjl.github.io/images/avatar.png</logo>
    <icon>https://jeromezjl.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Jerome</rights>
    <entry>
        <title type="html"><![CDATA[深度学习的一般步骤]]></title>
        <id>https://jeromezjl.github.io/post/shen-du-xue-xi-de-yi-ban-bu-zou/</id>
        <link href="https://jeromezjl.github.io/post/shen-du-xue-xi-de-yi-ban-bu-zou/">
        </link>
        <updated>2023-05-19T07:05:13.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/66021413">快速搞定 epoch, batch, iteration</a><br>
<a href="https://link.zhihu.com/?target=http%3A//playground.tensorflow.org">深度学习模拟网站，可观察参数变化对训练的影响</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【NLP】BiLSTM-CRF算法]]></title>
        <id>https://jeromezjl.github.io/post/nlp-bilstm-crf-suan-fa/</id>
        <link href="https://jeromezjl.github.io/post/nlp-bilstm-crf-suan-fa/">
        </link>
        <updated>2023-05-15T14:27:05.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/u010366748/article/details/113784204">BiLSTM-CRF实现中文命名实体识别（NER）</a></p>
<p><strong>概述</strong><br>
BiLSTM-CRF（Bidirectional Long Short-Term Memory - Conditional Random Field）是一种深度学习算法，常用于序列标注任务，如命名实体识别、词性标注等。BiLSTM-CRF结合了双向长短时记忆网络（BiLSTM）和条件随机场（CRF）两种技术，具有较强的建模能力和预测准确性。</p>
<p>BiLSTM是一种递归神经网络，可以捕捉序列中前后文的依赖关系。它由两个LSTM（Long Short-Term Memory）层组成，分别从左向右和从右向左处理输入序列，然后将它们的输出拼接起来。这样，每个时间步的输出包含了当前时刻及其前后若干时刻的信息，更好地表达了序列的语义。</p>
<p>CRF是一种概率模型，用于对序列标注结果进行建模，考虑标签之间的关联性和约束条件，可以使得标注结果更加合理和连贯。在BiLSTM-CRF中，CRF层接受BiLSTM层的输出作为输入，并且通过联合学习的方式，将BiLSTM层的输出和CRF层的标注结果进行训练，以最大化标注的准确性。</p>
<p>BiLSTM-CRF的训练过程通常采用反向传播算法，以最小化模型对标注数据的损失。在测试阶段，通过在CRF层上使用维特比算法，找到最可能的标注序列，作为模型的预测结果。</p>
<p>总之，BiLSTM-CRF算法在序列标注任务中表现出了良好的性能，能够捕捉序列中的长距离依赖关系和标签之间的约束关系，从而提高了模型的预测准确性。</p>
<p><strong>命名实体</strong><br>
在自然语言处理中，命名实体（Named Entity）是指具有特定语义的实体，如人名、地名、组织机构名、时间、数量、货币等。命名实体识别（Named Entity Recognition，NER）是一种信息抽取技术，用于自动识别文本中的命名实体，并将其分类为预定义的类型。</p>
<p>命名实体识别在信息检索、机器翻译、问答系统、自然语言生成等领域中有着广泛的应用。例如，在搜索引擎中，将用户查询中的命名实体与数据库中的实体进行匹配，可以帮助用户更快地找到所需信息。在机器翻译中，识别源文本中的命名实体可以帮助翻译系统更准确地理解句子的含义，从而提高翻译质量。</p>
<p>命名实体识别通常使用基于规则、基于统计的方法或基于深度学习的方法。其中，基于深度学习的方法，如BiLSTM-CRF等模型，因其在序列标注任务中的优越表现，已经成为了命名实体识别的主流方法。</p>
<p><strong>序列标注任务</strong><br>
序列标注任务是一种自然语言处理任务，旨在将输入序列中的每个元素标注为特定的类别。常见的序列标注任务包括词性标注、命名实体识别、情感分析、语义角色标注等。</p>
<p>在序列标注任务中，输入序列通常是一个由单词或字符组成的序列，每个单词或字符都要被标注为特定的类别。标注的类别可以是预定义的固定类别，例如名词、动词、形容词等，也可以是根据任务需要定义的自定义类别，例如人名、地名、组织机构名等。</p>
<p>序列标注任务通常使用监督学习的方法进行模型训练，例如最大熵模型、条件随机场、递归神经网络等。在最近几年，基于深度学习的方法，如卷积神经网络（CNN）、循环神经网络（RNN）和其变体，如LSTM、GRU等，已经成为序列标注任务中最有效的方法之一，取得了很好的效果。</p>
<p>序列标注任务在自然语言处理中有着广泛的应用，如文本分类、机器翻译、信息抽取、问答系统等。</p>
<p><strong>BIO-三位序列标注法（BIO-3）</strong><br>
BIO-三位序列标注法（BIO-3）是一种常用于序列标注任务的标注方法，特别在命名实体识别（NER）任务中广泛应用。该方法将每个标记分为三个部分：B（Beginning）、I（Inside）、O（Outside）。下面对BIO-3的含义进行解释：</p>
<p>B（Beginning）：表示实体的起始位置。在一个实体的第一个字上标记为B，例如&quot;B-Person&quot;表示一个人名实体的起始位置。</p>
<p>I（Inside）：表示实体的中间位置。在一个实体的非起始字上标记为I，例如&quot;I-Person&quot;表示一个人名实体的中间或结束位置。</p>
<p>O（Outside）：表示不属于任何实体的标记，即普通文本部分。</p>
<p>通过使用BIO-3标记法，我们可以准确地表示实体在文本中的起始和结束位置。这种方法的主要优点是灵活性，因为它可以处理不同长度和类型的实体。</p>
<p>除了BIO-3，还有其他常见的序列标注方法，包括：</p>
<p>IOB（Inside-Outside-Beginning）：与BIO-3类似，但使用I（Inside）和B（Beginning）标记来表示实体的起始和中间位置。</p>
<p>IOB2：与IOB方法类似，但在一段连续的实体标记序列中，每个实体的第一个字都标记为B，而后续的字标记为I。</p>
<p>IOE（Inside-Outside-End）：与BIO-3类似，但使用I（Inside）和E（End）标记来表示实体的中间和结束位置。</p>
<p>IO：只有I（Inside）和O（Outside）两个标记，没有明确的起始标记。</p>
<p>这些标注方法都是为了在序列标注任务中准确表示实体的位置和边界。具体选择哪种标注方法取决于任务的需求和数据集的特点。</p>
<p><a href="https://zhuanlan.zhihu.com/p/367995480"> 测试集、训练集、开发集的区别</a><br>
<a href="https://zhuanlan.zhihu.com/p/148813079">CRF条件随机场的原理、例子、公式推导和应用</a><br>
<a href="https://zhuanlan.zhihu.com/p/44042528">最通俗易懂的BiLSTM-CRF模型中的CRF层介绍</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[K-means]]></title>
        <id>https://jeromezjl.github.io/post/k-means/</id>
        <link href="https://jeromezjl.github.io/post/k-means/">
        </link>
        <updated>2023-05-10T13:27:56.000Z</updated>
        <content type="html"><![CDATA[<p>kelbow_visualizer</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【摄影】调色思路]]></title>
        <id>https://jeromezjl.github.io/post/she-ying-diao-se-si-lu/</id>
        <link href="https://jeromezjl.github.io/post/she-ying-diao-se-si-lu/">
        </link>
        <updated>2023-04-02T13:54:49.000Z</updated>
        <content type="html"><![CDATA[<p>降低纹理可以减少画面杂乱感，比如杂草背景<br>
背光人像可以通过提高清晰度提高人像亮度<br>
调节曝光要保证画面整体看起来和谐。比如白色色阶不能过于割裂</p>
<p>调色工具<br>
<a href="https://www.chinavid.com/color.html">高级在线配色器</a></p>
<p>色卡生成工具<br>
<a href="https://photokit.com/colors/palette-generator/?lang=zh">调色板生成器1</a><br>
<a href="https://colors.dopely.top/image-color-picker/">调色板生成器2</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[BPE]]></title>
        <id>https://jeromezjl.github.io/post/bpe/</id>
        <link href="https://jeromezjl.github.io/post/bpe/">
        </link>
        <updated>2023-03-30T06:22:31.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_43902773/article/details/115191790">基于BPE的汉语tokenization</a></p>
<h1 id="基于bpe的子词压缩">基于BPE的子词压缩</h1>
<p>对于英文语料来讲，特别是在预训练模型兴起之前，一种常见的分词方式是通过空格对英文语句直接进行分词。然而这种分词方式可能也会带来一些问题。</p>
<ol>
<li>英文单词由于时态、单复数、大小写等因素，可能具有多个单词变体，比如单词go具有这样的变体： going, gone, goes，单纯基于空格从语料中收集单词，可能会导致词表过大，进而导致模型学习过程中，需要设置较大的词向量矩阵，增加模型参数。</li>
<li>由于词表难以穷尽所有单词，以及网络中会出现一些新的词，导致某些词无法出现在词表中，即出现集外词（OOV）。<br>
BPE（Byte-Pair Encoding）是缓解这些问题的一种算法，其不再按照完整的单词进行分词，而是将单词划分成了子词（sub-word）的粒度。例如单词showed可以被划分为show和ed， 如此做法，可以有效缩减单词个数，同时通过拆解子词也能够缓解OOV问题。图1展示了一种BPE算法效果的示例，一方面通过右侧的子词组合可以表示左侧任意一个单词，另一方面通过子词的表示大大减小了原本词表的大小。<br>
<img src="https://jeromezjl.github.io/post-images/1680157576369.png" alt="" loading="lazy"><br>
图1 BPE算法示例</li>
</ol>
<h1 id="12-实现流程">1.2 实现流程</h1>
<p>如图2所示，使用BPE算法进行对文本进行分词，首先需要根据英文语料构建BPE的子词词表，根据此词表即可对给定的文本序列进行编码，即分词，获取分词后的文本序列。同时提供根据编码后的结果还原原始语句的方法。<br>
<img src="https://jeromezjl.github.io/post-images/1680157622297.png" alt="" loading="lazy"><br>
图2 BPE实现流程</p>
<h1 id="13-词表构建">1.3 词表构建</h1>
<p>词表构建是BPE算法的核心，首先需要准备一批语料，然后从语料中逐步统计词频，构建BPE子词词表。具体来讲，首先需要将训练数据中的每个单词切分成字符作为初始子词，并统计语料中的子词初始化子词词表。接下来，可以按照如下步骤逐步迭代：</p>
<ol>
<li>统计每一个连续子词对的出现频率，选择最高频子词对合并成新的子词，并将该子词对加入词表中；</li>
<li>根据最高频子词对，将语料中的这两个相邻子词进行合并；</li>
<li>如果组成最高频子词对的子词在原始语料中不再存在，则在词表中进行删除；</li>
<li>重复第1-3步直到达到设定的子词词表大小或迭代次数；<br>
下面通过一个例子说明如何构造子词词典，假设通过统计获得了如下预处理好的语料库，其中每个单词中的字符通过空格进行分割为子词，同时单词后使用</w>作为单词结尾符号：</li>
</ol>
<pre><code class="language-python">train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n i n g &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a n g u a g e &lt;/w&gt;': 3,'p r o c e s s i n g &lt;/w&gt;':7}
</code></pre>
<p>利用以上训练数据，初始化子词词表为：</p>
<pre><code class="language-python">bpe_vocab = {'a', 'e', 'p', '&lt;/w&gt;', 'g', 'o', 's', 'l', 'r', 'u', 'd', 'n', 'i', 't', 'c'}
</code></pre>
<p>接下来，便可以逐步统计最高频的相邻子词对，并对训练数据进行子词合并。</p>
<p>第1次迭代： 最高频连续子词对&quot;n&quot;和&quot;g&quot;出现了7+3+7=17次，合并成&quot;ng&quot;加入词表。&quot;n&quot;和&quot;g&quot;在语料库中依旧存在，因此不需要在词表中删除，语料库和词表在本次迭代之后的结果为：</p>
<pre><code class="language-python">train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n i ng &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3,'p r o c e s s i ng &lt;/w&gt;':7}
bpe_vocab = {'a', 'e', 'p', '&lt;/w&gt;', 'g', 'o', 's', 'l', 'r', 'u', 'd', 'n', 'i', 't', 'c', 'ng'}
</code></pre>
<p>第2次迭代： 最高频连续子词对&quot;i&quot;和&quot;ng&quot;出现了7+7=14次，合并成&quot;ing&quot;加入词表。子词&quot;i&quot;在语料库中不再存在，因此在词表中进行删除，语料库和词表在本次迭代之后的结果为：</p>
<pre><code class="language-python">train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n ing &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3,'p r o c e s s ing &lt;/w&gt;':7}
bpe_vocab = {'a', 'e', 'p', '&lt;/w&gt;', 'g', 'o', 's', 'l', 'r', 'u', 'd', 'n', 't', 'c', 'ng', 'ing'}
</code></pre>
<p>第3次迭代： 最高频连续子词对&quot;ing&quot;和&quot;</w>&quot;出现了7+7=14次，合并成&quot;ing</w>&quot;加入词表。&quot;ing&quot;在语料库中不再存在，因此在词表中进行删除，语料库和词表在本次迭代之后的结果为：</p>
<pre><code class="language-python">train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3,'p r o c e s s ing&lt;/w&gt;':7}
bpe_vocab = {'a', 'e', 'p', '&lt;/w&gt;', 'g', 'o', 's', 'l', 'r', 'u', 'd', 'n', 't', 'c', 'ng','ing&lt;/w&gt;'}
</code></pre>
<p>重复以上迭代过程，直到子词词表规模达到预先设定的大小或下一个最高频的子词对出现频率为1。</p>
<p>首先，定义函数get_subwords，用以统计子词以及对应的词频，并获取初始化后的子词词表bpe_vocab。</p>
<pre><code class="language-python">import re
import collections

def get_subwords(data):
    &quot;&quot;&quot;
    统计子词以及对应的词频
    &quot;&quot;&quot;
    subwords = collections.defaultdict(int)
    for word, freq in data.items():
        for subword in word.split():
            subwords[subword] += freq

    return subwords

train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n i n g &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a n g u a g e &lt;/w&gt;': 3,'p r o c e s s i n g &lt;/w&gt;':7}
subwords = get_subwords(train_data)
# 获取初始化的子词词表
bpe_vocab = set(subwords.keys())
print(&quot;词表：&quot;, bpe_vocab)
</code></pre>
<pre><code class="language-python">词表： {'d', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'i', 'g', 'c', 'r', 'l', 't', 'n', 'p', 'e'}
</code></pre>
<p>接下来，在构造词表过程中，需要统计相邻子词对的词频，以便获取最高频的词对，代码实现如下。</p>
<pre><code class="language-python">def get_pair_with_frequency(data):
    &quot;&quot;&quot;
    获取子词对以及子词集合
    &quot;&quot;&quot;
    pairs = collections.defaultdict(int)
    for word, freq in data.items():
        sub_words = word.split()
        for i in range(len(sub_words)-1):
            pair = (sub_words[i],sub_words[i+1])
            pairs[pair] += freq
    return pairs

pairs = get_pair_with_frequency(train_data)
print(&quot;子词词对：&quot;, pairs)
best_pair = max(pairs, key=pairs.get)
print(&quot;当前最高频的子词对: &quot;, best_pair)
</code></pre>
<pre><code class="language-python">子词词对： defaultdict(&lt;class 'int'&gt;, {('d', 'e'): 5, ('e', 'e'): 5, ('e', 'p'): 5, ('p', '&lt;/w&gt;'): 5, ('l', 'e'): 7, ('e', 'a'): 7, ('a', 'r'): 7, ('r', 'n'): 7, ('n', 'i'): 7, ('i', 'n'): 14, ('n', 'g'): 17, ('g', '&lt;/w&gt;'): 14, ('n', 'a'): 6, ('a', 't'): 6, ('t', 'u'): 6, ('u', 'r'): 6, ('r', 'a'): 6, ('a', 'l'): 6, ('l', '&lt;/w&gt;'): 6, ('l', 'a'): 3, ('a', 'n'): 3, ('g', 'u'): 3, ('u', 'a'): 3, ('a', 'g'): 3, ('g', 'e'): 3, ('e', '&lt;/w&gt;'): 3, ('p', 'r'): 7, ('r', 'o'): 7, ('o', 'c'): 7, ('c', 'e'): 7, ('e', 's'): 7, ('s', 's'): 7, ('s', 'i'): 7})
当前最高频的子词对:  ('n', 'g')
</code></pre>
<p>接下来，根据获取的最高频子词对，对训练语料中的相应子词进行合并，代码实现如下。</p>
<pre><code class="language-python">def merge_data_with_pair(pair, data):
    &quot;&quot;&quot;
    将语料中的最高频子词对进行合并
    输入：
        - pair: 最高频子词词对
        - data: 字典形式，统计好的输入语料
    &quot;&quot;&quot;
    result = {}
    bigram = re.escape(' '.join(pair))
    p = re.compile(r'(?&lt;!\S)' + bigram + r'(?!\S)')
    for word in data:
        merged_word = p.sub(''.join(pair), word)
        result[merged_word] = data[word]
    return result

train_data = merge_data_with_pair(best_pair, train_data)
print(&quot;语料库: &quot;, train_data)
</code></pre>
<pre><code class="language-python">语料库:  {'d e e p &lt;/w&gt;': 5, 'l e a r n i ng &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s i ng &lt;/w&gt;': 7}
</code></pre>
<p>最后，将最高频的子词对加入词表，对于不再存在于语料库中的子词在词表中进行删除。基于上述这流程，下面正式定义构建词表函数build_vocab，代码实现如下。</p>
<pre><code class="language-python">def build_vocab(train_data, num_merges):
    &quot;&quot;&quot;
    根据训练语料构建词表
    输入：
        - train_data: 字典形式，统计好的输入语料
        - num_merges: 迭代次数
    &quot;&quot;&quot;

    # 初始化词表
    subwords = get_subwords(train_data)
    bpe_vocab = set(subwords.keys())
    print(bpe_vocab, len(bpe_vocab))
    i = 1
    # 逐步生成词表
    for _ in range(num_merges):
        # 根据语料统计相邻子词对的词频
        pairs = get_pair_with_frequency(train_data)
        # 取频率最大的子词对, 如果pairs 为空或子词对的最大频次为1，则停止
        if not pairs:
            break
        best_pair = max(pairs, key=pairs.get)
        if pairs[best_pair] == 1:
            break
        # 合并语料
        train_data = merge_data_with_pair(best_pair, train_data)
        # 将子词加入词表中
        merged_word = &quot;&quot;.join(best_pair)
        bpe_vocab.add(merged_word)
        # 删除子词
        subwords = get_subwords(train_data)
        if best_pair[0] not in subwords:
            bpe_vocab.remove(best_pair[0])
        if best_pair[1] not in subwords:
            bpe_vocab.remove(best_pair[1])

        print(&quot;Iter - {}, 最高频子词对: {}&quot;.format(i, best_pair))
        print(&quot;训练数据: &quot;, train_data)
        print(&quot;词表: {}, {}\n&quot;.format(len(bpe_vocab), bpe_vocab))
        i += 1
    return bpe_vocab

num_merges = 14

train_data = {'d e e p &lt;/w&gt;': 5, 'l e a r n i n g &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a n g u a g e &lt;/w&gt;': 3,'p r o c e s s i n g &lt;/w&gt;':7}

bpe_vocab = build_vocab(train_data, num_merges)
print(&quot;词表: &quot;, bpe_vocab)
</code></pre>
<pre><code class="language-python">{'d', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'i', 'g', 'c', 'r', 'l', 't', 'n', 'p', 'e'} 15
Iter - 1, 最高频子词对: ('n', 'g')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'l e a r n i ng &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s i ng &lt;/w&gt;': 7}
词表: 16, {'d', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'i', 'g', 'c', 'r', 'ng', 'l', 't', 'n', 'p', 'e'}

Iter - 2, 最高频子词对: ('i', 'ng')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'l e a r n ing &lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing &lt;/w&gt;': 7}
词表: 16, {'d', 'ing', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'g', 'c', 'r', 'ng', 'l', 't', 'n', 'p', 'e'}

Iter - 3, 最高频子词对: ('ing', '&lt;/w&gt;')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'l e a r n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 16, {'d', 's', 'a', 'u', 'o', '&lt;/w&gt;', 'g', 'c', 'r', 'ng', 'l', 't', 'n', 'p', 'ing&lt;/w&gt;', 'e'}

Iter - 4, 最高频子词对: ('l', 'e')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'le a r n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 'le', 's', 'ng', 't', 'o'}

Iter - 5, 最高频子词对: ('le', 'a')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'lea r n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', '&lt;/w&gt;', 'g', 'p', 'e', 'lea', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't', 'o'}

Iter - 6, 最高频子词对: ('lea', 'r')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'lear n ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'lear', 'ng', 't', 'o'}

Iter - 7, 最高频子词对: ('lear', 'n')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learn ing&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', '&lt;/w&gt;', 'g', 'learn', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't', 'o'}

Iter - 8, 最高频子词对: ('learn', 'ing&lt;/w&gt;')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'p r o c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't', 'o'}

Iter - 9, 最高频子词对: ('p', 'r')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'pr o c e s s ing&lt;/w&gt;': 7}
词表: 18, {'a', 'u', 'c', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'pr', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't', 'o'}

Iter - 10, 最高频子词对: ('pr', 'o')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'pro c e s s ing&lt;/w&gt;': 7}
词表: 17, {'a', 'u', 'c', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'pro', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't'}

Iter - 11, 最高频子词对: ('pro', 'c')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'proc e s s ing&lt;/w&gt;': 7}
词表: 16, {'proc', 'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't'}

Iter - 12, 最高频子词对: ('proc', 'e')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'proce s s ing&lt;/w&gt;': 7}
词表: 16, {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', 'proce', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't'}

Iter - 13, 最高频子词对: ('proce', 's')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'proces s ing&lt;/w&gt;': 7}
词表: 16, {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'proces', 'r', 'ing&lt;/w&gt;', 'd', 's', 'ng', 't'}

Iter - 14, 最高频子词对: ('proces', 's')
训练数据:  {'d e e p &lt;/w&gt;': 5, 'learning&lt;/w&gt;': 7, 'n a t u r a l &lt;/w&gt;': 6, 'l a ng u a g e &lt;/w&gt;': 3, 'process ing&lt;/w&gt;': 7}
词表: 15, {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'process', 'ing&lt;/w&gt;', 'd', 'ng', 't'}

词表:  {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'process', 'ing&lt;/w&gt;', 'd', 'ng', 't'}
</code></pre>
<h1 id="14-语料编码">1.4 语料编码</h1>
<p>在获得子词词表之后，便可以根据该词表将文本序列进行编码，即分词。这里可以采用贪心的思想，根据子词词表中的子词长度对子词词表由大到小进行排序，然后对于一个待编码的单词，从前向后依次遍历词表中的子词，如果该子词在单词之后，则将该单词在子词位置进行切分，这样便可以获得最多三个单词子串：子词前的单词子串、子词串、子词后的单词子串，然后按照同样的思路继续遍历剩余的单词子串。如果在子词词表遍历完成之后，依然有一些单词子串没有被切分，则使用'<UNK>'进行替代。</p>
<p>下面来看一个例子，假设给定子词词表为：</p>
<pre><code class="language-python">[“ning&lt;/w&gt;”, “lear”, “deep&lt;/w&gt;”, “est&lt;/w&gt;”, “the&lt;/w&gt;”, “a&lt;/w&gt;”]
</code></pre>
<p>待分词的文本序列为:</p>
<pre><code class="language-python">[“the&lt;/w&gt;”, “deep&lt;/w&gt;”, “learning&lt;/w&gt;”]
</code></pre>
<p>则最后分词编码的结果为：</p>
<pre><code class="language-python">[“the&lt;/w&gt;”, “deep&lt;/w&gt;”, &quot;lear&quot;, “ning&lt;/w&gt;”]
</code></pre>
<p>接下来，先定义函数tokenize_word用于对单词进行编码。</p>
<pre><code class="language-python">import re

def tokenize_word(word, sorted_vocab, unknown_token='&lt;unk&gt;'):
    &quot;&quot;&quot;
    输入:
        - word: 待编码的单词
        - sorted_vocab: 排序后的子词词典
        - unknown_token: 不能被切分的子词替代符
    &quot;&quot;&quot;
    # 如果传入的词为空
    if word == &quot;&quot;:
        return []
    # 如果词表为空，则将输入的词替换为&lt;UNK&gt;
    if sorted_vocab == []:
        return [unknown_token] + len(string)

    word_tokens = []
    # 遍历词表拆分单词
    for i in range(len(sorted_vocab)):
        token = sorted_vocab[i]
        # 基于该token定义正则，同时将token里面包含句号的变成[.]
        token_reg = re.escape(token.replace('.', '[.]'))
        # 在当前word中进行遍历，找到匹配的token的起始和结束位置
        matched_positions = [(m.start(0), m.end(0)) for m in re.finditer(token_reg, word)]
        # 如果当前token没有匹配到相应串，则跳过
        if  len(matched_positions) == 0:
            continue
        
        # 获取匹配到的子串的起始位置
        end_positions = [matched_position[0] for matched_position in matched_positions]
        start_position = 0

        for end_position in end_positions:
            subword = word[start_position: end_position]
            word_tokens += tokenize_word(subword, sorted_vocab[i+1:], unknown_token)
            word_tokens += [token]
            start_position = end_position + len(token)
        # 匹配剩余的子串
        word_tokens += tokenize_word(word[start_position:], sorted_vocab[i+1:], unknown_token)
        break
    else:
        # 如果word没有被匹配，则映射为&lt;unk&gt;
        word_tokens = [unknown_token] * len(word)
    
    return word_tokens
</code></pre>
<p>定义函数tokenize用于对语句进行编码。</p>
<pre><code class="language-python">def tokenize(text, bpe_vocab):
    &quot;&quot;&quot;
    使用BPE对输入语句进行编码
    &quot;&quot;&quot;
    # 对子词词表按照子词长度进行排序
    sorted_vocab = sorted(bpe_vocab, key=lambda subword: len(subword), reverse=True)
    print(&quot;待编码语句: &quot;, text)
    tokens = []
    for word in text.split():
        word = word + &quot;&lt;/w&gt;&quot;
        word_tokens = tokenize_word(word, sorted_vocab, unknown_token='&lt;unk&gt;')
        tokens.extend(word_tokens)
    
    return tokens

text = &quot;natural language processing&quot;
tokens = tokenize(text, bpe_vocab)
print(&quot;词表: &quot;, bpe_vocab)
print(&quot;编码结果: &quot;, tokens)
</code></pre>
<pre><code class="language-python">待编码语句:  natural language processing
词表:  {'a', 'u', 'l', 'n', 'learning&lt;/w&gt;', '&lt;/w&gt;', 'g', 'p', 'e', 'r', 'process', 'ing&lt;/w&gt;', 'd', 'ng', 't'}
编码结果:  ['n', 'a', 't', 'u', 'r', 'a', 'l', '&lt;/w&gt;', 'l', 'a', 'ng', 'u', 'a', 'g', 'e', '&lt;/w&gt;', 'process', 'ing&lt;/w&gt;']
</code></pre>
<h1 id="15-语料解码">1.5 语料解码</h1>
<p>在将一串语句使用BPE进行编码后，如何还原成原来的语句呢。这种情况下，单词后设置的&lt;\w&gt;便起了作用。即可以一直合并分词后的子词，直到遇见&lt;\w&gt;便可以解码出一个完整单词。下面给出了一个例子。</p>
<p>假设使用BPE编码后的序列：</p>
<pre><code class="language-python">[“the&lt;/w&gt;”, “deep&lt;/w&gt;”, “lear”, “ning&lt;/w&gt;”]
</code></pre>
<p>则对应的解码结果为:</p>
<pre><code class="language-python">[&quot;the&quot;, &quot;deep&quot;,&quot;learning&quot;]
</code></pre>
<p>代码实现如下。</p>
<pre><code class="language-python">def restore(tokens):

    text = []
    word = []
    for token in tokens:
        if token[-4:] == &quot;&lt;/w&gt;&quot;:
            if token != &quot;&lt;/w&gt;&quot;:
                word.append(token[:-4])
            text.append(&quot;&quot;.join(word))
            word.clear()
        else:
            word.append(token)
    return text

tokens = [&quot;the&lt;/w&gt;&quot;, &quot;deep&lt;/w&gt;&quot;, &quot;lear&quot;, &quot;ning&lt;/w&gt;&quot;]
text = restore(tokens)
print(&quot;还原结果: &quot;, text)
</code></pre>
<pre><code class="language-python">还原结果:  ['the', 'deep', 'learning']
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[视频目标检测]]></title>
        <id>https://jeromezjl.github.io/post/shi-pin-mu-biao-jian-ce/</id>
        <link href="https://jeromezjl.github.io/post/shi-pin-mu-biao-jian-ce/">
        </link>
        <updated>2023-03-10T05:51:59.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_40557160/article/details/109536612">视频目标检测VID论文及代码（更新至2020.12）</a><br>
<a href="https://zhuanlan.zhihu.com/p/94986199">写给小白的YOLO介绍</a><br>
<a href="https://blog.csdn.net/breeze_blows/article/details/105323491">视频目标检测(video object detection)简单综述</a><br>
<a href="https://blog.csdn.net/weixin_43702653/article/details/123973629?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167842568816782427467521%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=167842568816782427467521&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123973629-null-null.142%5Ev73%5Einsert_down4,201%5Ev4%5Eadd_ask,239%5Ev2%5Einsert_chatgpt&amp;utm_term=R-CNN&amp;spm=1018.2226.3001.4187">R-CNN史上最全讲解</a><br>
<a href="https://blog.csdn.net/qq_40716944/article/details/114822515">YOLO系列详解：YOLOv1、YOLOv2、YOLOv3、YOLOv4、YOLOv5、YOLOv6、YOLOv7</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【Linux】内核模块开发]]></title>
        <id>https://jeromezjl.github.io/post/linux-nei-he-mo-kuai-kai-fa/</id>
        <link href="https://jeromezjl.github.io/post/linux-nei-he-mo-kuai-kai-fa/">
        </link>
        <updated>2023-03-09T01:59:01.000Z</updated>
        <content type="html"><![CDATA[<p>https://zhuanlan.zhihu.com/p/420194002</p>
<p>Linux 内核模块开发，首先需要下载和Linux系统内核相匹配的内核文件。<br>
<a href="https://mirror.bjtu.edu.cn/kernel/linux/kernel/">国内Linux内核下载镜像</a></p>
<p>Linux 内核文件编译（这步不需要，走弯路了）<br>
<a href="https://zhuanlan.zhihu.com/p/378149586">Linux内核编译很简单，6步编译一个自己的内核</a><br>
<a href="https://blog.csdn.net/hxxjxw/article/details/105899282">编译安装linux内核</a></p>
<p>这个博客讲vim和gcc编译c文件<br>
<a href="https://blog.csdn.net/m0_47668487/article/details/115289154">VMware下安装Ubuntu系统并编译运行C语言程序</a></p>
<p><a href="https://blog.csdn.net/qq_36417014/article/details/98239337">【linux环境下】【C语言编译】【使用makefile】【详细版】</a></p>
<p>在内核模块中使用printk()函数输出信息，而不是使用printf()等C语言标准库函数。</p>
<p>编写内核模块makefile和普通的不一样，需要按照一下格式：</p>
<p><strong>make 时报的错</strong><br>
makefile里要用tab，不能用空格<br>
一个函数在没有参数的情况下没有赋参数void</p>
<p>查看已经存在的mod：lsmod<br>
删除mod：rmmod modname<br>
将编译好的mod加载进去：sudo insmod hello.ko<br>
查看内核日志，最后为新模块产生的日志：dmesg<br>
看最近的内核日志：dmesg | tail<br>
实时监视内核日志的变化，并输出最新的日志信息：tail -f /var/log/kern.log<br>
删除make产生的所有文件：make clean</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[C++查缺补漏]]></title>
        <id>https://jeromezjl.github.io/post/ccha-que-bu-lou/</id>
        <link href="https://jeromezjl.github.io/post/ccha-que-bu-lou/">
        </link>
        <updated>2023-01-04T05:36:25.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/yourfriendyo/article/details/119544221">C语言详解：结构体</a><br>
<a href="https://blog.csdn.net/m0_52902391/article/details/120614881">模板类/模板函数 template 的用法(超详细)</a><br>
template：模板</p>
<h1 id="循环">循环</h1>
<p>while (cin &gt;&gt; x){}<br>
cin函数，输入NULL时返回0，输入其他值返回它的地址</p>
<h1 id="结构体">结构体</h1>
<p>typedef struct xxx {} yyy；yyy为结构体xxx的别名，是一种数据类型，需要实例化。<br>
<a href="https://blog.csdn.net/jacksls/article/details/108529761">定义结构体 typedef struct 的用法总结</a></p>
<p><strong>在结构体别名中定义结构体指针</strong></p>
<pre><code class="language-c">typedef struct DNode{
	ElemType data;
	DNode* prior, * next;
}DNode, * DLinkList;  // * DLinkList 就是指向DNode类型的指针，声明时用DNode和DLinkList都可以
</code></pre>
<h1 id="指针">指针</h1>
<p><a href="https://blog.csdn.net/weixin_39640298/article/details/84900326">C++指针详解</a><br>
&amp;：取地址<br>
*：取地址里面的值<br>
<a href="https://www.w3cschool.cn/cpp/cpp-passing-arrays-to-functions.html">向函数传递数组的写法</a><br>
用“-&gt;”的情况：<br>
A是一个类 class / struct<br>
p是一个指向A类型的指针，那么用p访问A中的成员变量和函数时，使用p-&gt;x，p-&gt;f(x)来访问。</p>
<p><strong>向函数传入变量的指针和引用的区别</strong><br>
传入指针时，函数参数中是对指针的定义 int* a，传入函数的是变量的地址，&amp;a；<br>
传入引用时，函数参数中是对原变量的引用 int &amp;a，传入函数的是原变量，a。<br>
总之，传入指针是 通过指针，对指针指向的内存地址进行操作；传入变量的引用是直接对原变量进行修改。二者效果一样，但是原理不一样。<br>
<code>指针</code></p>
<pre><code class="language-c">typedef struct SqList{
	int data[MaxSize];
	int length;
};

void InitList(SqList *list){
	cout&lt;&lt;&quot;type in the length of list:&quot;&lt;&lt;endl;
	cin&gt;&gt;list-&gt;length;
	cout&lt;&lt;&quot;type in the data:&quot;&lt;&lt;endl; 
	for(int i = 0; i&lt;list-&gt;length; i++)
		cin&gt;&gt;list-&gt;data[i];
}
int main(){
	SqList sqlist;
	InitList(&amp;sqlist);
}
</code></pre>
<p><code>引用</code></p>
<pre><code class="language-c">typedef struct SqList{
	int data[MaxSize];
	int length;
};

void InitList(SqList &amp;list){
	cout&lt;&lt;&quot;type in the length of list:&quot;&lt;&lt;endl;
	cin&gt;&gt;list.length;
	cout&lt;&lt;&quot;type in the data:&quot;&lt;&lt;endl; 
	for(int i = 0; i&lt;list.length; i++)
		cin&gt;&gt;list.data[i];
}
int main(){
	SqList sqlist;
	InitList(sqlist);
}
</code></pre>
<p>上面两段代码，如果用指针访问结构体，则需要用-&gt;访问结构体成员；如果用原结构体，则用 . 由此可见，指针和引用的差别。</p>
<p><strong>向函数中传入指针类型的数据</strong><br>
和上面的不同，上面传入的是变量的地址，在函数列表中被定义，成为指针。而本问题描述的是直接将指针类型的数据传入函数。</p>
<pre><code class="language-c">#include&lt;bits/stdc++.h&gt;

typedef struct DNode{
	ElemType data;
	DNode* prior, * next;
}DNode, * DLinkList;  //DLinkList为指向结构体的指针类型
 
//初始化双链表
bool InitDLinkList(DLinkList L) {  //此处和变量的指针一样，也可该写作 DNode* L
	L = (DLinkList)malloc(sizeof(DLinkList));
	if (L == NULL) {
		return false;          
	}
	L-&gt;prior = NULL;
	L-&gt;next = NULL;
	return true;
}

int main() {
	DLinkList L;  //定义指针类型数据L
	InitDLinkList(L);  //由于指针的值即为变量的地址，所以和&amp;+变量名一样，都是将地址传入函数。
	return 0;
}
</code></pre>
<p><strong>swap的例子</strong><br>
<code>指针</code></p>
<pre><code class="language-c"># include&lt;iostream&gt;
using namespace std;

void MySwap(int* a, int* b){  //在列表中定义两个指针a，b，分别指向传入变量a，b的地址 
	int t = 0;  
	t = *a;  //交换值 
	*a = *b;
	*b = t;
	
	//错误的思路：用指针交换来交换 
	int *t = NULL;  //定义中间指针t，用于指针之间的赋值 
	t = a;
	a = b;
	b = t;
	//以上操作只是让函数内的指针ab分别指向了ba，但没有对对应地址内的值进行任何改变 
}

int main(){
	int a = 1,b = 2;
	MySwap(&amp;a, &amp;b);  //传入变量ab的地址 
	cout&lt;&lt;a&lt;&lt;&quot; &quot;&lt;&lt;b;
}
//向函数传入变量的地址。把函数声明和传入函数的形式整体来看，就是 int* a = &amp;a; 
//也就是指针定义操作 
</code></pre>
<p><code>引用</code></p>
<pre><code class="language-c"># include&lt;iostream&gt;
using namespace std;

void MySwap(int　&amp;a, int　&amp;b){  //在列表中定义两个地址引用
	int t = 0;  
	t = a; //直接修改原变量
	a = b;
	b = t;
}

int main(){
	int a = 1,b = 2;
	MySwap(a, b);  //直接传入原始变量ab
	cout&lt;&lt;a&lt;&lt;&quot; &quot;&lt;&lt;b;
}
</code></pre>
<h1 id="类和对象">类和对象</h1>
<p>类中不带返回类型的函数为构造函数。造函数可用于为某些成员变量设置初始值。<br>
<a href="https://blog.csdn.net/qq_42565910/article/details/90346236">c语言malloc函数的用法和意义</a></p>
<p><strong>C++三种常见的实例化方法</strong></p>
<ol>
<li>静态实例化：在程序的全局或静态作用域中定义并初始化一个对象，该对象在程序整个生命周期内只存在一个实例。</li>
<li>堆实例化：使用 new 运算符在动态存储区域中分配内存并实例化一个对象。这样创建的对象在程序运行期间一直存在，直到使用 delete 运算符显式释放其内存。</li>
<li>栈实例化：在函数或代码块的作用域中定义并实例化一个对象，该对象的生命周期与所在的函数或代码块相同。对象在离开该作用域时自动销毁。</li>
</ol>
<p><strong>静态实例化的例子</strong></p>
<pre><code class="language-c++">class MyClass {
public:
    MyClass() : m_x(0) {}
    void setX(int x) { m_x = x; }
    int getX() const { return m_x; }
private:
    int m_x;
};

MyClass globalObject;  // 全局实例

int main() {
    static MyClass staticObject;  // 静态实例
    globalObject.setX(5);
    staticObject.setX(10);
    int globalX = globalObject.getX(); // globalX = 5
    int staticX = staticObject.getX(); // staticX = 10
    // ...
    return 0;
}
</code></pre>
<p>上面的例子中，通过调用 setX 和 getX 来对全局对象 globalObject 和静态对象 staticObject 的成员变量进行访问。</p>
<p><strong>堆实例化的例子</strong></p>
<pre><code class="language-c++">class MyClass {
public:
    MyClass() : m_x(0) {}
    void setX(int x) { m_x = x; }
    int getX() const { return m_x; }
private:
    int m_x;
};

int main() {
    MyClass* heapObject = new MyClass;  // 堆实例
    heapObject-&gt;setX(5);
    int heapX = heapObject-&gt;getX(); // heapX = 5
    // ...
    delete heapObject;
    return 0;
}
</code></pre>
<p>上面的例子中，通过调用 setX 和 getX 来对堆对象 heapObject 的成员变量进行访问。</p>
<p><strong>栈实例化的例子</strong></p>
<pre><code class="language-c++">class MyClass {
public:
    MyClass() : m_x(0) {}
    void setX(int x) { m_x = x; }
    int getX() const { return m_x; }
private:
    int m_x;
};

void someFunction() {
    MyClass stackObject;  // 栈实例
    stackObject.setX(5);
    int stackX = stackObject.getX(); // stackX = 5
    // ...
}

int main() {
    someFunction();
    return 0;
}
</code></pre>
<p>上面的例子中，通过调用 setX 和 getX 来对栈对象 stackObject 的成员变量进行访问。</p>
<p><strong>函数模板</strong><br>
若想向函数传入不同类型的数据，则还需要另外定义不同的函数。为解决该问题，引入函数模板template。</p>
<pre><code class="language-c">#include &lt;iostream&gt;
using namespace std;

template&lt;typename T&gt;  //定义模板数据类型 T
T add(T&amp; a, T&amp; b){  //把T当作一种数据类型来用
	return a+b;
}

int main()
{
	float a = 10.3, b = 20.5;  //如果是int，则直接传入函数即可
	cout&lt;&lt;add(a, b);
	return 0;
}
</code></pre>
<p>上例中，可以直接传入int/float等类型，而不用重新定义函数。</p>
<p><strong>类模板</strong><br>
参考如下构建栈的写法，照着写就行，功能也是可以随便定义函数的数据类型</p>
<pre><code class="language-c"># include&lt;iostream&gt;
using namespace std;

const int StackSize = 1024;			//定义栈的最大长度
template&lt;class T&gt;
class SeqStack {					//定义顺序栈的模板类
	public:
		SeqStack() { top = -1; }	//构造函数，初始化空栈
		void Push(T x);				//入栈操作
		T Pop();					//出栈操作
		T GetTop();					//查找栈顶元素
		bool Empty();				//判别栈是否为空
	private:
		T data[StackSize];			//定义数组
		int top;					//栈顶指针
};


template&lt;class T&gt;
void SeqStack&lt;T&gt;::Push(T x) {
	if (top &gt;= StackSize - 1) throw &quot;上溢&quot;;
	data[++top] = x;
}

template&lt;class T&gt;
T SeqStack&lt;T&gt;::Pop() {
	if (Empty()) throw &quot;下溢&quot;;
	return data[top--];
}

template&lt;class T&gt;
T SeqStack&lt;T&gt;::GetTop() {
	if (Empty()) throw &quot;下溢&quot;;
	return data[top];
}

template&lt;class T&gt;
bool SeqStack&lt;T&gt;::Empty() {
	if(top == -1) return true;
	else return false;
}

int main() {
	SeqStack&lt;int&gt; stack;  //声明的时候要加上数据类型
	stack.Push(1);
	stack.Push(2);
	stack.Push(3);
	cout &lt;&lt; stack.GetTop();
	cout&lt;&lt;endl;
	
	cout &lt;&lt; stack.Pop();
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAN网络]]></title>
        <id>https://jeromezjl.github.io/post/gan-wang-luo/</id>
        <link href="https://jeromezjl.github.io/post/gan-wang-luo/">
        </link>
        <updated>2022-12-26T11:37:25.000Z</updated>
        <content type="html"><![CDATA[<h1 id="图像预处理">图像预处理</h1>
<p>对文件夹下批量图片进行rename</p>
<pre><code>import os

# 图片存放的路径
path = r&quot;C:\Users\ZJL\Desktop\1&quot;

# 遍历更改文件名
num = 1
for file in os.listdir(path):
    os.rename(os.path.join(path,file),os.path.join(path,str(num))+&quot;.jpg&quot;)
    num = num + 1
</code></pre>
<p>本次项目只有八张图片，我们需要进行数据增强，获取更大的数据集。</p>
<p>首先，要对图像进行<strong>分辨率的统一</strong>。分辨率，即为图像中像素点的个数，例如，一个分辨率为 1920x1080 的图像，表示它在水平方向上有 1920 个像素，在垂直方向上有 1080 个像素。</p>
<p>问：为什么相同分辨率，相同文件类型，但是图片的文件大小不一样？<br>
答：<br>
图像内容的复杂程度：相同分辨率的图像，如果其内容越复杂，文件大小就可能越大。因为图像的复杂程度与其所包含的信息量有关，而信息量越大，文件大小也就越大。</p>
<p>像素的位深度：像素的位深度指的是每个像素能够表示的颜色的数量。例如，8 位深度的像素可以表示 256 种颜色，而 16 位深度的像素可以表示 65,536 种颜色。相同分辨率的图像，如果其像素的位深度不同，文件大小也可能会不同。</p>
<p>元数据的不同：图像文件中可能包含一些元数据，例如创建时间、修改时间、拍摄设备等信息，这些元数据的不同也可能会导致文件大小的差异。</p>
<p>在神经网络中，我们通常需要将输入图像的尺寸规范化为相同的分辨率。</p>
<p>然后我们进行数据增强</p>
<p>训练循环顺序：<br>
步骤1<br>
生成器不动，生成器产生一批假图片，再拿取一批真实图片，喂给判别器，训练判别器。<br>
我们希望判别器对假图片打上标签0，对真图片打上标签1<br>
步骤2<br>
判别器不动，训练生成器</p>
<p><a href="https://blog.csdn.net/weixin_44887621/article/details/120535309">pytorch保存图片 save_image ，读取图片</a></p>
<p>训练GAN网络训练多少次比较合适？<br>
最好使用一种称为 &quot;early stopping&quot; 的方法，即在模型在验证集上的表现开始下降时停止训练。这样可以避免模型出现过拟合的情况。</p>
<p>另外，也可以使用 &quot;learning rate decay&quot; 的方法来防止模型出现过拟合的情况。这种方法的原理是，在训练过程中，会逐渐降低学习率，以便模型能够更加稳定地收敛到最优解。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数据归一化处理]]></title>
        <id>https://jeromezjl.github.io/post/shu-ju-gui-yi-hua-chu-li/</id>
        <link href="https://jeromezjl.github.io/post/shu-ju-gui-yi-hua-chu-li/">
        </link>
        <updated>2022-12-25T11:59:16.000Z</updated>
        <content type="html"><![CDATA[<p>数据归一化是一种常用的预处理技术，它的目的是将不同范围的数据转换为相同范围的数据，这样可以使不同的数据具有相似的分布和取值范围。</p>
<p>常见的数据归一化方法有以下几种：</p>
<p><strong>最值归一化（Min-Max Normalization）</strong><br>
最值归一化是将数据映射到[0,1]范围内，公式如下：</p>
<p>X_normalized = (X - Xmin) / (Xmax - Xmin)</p>
<p>其中，Xmin和Xmax分别是数据集中的最小值和最大值。</p>
<p><strong>均值方差归一化（Standardization）</strong><br>
均值方差归一化是将数据转换为均值为0，方差为1的数据，公式如下：</p>
<p>X_normalized = (X - Xmean) / Xstd</p>
<p>其中，Xmean和Xstd分别是数据集的均值和标准差。</p>
<p><strong>小数定标归一化</strong><br>
小数定标归一化是将数据的小数点移动到某一位置，使得数据范围在一定程度上缩小。例如，将数据的小数点向左移动2位，可以将数据的范围缩小100倍。</p>
<p><strong>对数归一化</strong><br>
对数归一化是将数据取对数后进行归一化处理。这种方法通常用于处理数据的取值范围差异很大的情况。</p>
<p>数据归一化的目的是使得数据的分布更加规律<br>
归一化处理可以使不同的数据具有相似的分布和取值范围，这在许多机器学习算法中是很有用的。例如，在使用梯度下降算法进行模型训练时，如果数据的范围差异很大，模型可能会在局部最小值附近来回震荡，导致收敛速度减慢。归一化处理可以使梯度下降算法更快地收敛，并且可以使模型的泛化能力更强。</p>
<p>但是，也要注意，如果数据已经具有相似的分布和取值范围，则不需要进行归一化处理。另外，在使用归一化处理后的数据进行模型训练后，在使用模型进行预测时，还需要将输入数据进行相应的反归一化处理，才能得到正确的预测结果。</p>
<p><strong>使用pytorch进行归一化操作</strong></p>
<pre><code class="language-python">normalize = transforms.Normalize((mean,), (std,))
</code></pre>
<p>其中 mean 为均值，std为方差，想进行归一化操作需要先计算出数据的均值和方差。</p>
<p>例如对MNIST数据集的处理：</p>
<pre><code class="language-python"># 定义图像处理方法
tranform = transforms.Compose([
    transforms.ToTensor(),  # 将图片转换成Tensor
    transforms.Normalize((0.1307,), (0.3081,))  # 进行数据归一化处理
])
</code></pre>
<p>其中 0.1307 和 0.3081 分别是MNIST的均值和方差，可以自己计算，也可以网上查<br>
等同于 X_normalized = (X - 0.1307) / 0.3081，转化为均值为0，方差为1的数据。</p>
]]></content>
    </entry>
</feed>